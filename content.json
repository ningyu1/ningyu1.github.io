[{"title":"解决安装Homebrew过程遇到的问题","date":"2021-01-18T06:07:26.000Z","path":"20210118/homebrew-install.html","text":"本篇主要讲解在国内安装Homebrew遇到的各种错误如何解决，让你可以轻松安装Homebrew，用mac的同学应该对Homebrew并不陌生，这里简单介绍一下Homebrew Homebrew简介引用 官方 的一句话：Homebrew是Mac OS 不可或缺的套件管理器。 Homebrew是一款Mac OS平台下的软件包管理工具，拥有安装、卸载、更新、查看、搜索等很多实用的功能。简单的一条指令，就可以实现包管理，而不用你关心各种依赖和文件路径的情况，十分方便快捷。 所以它是Mac必备神器Homebrew。 安装时遇到的错误一安装的命令很简单如下script/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" 当你在国内运行上面命令时会遇到下面的错误 scriptcurl: (7) Failed to connect to raw.githubusercontent.com port 443: Connection refused 这是因为被墙了，如果你是科学上网的话，就使用你上网的神器来代理，这块我想说的就是使用代理收费的肯定比免费的要好一些，如果可以的话花钱买一个，毕竟天天都要使用。 那么如何代理？使用下面命令 假设我的代理http端口是：1087，socket是：869 scriptexport https_proxy=http://127.0.0.1:1087 http_proxy=http://127.0.0.1:1087 all_proxy=socks5://127.0.0.1:869 ps. 将端口替换成你自己的代理端口，输入上面的命令代理只会在本次打开的terminal生效。 设置完代理之后再运行安装命令就不会看到无法连接raw.githubusercontent.com，紧接着提示需要你输入电脑密码，输入密码后它会提示你如下信息： script==&gt; This script will install:/usr/local/bin/brew/usr/local/share/doc/homebrew/usr/local/share/man/man1/brew.1/usr/local/share/zsh/site-functions/_brew/usr/local/etc/bash_completion.d/brew/usr/local/HomebrewPress RETURN to continue or any other key to abort 输入回车直接安装即可。 安装时遇到的错误二这里需要注意一个问题，它会去github上下载Homebrew代码进行安装。代码现在完后安装他会卡在某一个地方，比如说我这里卡在 script==&gt; /usr/bin/sudo /usr/sbin/chown jiuye:admin /usr/local/Homebrew==&gt; Downloading and installing Homebrew...HEAD is now at 48e44870e Merge pull request #10334 from SeekingMeaning/rubocop-spec-descriptions 长时间卡在这里不动，我直接Control + C退出，因为源码已经下载安装完成，其余的不知道为啥卡在这里，但是它已经安装成功了。 退出后运行brew -v测试一下是否可用，如果可以使用就证明安装成功。 使用brew安装工具包遇到的错误三比如说我们安装wget的时候会遇到如下问题，它会长时间卡如下地方 scriptUpdating Homebrew... 如果长时间卡在升级homebrew的话，我们可以尝试Control + C退出homebrew升级，这个时候它会跳过升级直接安装我们需要的包直到安装结束，如下所示： scriptMacBook-Pro:~ jiuye$ brew install wget==&gt; Downloading https://homebrew.bintray.com/bottles-portable-ruby/portable-ruby-2.6.3_2.yosemite.bottle.tar.gz######################################################################## 100.0%==&gt; Pouring portable-ruby-2.6.3_2.yosemite.bottle.tar.gzUpdating Homebrew...^C==&gt; Downloading https://homebrew.bintray.com/bottles/gettext-0.20.2_1.mojave.bot==&gt; Downloading from https://d29vzk4ow07wi7.cloudfront.net/52067198cab528f05fdc0######################################################################## 100.0%==&gt; Downloading https://homebrew.bintray.com/bottles/libunistring-0.9.10.mojave.==&gt; Downloading from https://d29vzk4ow07wi7.cloudfront.net/1d0c8e266acddcebeef3d######################################################################## 100.0% 到目前为止我们就成功的安装和测试了Homebrew，本次主要收录我在使用过程中遇到的问题，如果后续安装其他包遇到其他问题的话，我也会持续的更新它收录在一起。 特殊说明到最后要说明一点，Homebrew在安装软件包的时候，它会将软件包安装到独立目录，并将其文件软链接至 /usr/local ，通过ls -l查看 scriptls -l /usr/local/bin/lrwxr-xr-x 1 xxx xxx 32 1 18 13:33 wget -&gt; ../Cellar/wget/1.20.3_2/bin/wget-rwxr-xr-x 1 xxx xxx 123 3 7 2019 wish-rwxr-xr-x 1 xxx xxx 123 3 7 2019 wish8.6lrwxr-xr-x 1 xxx xxx 39 1 18 13:33 xgettext -&gt; ../Cellar/gettext/0.20.2_1/bin/xgettext","tags":[{"name":"Homebrew","slug":"Homebrew","permalink":"https://ningyu1.github.io/tags/Homebrew/"},{"name":"trouble shooting","slug":"trouble-shooting","permalink":"https://ningyu1.github.io/tags/trouble-shooting/"}]},{"title":"讲一讲加密数据如何进行模糊查询","date":"2020-12-30T08:28:10.000Z","path":"20201230/encrypted-data-fuzzy-query.html","text":"在上一篇讲一讲数据安全，如何有效预防脱库 中我们提到了加密后的数据对模糊查询不是很友好，本篇就针对加密数据模糊查询这个问题来展开讲一讲实现的思路。 为了数据安全我们在开发过程中经常会对重要的数据进行加密存储，常见的有：密码、手机号、电话号码、详细地址、银行卡号、信用卡验证码等信息，这些信息对加解密的要求也不一样，比如说密码我们需要加密存储，一般使用的都是不可逆的慢hash算法，慢hash算法可以避免暴力破解（典型的用时间换安全性），在检索时我们既不需要解密也不需要模糊查找，直接使用密文完全匹配，但是手机号就不能这样做，因为手机号我们要查看原信息，并且对手机号还需要支持模糊查找，因此我们今天就针对可逆加解密的数据支持模糊查询来看看有哪些实现方式。 在网上随便搜索了一下，关于《加密后的模糊查询》 的帖子很多，顺便整理了一下实现的方法，不得不说很多都是不靠谱的做法，甚至有一些沙雕做法，接下来我们就对这些做法来讲讲实现思路和优劣性。 如何对加密后的数据进行模糊查询我整理了一下对加密的数据模糊查询大致分为三类做法，如下所示： 沙雕做法（不动脑思考直男的思路，只管实现功能从不深入思考问题） 常规做法（思考了查询性能问题，也会使用一些存储空间换性能等做法） 超神做法（比较高端的做法从算法层面上思考） 我们就对这三种实现方法一一来讲讲实现思路和优劣性，首先我们先看沙雕做法。 沙雕做法 将所有数据加载到内存中进行解密，解密后通过程序算法来模糊匹配 将密文数据映射一份明文映射表，俗称tag表，然后模糊查询tag来关联密文数据 沙雕一我们先来看看第一个做法，将所有数据加载到内存中进行解密，这个如果数据量小的话可以使用这个方式来做，这样做既简单又实惠，如果数据量大的话那就是灾难，我们来大致算一下。 一个英文字母(不分大小写)占一个字节的空间，一个中文汉字占两个字节的空间，用DES来举例，13800138000加密后的串HE9T75xNx6c5yLmS5l4r6Q==占24个字节。 条数 Bytes MB 100w 2400万 22.89 1000w 2.4亿 228.89 1亿 24亿 2288.89 轻则上百兆，重则上千兆，这样分分钟给应用程序整成Out of memory，这样做如果数据少只有几百、几千、几万条时是完全可以这样做的，但是数据量大就强烈不建议了。 沙雕二我们再来看第二个做法，将密文数据映射一份明文映射表，然后模糊查询映射表来关联密文数据，what？？？！！！那我们为什么要对数据加密呢，直接不加密不是更好么！ 我们既然对数据加密肯定是有安全诉求才会这样做，增加一个明文的映射表就违背了安全诉求，这样做既不安全也不方便完全是脱裤子放x，多此一举，强且不推荐。 常规做法我们接下来看看常规的做法，也是最广泛使用的方法，此类方法及满足的数据安全性，又对查询友好。 在数据库实现加密算法函数，在模糊查询的时候使用decode(key) like &#39;%partial% 对密文数据进行分词组合，将分词组合的结果集分别进行加密，然后存储到扩展列，查询时通过key like &#39;%partial%&#39; 常规一在数据库中实现与程序一致的加解密算法，修改模糊查询条件，使用数据库加解密函数先解密再模糊查找，这样做的优点是实现成本低，开发使用成本低，只需要将以往的模糊查找稍微修改一下就可以实现，但是缺点也很明显，这样做无法利用数据库的索引来优化查询，甚至有一些数据库可能无法保证与程序实现一致的加解密算法，但是对于常规的加解密算法都可以保证与应用程序一致。 如果对查询性能要求不是特别高、对数据安全性要求一般，可以使用常见的加解密算法比如说AES、DES之类的也是一个不错的选择。 如果公司有自己的算法实现，并且没有提供多端的算法实现，要么找个算法好的人去研究吃透补全多端实现，要么放弃使用这个办法。 常规二对密文数据进行分词组合，将分词组合的结果集分别进行加密，然后存储到扩展列，查询时通过key like &#39;%partial%&#39;，这是一个比较划算的实现方法，我们先来分析一下它的实现思路。 先对字符进行固定长度的分组，将一个字段拆分为多个，比如说根据4位英文字符（半角），2个中文字符（全角）为一个检索条件，举个例子： ningyu1使用4个字符为一组的加密方式，第一组ning ，第二组ingy ，第三组ngyu ，第四组gyu1 … 依次类推。 如果需要检索所有包含检索条件4个字符的数据比如：ingy ，加密字符后通过 key like “%partial%” 查库。 我们都知道加密后长度会增长，增长的这部分长度存储就是我们要花费的额外成本，典型的使用成本来换取速度，密文增长的幅度随着算法不同而不同以DES举例，13800138000加密前占11个字节，加密后的串HE9T75xNx6c5yLmS5l4r6Q==占24个字节，增长是2.18倍，所以一个优秀的算法是多么的重要，能为公司节省不少成本，但是话又说回来算法工程师的工资也不低，所以我也不知道是节省成本还是增加成本，哈哈哈…你们自己算吧。 回到主题，这个方法虽然可以实现加密数据的模糊查询，但是对模糊查询的字符长度是有要求的，以我上面举的例子模糊查询字符原文长度必须大于等于4个英文/数字，或者2个汉字，再短的长度不建议支持，因为分词组合会增多从而导致存储的成本增加，反而安全性降低。 大家是否都对接过 淘宝、拼多多、JD他们的api，他们对平台订单数据中的用户敏感数据就是加密的同时支持模糊查询，使用就是这个方法，下面我整理了几家电商平台的密文字段检索方案的说明，感兴趣的可以查看下面链接。 淘宝密文字段检索方案阿里巴巴文字段检索方案拼多多密文字段检索方案京东密文字段检索方案 ps. 基本上都是一样的，果然都是互相抄袭，连加密后的数据格式都一致。 这个方法优点就是实现起来不算复杂，使用起来也较为简单，算是一个折中的做法，因为会有扩展字段存储成本会有升高，但是可利用数据库索引优化查询速度，推荐使用这个方法。 超神做法我们接下来看看优秀的做法，此类做法难度较高，都是从算法层面来考虑，有些甚至会设计一个新算法，虽然已有一些现成的算法参考，但是大多都是半成品无法拿来直接使用，所以还是要有人去深入研究和整合到自己的应用中去。 从算法层面思考，甚至会设计一个新算法来支持模糊查找 这个层面大多是专业算法工程师的研究领域，想要设计一个有序的、非不可逆的、密文长度不能增长过快的算法不是一件简单的事情，大致的思路是这样的，使用译码的方式进行加解密，保留密文和原文一样的顺序，从而支持密文模糊匹配，说的比较笼统因为我也不是这方面的专家没有更深一步的研究过，所以我从网上找了一些资料可以参考一下。 数据库中字符数据的模糊匹配加密方法 这里提到的Hill密码处理和模糊匹配加密方法FMES可以重点看看. 一种基于BloomFilter的改进型加密文本模糊搜索机制研究 支持快速查询的数据库如何加密 基于Lucene的云端搜索与密文基础上的模糊查询 基于Lucene的思路就跟我们上面介绍的常规做法二类似，对字符进行等长度分词，将分词后的结果集加密后存储，只不过存储的db不一样，一个是关系型数据库，一个是es搜索引擎。 云存储中一种支持可验证的模糊查询加密方案 总结我们到这里对加密数据的检索方案全部介绍完了，我们首先提到的是网上搜索随处可见的沙雕做法，在这里也讲了不推荐使用这些沙雕做法，尽量使用常规做法，如果公司有专业算法方向人才的话不妨可以考虑基于算法层面的超神做法。 总的来说从投入、产出比、及实现、使用成本来算的话常规做法二是非常推荐的。 最后送上那句老话，Keep Real，Love and peace！","tags":[{"name":"encrypt","slug":"encrypt","permalink":"https://ningyu1.github.io/tags/encrypt/"},{"name":"security","slug":"security","permalink":"https://ningyu1.github.io/tags/security/"}]},{"title":"讲一讲数据安全，如何有效预防脱库","date":"2020-12-29T10:49:30.000Z","path":"20201229/datasource-security.html","text":"今天讲一讲数据的安全问题，我们本篇不从DBA、网络架构层面来讲述数据安全，这部分有很专业的架构和云上产品来解决，本篇重点从开发人员角度讲述如何避免数据安全的漏洞。 我相信大部分人都看到过这样的新闻，某某论坛泄漏了用户密码，某某物流公司泄漏了用户的手机号等等，我一直坚信大部分数据泄漏都是内部管理出现了问题，大部分都是内部团队有意或无意泄漏了数据，如果要从外界通过漏洞攻克不是没有可能但是成本是巨大的，所以人为的泄漏往往是需要更加关注的问题，那作为软件生产的主力军（程序员）如何来避免挖坑？那我们接下来就主要讲讲从开发角度如何避免数据泄漏的可能性。 从网上找了一些 数据安全治理 的相关资料，有兴趣可以参考一下。 我们从程序员角度来讲讲如何有效的预防数据安全问题。 数据的访问控制我们先来看看哪些是经常访问数据库的用户？ 软件程序（应用程序、数据库中间件） 人员：运维、开发、测试、产品、等 那接下来我们就来看看从这几点如何来控制数据库的访问。 软件程序层面这里说的软件程序包含：应用程序、数据库中间件等，作为数据库的第一用户我们如何有效的规避数据安全的问题呢？ 我们先来说说现在的软件开发用到的一些框架，无论是java、go、python或其他，已经有很丰富的orm和datasource框架或工具，我下面罗列一些java中常用jdbc连接池和orm框架以及数据库中间件 名称 说明 是否有加解密策略 druid 阿里巴巴开源的数据库连接吃 有 dbcp Apache的开源数据库连接池 无 c3p0 一个开源的JDBC连接池 无 atomikos 一款分布式事务框架 无 mybatis 一款开源orm框架 无 hibernate 一款开源orm框架 无 mycat 开源分布式数据库中间件 无 shardingsphere Apache的开源分布式数据库中间件 有 cobar 阿里巴巴开源分片数据库和表的代理 有 我相信很多程序的数据库连接与密码都是通过配置文件来保存的，假如应用服务器被黑客利用软件漏洞拿下，我相信通过部署的软件可以翻出数据库连接的配置，那么针对这一点我们如何有效的避免呢？ 数据库连接密码加密一般我们为了做数据库高可用都会给数据库集群中间做一层代理，通过域名的方式来暴漏连接，这样做的好处就是数据库failover的时候应用程序可以不需要重启，只用重新创建连接即可。因此这层代理可以有效的防止数据库真实部署的机器被暴漏出去，起到了一定的安全作用。 虽然连接层面有一层代理来杜绝真实服务器被暴漏，但是我们在通过jdbc连接的时候往往是有密码访问的，我相信很多数据库的密码是明文的存储在配置文件中，虽然现在都用配置中心（configcenter）来统一管理应用的配置，如果使用明文来保存密码始终是无法规避泄漏的风险，因为应用程序始终要进行连接，在连接的时候要读取配置，不管配置是从云端同步下来还是从本地读取，只要是明文存储密码的就会存在安全问题。 其实大多的数据库连接池都有对数据库访问密码加解密的功能，因此我们可以通过把数据库访问的密码进行加密来解决安全问题。 下来我使用druid举个例子，具体的看看如何使用，也可以查看druid官方 示例 通过使用ConfigFilter为数据库密码提供加密功能 &lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\" destroy-method=\"close\"&gt; ................. &lt;!-- 如果fitlers走的配置中心，请去配置中心修改 --&gt; &lt;property name=\"filters\" value=\"$&#123;filters&#125;\" /&gt; &lt;!-- 如果没有配置中心请直接修改 --&gt; &lt;property name=\"filters\" value=\"stat,config\" /&gt; &lt;!-- 以上两种filters配置2选一 --&gt; &lt;property name=\"connectionProperties\" value=\"config.decrypt=true;config.decrypt.key=$&#123;publickey&#125;\" /&gt; .................&lt;/bean&gt; filters=stat改为filters=stat,config jdbc.xxxx.password=123456改为jdbc.xxxx.password=加密后的值 增加publickey=公钥 ps. 如果使用的是配置中心那么创建对应的配置项即可。 非对称秘钥对的生成方式有很多种，这里我给个在线生成的链接 加密后的密文是一段比较长的字符，例如下面这段示例 jdbc.password=p9i+fChqlaYnfhI+NoJqmrGwTyWwlFZ1W7Vi7i2MGZ8agFkGxGr/kWU//yDvPyXZ6YwJwnMKQ4zXpTZnfxWaRjfqWIRG+JzxSdSYEMp/bRCiIvzF6y8FdVCqN/0m0eQeZFvMCdIf4wqhKF0QRCEOTysZ3oGg7t5o35CIMpV1A5Y= 其他的jdbc连接池也都有类似的功能，但是不排除有一些没有这个功能的就需要我们自己动手开发来增强这部分功能。 首先我们需要了解数据库连接加解密的思路，只要有思路实现都是很简单的，其实数据库连接加解密思路很简单，在真正创建数据库连接的时候读取加密的密码进行解密后再进行数据库连接，那接下来我们给dbcp扩展这个功能。 import java.sql.SQLFeatureNotSupportedException;import java.util.Properties;import java.util.logging.Logger;import org.apache.commons.dbcp.BasicDataSource;import org.slf4j.LoggerFactory;public class SecurityBasicDataSource extends BasicDataSource &#123; private final org.slf4j.Logger logger = LoggerFactory.getLogger(SecurityBasicDataSource.class); @Override public Logger getParentLogger() throws SQLFeatureNotSupportedException &#123; throw new SQLFeatureNotSupportedException(); &#125; @Override public void setPassword(String password) &#123; try &#123; //这里可以从任意地方读取数据库配置 Properties p = ConfigLoaderUtils.loadConfig(\"jdbc.properties\"); String publickey = p.getProperty(\"publickey\"); //ConfigTools是实现私钥、公钥对加解密实现 password = ConfigTools.decrypt(publickey, password); super.setPassword(password); &#125; catch(Exception e) &#123; logger.error(\"解密password出错\", e); &#125; &#125;&#125; 首先我们继承dbcp数据源org.apache.commons.dbcp.BasicDataSource 重写setPassword 设置密码的时候通过公钥和密文进行解密 这样我们就给dbcp扩展了数据库连接加解密的功能，是不是很简单。 到这里我们就对数据库连接密码加密的方法介绍完毕，这样做的好处有什么呢？假设当应用服务器被坏人俘虏后，他想通过应用的配置信息轻松的获取数据库访问密码是不太可能，采用 公开密钥加密 安全性还是很高的，它是一种非对称加密算法想要了解更多的可以点开维基百科的连接查看。 敏感数据加解密前面我们介绍完了数据库连接上的安全问题以及如何解决，接下来我们继续介绍数据库中存储的敏感数据应该如何处理。 我相信很多人都接触过导出生产数据需要经过 数据脱敏 ，需要经过数据脱敏的大多都是存储的明文数据，比如说用户的手机号、详细地址、银行卡号、信用卡验证码、用户密码、等。 如果我们将这些敏感数据在存储入库的时候进行加密，数据库中存储的是密文数据，这样及时被脱库我相信也没有那么容易破解，有人可能说密码破解外界有 彩虹表 ，彩虹表是一个用于加密散列函数逆运算的预先计算好的表，常用于破解加密过的密码散列，针对于用户详细地址、银行卡号我相信彩虹表是无能为力的，如果使用暴力破解时间上的成本也是难以想象的，可能需要xxxxxx亿年，哈哈哈。 我们对数据加解密使用对称加解密算法AES或DES，为什么不使用非对称的公开密钥加密 ？ 虽然非对称加解密算法安全性高，但是非对称加解密算法加密后的值太长不利于存储，所以我们需要使用固定长度或者可控长度的加解密算法，刚好对称加解密算法符合要求，这里使用DES作为示例，当然可以替换成任意的加解密算法。 先说说数据落库时的加解密实现思路，假设我们需要存储用户详情，其中有姓名、电话、联系地址、银行卡号等信息，我们在持久化用户详情的时候对敏感字段进行加密计算出密文，再将密文存入数据库，当查询用户详情的时候，先从数据库查询出密文，通过对密文的解密和脱敏再返回给前台，这样我们就可以达到我们想要的效果，这里需要特殊说明一下，密文对模糊查询不是很友好，但是也可以实现模糊查询，具体的实现思路有很多种，这里我们就不多做介绍，感兴趣的话我后面可以单独出一篇支持模糊查询的加解密算法，回到主题我们就以这个案例进行实现。 首先我们需要对敏感字段进行打标记，java的annotation可以帮助我们实现打标 import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.FIELD)public @interface Cipher &#123;&#125; 我们可以给用户对象的敏感字段：手机号、银行卡、详细地址 上标注@Cipher注释，说明这几个字段我们在保存、修改的时候需要加密，在查询的时候需要解密。 下来我们就要找一个公共的地方来统一的进行加解密处理，作为一名合格的程序员需要想尽一切办法来偷懒，并不是在所有CRUD的地方进行加解密调用这样会很傻很天真，作为被广泛使用的orm框架之一的mybatis这里我使用它作为示例讲解实现思路。 mybatis提供拦截器机制，可以对执行的CRUD进行拦截处理操作，pagehelper 是一个分页的mybatis插件，就是利用拦截的机制来扩展分页功能。 我们刚才有说过我们需要对insert、update操作进行加密，对select操作进行解密，在mybatis的底层保存和修改都是update方法，查询都是query方法，刚好我们就对这两个方法进行拦截处理。 import java.lang.reflect.Field;import java.util.List;import java.util.Properties;import org.apache.commons.lang3.StringUtils;import org.apache.ibatis.executor.Executor;import org.apache.ibatis.mapping.MappedStatement;import org.apache.ibatis.plugin.Interceptor;import org.apache.ibatis.plugin.Intercepts;import org.apache.ibatis.plugin.Invocation;import org.apache.ibatis.plugin.Plugin;import org.apache.ibatis.plugin.Signature;import org.apache.ibatis.session.ResultHandler;import org.apache.ibatis.session.RowBounds;import org.apache.ibatis.session.defaults.DefaultSqlSession.StrictMap;import org.slf4j.Logger;import org.slf4j.LoggerFactory;@Intercepts(&#123; @Signature(type = Executor.class, method = \"update\", args = &#123; MappedStatement.class, Object.class &#125;), @Signature(type = Executor.class, method = \"query\", args = &#123; MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class &#125;) &#125;)public class CipherHelper implements Interceptor &#123; private final Logger logger = LoggerFactory.getLogger(CipherHelper.class); /** * 加密密钥&lt;/br&gt; 为null，使用默认密钥进行加解密&lt;/br&gt; */ private String secureKey = null; /** * 是否允许宽容处理&lt;/br&gt; 宽容处理的话，使用原值，反之throw &#123;@link CipherException&#125;&lt;/br&gt; */ private boolean lenient = false; @Override public Object intercept(Invocation invocation) throws Throwable &#123; String methodName = invocation.getMethod().getName(); if (methodName.equals(\"update\") || methodName.equals(\"query\")) &#123; Object parameter = invocation.getArgs()[1]; if (parameter instanceof List) &#123; List&lt;?&gt; list = (List&lt;?&gt;) parameter; for (Object obj : list) &#123; encrypt(obj); &#125; &#125; else if(parameter instanceof StrictMap) &#123; StrictMap&lt;?&gt; strictMap = (StrictMap&lt;?&gt;) parameter; if (strictMap.containsKey(\"list\")) &#123; List&lt;?&gt; list = (List&lt;?&gt;) strictMap.get(\"list\"); for (Object obj : list) &#123; encrypt(obj); &#125; &#125; else if (strictMap.containsKey(\"array\")) &#123; Object[] objects = (Object[]) strictMap.get(\"array\"); for (Object obj : objects) &#123; encrypt(obj); &#125; &#125; &#125; else &#123; encrypt(parameter); &#125; &#125; Object returnValue = invocation.proceed(); if (methodName.equals(\"query\")) &#123; if (returnValue instanceof List) &#123; List&lt;?&gt; list = (List&lt;?&gt;) returnValue; for (Object obj : list) &#123; decrypt(obj); &#125; &#125; else &#123; decrypt(returnValue); &#125; &#125; return returnValue; &#125; /** * 加密处理 * * @param parameter * @throws IllegalAccessException */ private void encrypt(Object parameter) throws IllegalAccessException &#123; if (parameter == null) return; Class&lt;?&gt; clazz = parameter.getClass(); if (!clazz.getSimpleName().endsWith(\"Entity\")) &#123; return; &#125; for (; clazz != Object.class; clazz = clazz.getSuperclass()) &#123; Field[] fields = clazz.getDeclaredFields(); for (int i = 0; i &lt; fields.length; i++) &#123; if (!fields[i].isAnnotationPresent(Cipher.class)) &#123; continue; &#125; if (!fields[i].getType().equals(String.class)) &#123; logger.debug(\"加密字段只支持String类型,当前类型非String,跳过!\"); continue; &#125; fields[i].setAccessible(true); String v = (String) fields[i].get(parameter); if (StringUtils.isBlank(v)) &#123; logger.debug(\"加密字段值为null,跳过!\"); continue; &#125; try &#123; String crypt = DESTools.encrypt(secureKey, v); fields[i].set(parameter, crypt); logger.debug(\"加密处理字段,&#123;&#125;\", fields[i].getName()); &#125; catch (Exception e) &#123; if (lenient) &#123; logger.warn(\"加密处理失败,宽容处理使用原值\"); &#125; else &#123; throw new CipherException(\"加密处理失败,不允许宽容处理[\"+v+\"]\", e); &#125; &#125; &#125; &#125; &#125; /** * 解密处理 * * @param obj * @throws IllegalAccessException * @throws Exception */ private void decrypt(Object obj) throws IllegalAccessException, Exception &#123; if (obj == null) return; Class&lt;?&gt; clazz = obj.getClass(); if (!clazz.getSimpleName().endsWith(\"Entity\")) &#123; return; &#125; for (; clazz != Object.class; clazz = clazz.getSuperclass()) &#123; Field[] fields = clazz.getDeclaredFields(); for (int i = 0; i &lt; fields.length; i++) &#123; if (!fields[i].isAnnotationPresent(Cipher.class)) &#123; continue; &#125; if (!fields[i].getType().equals(String.class)) &#123; logger.debug(\"解密字段只支持String类型,当前类型非String,跳过!\"); continue; &#125; fields[i].setAccessible(true); String v = (String) fields[i].get(obj); if (StringUtils.isBlank(v)) &#123; logger.debug(\"解密字段值为null,跳过!\"); continue; &#125; try &#123; String crypt = DESTools.decrypt(secureKey, v); fields[i].set(obj, crypt); logger.info(\"解密处理字段,&#123;&#125;\", fields[i].getName()); &#125; catch (Exception e) &#123; if (lenient) &#123; logger.warn(\"解密处理失败,宽容处理使用原值\"); &#125; else &#123; throw new CipherException(\"解密处理失败,不允许宽容处理[\"+v+\"]\", e); &#125; &#125; &#125; &#125; &#125; @Override public Object plugin(Object target) &#123; return Plugin.wrap(target, this); &#125; @Override public void setProperties(Properties properties) &#123; if (properties != null &amp;&amp; StringUtils.isNotBlank(properties.getProperty(\"secureKey\"))) &#123; this.secureKey = properties.getProperty(\"secureKey\"); &#125; if (properties != null &amp;&amp; StringUtils.isNoneBlank(properties.getProperty(\"lenient\"))) &#123; this.lenient = Boolean.parseBoolean(properties.getProperty(\"lenient\")); &#125; &#125;&#125; 通过mybatis的插件扩展机制在执行过程进行拦截处理，plugin方法是插件的装载方法，setProperties方法设置关键属性，比如说密钥串。 接下来我们对每个方法进行讲解： encrypt：是加密方法，这里加密方法需要注意的是，mybatis参数支持Pojo 、Map、StrictMap、List、Array，我们使用注解@Cipher是用在类上的所以只对Pojo生效，如果是Map它天生的key，value格式无法支持打标，我们这里对Map类型进行跳过不处理，如果非要处理Map也是有办法的，需要固定加解密的key值，对特定的key进行识别并加解密替换value，加密方法通过查找有注解@Cipher的字段进行加密并且回填值。 decrypt：是解密方法，主要用在查询时的解密，这里需要注意的是查询有可能返回特定的Pojo也可能返回List，所以这里解密的时候需要根据类型来分别处理，如果是List需要进行很层次查找，如果是Pojo那就查找使用注解@Cipher的字段进行解密并且回填值。 intercept：是拦截方法，在update、query前后进行拦截处理，在这个方法里需要进行如下步骤： 识别当前执行的method是update还是query 如果是update那就进行加密 如果是query那就进行解密 识别参数类型是List、StrictMap、Pojo 如果是List需要再深层次看一下List里是什么类型，这里建议使用递归方式 如果List里是Pojo那就循环调用encrypt方法 如果List里是Map跳过处理，或者使用上面我们说的识别某些固定key进行加密处理 如果是StrictMap需要再深层次看一下StrictMap里是什么类型，这里建议使用递归方式 如果StrictMap里是list那就循环调用encrypt方法 如果StrictMap里是array那就循环调用encrypt方法 如果是Pojo那就调用encrypt方法 执行sql处理获取返回值 获取返回值并且执行的方法是query时，进行解密处理 识别返回的类型是List还是Pojo 如果是List深层次查找内部类型，这里建议使用递归方式 如果List里是Pojo那就循环调用decrypt方法 如果List里是Map跳过处理，或者使用上面我们说的识别某些固定key进行解密处理 如果是Pojo那就调用decrypt方法 到这里数据加解密的核心逻辑就介绍完了。 这里我们回顾一下，我们先是对数据库连接密码进行加解密，然后又对敏感数据落库和查询时进行加解密，第一步连接密码加密预防坏人即使攻击拿到了应用服务器的操作权限他也无法轻易的攻克我们的数据库访问密码，第二步敏感数据加解密预防坏人即使攻克了我们的数据库（俗称脱库）他也无法获取用户的隐私数据，这样就有效的保证了用户隐私数据的安全性。 到这里我们就对软件程序层面的数据安全防护手段介绍完毕，接下来我们再从人员访问控制方面来看看有什么有效的手段。 人员层面前面我们说了绝大多数的数据泄密都不是技术问题而是人员管理问题，我们要对人员进行有效的管理与控制。 开发或测试人员这类人一般对数据是有CRUD的诉求，针对这类人员的控制有如下几个方面 开发人员只能连接测试环境数据库，不允许连接生产数据库，即使连接vpn也不行。 开发人员申请数据库需要走运维工单流程，运维提供数据库连接密码时应直接提供密文，或者运维直接给配置到配置中心。 配置文件或配置中心禁止存储明文密码，需要对jdbc等其他敏感密码进行脱敏处理。 生产服务器需要通过跳板机访问，禁止开发使用root直接操作，如果看应用日志可以走日志平台，实在没有日志平台可以给跳板机开通app用户只给查看固定目录日志的权限，如果要发布走devops平台，如果没有可以提供给运维进行发布。 查询生产数据走dms平台，对敏感信息进行脱敏或隐藏，对上线的sql和日常的查询日志做到dms可管控。 提交到开放环境时需要注意以下几点 提交到开放的仓库（github、gitlab、gitee等），需要对代码进行审核，避免有hardcode的公司服务器密码、ip、端口、密钥等。 提交到开放的论坛（csdn、oschina、知乎、公众号、社区分享等），需要对文章进行审核，避免有不允许公开的技术细节或敏感信息。 运维或DBA人员这类人一般操作权限都很高，出问题概率最高的人员，有很多删库跑路或误操作rm -rf的例子哈哈哈！所以这类人更要重点管控。 需要搭建和处理运维工单平台，用于开发提出的运维资源申请，尤其是数据库密码，直接提供加密后的密文和公钥。 需要搭建和处理数据库管理工具dms，用于开发日常生产数据查询和发版时SQL升级。 需要提供跳板机和给跳板机提供不同等级的用户，提供给特别需要的人访问生产环境机器。 需要提供devops平台或者自动化发版工具，避免手动操作失误带来问题，对开发提供升级发布的流水线。 对服务器密码需要进行加密存储，可以借助密码管理工具。 运维最好也不要使用root用户操作服务器，使用特定权限的用户操作。 dba最好也不要使用root用户操作数据库，使用特定权限的用户操作。 制定责任人机制，对应的责任项必须到具体人，具体可以参考 责任分配矩阵RAM 。 关键重要的操作需要至少两个人在场，具体可以参考 责任分配矩阵RAM 。 产品或业务人员这类人一般对数据有查询和分析的诉求，有分析诉求就需要导出数据，所以分析诉求统一走公司BI工具，也有少部分有修改的诉求。 查询分析数据，统一接入BI工具，并且BI工具需要有功能和数据权限，并对敏感数据导出加以控制，导出走审批并脱敏。 提交数据变更，统一接入dms平台。 产品的分析文件（word、excel、ppt）应该进行加密，这种一般依赖公司引入文档安全的解决方案，要花钱的，如果不想花钱那就没啥好办法。 总结到这里整篇也就差不多都介绍完了，我们现在回顾一下，首先我们介绍了数据安全的问题，并且说明了安全问题一般发生在两个方面，一个是软件程序，一个是人员管理。 我们在软件程序方面介绍了两种预防数据安全的手段，一个是数据库连接密码加解密，一个是数据加解密，数据库连接加密可以有效预防服务器被攻击后通过翻找程序来进一步攻击数据库，数据加解密可以有效预防数据库被攻击或脱库后泄漏用户及公司隐私数据。 我们在人员方面首先对人员进行了分类，针对每一类人的诉求谈了管控的手段，说了这么多的控制手段，并不是说对员工不信任，我们这里说的控制并不等于限制，说了这么多的终极目标是搭建一套有序的安全的管理机制，在安全的范围内给员工提供最大化的发挥空间，规避有心或无心的泄密，最后送上那句老话，Keep Real，Love and peace！","tags":[{"name":"security","slug":"security","permalink":"https://ningyu1.github.io/tags/security/"},{"name":"datasource","slug":"datasource","permalink":"https://ningyu1.github.io/tags/datasource/"}]},{"title":"使用Travis CI部署Hexo","date":"2020-04-30T04:19:26.000Z","path":"20200430/travis-ci-deploy-hexo.html","text":"今天说一下使用travis ci来部署hexo，在说这个之前呢要先提几个概念，CI/CD（是一种通过在应用开发阶段引入自动化来频繁向客户交付应用的方法）。 什么是CI？ 持续集成，Continuous Integration，简称 CI 什么是CD？ 持续交付，Continuous Deployment，简称CD 我们都知道软件开发写代码只是其中的一部分，写出代码后需要构建（build）、测试（test）、发布（deploy）。 这些都是比较按部就班的操作，所以有很多工具化的支持，为了提高软件开发效率，构建和测试的工具有很多，我们最熟知的是jenkins，相信很多人都用过，还有很多如gitlab-ci、travis-ci、等。 今天我们就说一下travis-ci的简单使用，刚好我的blog每次都要编译然后提交到github，刚好用它做一个演示。 Travis CI的介绍Travis CI 是CI / CD生态系统中比较常见的名号之一，最初设定为开源项目，并在多年扩展之后转为闭源项目。它专注于CI工作，通过自动化测试和警报系统提高构建过程的效能。 它有什么作用？Travis-CI允许用户在部署代码时对代码进行快速测试。它支持代码大小变更，可识别构建与测试中发生的一切变更。检测到变更后，Travis CI可以提供有关变更是否成功的反馈。 开发人员可以使用Travis CI对运行时进行观察，并行运行多项测试，并将该工具与Slack、HipChat以及Email等集成，从而通过多种渠道获取问题或构建失败通知。 Travis CI支持容器构建，并支持Linux Ubuntu和OSX。您可以在不同的编程语言中使用它，例如Java，C＃，Clojure，GO，Haskell，Swift，Perl等等。其具备一份相对有限的第三方集成列表，但由于关注重点在于CI而非CD，因此其可能解决不了您的实际问题。 使用Travsi CI发布Hexo我的blog使用的是Hexo，它有丰富的模板可以选择，支持markdown写文章再构建生成静态html，所以当时就选用了它。 在做之前我们需要准备一些东西，如下： Step 1首先我们要在github上创建一个repository，给这个repository创建两个分支，我这里使用master作为静态html分支，blog-source作为博客源码分支。 ps. 分支名称都随意，有人喜欢用master作为源码分支，gh-pages作为静态html分支，都可以请随意。 Step 2去github上获取accesstoken，可以去https://github.com/settings/tokens获取，生成一个token（generate new token），token的scope范围看自己的需求选择，我这里选择的是repo下全部。 生成的token记得自己先保存起来，因为刷新页面后你就再也看不到它了，如果忘记了那就去重新生成一个（regenerate token） 图四 图五 Step 3在blog库的blog-source分支中添加.travis.yml language: node_jsnode_js: 10.16.3install: - npm installscript: bash ./deploy.shbranches: only: - blog-sourcenotifications: email: false hexo采用nodejs开发，所以这里语言选择nodejs，我这里选择nodejs版本是10.16.3，因为高版本nodejs下hexo生成的静态文件有问题，如果是其他的程序可以使用stable。 install阶段执行npm安装依赖。 script阶段执行一个外部脚本，在同.travis.yml路径下创建shell脚本deploy.sh #!/usr/bin/env sh# 确保脚本抛出遇到的错误set -e# 生成静态文件hexo generate# 进入生成的文件夹cd ./public#创建.nojekyll 防止Github Pages build错误touch .nojekyllgit initgit add -Agit commit -m \"deploy\"git push -f \"https://$&#123;access_token&#125;@github.com/ningyu1/blog.git\" master:mastercd - 脚本中先执行hexo -g（等同于hexo generate）生成静态html文件，文件生成在当前目录下的public文件夹。 进入到public文件夹下执行git命令，这里需要注意的是使用git push -f强制推送，如果没有设置git user.name和git user.email的话提交的用户是Travis Ci User ps. 这里特殊说明一下变量 ${access_token}，这里使用travis ci的运行时环境变量，像这种相对重要的信息放到运行时环境变量会安全一些，避免别人拿到我的AccessToken做一些坏事情，哈哈。 Step 4登录travis-ci，可以使用github三方登录，添加一个github仓库，travis跟github集成的还是非常紧密和方便的，添加仓库可以直接读取github上的仓库，在列表里面找到blog打开使用travis，如图一。 图一 进入dashbord查看刚才添加的库信息，选择More options-&gt;Settings，添加Environment Variables 创建一个access_token的环境变量，可以选择那些branch使用，DISPLAY VALUE IN BUILD LOG是控制构建日志中是否要输出变量的值，为了安全起见建议不用开启，如图二 图二 Step 5travis-ci接收到github的事件请求就会自动触发job。 一切准备就绪之后提交并推送代码到github仓库，这样travis会接收到github的push event事件，可以去More options-&gt;Requests中查看接收到的请求信息，如图三 图三 如果没有啥特殊情况看构建日志就可以看到成功信息。 Problem这里我遇到了一个问题，我使用hexo只支持10.x一下的nodejs版本，刚开始使用的node_js: stable，查看job日志可以看到使用的版本号如下 $ node --versionv14.0.0$ npm --version6.14.4$ nvm --version0.35.3 v14.x 版本导致hexo生成的html文件都是0 byte，果断的降低了nodejs版本就好了。","tags":[{"name":"travis-ci","slug":"travis-ci","permalink":"https://ningyu1.github.io/tags/travis-ci/"},{"name":"hexo","slug":"hexo","permalink":"https://ningyu1.github.io/tags/hexo/"}]},{"title":"一分钟弄清楚事务四要素：ACID","date":"2020-03-24T18:19:26.000Z","path":"20200325/one-minute-transaction-ACID.html","text":"在学习数据库时一定都听说过事务的四要素：ACID，但是大多数人对事务四要素的理解一直停留在课本概念层面并没有仔细的琢磨，当我们在实际工作中遇到问题时经常要去回顾这四要素的概念，甚至很多人说不清事务四要素具体是什么。 相信大家在实际工作中最常遇到的问题就是死锁（dead lock），说到死锁就不得不说先说事务，我们都知道死锁是并发事务时经常会遇到的问题，当然死锁的场景也非常多并且与数据库事务隔离级别有着很大的关系，这些不懂都没有关系，今天我们就花一分钟来理解消化事务的四要素。 事务四要素：ACID说到事务的四个要素，最容易理解的就是原子性，但是其他三个要素：一致性、隔离性、持久性也是非常重要，恰恰也是经常被人忽视的。 原子性（Atomicity）原子性非常容易被人理解，直白点说就是一个事务中的所有操作（CRUD）就像是一个原子操作一样不可分割开来，要么全部成功，要么全部失败，不允许部分成功部分失败。 举个例子： 往篮子里放入一个苹果 随后从篮子里拿出一个梨这两个动作要么都成功，要么都失败，不存在只往篮子里放苹果而没拿梨，也不存在只从篮子里拿梨而没有放苹果。 原子性的侧重点在于多个动作必须同时成功或者同时失败。 一致性（Consistency）网上争议最多的就是对一致性的理解，公说公有理婆说婆有理，我觉得还是仁者见仁智者见智。 说法一：事务开始和结束后，数据库的完整性约束没有被破坏，如外键约束。说法二：一个事务单元需要提交之后才会被其他事务可见。 网上有很多用张三给李四转账的例子来说明一致性，但是看起来感觉跟原子性的概念雷同，这也是经常会有人傻傻分不清一致性和原子性的区别。 说法三：一致性和原子性的区别在于两者的侧重点不同，原子性关注的是状态，要么全部成功，要么全部失败，不存在部分成功的状态。而一致性关注的是数据的可见性，一个事务的中间状态的数据对外部不可见，只有最初状态和最终状态的数据对外可见。 其实这个说法是对的，但是理解起来不通俗易懂甚至有些模糊，很难让人很通俗易懂的明白其中的区别。 而且看到上面区别解释后又会有人提出挑战说，当事务的隔离级别是Read Uncommitted（读未提交）时，可以把事务的中间状态数据对其他事务可见，这个不就是违背了一致性么？ 其实事务的隔离级别就是在事务的四要素和性能上面做平衡，有时候为了提高性能，会适度的破坏一致性原则。 这篇文章是我见过对一致性理解最靠谱的。 说回到主题一致性的理解上，我对一致性的理解是这样的，一致性关注的点是数据的操作结果是否与用户业务预期一致，这里有两点需要注意。 一致性关注的是结果状态，什么是结果状态？它是一个要达到的预期效果并非是一个保证手段。而数据库的唯一建、外键、主键等这些约束建和AID原则：原子性（A）、隔离性（I）、持久性（D）以及提交、回滚等动作是保证结果能达到与预期效果一致的手段。 一致性它是由用户的业务决定的并非数据库决定的，网上很多的例子解释一致性都是狭义的理解，为什么这样说的？比如说账户扣钱，如果业务约束账户不允许为负数，那当扣成负数的时候就会通过回滚来保持一致性，如果业务约束账户允许为负数，那当扣成负数也可以正常提交来保持一致性，那这两个最终的状态是完全不一样的，但都是满足用户预先设置好的约束规则，所以一致性是由用户来决定的，从结果来看只要符合业务预期约束就是满足一致性的。 隔离性（Isolation）并发事务之间不会互相影响，就像串行执行一样，也就是说并发事务之间都是互相隔离的，你不影响我，我也不影响你。隔离性侧重点是并发事务之间的影响，说到并发事务就要提到数据库的隔离级别，有的时候会通过调整数据库的隔离级别来适度的破坏一致性和隔离性，从而提高数据库处理性能。 ps. 画外音，隔离性是我们需要重点关注的，因为不同的隔离级别，可能对应的加锁过程不一样，而正是因为引入了各种各样的隔离级别，才让锁问题变得格外复杂。解决和分析死锁问题，重点就是要搞清楚数据库的隔离级别。那么隔离级别是个什么东西呢？我们会在后面出单独的文章来重点说明。 持久性（Durability）持久性就非常好理解了，事务提交后即持久化到磁盘不会丢失。持久性侧重的是数据不丢失，这个跟网上讨论最多的 （“丢失更新”、“提交覆盖”、“Read-Modify-Write问题”）很容易混淆，看起来效果都是没有存入正确的数据，看起来好像数据丢失了一样。实际上两者区别很大的，前者是说数据存到物理磁盘不会丢失，而后者则说的是并发事务中的相互影响导致最终的数据结果不同。 总结这一章我们对事务的ACID进行了快速的理解，这里容易混淆的有原子性和一致性。 原子性的侧重点在于操作完整不可分隔，往篮子里放入一个苹果随后从篮子里拿出一个梨，不存在只往篮子里放入苹果没有拿梨，也不存在只从篮子里拿梨没有放入苹果。 一致性的侧重点在于结果状态是否与用户的预期效果一致。 隔离性的侧重点在于并发事务之间互不影响，切记不是你中有我我中有你。 持久性的侧重点在于数据落盘不丢，切记不是并发事务导致的最终数据结果丢失。 下一章我们会从事务的隔离级别来进行快速学习和掌握，隔离级别会分两章来进行，先让大家搞清楚我们最常挂在嘴边的也是面试最常问道的：脏读、幻读、不可重复度、可重复度、丢失更新的定义和区别，我会尽量用通俗易懂的方式来让大家明白。 附录这里从网上找了一些关于事务的文章，不用太纠结对错，仁者见仁，智者见智，有句俗话是这样说的：不要太认真，认真你就输了，哈哈。。。。 https://www.aneasystone.com/archives/2017/10/solving-dead-locks-one.html https://www.cnblogs.com/autointerface/p/11959711.html http://novoland.github.io/%E6%95%B0%E6%8D%AE%E5%BA%93/2014/07/26/MySQL%E6%80%BB%E7%BB%93.html ps. 文章中有哪些错误的地方欢迎指正。 好像文章有点长阅读起来超过了一分钟，看来功力还不够没有压缩到一分钟，希望能帮助到需要的人。 Love and peace！","tags":[{"name":"transaction","slug":"transaction","permalink":"https://ningyu1.github.io/tags/transaction/"},{"name":"acid","slug":"acid","permalink":"https://ningyu1.github.io/tags/acid/"}]},{"title":"[转]研究 Dubbo 网卡地址注册时的一点思考","date":"2019-10-16T03:08:26.000Z","path":"20191016/dubbo-network-interfaces.md.html","text":"最近看到一篇Apache Dubbo官方Blog中对dubbo网卡实现的代码解读，觉得讲的非常好所以特别分享一下，话不多说直接看原文吧。 研究 Dubbo 网卡地址注册时的一点思考1 如何选择合适的网卡地址可能相当一部分人还不知道我这篇文章到底要讲什么，我说个场景，大家应该就明晰了。在分布式服务调用过程中，以 Dubbo 为例，服务提供者往往需要将自身的 IP 地址上报给注册中心，供消费者去发现。在大多数情况下 Dubbo 都可以正常工作，但如果你留意过 Dubbo 的 github issue，其实有不少人反馈：Dubbo Provider 注册了错误的 IP。如果你能立刻联想到：多网卡、内外网地址共存、VPN、虚拟网卡等关键词，那我建议你一定要继续将本文看下去，因为我也想到了这些，它们都是本文所要探讨的东西！那么“如何选择合适的网卡地址”呢，Dubbo 现有的逻辑到底算不算完备？我们不急着回答它，而是带着这些问题一起进行研究，相信到文末，其中答案，各位看官自有评说。 2 Dubbo 是怎么做的Dubbo 获取网卡地址的逻辑在各个版本中也是千回百转，走过弯路，也做过优化，我们用最新的 2.7.2-SNAPSHOT 版本来介绍，在看以下源码时，大家可以怀着质疑的心态去阅读，在 dubbo github 的 master 分支可以获取源码。获取 localhost 的逻辑位于 org.apache.dubbo.common.utils.NetUtils#getLocalAddress0() 之中 private static InetAddress getLocalAddress0() &#123; InetAddress localAddress = null; // 首先尝试获取 /etc/hosts 中 hostname 对应的 IP localAddress = InetAddress.getLocalHost(); Optional&lt;InetAddress&gt; addressOp = toValidAddress(localAddress); if (addressOp.isPresent()) &#123; return addressOp.get(); &#125; // 没有找到适合注册的 IP，则开始轮询网卡 Enumeration&lt;NetworkInterface&gt; interfaces = NetworkInterface.getNetworkInterfaces(); if (null == interfaces) &#123; return localAddress; &#125; while (interfaces.hasMoreElements()) &#123; NetworkInterface network = interfaces.nextElement(); Enumeration&lt;InetAddress&gt; addresses = network.getInetAddresses(); while (addresses.hasMoreElements()) &#123; // 返回第一个匹配的适合注册的 IP Optional&lt;InetAddress&gt; addressOp = toValidAddress(addresses.nextElement()); if (addressOp.isPresent()) &#123; return addressOp.get(); &#125; &#125; &#125; return localAddress;&#125; Dubbo 这段选取本地地址的逻辑大致分成了两步 先去 /etc/hosts 文件中找 hostname 对应的 IP 地址，找到则返回；找不到则转 2 轮询网卡，寻找合适的 IP 地址，找到则返回；找不到返回 null，在 getLocalAddress0 外侧还有一段逻辑，如果返回 null，则注册 127.0.0.1 这个本地回环地址 首先强调下，这段逻辑并没有太大的问题，先别急着挑刺，让我们来分析下其中的一些细节，并进行验证。 2.1 尝试获取 hostname 映射 IPDubbo 首先选取的是 hostname 对应的 IP，在源码中对应的 InetAddress.getLocalHost(); 在 *nix 系统实际部署 Dubbo 应用时，可以首先使用 hostname 命令获取主机名 xujingfengdeMacBook-Pro:~ xujingfeng$ hostnamexujingfengdeMacBook-Pro.local 紧接着在 /etc/hosts 配置 IP 映射，为了验证 Dubbo 的机制，我们随意为 hostname 配置一个 IP 地址 127.0.0.1 localhost1.2.3.4 xujingfengdeMacBook-Pro.local 接着调用 NetUtils.getLocalAddress0() 进行验证，控制台打印如下： xujingfengdeMacBook-Pro.local/1.2.3.4 2.2 判定有效的 IP 地址在 toValidAddress 逻辑中，Dubbo 存在以下逻辑判定一个 IP 地址是否有效 private static Optional&lt;InetAddress&gt; toValidAddress(InetAddress address) &#123; if (address instanceof Inet6Address) &#123; Inet6Address v6Address = (Inet6Address) address; if (isValidV6Address(v6Address)) &#123; return Optional.ofNullable(normalizeV6Address(v6Address)); &#125; &#125; if (isValidV4Address(address)) &#123; return Optional.of(address); &#125; return Optional.empty();&#125; 依次校验其符合 Ipv6 或者 Ipv4 的 IP 规范，对于 Ipv6 的地址，见如下代码： static boolean isValidV6Address(Inet6Address address) &#123; boolean preferIpv6 = Boolean.getBoolean(\"java.net.preferIPv6Addresses\"); if (!preferIpv6) &#123; return false; &#125; try &#123; return address.isReachable(100); &#125; catch (IOException e) &#123; // ignore &#125; return false;&#125; 首先获取 java.net.preferIPv6Addresses 参数，其默认值为 false，鉴于大多数应用并没有使用 Ipv6 地址作为理想的注册 IP，这问题不大，紧接着通过 isReachable 判断网卡的连通性。例如一些网卡可能是 VPN/虚拟网卡的地址，如果没有配置路由表，往往无法连通，可以将之过滤。 对于 Ipv4 的地址，见如下代码： static boolean isValidV4Address(InetAddress address) &#123; if (address == null || address.isLoopbackAddress()) &#123; return false; &#125; String name = address.getHostAddress(); boolean result = (name != null &amp;&amp; IP_PATTERN.matcher(name).matches() &amp;&amp; !Constants.ANYHOST_VALUE.equals(name) &amp;&amp; !Constants.LOCALHOST_VALUE.equals(name)); return result;&#125; 对比 Ipv6 的判断，这里我们已经发现前后不对称的情况了 Ipv4 相比 Ipv6 的逻辑多了 Ipv4 格式的正则校验、本地回环地址校验、ANYHOST 校验 Ipv4 相比 Ipv6 的逻辑少了网卡连通性的校验 大家都知道，Ipv4 将 127.0.0.1 定为本地回环地址， Ipv6 也存在回环地址：0:0:0:0:0:0:0:1 或者表示为 ::1。改进建议也很明显，我们放到文末统一总结。 2.3 轮询网卡如果上述地址获取为 null 则进入轮询网卡的逻辑（例如 hosts 未指定 hostname 的映射或者 hostname 配置成了 127.0.0.1 之类的地址便会导致获取到空的网卡地址），轮询网卡对应的源码是 NetworkInterface.getNetworkInterfaces() ，这里面涉及的知识点就比较多了，支撑起了我写这篇文章的素材，Dubbo 的逻辑并不复杂，进行简单的校验，返回第一个可用的 IP 即可。 性子急的读者可能忍不住了，多网卡！合适的网卡可能不止一个，Dubbo 怎么应对呢？按道理说，我们也替 Dubbo 说句公道话，客官要不你自己指定下？我们首先得对多网卡的场景达成一致看法，才能继续把这篇文章完成下去：我们只能尽可能过滤那些“不对”的网卡。Dubbo 看样子对所有网卡是一视同仁了，那么是不是可以尝试优化一下其中的逻辑呢？ 许多开源的服务治理框架在 stackoverflow 或者其 issue 中，注册错 IP 相关的问题都十分高频，大多数都是轮询网卡出了问题。既然事情发展到这儿，势必需要了解一些网络、网卡的知识，我们才能过滤掉那些明显不适合 RPC 服务注册的 IP 地址了。 3 Ifconfig 介绍我并没有想要让大家对后续的内容望而却步，特地选择了这个大家最熟悉的 Linux 命令！对于那些吐槽：“天呐，都 2019 年了，你怎么还在用 net-tools/ifconfig，iproute2/ip 了解一下”的言论，请大家视而不见。无论你使用的是 mac，还是 linux，都可以使用它去 CRUD 你的网卡配置。 3.1 常用指令启动关闭指定网卡： ifconfig eth0 upifconfig eth0 down ifconfig eth0 up 为启动网卡 eth0，ifconfig eth0 down 为关闭网卡 eth0。ssh 登陆 linux 服务器操作的用户要小心执行这个操作了，千万不要蠢哭自己。不然你下一步就需要去 google：“禁用 eth0 网卡后如何远程连接 Linux 服务器” 了。 为网卡配置和删除IPv6地址： ifconfig eth0 add 33ffe:3240:800:1005::2/64 #为网卡eth0配置IPv6地址ifconfig eth0 del 33ffe:3240:800:1005::2/64 #为网卡eth0删除IPv6地址 用 ifconfig 修改 MAC 地址： ifconfig eth0 hw ether 00:AA:BB:CC:dd:EE 配置 IP 地址： [root@localhost ~]# ifconfig eth0 192.168.2.10[root@localhost ~]# ifconfig eth0 192.168.2.10 netmask 255.255.255.0[root@localhost ~]# ifconfig eth0 192.168.2.10 netmask 255.255.255.0 broadcast 192.168.2.255 启用和关闭arp协议： ifconfig eth0 arp #开启网卡eth0 的arp协议ifconfig eth0 -arp #关闭网卡eth0 的arp协议 设置最大传输单元： ifconfig eth0 mtu 1500 #设置能通过的最大数据包大小为 1500 bytes 3.2 查看网卡信息在一台 ubuntu 上执行 ifconfig -a ubuntu@VM-30-130-ubuntu:~$ ifconfig -aeth0 Link encap:Ethernet HWaddr 52:54:00:a9:5f:ae inet addr:10.154.30.130 Bcast:10.154.63.255 Mask:255.255.192.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:149673 errors:0 dropped:0 overruns:0 frame:0 TX packets:152271 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:15205083 (15.2 MB) TX bytes:21386362 (21.3 MB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) docker0 Link encap:Ethernet HWaddr 02:42:58:45:c1:15 inet addr:172.17.0.1 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B)tun0 Link encap:UNSPEC HWaddr 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00 UP POINTOPOINT NOARP MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:100 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) 为了防止黑客对我的 Linux 发起攻击，我还是偷偷对 IP 做了一点“改造”，请不要为难一个趁着打折+组团购买廉价云服务器的小伙子。对于部分网卡的详细解读: eth0 表示第一块网卡， 其中 HWaddr 表示网卡的物理地址，可以看到目前这个网卡的物理地址(MAC 地址）是 02:42:38:52:70:54 inet addr 用来表示网卡的 IP 地址，此网卡的 IP 地址是 10.154.30.130，广播地址， Bcast: 172.18.255.255，掩码地址 Mask:255.255.0.0 lo 是表示主机的回环地址，这个一般是用来测试一个网络程序，但又不想让局域网或外网的用户能够查看，只能在此台主机上运行和查看所用的网络接口。比如把 HTTPD 服务器的指定到回坏地址，在浏览器输入 127.0.0.1 就能看到你所架构的 WEB 网站了。但只有你能看得到，局域网的其它主机或用户则无从知晓。 第一行：连接类型：Ethernet（以太网）HWaddr（硬件mac地址） 第二行：网卡的IP地址、子网、掩码 第三行：UP（代表网卡开启状态）RUNNING（代表网卡的网线被接上）MULTICAST（支持组播）MTU:1500（最大传输单元）：1500字节（ifconfig 不加 -a 则无法看到 DOWN 的网卡） 第四、五行：接收、发送数据包情况统计 第七行：接收、发送数据字节数统计信息。 紧接着的两个网卡 docker0，tun0 是怎么出来的呢？我在我的 ubuntu 上装了 docker 和 openvpn。这两个东西应该是日常干扰我们做服务注册时的罪魁祸首了，当然，也有可能存在 eth1 这样的第二块网卡。ifconfig -a 看到的东西就对应了 JDK 的 api ：NetworkInterface.getNetworkInterfaces() 。我们简单做个总结，大致有三个干扰因素 以 docker 网桥为首的虚拟网卡地址，毕竟这东西这么火，怎么也得单独列出来吧？ 以 TUN/TAP 为代表的虚拟网卡地址，多为 VPN 场景 以 eth1 为代表的多网卡场景，有钱就可以装多网卡了！ 我们后续的篇幅将针对这些场景做分别的介绍，力求让大家没吃过猪肉，起码看下猪怎么跑的。 4 干扰因素一：Docker 网桥熟悉 docker 的朋友应该知道 docker 会默认创建一个 docker0 的网桥，供容器实例连接。如果嫌默认的网桥不够直观，我们可以使用 bridge 模式自定义创建一个新的网桥： ubuntu@VM-30-130-ubuntu:~$ docker network create kirito-bridgea38696dbbe58aa916894c674052c4aa6ab32266dcf6d8111fb794b8a344aa0d9ubuntu@VM-30-130-ubuntu:~$ ifconfig -abr-a38696dbbe58 Link encap:Ethernet HWaddr 02:42:6e:aa:fd:0c inet addr:172.19.0.1 Bcast:172.19.255.255 Mask:255.255.0.0 UP BROADCAST MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) 使用 docker network 指令创建网桥之后，自动创建了对应的网卡，我只给出了 ifconfig -a 的增量返回部分，可以看出多了一个 br-a38696dbbe58 的网卡。 我有意区分了“网桥”和“网卡”，可以使用 bridge-utils/brctl 来查看网桥信息： ubuntu@VM-30-130-ubuntu:~$ sudo brctl showbridge name bridge id STP enabled interfacesbr-a38696dbbe58 8000.02426eaafd0c nodocker0 8000.02425845c215 no 网桥是一个虚拟设备，这个设备只有 brctl show 能看到，网桥创建之后，会自动创建一个同名的网卡，并将这个网卡加入网桥。 5 干扰因素二：TUN/TAP 虚拟网络设备平时我们所说的虚拟网卡、虚拟机，大致都跟 TUN/TAP 有关。我的读者大多数是 Java 从业者，相信我下面的内容并没有太超纲，不要被陌生的名词唬住。对于被唬住的读者，也可以直接跳过 5.1~5.3，直接看 5.4 的实战。 5.1 真实网卡工作原理 1918847-496d0e96c237f25a 上图中的 eth0 表示我们主机已有的真实的网卡接口 (interface)。 网卡接口 eth0 所代表的真实网卡通过网线(wire)和外部网络相连，该物理网卡收到的数据包会经由接口 eth0 传递给内核的网络协议栈(Network Stack)。然后协议栈对这些数据包进行进一步的处理。 对于一些错误的数据包,协议栈可以选择丢弃；对于不属于本机的数据包，协议栈可以选择转发；而对于确实是传递给本机的数据包,而且该数据包确实被上层的应用所需要，协议栈会通过 Socket API 告知上层正在等待的应用程序。 5.2 TUN 工作原理 1918847-85ea08bc89d9427e 我们知道，普通的网卡是通过网线来收发数据包的话，而 TUN 设备比较特殊，它通过一个文件收发数据包。 如上图所示，tunX 和上面的 eth0 在逻辑上面是等价的， tunX 也代表了一个网络接口,虽然这个接口是系统通过软件所模拟出来的. 网卡接口 tunX 所代表的虚拟网卡通过文件 /dev/tunX 与我们的应用程序(App)相连，应用程序每次使用 write 之类的系统调用将数据写入该文件，这些数据会以网络层数据包的形式，通过该虚拟网卡，经由网络接口 tunX 传递给网络协议栈，同时该应用程序也可以通过 read 之类的系统调用，经由文件 /dev/tunX 读取到协议栈向 tunX 传递的所有数据包。 此外，协议栈可以像操纵普通网卡一样来操纵 tunX 所代表的虚拟网卡。比如说，给 tunX 设定 IP 地址，设置路由，总之，在协议栈看来，tunX 所代表的网卡和其他普通的网卡区别不大，当然，硬要说区别，那还是有的,那就是 tunX 设备不存在 MAC 地址，这个很好理解，tunX 只模拟到了网络层，要 MAC地址没有任何意义。当然，如果是 tapX 的话，在协议栈的眼中，tapX 和真实网卡没有任何区别。 是不是有些懵了？我是谁，为什么我要在这篇文章里面学习 TUN！因为我们常用的 VPN 基本就是基于 TUN/TAP 搭建的，如果我们使用 TUN 设备搭建一个基于 UDP 的 VPN ，那么整个处理过程可能是这幅样子： 1918847-ac4155ec7e9489b2 5.3 TAP 工作原理TAP 设备与 TUN 设备工作方式完全相同，区别在于： TUN 设备是一个三层设备，它只模拟到了 IP 层，即网络层 我们可以通过 /dev/tunX 文件收发 IP 层数据包，它无法与物理网卡做 bridge，但是可以通过三层交换（如 ip_forward）与物理网卡连通。可以使用ifconfig之类的命令给该设备设定 IP 地址。 TAP 设备是一个二层设备，它比 TUN 更加深入，通过 /dev/tapX 文件可以收发 MAC 层数据包，即数据链路层，拥有 MAC 层功能，可以与物理网卡做 bridge，支持 MAC 层广播。同样的，我们也可以通过ifconfig之类的命令给该设备设定 IP 地址，你如果愿意，我们可以给它设定 MAC 地址。 关于文章中出现的二层，三层，我这里说明一下，第一层是物理层，第二层是数据链路层，第三层是网络层，第四层是传输层。 5.4 openvpn 实战openvpn 是 Linux 上一款开源的 vpn 工具，我们通过它来复现出影响我们做网卡选择的场景。 安装 openvpn sudo apt-get install openvpn 安装一个 TUN 设备： ubuntu@VM-30-130-ubuntu:~$ sudo openvpn --mktun --dev tun0Mon Apr 29 22:23:31 2019 TUN/TAP device tun0 openedMon Apr 29 22:23:31 2019 Persist state set to: ON 安装一个 TAP 设备： ubuntu@VM-30-130-ubuntu:~$ sudo openvpn --mktun --dev tap0Mon Apr 29 22:24:36 2019 TUN/TAP device tap0 openedMon Apr 29 22:24:36 2019 Persist state set to: ON 执行 ifconfig -a 查看网卡，只给出增量的部分： tap0 Link encap:Ethernet HWaddr 7a:a2:a8:f1:6b:df BROADCAST MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:100 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B)tun0 Link encap:UNSPEC HWaddr 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00 inet addr:10.154.30.131 P-t-P:10.154.30.131 Mask:255.255.255.255 UP POINTOPOINT NOARP MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:100 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) 这样就解释了文章一开始为什么会有 tun0 这样的网卡了。这里读者可能会有疑惑，使用 ifconfig 不是也可以创建 tap 和 tun 网卡吗？当然啦，openvpn 是一个 vpn 工具，只能创建名为 tunX/tapX 的网卡，其遵守着一定的规范，ifconfig 可以随意创建，但没人认那些随意创建的网卡。 6 干扰因素三：多网卡 image-20190429223515625 这个没有太多好说的，有多张真实的网卡，从普哥那儿搞到如上的 IP 信息。 7 MAC 下的差异虽然 ifconfig 等指令是 *nux 通用的，但是其展示信息，网卡相关的属性和命名都有较大的差异。例如这是我 MAC 下执行 ifconfig -a 的返回： xujingfengdeMacBook-Pro:dubbo-in-action xujingfeng$ ifconfig -alo0: flags=8049&lt;UP,LOOPBACK,RUNNING,MULTICAST&gt; mtu 16384 options=1203&lt;RXCSUM,TXCSUM,TXSTATUS,SW_TIMESTAMP&gt; inet 127.0.0.1 netmask 0xff000000 inet6 ::1 prefixlen 128 inet6 fe80::1%lo0 prefixlen 64 scopeid 0x1 nd6 options=201&lt;PERFORMNUD,DAD&gt;gif0: flags=8010&lt;POINTOPOINT,MULTICAST&gt; mtu 1280stf0: flags=0&lt;&gt; mtu 1280XHC0: flags=0&lt;&gt; mtu 0XHC20: flags=0&lt;&gt; mtu 0en0: flags=8863&lt;UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST&gt; mtu 1500 ether 88:e9:fe:88:a0:76 inet6 fe80::1cab:f689:60d1:bacb%en0 prefixlen 64 secured scopeid 0x6 inet 30.130.11.242 netmask 0xffffff80 broadcast 30.130.11.255 nd6 options=201&lt;PERFORMNUD,DAD&gt; media: autoselect status: activep2p0: flags=8843&lt;UP,BROADCAST,RUNNING,SIMPLEX,MULTICAST&gt; mtu 2304 ether 0a:e9:fe:88:a0:76 media: autoselect status: inactiveawdl0: flags=8943&lt;UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST&gt; mtu 1484 ether 66:d2:8c:8c:dd:85 inet6 fe80::64d2:8cff:fe8c:dd85%awdl0 prefixlen 64 scopeid 0x8 nd6 options=201&lt;PERFORMNUD,DAD&gt; media: autoselect status: activeen1: flags=8963&lt;UP,BROADCAST,SMART,RUNNING,PROMISC,SIMPLEX,MULTICAST&gt; mtu 1500 options=60&lt;TSO4,TSO6&gt; ether aa:00:d0:13:0e:01 media: autoselect &lt;full-duplex&gt; status: inactiveen2: flags=8963&lt;UP,BROADCAST,SMART,RUNNING,PROMISC,SIMPLEX,MULTICAST&gt; mtu 1500 options=60&lt;TSO4,TSO6&gt; ether aa:00:d0:13:0e:00 media: autoselect &lt;full-duplex&gt; status: inactivebridge0: flags=8863&lt;UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST&gt; mtu 1500 options=63&lt;RXCSUM,TXCSUM,TSO4,TSO6&gt; ether aa:00:d0:13:0e:01 Configuration: id 0:0:0:0:0:0 priority 0 hellotime 0 fwddelay 0 maxage 0 holdcnt 0 proto stp maxaddr 100 timeout 1200 root id 0:0:0:0:0:0 priority 0 ifcost 0 port 0 ipfilter disabled flags 0x2 member: en1 flags=3&lt;LEARNING,DISCOVER&gt; ifmaxaddr 0 port 9 priority 0 path cost 0 member: en2 flags=3&lt;LEARNING,DISCOVER&gt; ifmaxaddr 0 port 10 priority 0 path cost 0 nd6 options=201&lt;PERFORMNUD,DAD&gt; media: &lt;unknown type&gt; status: inactiveutun0: flags=8051&lt;UP,POINTOPOINT,RUNNING,MULTICAST&gt; mtu 2000 inet6 fe80::3fe0:3e8b:384:9968%utun0 prefixlen 64 scopeid 0xc nd6 options=201&lt;PERFORMNUD,DAD&gt;utun1: flags=8051&lt;UP,POINTOPOINT,RUNNING,MULTICAST&gt; mtu 1380 inet6 fe80::7894:3abc:5abd:457d%utun1 prefixlen 64 scopeid 0xd nd6 options=201&lt;PERFORMNUD,DAD&gt; 内容很多，我挑几点差异简述下： 内容展示形式不一样，没有 Linux 下的接收、发送数据字节数等统计信息 真实网卡的命名不一样：eth0 -&gt; en0 虚拟网卡的命名格式不一样：tun/tap -&gt; utun 对于这些常见网卡命名的解读，我摘抄一部分来自 stackoverflow 的回答： In arbitrary order of my familarity / widespread relevance: lo0 is loopback. en0 at one point “ethernet”, now is WiFi (and I have no idea what extra en1 or en2 are used for). fw0 is the FireWire network interface. stf0 is an IPv6 to IPv4 tunnel interface) to support the transition from IPv4 to the IPv6 standard. gif0 is a more generic tunneling interface) [46]-to-[46]. awdl0 is Apple Wireless Direct Link p2p0 is related to AWDL features. Either as an old version, or virtual interface with different semantics than awdl. the “Network” panel in System Preferences to see what network devices “exist” or “can exist” with current configuration. many VPNs will add additional devices, often “utun#” or “utap#” following TUN/TAP (L3/L2)virtual networking devices. use netstat -nr to see how traffic is currently routed via network devices according to destination. interface naming conventions started in BSD were retained in OS X / macOS, and now there also additions. 8 Dubbo 改进建议我们进行了以上探索，算是对网卡有一点了解了。回过头来看看 Dubbo 获取网卡的逻辑，是否可以做出改进呢？ Dubbo Action 1: 保持 Ipv4 和 Ipv6 的一致性校验。为 Ipv4 增加连通性校验；为 Ipv6 增加 LoopBack 和 ANYHOST 等校验。 Dubbo Action 2: NetworkInterface network = interfaces.nextElement();if (network.isLoopback() || network.isVirtual() || !network.isUp()) &#123; continue;&#125; JDK 提供了以上的 API，我们可以利用起来，过滤一部分一定不正确的网卡。 Dubbo Action 3: 我们本文花了较多的篇幅介绍了 docker 和 TUN/TAP 两种场景导致的虚拟网卡的问题，算是较为常见的一个影响因素，虽然他们的命名具有固定性，如 docker0、tunX、tapX，但我觉得通过网卡名称的判断方式去过滤注册 IP 有一些 hack，所以不建议 dubbo contributor 提出相应的 pr 去增加这些 hack 判断，尽管可能会对判断有所帮助。 对于真实多网卡、内外网 IP 共存的场景，不能仅仅是框架层在做努力，用户也需要做一些事，就像爱情一样，我可以主动一点，但你也得反馈，才能发展出故事。 Dubbo User Action 1: 可以配置 /etc/hosts 文件，将 hostname 对应的 IP 显式配置进去。 Dubbo User Action 2: 可以使用启动参数去显式指定注册的 IP： -DDUBBO_IP_TO_REGISTRY=1.2.3.4 也可以指定 Dubbo 服务绑定在哪块网卡上： -DDUBBO_IP_TO_BIND=1.2.3.4 9 参考文章TUN/TAP 设备浅析 what-are-en0-en1-p2p-and-so-on-that-are-displayed-after-executing-ifconfig 原文地址 | 纠错","tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://ningyu1.github.io/tags/dubbo/"},{"name":"网卡地址注册","slug":"网卡地址注册","permalink":"https://ningyu1.github.io/tags/网卡地址注册/"}]},{"title":"Trouble Shooting —— CAS Server集群环境下TGC验证问题","date":"2019-10-15T06:05:53.000Z","path":"20191015/118-cas-server-pit.html","text":"之前写了一篇cas server故障排查的文章《Trouble Shooting —— CAS Server集群环境下TGC验证问题排查，需要开启会话保持》 ，之前这张文章写的是开启会话保持来解决这个故障，但是这个方式没有充分的发挥cas server集群的功能，因此这次讲一下另外一种解决方法，真正的解决cas server集群环境下的问题 我们可以点击上面的文章链接进去回顾一下具体的问题。 问题分析错误是出在cas ticket cookie在cas server服务端验证时出现了问题，这里解释一下这个问题现象。 当我们cas server部署两台服务时，前端采用nginx做负载均衡，当我们访问cas server的时候nginx会随机选择一个服务端返回给前端，因此在第一次登陆的时候是由serverA生成的ticket，ticket中包含了客户端ip，当下次访问时路由到serverB时ticket验证的时候获取的客户端ip不一致导致的问题。 重点是在类：org.apereo.cas.web.support.DefaultCasCookieValueManager.obtainCookieValue方法 这里以cas server5.0.4版本为例看一下源码： public String obtainCookieValue(final Cookie cookie, final HttpServletRequest request) &#123; final String cookieValue = this.cipherExecutor.decode(cookie.getValue()); LOGGER.debug(\"Decoded cookie value is [&#123;&#125;]\", cookieValue); if (StringUtils.isBlank(cookieValue)) &#123; LOGGER.debug(\"Retrieved decoded cookie value is blank. Failed to decode cookie [&#123;&#125;]\", cookie.getName()); return null; &#125; final String[] cookieParts = cookieValue.split(String.valueOf(COOKIE_FIELD_SEPARATOR)); if (cookieParts.length != COOKIE_FIELDS_LENGTH) &#123; throw new IllegalStateException(\"Invalid cookie. Required fields are missing\"); &#125; final String value = cookieParts[0]; final String remoteAddr = cookieParts[1]; final String userAgent = cookieParts[2]; if (StringUtils.isBlank(value) || StringUtils.isBlank(remoteAddr) || StringUtils.isBlank(userAgent)) &#123; throw new IllegalStateException(\"Invalid cookie. Required fields are empty\"); &#125; if (!remoteAddr.equals(request.getRemoteAddr())) &#123; throw new IllegalStateException(\"Invalid cookie. Required remote address does not match \" + request.getRemoteAddr()); &#125; final String agent = WebUtils.getHttpServletRequestUserAgent(request); if (!userAgent.equals(agent)) &#123; throw new IllegalStateException(\"Invalid cookie. Required user-agent does not match \" + agent); &#125; return value; &#125; 我们可以看出在ticket解决之后进行验证时获取的客户端ip是从：request.getRemoteAddr()获取的，这种方式获取在4、7层负载均衡的时候是无法获取真实的客户端ip。 接下来我们再看一下生成ticket的规则代码： public String buildCookieValue(final String givenCookieValue, final HttpServletRequest request) &#123; final StringBuilder builder = new StringBuilder(givenCookieValue); final ClientInfo clientInfo = ClientInfoHolder.getClientInfo(); builder.append(COOKIE_FIELD_SEPARATOR); builder.append(clientInfo.getClientIpAddress()); final String userAgent = WebUtils.getHttpServletRequestUserAgent(request); if (StringUtils.isBlank(userAgent)) &#123; throw new IllegalStateException(\"Request does not specify a user-agent\"); &#125; builder.append(COOKIE_FIELD_SEPARATOR); builder.append(userAgent); final String res = builder.toString(); LOGGER.debug(\"Encoding cookie value [&#123;&#125;]\", res); return this.cipherExecutor.encode(res); &#125; ticket的生成是从clientInfo.getClientIpAddress()获取客户端ip 我们再看org.apereo.inspektr.common.web.ClientInfo public ClientInfo(final HttpServletRequest request, final String alternateServerAddrHeaderName, final String alternateLocalAddrHeaderName, final boolean useServerHostAddress) &#123; try &#123; String serverIpAddress = request != null ? request.getLocalAddr() : null; String clientIpAddress = request != null ? request.getRemoteAddr() : null; if (request != null) &#123; if (useServerHostAddress) &#123; serverIpAddress = Inet4Address.getLocalHost().getHostAddress(); &#125; else if (alternateServerAddrHeaderName != null &amp;&amp; !alternateServerAddrHeaderName.isEmpty()) &#123; serverIpAddress = request.getHeader(alternateServerAddrHeaderName) != null ? request.getHeader(alternateServerAddrHeaderName) : request.getLocalAddr(); &#125; if (alternateLocalAddrHeaderName != null &amp;&amp; !alternateLocalAddrHeaderName.isEmpty()) &#123; clientIpAddress = request.getHeader(alternateLocalAddrHeaderName) != null ? request.getHeader (alternateLocalAddrHeaderName) : request.getRemoteAddr(); &#125; &#125; this.serverIpAddress = serverIpAddress == null ? \"unknown\" : serverIpAddress; this.clientIpAddress = clientIpAddress == null ? \"unknown\" : clientIpAddress; &#125; catch (final Exception e) &#123; throw new RuntimeException(e); &#125; &#125; 从中看出5.0.4版本支持了传入header的来自定义客户端ip获取 但是5.0.4依然有问题它没有改全，从上面的ticket生成逻辑(org.apereo.cas.web.support.DefaultCasCookieValueManager)中可以看出来，生成的时候是通过：clientInfo.getClientIpAddress()，但是验证的时候是通过：request.getRemoteAddr()获取验证的，所以只要加了4,7层负载的话就会存在这个问题。 以上就是整个问题的分析过程，接下来看我们怎么来解决这个问题。 解决方案cas在tikcet生成与验证的时候都有配置项提供自定义。 只要我们关闭ticket加解密就可以规避这个问题，但是安全性上稍微低一些，如果不想关闭ticket加解密休需要修改配置和代码。 如果开启cas.tgc.cipherEnabled=true 需要同时多台server配置相同的cas.tgc.signingKey、cas.tgc.encryptionKey保证cookie加解密秘钥相同 修改代码让验证cookie获取客户端ip保持一致，如果是cas server 5.0.4版本可以修改org.apereo.cas.audit.spi.config.CasCoreAuditConfiguration类中的org.apereo.inspektr.common.web.ClientInfoThreadLocalFilter增加初始化参数来自定义客户端ip获取headerName @Bean public FilterRegistrationBean casClientInfoLoggingFilter() &#123; final FilterRegistrationBean bean = new FilterRegistrationBean(); bean.setFilter(new ClientInfoThreadLocalFilter()); bean.setUrlPatterns(Collections.singleton(&quot;/*&quot;)); bean.setName(&quot;CAS Client Info Logging Filter&quot;); bean.addInitParameter(ClientInfoThreadLocalFilter.CONST_IP_ADDRESS_HEADER,&quot;X-Forwarded-For&quot;); return bean; &#125; 修改org.apereo.cas.web.support.DefaultCasCookieValueManager.obtainCookieValue代码，保持生成tikcet和验证ticket时获取客户端ip都使用clientInfo.getClientIpAddress() 关闭cas tgc的加解密：cas.tgc.cipherEnabled=false，牺牲安全性就可以规避这个问题 建议使用配置的方式来调整，这样可以充分的发挥集群的功能。 世界和平、Keep Real！","tags":[{"name":"trouble shooting","slug":"trouble-shooting","permalink":"https://ningyu1.github.io/tags/trouble-shooting/"},{"name":"CAS","slug":"CAS","permalink":"https://ningyu1.github.io/tags/CAS/"},{"name":"iphash","slug":"iphash","permalink":"https://ningyu1.github.io/tags/iphash/"},{"name":"TomcatRedisSessionManager","slug":"TomcatRedisSessionManager","permalink":"https://ningyu1.github.io/tags/TomcatRedisSessionManager/"},{"name":"Invalid cookie. Required remote address does not match ip","slug":"Invalid-cookie-Required-remote-address-does-not-match-ip","permalink":"https://ningyu1.github.io/tags/Invalid-cookie-Required-remote-address-does-not-match-ip/"}]},{"title":"Tomcat对[RFC 3986]规范的支持，导致一些特殊请求报错","date":"2019-06-26T09:46:21.000Z","path":"20190626/117-tomcat-RFC3986.html","text":"背景​ Tomcat在升级版本时遇到的一些问题，在升级tomcat版本后发现原有的功能莫名其妙的出现了错误，我们接下来看一下具体的问题以及分析一下具体的原因 问题分析我们来具体看一下报错的请求报文 http://localhost:8080/xx-rest/v1/report/salesOrder?salesStatusList[]=&amp;orderStatus=&amp;salesTypeList[]=&amp;itIsClose=&amp;salesNo=&amp;warehouseNo=&amp;orderNo=&amp;referenceNo=&amp;skuName=&amp;skuBarcode=&amp;shopNoList[]=&amp;creTimeBeg=2019-06-21+00:00:00&amp;creTimeEnd=2019-06-21+23:59:59&amp;platformOrderTimeBeg=&amp;platformOrderTimeEnd=&amp;endFinishTimeBeg=&amp;endFinishTimeEnd=&amp;page=1&amp;pageSize=50&amp;customerNo=&amp;__preventCache=1561084397458 调用后返回的是400的错误，并且进行了测试，当请求参数中存在[]时就会发生错误，去掉后可正常访问 我们查看到后台的错误具体如下： 2019/6/21 上午11:48:052019-06-21 11:48:05.590 [http-apr-8080-exec-3] INFO com.xxx.doFilter(CORSFilter.java:75) - CORS filter &gt;&gt;&gt;&gt;&gt;&gt; Because host:xxx.domain.com and origin:https://xxx.domain.com so Access-Control-Allow-Origin:https://xxx.domain.com2019/6/21 上午11:48:05Jun 21, 2019 11:48:05 AM org.apache.coyote.http11.AbstractHttp11Processor process2019/6/21 上午11:48:05INFO: Error parsing HTTP request header2019/6/21 上午11:48:05 Note: further occurrences of HTTP header parsing errors will be logged at DEBUG level.2019/6/21 上午11:48:05java.lang.IllegalArgumentException: Invalid character found in the request target. The valid characters are defined in RFC 7230 and RFC 39862019/6/21 上午11:48:05 at org.apache.coyote.http11.InternalAprInputBuffer.parseRequestLine(InternalAprInputBuffer.java:240)2019/6/21 上午11:48:05 at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1052)2019/6/21 上午11:48:05 at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:637)2019/6/21 上午11:48:05 at org.apache.tomcat.util.net.AprEndpoint$SocketWithOptionsProcessor.run(AprEndpoint.java:2492)2019/6/21 上午11:48:05 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)2019/6/21 上午11:48:05 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)2019/6/21 上午11:48:05 at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)2019/6/21 上午11:48:05 at java.lang.Thread.run(Thread.java:748) 非法参数：Invalid character found in the request target. The valid characters are defined in RFC 7230 and RFC 3986 意思说的是请求中包含了无效的字符，具体去看RFC 7230 and RFC 3986规范中的字符定义。 这个问题很纳闷！因为以前是没有遇到过的，于是先去看tomcat对RFC 7230 and RFC 3986规范的支持情况。 Tomcat从 7.0.73, 8.0.39, 8.5.7 版本后添加了对Url的限制，遵循的就是RFC 7230 and RFC 3986规范。那我们就先搞清楚规范中描述的是什么。 [RFC 3986]https://www.ietf.org/rfc/rfc3986.txt 我们只需关注规范中字符定义这块，我截图的地方 意思说的是规范中定义url中只允许包含英文字母(a-zA-Z)、数字(0-9)、-_.~四个特殊字符，保留字符用作特定领域分隔符，如果url中有用到需要进行转义 保留的字符有：! * ’ ( ) ; : @ &amp; = + $ , / ? # [ ] 我们知道了RFC3986规范中的定义和tomcat支持规范的版本后问题就很明了了，我们来看一下我们使用的tomcat版本具体是多少，经过查看具体如下： 环境 版本 UAT apache-tomcat-7.0.67 PRD apache-tomcat-7.0.67 dev、qa jdk7 使用的镜像是：tomcat:7，具体的tomcat版本是： Apache Tomcat/7.0.70 dev、qa jdk8 使用的镜像是：tomcat:7-jre8，具体的tomcat版本是：Apache Tomcat/7.0.88 问题就出在这里，我们使用的tomcat版本刚好是遵循RFC3986规范的tomcat版本。 解决办法知道了原因之后，具体的解决办法就比较明确了，大概有以下几种： 对请求编码解码。 encodeURI，decodeURI，但是有的时候参数名中出现保留字符是比较麻烦的，需要对参数名进行转义，后台再解析参数时需要先对参数名解码后再通过参数名获取具体参数值 tomcat降版本到7.0.73以下，这个是比较好操作的","tags":[{"name":"Tomcat","slug":"Tomcat","permalink":"https://ningyu1.github.io/tags/Tomcat/"},{"name":"RFC3986","slug":"RFC3986","permalink":"https://ningyu1.github.io/tags/RFC3986/"}]},{"title":"使用StopWatch优雅的输出执行耗时","date":"2019-05-05T05:20:21.000Z","path":"20190505/116-stop-watch.html","text":"背景​ 有时我们在做开发的时候需要记录每个任务执行时间，或者记录一段代码执行时间，最简单的方法就是打印当前时间与执行完时间的差值，然后这样如果执行大量测试的话就很麻烦，并且不直观，如果想对执行的时间做进一步控制，则需要在程序中很多地方修改，目前spring-framework提供了一个StopWatch类可以做类似任务执行时间控制，也就是封装了一个对开始时间，结束时间记录工具 示例我们来看几个示例 统计输出总耗时import org.springframework.util.StopWatch; public class SpringStopWatchExample &#123; public static void main (String[] args) throws InterruptedException &#123; StopWatch sw = new StopWatch(); sw.start(); //long task simulation Thread.sleep(1000); sw.stop(); System.out.println(sw.getTotalTimeMillis()); &#125;&#125; 输出 1013 输出最后一个任务的耗时public class SpringStopWatchExample2 &#123; public static void main (String[] args) throws InterruptedException &#123; StopWatch sw = new StopWatch(); sw.start(\"A\");//setting a task name //long task simulation Thread.sleep(1000); sw.stop(); System.out.println(sw.getLastTaskTimeMillis()); &#125;&#125; 输出 1009 以优雅的格式打出所有任务的耗时以及占比import org.springframework.util.StopWatch; public class SpringStopWatchExample3 &#123; public static void main (String[] args) throws InterruptedException &#123; StopWatch sw = new StopWatch(); sw.start(\"A\"); Thread.sleep(500); sw.stop(); sw.start(\"B\"); Thread.sleep(300); sw.stop(); sw.start(\"C\"); Thread.sleep(200); sw.stop(); System.out.println(sw.prettyPrint()); &#125;&#125; 输出 StopWatch &apos;&apos;: running time (millis) = 1031-----------------------------------------ms % Task name-----------------------------------------00514 050% A00302 029% B00215 021% C 序列服务输出耗时信息@Overridepublic long nextSeq(String name) &#123; StopWatch watch = new StopWatch(); watch.start(\"单序列获取总消耗\"); long sequence = generator.generateId(name); watch.stop(); logger.info(watch.prettyPrint()); return sequence;&#125; 更多用法不同的打印结果 getTotalTimeSeconds() 获取总耗时秒，同时也有获取毫秒的方法 prettyPrint() 优雅的格式打印结果，表格形式 shortSummary() 返回简短的总耗时描述 getTaskCount() 返回统计时间任务的数量 getLastTaskInfo().getTaskName() 返回最后一个任务TaskInfo对象的名称更多查看文档 总结以后我们统计代码执行效率建议大家都使用这个工具来进行输出，不需要在starttime、endtime再相减计算，用优雅的方式来完成这件事情。","tags":[{"name":"Java","slug":"Java","permalink":"https://ningyu1.github.io/tags/Java/"},{"name":"StopWatch","slug":"StopWatch","permalink":"https://ningyu1.github.io/tags/StopWatch/"},{"name":"Spring","slug":"Spring","permalink":"https://ningyu1.github.io/tags/Spring/"}]},{"title":"PageHelper生成Count语句逻辑分析","date":"2019-04-22T11:24:21.000Z","path":"20190422/115-mybatis-pagehelper-count.html","text":"背景在使用Mybatis分页插件时经常会遇到Mybatis生成的count语句效率很低，今天我们就看一下Mybatis中的countsql的生成逻辑是什么，为何会生成低效的countsql，怎么写sql可以避免低效countsql。 源码分析com.github.pagehelper.parser.CountSqlParser /** * 将sql转换为count查询 * * @param select */public void sqlToCount(Select select) &#123; SelectBody selectBody = select.getSelectBody(); // 是否能简化count查询 if (selectBody instanceof PlainSelect &amp;&amp; isSimpleCount((PlainSelect) selectBody)) &#123; ((PlainSelect) selectBody).setSelectItems(COUNT_ITEM); &#125; else &#123; PlainSelect plainSelect = new PlainSelect(); SubSelect subSelect = new SubSelect(); subSelect.setSelectBody(selectBody); subSelect.setAlias(TABLE_ALIAS); plainSelect.setFromItem(subSelect); plainSelect.setSelectItems(COUNT_ITEM); select.setSelectBody(plainSelect); &#125;&#125; /** * 是否可以用简单的count查询方式 * * @param select * @return */public boolean isSimpleCount(PlainSelect select) &#123; //包含group by的时候不可以 if (select.getGroupByColumnReferences() != null) &#123; return false; &#125; //包含distinct的时候不可以 if (select.getDistinct() != null) &#123; return false; &#125; for (SelectItem item : select.getSelectItems()) &#123; //select列中包含参数的时候不可以，否则会引起参数个数错误 if (item.toString().contains(\"?\")) &#123; return false; &#125; //如果查询列中包含函数，也不可以，函数可能会聚合列 if (item instanceof SelectExpressionItem) &#123; if (((SelectExpressionItem) item).getExpression() instanceof Function) &#123; return false; &#125; &#125; &#125; return true;&#125; 总结看代码比较清晰明了，话不多说，总结如下： sql包含group by的时候，会生成带子查询的低效countsql sql包含distinct的时候，会生成带子查询的低效countsql sql的列中包含参数的时候，会生成带子查询的低效countsql sql的列中包含函数的时候，会生成带子查询的低效countsql pagehelper官方最新版更新到了：5.1.6 5.1.5版本有一个优化是对函数进行区分，如果是聚合函数生成带子查询的countsql，如果非聚合函数生成简单的countsql。 具体可以查看：V5.1.5 changelog 看了一下4.2.1 —— 5.1.6之间的版本，除了5.1.5支持了函数区分的支持以外，其他版本没有countsql生成相关的优化，所以sql中包含group by、distinct、列中包含参数，聚合函数会生成低效的countsql。","tags":[{"name":"Java","slug":"Java","permalink":"https://ningyu1.github.io/tags/Java/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://ningyu1.github.io/tags/Mybatis/"},{"name":"PageHelper","slug":"PageHelper","permalink":"https://ningyu1.github.io/tags/PageHelper/"}]},{"title":"Mybatis PageHelper分页遇到的坑，莫名其妙的增加了limit ?,?","date":"2019-04-02T07:36:21.000Z","path":"20190402/114-mybatis-pagehelper-pit.html","text":"背景在使用Mybatis分页插件PageHelper的时候我相信或多或少都会遇到这样的问题，明明没有分页的语句执行后sql语句被自动添加了limit ？,?，看起来非常的莫名其妙，其实这个问题非常明确，就是Java基本功的问题，由于开发使用的是pagehelper.startPage方式，弄出这个问题就是对pagehelper的分页原理不理解而导致的。 首先我们先介绍一下Mybatis的分页用法。 Mybatis分页用法RowBounds用法显示的使用RowBounds参数，这种方法是最安全的，在经过Mybatis处理的时候会根据RowBounds参数来自动添加limit表达式，但是这种方法有个缺点，就是需要分页的方法都要增加RowBounds这个参数，其实也很正常，这也是最原始的用法，只是现在开发被惯叼了，又想少写代码又想使用最全的功能。 PageHelper用法使用pagehelper，这个是一个使用率最高的Mybatis分页插件，使用起来也比较方便，但是包装了很多高级的功能需要理解他的机制，要不然很容易写出bug，例如这次的问题，sql中明明没有使用分页，但是最后执行的sql语句中多了limit。 pagehelper的4.x以上的版本使用pageHelper.startPage方法来进行分页，这种方法是在需要执行的sql之前调用一次，例如： PageHelper.startPage(1, 10);list = countryMapper.selectIf(param1); PageHelper优缺点优点： 使用简单 对sql无侵入 缺点： 不是及其安全的方式（至少跟采用RowBounds参数进行分页的方式来比较） PageHelper分页原理PageHelper采用ThreadLocal来进行分页标识设置，pagehelper保证的是当代码执行到Executor 方法时出现错误，它会在finally快中清理ThreadLocal中的分页标识，如果代码没有执行到Executor方法就出现异常，那就会造成ThreadLocal污染。当我们执行PageHelper.startPage(1, 10);这一行的时候，其实是在当前线程的ThreadLocal中设置了分页的变量，当执行到countryMapper.selectIf(param1);的时候会通过Executor拦截，从ThreadLocal中获取分页标记，如果存在分页标记就在当前执行的sql语句中增加分页表达式，当Executor拦截执行的时候finally中会清理ThreadLocal中的分页变量。 问题分析接下来让我们看一下出现的错误 2019-03-28 00:00:00.150 [DubboServerHandler-xx.xx.xx.xx:yyyy-thread-191] DEBUG org.apache.ibatis.logging.jdbc.BaseJdbcLogger.debug(BaseJdbcLogger.java:139) - ==&gt; Preparing: SELECT id, job...skipping...### The error may involve xx.yy.zz.XXXXMapper.loadExpress-Inline### The error occurred while setting parameters### SQL: select field as fieldName from table where field= ? order by id ASC limit 1 limit ?,?### Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &apos;limit 0,50&apos; at line 5; bad SQL grammar []; nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &apos;limit 0,50&apos; at line 5, dubbo version: 2.5.3, current host: 10.24.232.204 #-# org.springframework.jdbc.BadSqlGrammarException:### Error querying database. Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &apos;limit 0,50&apos; at line 5### The error may exist in URL [jar:file:/usr/local/dubbo/xxx/lib/xxx-yyy-1.0.0.jar!/sqlMap/express/XXXXMapper.xml]### The error may involve xx.yy.zz.XXXXMapper.loadExpress-Inline### The error occurred while setting parameters### SQL: select field as fieldName from table where field= ? order by id ASC limit 1 limit ?,?### Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &apos;limit 0,50&apos; at line 5; bad SQL grammar []; nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &apos;limit 0,50&apos; at line 5 我们来看一下方法实现代码 @Overridepublic XXXVo loadExpress(param)&#123; XXXEntity param = new XXXEntity(); param.setBusinessNo(businessNo); XXXEntity entity = XXXMapper.loadExpress(param); //省略无关代码&#125; 我们看一下sqlmap &lt;select id=&quot;loadExpress&quot; parameterType=&quot;xx.yy.zz.XXXEntity&quot; resultType=&quot;xx.yy.zz.XXXEntity&quot;&gt; select field as fieldName from table where business_no= #&#123;businessNo&#125; order by id ASC limit 1&lt;/select&gt; 这个方法是唯一入口，并且没有执行pagehelper.startPage，但是语句在执行的时候自动加了limit 0,50，这个分页的数据非常像是页面的列表查询设置的分页变量。 其实问题所在是执行线程被污染，因为我们都是使用线程池的，当前执行所用的线程是会被放回池子中被反复使用的，如果某个执行污染了线程那就会影响下一个执行的代码。 我们来举个例子，看如下代码： public void method01() &#123; //@1 PageHelper.startPage(1, 10); //@5 List&lt;Country&gt; list; if(param1.get() != null)&#123; //@2 list = countryMapper.selectIf(param1); &#125; else &#123; list = new ArrayList&lt;Country&gt;(); &#125;&#125; public List&lt;Country&gt; method02() &#123; //@3 List&lt;Country&gt; list = countryMapper.selectNotPage(param1); //@4 return list;&#125; 假设我们一个请求进来调用method01()方法，随后另外的请求进来调用的是method02()方法，假定我们的线程池数量是1，让两个请求使用同一个线程。 请求从@1处进入 执行到@2处发生了NullPointException异常 随后的请求从@3处进入 执行@4处时执行的sql会被自动添加limit ?,?。 错误原因因为前一个请求执行@5处时设置了分页标识到ThreadLocal中，当执行到@2处时触发了异常，@5处设置的分页变量没有被消费和清理，线程被污染，因此另一个请求进来复用了这个线程，当执行到@4处时PageHelper拦截器从ThreadLocal中获取到分页变量并自动增加了limit ?,?语句。 解决方法推荐使用的方式在执行PageHelper.startPage(1, 10);之后紧跟着执行Executor，避免这两行之间出现错误，将我们上图举例中的代码修改一下如下： public void method01() &#123; List&lt;Country&gt; list; if(param1.get() != null)&#123; //两行紧挨着执行，避免出现异常 PageHelper.startPage(1, 10); list = countryMapper.selectIf(param1); &#125; else &#123; list = new ArrayList&lt;Country&gt;(); &#125;&#125; ps. 要保证两行紧挨着执行，并且在执行了PageHelper.startPage之后与countryMapper.selectIf之前保证不会出错误。 不推荐使用方式使用finally快进行清理，如下图： public void method01() &#123; List&lt;Country&gt; list; if(param1.get() != null)&#123; //修改面太大，代码侵入太多 try &#123; PageHelper.startPage(1, 10); list = countryMapper.selectIf(param1); &#125; finally &#123; PageHelper.clearPage(); &#125; &#125; else &#123; list = new ArrayList&lt;Country&gt;(); &#125;&#125; ps. 参考pagehelper的安全使用指南 总结只有理解了pagehelper的分页机制之后才能别面写法带来的bug，我相信当我提到pagehelper采用ThreadLocal实现的分页标识传递时，应该有很多人已经明白了问题所在。任何通过ThreadLocal传递变量时都有可能出现线程污染的问题，尽量规避掉。 ThreadLocal传递变量是个非常好的方式，俗称为隐士传参，具有包装透明的效果，正因为这个特性更要注意安全清理的问题，需要全面思考代码执行过程中是否会出现错误，出现错误是否能友好的清理掉线程中透传的变量，如果处理不得当就会造成线程污染。","tags":[{"name":"Java","slug":"Java","permalink":"https://ningyu1.github.io/tags/Java/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://ningyu1.github.io/tags/Mybatis/"},{"name":"PageHelper","slug":"PageHelper","permalink":"https://ningyu1.github.io/tags/PageHelper/"}]},{"title":"Java对象复制类库性能对比","date":"2019-03-22T08:03:21.000Z","path":"20190322/113-object-copy.html","text":"背景在开发中我们经常会用到对象之间的互相拷贝，Java中对象拷贝的类库也比较多，常见的有Spring BeanUtils，Apache BeanUtils，等并且在很多大厂公司对对象拷贝也有详尽的说明，避免大家踩坑。 功能对比 耗时(毫秒) 1000次 10,000次 100,100次 Apache BeanUtils 298 983 4211 Cglib BeanCopier 89 120 203 Spring BeanUtils 92 160 524 性能对比 Apache BeanUtils Cglib BeanCopier Spring BeanUtils 非public类 不支持 支持 支持 基本类型与装箱类型，int-&gt;Integer，Integer-&gt;int 支持，可以copy 不支持，不copy 不支持，不copy int-&gt;long，long-&gt;int，int-&gt;Long，Integer-&gt;long 不支持 不支持 不支持 源对象相同属性无get方法 不支持 不copy 不支持 不copy 不支持 不copy 目标对象相同属性无get方法 支持 不支持 支持 目标对象相同属性无set方法 不copy，不报错 报错 不copy，不报错 源对象相同属性无set方法 支持 支持 支持 目标对象相同属性set方法返回非void 不设置，其他正常属性可以copy 不设置，导致其他属性都无法copy 支持，能够copy 目标对象多字段 支持 支持 支持 目标对象少字段 支持 支持 支持 结论从性能对比来看： cglib的BeanCopier最好， Spring BeanUtils稍微差点，但也还可以，Apache BeanUtils性能最差 从功能对比来看，cglib 在set方法返回非void时，会导致其他属性无法copy，目标没有set方法时，会报错，还存在并且有多项不支持的情况","tags":[{"name":"Java","slug":"Java","permalink":"https://ningyu1.github.io/tags/Java/"},{"name":"对象拷贝","slug":"对象拷贝","permalink":"https://ningyu1.github.io/tags/对象拷贝/"}]},{"title":"谈一谈前后端分离的优劣势","date":"2019-03-11T11:11:21.000Z","path":"20190311/112-front-end-and-back-end-separation.html","text":"从公司内网转载一篇同事整理的资料，关于前后端分离的优劣方面，整理的比较全面，推荐不明白为什么要前后端分离的同学阅读。 首先说明：前后端分离并非仅仅只是一种开发模式，而是一种架构模式（前后端分离架构）。 开发模式对比 序号 老的开发模式（后端以Java为例） 新的开发模式（后端以Java为例） 1 产品经理/领导/客户提出需求 产品经理/领导/客户提出需求 2 UI做出设计图 UI做出设计图 3 前端工程师做html页面 前后端约定接口&amp;数据&amp;参数 4 后端工程师将html页面套成jsp页面 前后端并行开发 5 集成出现问题 前端返工 后端返工 前后端集成 6 二次集成 集成成功 交付 前端页面调整 集成成功 交互 请求方式对比 序号 老的开发模式（后端以Java为例） 新的开发模式（后端以Java为例） 1 客户端请求 浏览器发送请求 2 服务端的servlet或controller接收请求 直接到达html页面（前端控制路由与渲染页面，整个项目开发的权重前移） 3 调用service,dao代码完成业务逻辑 html页面负责调用服务端接口产生数据 4 返回jsp jsp展现一些动态的代码 填充html，展现动态效果，在页面上进行解析并操作DOM或数据 前后端分离的优势 序号 优势 1 可以实现真正的前后端解耦，前端服务器使用nginx，后端/应用服务器使用tomcat，加快整体响应速度 2 发现bug，可以快速定位是谁的问题，不会出现互相踢皮球的现象 3 减少后端服务器的并发/负载压力 4 即使后端服务暂时超时或者宕机了，前端页面也会正常访问，只不过数据刷不出来而已 5 多端应用 6 页面显示的东西再多也不怕，因为是异步加载 7 增加代码的维护性&amp;易读性 8 提升开发效率，因为可以前后端并行开发，而不是像以前的强依赖 9 前端大量的组件代码得以复用，组件化，提升开发效率，抽出来 10 在nginx中部署证书，外网使用https访问，并且只开放443和80端口，其他端口一律关闭（防止黑客端口扫描），内网使用http，性能和安全都有保障。 11 nginx支持页面热部署，不用重启服务器，前端升级更无缝。 12 前端项目中可以加入mock测试（构造虚拟测试对象来模拟后端，可以独立开发和测试） 前后端分离的劣势有联调、沟通环节，这个过程非常花时间，也容易出bug，还很难维护。 前后端分离-术业有专攻后端： 把精力放在 高并发，高可用，高性能，安全，存储，业务等等研究上 例如：设计模式，原理及源码，事务隔离与锁机制，http/tcp，多线程，分布式架构，弹性计算架构，微服务架构，性能优化，以及相关的项目管理等等 前端： 把精力放在页面表现，速度流畅，兼容性，用户体验等等 例如：html5，css3，jquery，angularjs，reactjs，vuejs，webpack，less/sass，gulp，nodejs，Google V8引擎，javascript多线程，模块化，面向切面编程，设计模式，浏览器兼容性，性能优化等等 总结 序号 总结 1 前后端分离并非仅仅只是一种开发模式，而是一种架构模式（前后端分离架构）。 2 千万不要以为只有在撸代码的时候把前端和后端分开就是前后端分离了，需要区分前后端项目。 3 前端项目与后端项目是两个项目，放在两个不同的服务器，需要独立部署，两个不同的工程，两个不同的代码库，不同的开发人员。 4 前后端工程师需要约定交互接口，实现并行开发，开发结束后需要进行独立部署，前端通过ajax来调用http请求调用后端的restful api。 5 前端只需要关注页面的样式与动态数据的解析&amp;渲染，而后端专注于具体业务逻辑。","tags":[{"name":"前后端分离","slug":"前后端分离","permalink":"https://ningyu1.github.io/tags/前后端分离/"}]},{"title":"谈一谈开发团队代码质量如何管控与提升","date":"2019-03-07T06:37:21.000Z","path":"20190307/111-code-quality-management.html","text":"今天我们谈一下开发团队代码质量如何做到管控与提升，我相信很多公司都会面临这样的问题，开发团队大人员技术水平参差不齐，代码写的不够规范，代码扫描问题修改太过滞后，代码库管理每个团队都不一致，偶尔还会合并丢失一些代码，code review费人费时效率不高，开发任务的管理以及任务与代码的可追溯问题，等等之类的问题，我们能否制定一套从设计到开发再到交付一整套的管控方案来帮助开发团队管控代码的质量？下来我就针对这些问题展开来谈谈我的想法。 举个例子比如说我们要增加代码和任务之间的可追溯性，我们可能考虑采用git+jira关联的方式对开发人员每笔提交在提交comment中增加jira编号，这是就是一个规范，但是规范落地如何检查？开发人员如果忘记在comment中添加就会造成关联失败，那我们就要采用工具的方式帮助开发人员在提交时检查comment是否符合规范。 比如说我们有制定编码规范，也采用了sonar去扫描代码的问题，但是这个方式的缺点是太过滞后，需要质量人员跟进去推动并且效果也不是很好，我们是否可以考虑前置检查点帮助开发人员在代码编写和提交时能主动的发现问题，在代码提交的时候发现规范问题可以直接进行解决再提交，我们可以考虑采用git加checkstyle、pmd、fingbug等工具插件，在代码提交的时候进行规范检测并且进行告警，这样就可以很好的帮助开发人员及时的发现问题，并不是开发已经提交了再去sonar上检查代码规范来发现问题再事后的安排人员去解决，开发人员都有一个习惯，当功能开发好没有问题后他们很少会去主动的修改与重构代码，这样就会导致迟迟不能推进，我们提前了检查点帮助开发人员及时发现问题就可以更好的推行规范的落地。 因此我们要考虑提供一整套代码质量管理的机制，应用在开发全生命周期中，并在关键的流程节点进行验证，从而把控与提升代码的质量。 常见的问题及我的看法静态代码扫描太滞后，推进吃力我相信大多都会使用类似sonar这类的静态代码检查工具来检查代码，这里我们不说工具的好坏，我们只说检查问题的修复情况，我相信很多开发都会有一种习惯，在代码写完之后如果上线没有问题的话他们是很少会去主动的优化代码，即使你扫描结果告诉他他也会有各种理由推脱，当然我们可以通过管理的手段强制他们修改，比如说blocker、critical级别的必须全部改掉，其余的看情况修改，当然通过管理手段从上往下会有一定的效果，但是这些都是比较滞后的方式，我们能不能提前发现问题让开发在功能开发过程中就把发现的问题改掉？ 这个当然是可以的，我们可以利用代码检查的机制，在代码开发中就让开发去扫描发现问题，在代码提交的时候去校验如果有严重的禁止代码提交。这样一来我们就可以提前来发现并解决问题，这样可能会带来的是开发人员的排斥，开发人员都觉得自己代码写的没有问题，所以这块我们需要把控这个检查规则的宽松度，我们可以结合公司的开发规范，整理不同级别的问题，通过先简后严的方式，先把开发的习惯培养起来后再逐渐的提升严格度，这样一来开发就有个适应期也比较好接受，比如说：我们通过checkstyle的规则模板定义，前期把一些无用导入包、命名不规范、导入包用*、system.out语句这类接受度高的作为error级别来推动开发适应从而培养这种良好的习惯。 团队Code Review没有跑起来或跑的太费事费力在技术行业做了一定时间的人应该都知道code review是多么的重要，一可以促进团队人员之间互相交流，二可以提升整体团队的技术水平，学习优秀人员写的代码，帮助初级人员提升代码编写能力，所以code review还是强烈必须要做的，至于怎么做code review？我谈一下我的想法和建议 比较常见的方式是定期团队内组织全体人员进行集中式的code review，我比较推荐利用工具在线的操作方式来做code review，现在开源非常的火也可以参考学习开源团队code review的方式，比如说github有pull request，gitlab有merge request，可以在这个合并代码的节点上进行code review，这样做的好处是第一比较开放，只要能看到合并代码请求的都可以进行review，第二可以留下review记录，互相的想法沟通和建议可以很好的留存下来并且可以通过UI的方式友好的展示出来，从而提升code review效率。 这个当然需要结合git flow的机制来协作完成。 代码库分支、版本管理不规范，合并丢代码团队多了或团队大了，每个人或多或少对git的管理与使用理解不一致，这样就造成了分支、版本管理的混乱，这样在版本代码合并时就会产生很多冲突，我们可以指定一套规范性的东西，指导开发团队进行分支、版本的管理，这里说到的是指导不是限制，要让开发在可控的范围内自由发挥。 可以参考git flow、github flow等，当然我们要统一一个工作流程推广给开发团队中。 前面我们说了用代码合并来进行code review，这样我们就要让开发人员在每开发完一个任务的时候就要进行一次代码合并，git是一个优秀的分布式代码库管理工具，我们利用git的分布式特性，以及灵活的流程机制来规范大家的使用。 例如： 一次迭代冲刺或一个版本对应一个develop-*分支和release-*，并且控制分支的push与merge权限，固定一个master分支并且控制master分支的权限，让个人开发通过feature-{username|功能名称}-*分支来进行功能开发，当一个任务或者一个功能开发完成进行一次develop-*分支的合并，这样一来及可以code review也可以有序的管理分支上的代码，当开发人员提交合并请求时发生了冲突就需要开发人员自己解决完冲突后再进行代码合并请求，这样一来版本分支上代码是有序的。 Name From Remark master - 只能有一个并并且固定的 develop-* 从master创建 开发分支，可以结合jira的sprint，一个sprint对应一个，迭代开始时创建，’*’ 通常可以是一个发布周期或者一个冲刺命名 release-* 从master创建 预发布分支，可以结合jira的sprint，一个sprint对应一个，迭代开始时创建，’*’ 通常可以是一个发布周期或者一个冲刺命名 feature-{username or 功能名称}-* 从develop-*创建 开发人员分支，这个分支的声明周期很短，在这个功能开发完成通过Merge Request发起合并进行code review之后合并从而删除分支 以上可以定位分支约定。 具体的操作可以参考下面描述： sprint开始时（需求确认后），从master创建develop分支，例如是develop-V1.2.0 开发人员从对应的develop分支创建自己的feature分支进行开发 如果master分支发生变更，需要从master分支合并到对应的develop分支、可以考虑定期合并一次 feature分支合并到对应的develop之前，需要从develop分支合并到feature分支（这个避免和其他人提交进行冲突，规范开发人员自己解决掉冲突后才能发起合并请求） feature分支合并到对应的develop之后，发布到测试环境进行测试（测试环境直接使用对应的develop分支） develop分支在测试环境测试通过之后，合并到对应的release分支并发布到预发布环境（UAT）进行测试 release分支在预发布环境（UAT）验证通过后，合并到master分支并发布到生产环境进行验证 发布到生产环境后从master分支构建对应的版本tag 可同时支持多个sprint的并行。 代码提交备注写的很难懂甚至很随意代码的提交备注非常重要，尤其是在合并代码时产生冲突，第一时间肯定是根据提交日期去看本次提交做了什么修改，如果说备注随便填写，或者有些都没有填这样在回头来看的时候，及时是提交本人他也不能第一时间看出具体做了哪些修改，因此我觉得作为一个开发人员提交备注写的清晰明了是一件必备的职业素养，至于一些不按照规范的技术人员我们也可以要求他们按照规范必须填写。 那如何做到对备注填写的质量把控呢？我们可以通过版本管理工具在提交代码时进行提交备注检测，比如说对长度的限制，至少要15个字符，或者对格式做一些验证，必须包含任务编号之类，这样一来就可以有效的控制代码提交备注的质量以及可读性。 我们现在常用的git就有hook机制可以提供在代码提交前后做一些钩子，利用钩子来控制允许提交或者拒绝提交，比如说git的pre-commit和commit-msg 开发人员的任务管理与提交代码没有关联，无法查看某个任务具体提交了哪些代码优秀的开发人员主动性都是很好的，主动性对开发来说也是非常重要的职业素养，不要让人催促你来完成任务，自己要学会主动找任务去做主动想如何优化与提升，所以时间任务管理是非常重要的，我任务开发人员都应该具备自己的时间任务管理能力，无论用什么工具只要能管理跟踪好自己的任务就是不错的人员。 公司一般都有任务管理工具，有的用禅道、有的用jira，现在用jira的相对多一些，jira的功能丰富也可以促进团队进行敏捷的任务管理，我们可以通过打通任务管理工具和代码版本工具，让代码提交的时候通过任务编号产生关联，从而可以在任务中看到代码修改的片段。 这里我用jira+git举个例子，比如说我们利用jira做scrum的敏捷管理，在制定好epic、story、task、subtask后，可以通过scrum模型的管理手段，在开发过程中通过插件、图标的数据来分析是否有风险？那个人的任务delay？那个人的任务制定还可以再进行拆分？等，从而尽早的做出调整来控制整个迭代周期按时完成。利用git提交的备注写入jira编号，通过jira和git的插件打通任务与提交代码的关联，这样一来我们就可以很好的看到任务执行过程数据与具体改动了哪些代码，从而提升开发效率。 统一管理校验规则版本，由简到严循序渐进的方式提升代码质量我们上面说到的利用了checkstyle来验证代码风格，通过git hook来控制提交备注的规范，这些都需要自定义一些脚本，这些脚本也应该利用git进行有效的管理，我们能力能做到统一的调整了规则与脚本，开发过程中的应用立即使用最新的验证规则？还有git hooks的脚本是在开发机器本地运行的，这样就带来了一个问题如何让开发去安装脚本呢？叫他们手动安装？写个bat或shell脚本让开发执行一次？ 我觉得更好的方式是对开发透明在他们不知觉的时候已经悄悄的安装，我们可以利用git对规则与脚本的版本进行管理，利用nginx可以通过http方式直接访问规则与脚本文件，通过自定义maven plugin在代码build的时候验证开发机器上是否已经安装，如果没有就给它自动安装与自动更新。 这样我们只要修改了规则与脚本后进行版本发布，开发机就会自动的更新下来从而可以立即生效。 开发团队技术氛围低沉很多公司开发团队一味的满头苦干，很容易忽视团队内的技术分享，再加上团队内人员进进出出有一些正能量的人当然也有一些负能量的人，这都是常事，但是不管怎样我相信做技术的人都愿意提升自己的技术能力，不管是工作中实践学习还是说参加沙龙或者论坛，都是很好的学习渠道，人的精力也是比较有限不可能关注很多面，通过团队内的技术分享，把每个人擅长的部分分享给大家，互相学习来提升凝聚力和团队整体的技术水平，这样长期以来我相信团队内的技术氛围肯定不会差。 总结以上就是我对代码质量管理与提升方面的经验与思考，里面涉及到很多东西，有流程的制定、工具的协作、工具的打通、规范的制定等，因此这是一个系统性的方案，希望可以利用一整套代码质量管理的流程，在关键的流程节点来把控代码的质量，形成闭环，希望可以帮助有需要的人，如果有更好的建议也希望大家多提意见进行补充，没有完美的方式，只有找到适合的可落地的就是好的。","tags":[{"name":"代码质量管理","slug":"代码质量管理","permalink":"https://ningyu1.github.io/tags/代码质量管理/"},{"name":"git flow","slug":"git-flow","permalink":"https://ningyu1.github.io/tags/git-flow/"},{"name":"jira git","slug":"jira-git","permalink":"https://ningyu1.github.io/tags/jira-git/"},{"name":"code review","slug":"code-review","permalink":"https://ningyu1.github.io/tags/code-review/"},{"name":"git hook","slug":"git-hook","permalink":"https://ningyu1.github.io/tags/git-hook/"},{"name":"check style","slug":"check-style","permalink":"https://ningyu1.github.io/tags/check-style/"}]},{"title":"疑似Batch处理事务问题，保存了该回滚的数据","date":"2019-02-20T06:34:21.000Z","path":"20190220/110-mybatis-batch.html","text":"这篇文章转自公司内网wiki中一篇不错的问题分析文章， 问题描述 两个事物， 在第一个事务报错是则执行第二个事务 两个事物都是执行下面的批量操作 两个事务的批量操作是插入到相同的两张表中，如下代码 第一个事务预计在第一个表中插入3条记录， 第二个表中插入3条记录，但是第一个表的第一个记录就违反了约束，报错异常； 第一个事务失败后，执行第二个事务，第二个事务插入两个表中各一条记录。 实际结果：第一个表有一条记录（第二个事务中插入的），第二个表中有4条记录（除了第二个事务中的一条，还有第一个事务中的3条数据） 问题点是在第一个事务抛异常回滚了，第一个表成功回滚，但是第二个事务将第一个事务中的第二个表的数据提交了。 问题原因 我们说明批量操作是指：如下的样例:insert into t(field) values(v1),(v2),(v3) sqlSession.commit();实际上并不是事务的commit，而只是执行sql 2个事务绑定的是同一个connection。 在一个mybatis的sqlSession 批量中操作两张表，则会生成两个prepareStatement， 而prepareStatement对象在mybatis中有cache。 回滚时回滚到savepoint 基于上面6点， 当第一个事务的第一个表执行是失败后（在第一个表的失败位置上设置一个savepoint，回滚时值回滚到这个savepoint，第二个preparestatement被缓存了） 问题总结 本问题不设计到事务传播机制与隔离级别 本例为一个错误使用范例，即不能在一个mybatis的sqlSession批量中操作两张表 注意：PreparedStatement确实适合执行相同sql的批处理，Statement适合执行不同sql的批处理 一些代码跟踪截图这里就不方便放出来请见谅。","tags":[{"name":"mybatis","slug":"mybatis","permalink":"https://ningyu1.github.io/tags/mybatis/"},{"name":"batch","slug":"batch","permalink":"https://ningyu1.github.io/tags/batch/"}]},{"title":"RESTful开发日期类型字段如何正确传递","date":"2019-02-12T07:30:21.000Z","path":"20190212/109-restful-date-convert.html","text":"RESTful开发时经常会遇到参数传入日期类型及返回的日期类型值，日期和时间戳如果没有适当和一致地处理，就会给人带来头痛的问题，我这里建议大家使用统一格式化的时间字符串yyyy-MM-dd HH:mm:ss，为什么建议这个呢？这样看起来比较直观，前后端联调起来比较高效。 下面我们就细说一下日期类型的参数将如何处理。 GET方法时参数传入日期类型该如何处理举例 url如下： http://localhost:8081/test/time_get?time=2018-07-09 10:38:57 Controller代码： import java.util.Date;@RequestMapping(value = &quot;/time_get&quot;, method = RequestMethod.GET)@ResponseBodypublic Response&lt;Date&gt; time_get(Date time) &#123; logger.info(&quot;time:&#123;&#125;&quot;, time); return Response.createResponse(time);&#125; 在这种情况下日期参数是无法成功的传入到controller方法里，会爆出如下的异常： org.springframework.core.convert.ConversionFailedException: Failed to convert from type java.lang.String to type java.util.Date for value &apos;2018-07-09 10:38:57&apos;; nested exception is java.lang.IllegalArgumentExceptionat org.springframework.core.convert.support.ObjectToObjectConverter.convert(ObjectToObjectConverter.java:81) ~[spring-core-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.core.convert.support.ConversionUtils.invokeConverter(ConversionUtils.java:35) ~[spring-core-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.core.convert.support.GenericConversionService.convert(GenericConversionService.java:178) ~[spring-core-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.beans.TypeConverterDelegate.convertIfNecessary(TypeConverterDelegate.java:161) ~[spring-beans-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.beans.TypeConverterDelegate.convertIfNecessary(TypeConverterDelegate.java:93) ~[spring-beans-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.beans.TypeConverterSupport.doConvert(TypeConverterSupport.java:64) ~[spring-beans-4.0.0.RELEASE.jar:4.0.0.RELEASE] ... 43 common frames omittedCaused by: java.lang.IllegalArgumentException: null at java.util.Date.parse(Date.java:615) ~[na:1.7.0_45] at java.util.Date.&lt;init&gt;(Date.java:272) ~[na:1.7.0_45] at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[na:1.7.0_45] at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) ~[na:1.7.0_45] at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[na:1.7.0_45] at java.lang.reflect.Constructor.newInstance(Constructor.java:526) ~[na:1.7.0_45] at org.springframework.core.convert.support.ObjectToObjectConverter.convert(ObjectToObjectConverter.java:76) ~[spring-core-4.0.0.RELEASE.jar:4.0.0.RELEASE] ... 48 common frames omitted 那如何解决上面的问题？使用@DateTimeFormat(pattern = &quot;yyyy-MM-dd HH:mm:ss&quot;)加到日期参数之前，像下面那样使用一样。 Controller代码： import java.util.Date; @RequestMapping(value = &quot;/time_get&quot;, method = RequestMethod.GET)@ResponseBodypublic Response&lt;Date&gt; time_get(@DateTimeFormat(pattern = &quot;yyyy-MM-dd HH:mm:ss&quot;) Date time) &#123; logger.info(&quot;time:&#123;&#125;&quot;, time); return Response.createResponse(time);&#125; 提示：年月日：pattern=”yyyy-MM-dd”，年月日时分秒：pattern=”yyyy-MM-dd HH:mm:ss” 请求体： GET /test/time_get1?time=2018-07-09 11:31:00 HTTP/1.1Host: localhost:8081 后端接收到的信息，debug截图： POST方法时参数传入日期类型该如何处理当使用@RequestBody接受一个VO对象时@DateTimeFormat就会失效，因为我们走的是Json序列化与反序列化，@DateTimeFormat只会生效与object序列化、反序列化。如果使用的Spring可以自定义messageConvert或者增强MappingJackson2HttpMessageConverter中的ObjectMapper 代码如下： import java.text.SimpleDateFormat;import java.util.ArrayList;import java.util.List;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.http.converter.HttpMessageConverter;import org.springframework.http.converter.json.MappingJackson2HttpMessageConverter;import org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport;import org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping;import com.fasterxml.jackson.databind.DeserializationFeature;import com.fasterxml.jackson.databind.ObjectMapper;@Configurationpublic class WebConfig extends WebMvcConfigurationSupport &#123; @Override protected void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; List&lt;HttpMessageConverter&lt;?&gt;&gt; messageConverters = new ArrayList&lt;HttpMessageConverter&lt;?&gt;&gt;(); addDefaultHttpMessageConverters(messageConverters); for (int i = 0; i &lt; messageConverters.size(); i++) &#123; HttpMessageConverter&lt;?&gt; mc = messageConverters.get(i); if (mc instanceof MappingJackson2HttpMessageConverter) &#123; ObjectMapper objectMapper = new ObjectMapper(); //当json中属性在反序列化时，javabean中没有找到属性就忽略，如果FAIL_ON_UNKNOWN_PROPERTIES=true找不到属性会报错 objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false); //设置序列化、反序列化时日期类型的格式 objectMapper.setDateFormat(new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;)); ((MappingJackson2HttpMessageConverter) mc).setObjectMapper(objectMapper); &#125; converters.add(mc); &#125; &#125;&#125; 注意：使用Jackson进行json序列化反序列化，默认可以处理yyyy-MM-dd这个格式，但是反序列化后的时间会差8小时 通过上面对json序列化反序列化的配置后日期参数处理就变的简单了，效果如下。 Controller代码： @RequestMapping(value = &quot;/time_post&quot;, method = RequestMethod.POST)@ResponseBodypublic Response&lt;Date&gt; time_post(@RequestBody TestVo vo) &#123; logger.info(&quot;time:&#123;&#125;&quot;, vo.getTime()); return Response.createResponse(vo.getTime());&#125; VO代码： public class TestVo implements Serializable &#123; private static final long serialVersionUID = 7435595656552442126L; private Date time; public Date getTime() &#123; return time; &#125; public void setTime(Date time) &#123; this.time = time; &#125;&#125; 提示：VO中无需使用@DateTimeFormat，就是一个普通的javabean即可 请求体： POST /test/time_post HTTP/1.1Host: localhost:8081Content-Type: application/json&#123; &quot;time&quot;:&quot;2018-07-09 15:31:00&quot;&#125; 后端接收到的信息，debug截图 PUT方法时参数传入日期类型该如何处理如果put传参方式与get一样在方法上直接传参（url?time=2018-07-09 10:38:57），那参考get请求参数处理方式即可 如果put传参方式与post一样使用@RequestBody传入json格式数据，那么参考post请求参数处理方式即可 请求体： PUT /test/time_put HTTP/1.1Host: localhost:8081Content-Type: application/json&#123; &quot;time&quot;:&quot;2018-07-09 15:31:00&quot;&#125; 后端接收到的信息，debug截图 前面都说的是request时日期格式处理方式，那么我们继续说一下response时日期格式如何处理。 Response中日期格式该如何处理SpringMVC使用@ResponseBody时，日期格式默认显示为时间戳，不管方法直接返回Date类型、或者VO类型时，时间格式都一样返回时间戳，例如这样。 请求体： POST /test/time_post1 HTTP/1.1Host: localhost:8081Content-Type: application/json&#123; &quot;time&quot;:&quot;2018-07-09&quot;&#125; 响应体： &#123; &quot;code&quot;: &quot;&quot;, &quot;message&quot;: &quot;&quot;, &quot;items&quot;: &#123; &quot;time&quot;: 1531094400000 &#125;&#125; 那如果我们要以字符串格式返回呢，那该如何处理？ 方法一增加统一的messageConvert处理： 如果使用的spring可以自定义messageConvert或者增强MappingJackson2HttpMessageConverter中的ObjectMapper 代码在POST方法时参数传入日期类型该如何处理这个章节 方法二通过@JsonFormat注解处理： 请在VO对象的date字段上加上@JsonFormat(pattern=&quot;yyyy-MM-dd HH:mm:ss&quot;,timezone = &quot;GMT+8&quot;),例如下面代码： VO代码： public class TestVo implements Serializable &#123; private static final long serialVersionUID = 7435595656552442126L; @JsonFormat(pattern=&quot;yyyy-MM-dd HH:mm:ss&quot;,timezone = &quot;GMT+8&quot;) private Date time; public Date getTime() &#123; return time; &#125; public void setTime(Date time) &#123; this.time = time; &#125;&#125; 注意：@JsonFormat(pattern=”yyyy-MM-dd HH:mm:ss”,timezone = “GMT+8”) ，即可将json返回的对象为指定的类型。 返回日期格式使用的是”yyyy-MM-dd HH:mm:ss”样式字符串示例： 请求体： POST /test/time_post1 HTTP/1.1Host: localhost:8081Content-Type: application/json&#123; &quot;time&quot;:&quot;2018-07-09 15:31:00&quot;&#125; 响应体： &#123; &quot;code&quot;: &quot;&quot;, &quot;message&quot;: &quot;&quot;, &quot;items&quot;: &#123; &quot;time&quot;: &quot;2018-07-09 15:31:00&quot; &#125;&#125; 日期格式处理规范这里有的人喜欢使用时间戳，有的人喜欢使用统一格式化的时间字符串yyyy-MM-dd HH:mm:ss，我个人的建议使用后者，因为这样比较直观调试交流起来也比较方便。 使用哪种没有对错，其实就是一种规范，统一规范可以提升协作效率，因此我建议的规范如下： 前端传入日期格式：yyyy-MM-dd HH:mm:ss，例如：2018-07-09 12:55:12（不使用时间戳，前后双方联调时查看起来更加友好） 后端返回日期格式：yyyy-MM-dd HH:mm:ss，例如：2018-07-09 12:55:12（不使用时间戳，前后双方联调时查看起来更加友好） 后端json序列化、反序列化框架：定义任何一种高效的json工具都行，例如：Fastjson、Gson、Jackson lib 序列化、反序列化日期格式规范：pattern=”yyyy-MM-dd HH:mm:ss”,timezone = “GMT+8”，除特出场景可以使用pattern=”yyyy-MM-dd”,timezone = “GMT+8” 不要随意自定义convert处理日期格式以及其他特殊格式转换，应该交由基础框架组或架构组统一在框架层面解决，对业务开发透明，或者在有些小公司由Leader或高开来担当。 这些都是我个人摸爬滚打多年码出来的心得体会，说的不好还请见谅，希望可以帮助有需要的人。","tags":[{"name":"restful","slug":"restful","permalink":"https://ningyu1.github.io/tags/restful/"},{"name":"date-convert","slug":"date-convert","permalink":"https://ningyu1.github.io/tags/date-convert/"}]},{"title":"谈一谈自定义字段实现的几种方式","date":"2019-01-03T07:50:21.000Z","path":"20190103/108-custom-field.html","text":"我们经常会遇到项目中很多对表单进行自定义，比如说saas应用针对租户自定义表单字段名称，自定义列表名称。还有更高级自定义，比如说自定义的模块，表单、字段、字段类型、流程等自定义。 提供自定义也是一个系统扩展性的体现，自定义功能的强大自然能适应更多的用户场景。 接下来我们就看看自定义的实现方案通常都有哪些方式。 常见的自定义字段的实现方式分为三种由简到繁，扩展性、复杂性也是逐渐增强的，每个方式各有优劣解决的场景也有所不同，具体往下看。 列式存储自定义字段（扩展字段 ext field）模型如下： ID Name Ext1(性别) Ext2(地区) Ext3(QQ) Ext4(WECHAT) 1 韩梅梅 女 Shanghai 10000 2 李磊 男 Beijing abc001 优点： 实现成本最低 可以直接表连接进行检索 缺点： 扩展能力一般，有上限 浪费资源，比如说有20个扩展字段，一行只用到2个，其余的18个都要存储null来浪费空间。 能解决的场景比较有限。 EAV模型 Entity-Attribute-Value（实体、属性、值）对象属性存储在一个有三列的表中：实体，属性和值（entity，attribute，value)。实体（entiry）表示所描述的数据项，例如一个产品或汽车。属性（attribute）表示描述实体的数据，例如一个产品将有价格，重量和许多其他属性。值（value）是属性的值，例如产品可能有一个9.99英镑的价格属性。此外值可以基于数据类型进行分割，所以可将EAV表分为字符串、整数、日期和长文本（long text）表。依据数据类型分割是为了支持索引,使得数据库执行可能的类型检查验证。 EAV表模型带来了数据的灵活性，是的增加对象的属性不需要用增加数据库的字段，有很高的灵活性。但是EAV表也有较大的性能问题。通常，EAV表带来的一个问题是当查找多个字段时，需要进行关联查询join,这样的查询效率比较低。为了提高查询效率，我们可以对商品属性表进行矩阵转积处理(pivoting)。 一种方式是在代码中读出后存入cache中,当修改attributes表后触发更新cache或用cron定期更新;另一种方法是将关联信息组成一张大的临时表，数据的更新可以用数据库的触发器触发更新。由于大量数据在代码中进行处理会带来了DB的额外IO和服务器性能问题。当使用EAV表模型时，InnoDB比MYISAM的性能要好不少。 ps. 我们常用的行模型（纵向）存储就是EAV模型实现的一种方式。 模型如下： 人员表（Entity） ID Name 1 韩梅梅 2 李磊 扩展映射（Entities） Entity Attribute Value 1 sex（性别） 女 2 sex（性别） 男 1 region（地区） Shanghai 2 region（地区） Beijing 1 QQ 10000 2 WECHAT abc001 优点： 扩展能力较强 理论上无上限 可以支持几乎所有的自定义字段的需求 缺点： 关联查询效率低下 需要维护自定义字段与值的关系表 Json格式存储自定义字段json格式非常丰富，在描述自定义字段的这方面比较适合，可以把一行多列的数据压缩到一个json text内，也比较节省空间，json格式可以无限扩展，还可支持多个自定义字段有不同的格式。 模型如下： ID Name Content 1 韩梅梅 {“sex”:”女”,”region”:”Shanghai”,”QQ”:”10000”} 2 李磊 {“sex”:”女”,”region”:”Beijing”,”WECHAT”:”abc001”} ps. 支持以上的两种不同的自定义格式并存 优点： 扩展能力强 理论上无上限 可以支持几乎所有的自定义字段的需求 无需维护自定义字段与值关系 缺点： 数据库需要支持json type，不建议使用text类型 不支持关联查询（mongodb除外） 自定义字段检索需要通过其他方式，例如搜索引擎。（mongodb除外） 数据库对Json格式支持情况数据库对Json类型的支持： Mysq5.7（CRUD参考） PostgreSQL（CRUD参考，json与jsonb区别） MongoDB（CRUD参考） 数据库对json类型的检索支持： Mysql5.7： 支持索引：通过虚拟列的功能可以对JSON中部分的数据进行索引。（相比PG和MongoDB弱一些，通过json_extract()函数做一些简单查询） PostgreSQL：支持检索，可以复杂查询 MongoDB：支持检索，可以复杂查询，支持map reduce ORM框架对Json类型的支持： Mybatis支持json格式字段映射到POJO，方便json格式的bean与数据库映射。 Hibernate支持json格式字段映射到POJO，方便json格式的bean与数据库映射。 Mysql5.7.x json操作官方文档： json-creation-functions json-search-functions json-modification-functions Mysql5.7.x 注意事项： JSON_UNQUOTE 、-&gt;、-&gt;&gt; 之间的区别 下面三个表达式返回相同的值 JSON_UNQUOTE( JSON_EXTRACT(column, path) ) JSON_UNQUOTE(column -&gt; path) column-&gt;&gt;path JSON_CONTAINS_PATH 参数说明 第二个参数为’one’或’all’的区别 ‘one’：至少存在一个路径返回1，反之返回0 ‘all’：全部路径存在返回1，反之返回0 JSON_CONTAINS 参数说明 第二个参数是不接受整数的，无论 json 元素是整型还是字符串，否则会出现这个错误 5.7.x不同版本支持的程度： MySQL 5.7.13 支持操作符 -&gt;&gt; MySQL 5.7.9 支持操作符 -&gt; （JSON_EXTRACT()函数别名） 重命名函数JSON_APPEND()为JSON_ARRAY_APPEND()，函数作用：将值追加到JSON文档中指定数组的末尾并返回结果，未来会删除’JSON_APPEND()’ MySQL 5.7.22 支持JSON_ARRAYAGG()返回json数组形式结果集，JSON_OBJECTAGG()返回kson对象形式结果集 添加JSON_MERGE_PATCH()，作用：合并结果（相同path） 添加JSON_MERGE_PRESERVE()，作用：合并数据（不同path） 弃用JSON_MERGE()，使用JSON_MERGE_PRESERVE() / JSON_MERGE_PATCH()，未来会删除’JSON_MERGE()’ 实现方式不局限于上面说到的方式，有更好的方式欢迎留言进行沟通。","tags":[{"name":"custom-field","slug":"custom-field","permalink":"https://ningyu1.github.io/tags/custom-field/"}]},{"title":"自1996年起的(Best Paper)计算机科学最佳论文奖收录","date":"2018-12-28T09:38:21.000Z","path":"20181228/107-best-paper.html","text":"原文地址： https://jeffhuang.com/best_paper_awards.html 我擦好牛逼了，自1996年起的计算机科学最佳论文奖全收录，不说了戳开看吧。","tags":[{"name":"best-paper","slug":"best-paper","permalink":"https://ningyu1.github.io/tags/best-paper/"}]},{"title":"[Enhancement]Enumeration type support, Dubbo Plugin for Apache JMeter - V1.3.8","date":"2018-12-18T05:57:21.000Z","path":"20181218/106-jmeter-plugin-dubbo-1.3.8.html","text":"项目地址github: jmeter-plugin-dubbo 码云: jmeter-plugin-dubbo V1.3.8What is new: Enumeration type support. #34 Support group to zookeeper,redis registration center. #33 新版改进： 支持枚举类型参数。#34 zookeeper、redis作为注册中心时增加group支持。 #33 ps. 参数类型支持：枚举类型以及参数对象内属性为枚举类型 截图 ps. dubbo:registry group: 服务注册分组，跨组的服务不会相互影响，也无法相互调用，适用于环境隔离。 具体查看dubbo文档","tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://ningyu1.github.io/tags/dubbo/"},{"name":"jmeter","slug":"jmeter","permalink":"https://ningyu1.github.io/tags/jmeter/"},{"name":"test","slug":"test","permalink":"https://ningyu1.github.io/tags/test/"},{"name":"Dubbo可视化测试工具","slug":"Dubbo可视化测试工具","permalink":"https://ningyu1.github.io/tags/Dubbo可视化测试工具/"},{"name":"Jmeter对Dubbo接口进行可视化压力测试","slug":"Jmeter对Dubbo接口进行可视化压力测试","permalink":"https://ningyu1.github.io/tags/Jmeter对Dubbo接口进行可视化压力测试/"},{"name":"Dubbo Jmeter插件","slug":"Dubbo-Jmeter插件","permalink":"https://ningyu1.github.io/tags/Dubbo-Jmeter插件/"}]},{"title":"雪花算法-记录","date":"2018-12-07T03:51:21.000Z","path":"20181207/105-snowflake.html","text":"最近看到了一篇分析雪花算法的文章还不错，然后整理了一下分享出来。 先来科普一下SnowFlake算法 算法原理Twitter Snowflake 生成的 unique ID 的组成 (由高位到低位): 41 bits: Timestamp (毫秒级)10 bits: 节点 ID (datacenter ID 5 bits + worker ID 5 bits)12 bits: sequence number一共 63 bits (最高位是 0). | 0(最高位预留) | 时间戳(41位) | 机器ID(10位) | 自增序列(12位) |unique ID 生成过程: 10 bits 的机器号, 在 ID 分配 Worker 启动的时候，从一个 Zookeeper 集群获取 (保证所有的 Worker 不会有重复的机器号)； 41 bits 的 Timestamp: 每次要生成一个新 ID 的时候，都会获取一下当前的 Timestamp, 然后分两种情况生成 sequence number； 如果当前的 Timestamp 和前一个已生成 ID 的 Timestamp 相同 (在同一毫秒中)，就用前一个 ID 的 sequence number + 1 作为新的 sequence number (12 bits);如果本毫秒内的所有 ID 用完，等到下一毫秒继续 (这个等待过程中, 不能分配出新的 ID)； 如果当前的 Timestamp 比前一个 ID 的 Timestamp 大, 随机生成一个初始 sequence number (12bits) 作为本毫秒内的第一个 sequence number； 41-bit的时间可以表示（1L&lt;&lt;41）/(1000L x 3600 x 24 x 365)=69年的时间，10-bit机器可以分别表示1024台机器。如果我们对IDC划分有需求，还可以将10-bit分5-bit给IDC，分5-bit给工作机器。这样就可以表示32个IDC，每个IDC下可以有32台机器，可以根据自身需求定义。12个自增序列号可以表示2^12个ID，理论上snowflake方案的QPS约为409.6w/s，这种分配方式可以保证在任何一个IDC的任何一台机器在任意毫秒内生成的ID都是不同的。 优缺点这里就不赘述了。 那我们继续看一个经典的Java版本的实现，这个在网上一搜一大把，官方原版的Scala版本 public class Snowflake &#123; private static final Logger logger = LoggerFactory.getLogger(Snowflake.class); /** * 机器ID */ private final long workerId; /** * 时间起始标记点，作为基准，一般取系统的最近时间，默认2017-01-01 */ private final long epoch = 1483200000000L; /** * 机器id所占的位数（源设计为5位，这里取消dataCenterId，采用10位，既1024台） */ private final long workerIdBits = 10L; /** * 机器ID最大值: 1023 (从0开始) */ private final long maxWorkerId = -1L ^ -1L &lt;&lt; this.workerIdBits; /** * 机器ID向左移12位 */ private final long workerIdShift = this.sequenceBits; /** * 时间戳向左移22位(5+5+12) */ private final long timestampLeftShift = this.sequenceBits + this.workerIdBits; /** * 序列在id中占的位数 */ private final long sequenceBits = 12L; /** * 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095)，12位 */ private final long sequenceMask = -1L ^ -1L &lt;&lt; this.sequenceBits; /** * 并发控制，毫秒内序列(0~4095) */ private long sequence = 0L; /** * 上次生成ID的时间戳 */ private long lastTimestamp = -1L; private final int HUNDRED_K = 100_000; /** * @param workerId 机器Id */ private Snowflake(long workerId) &#123; if (workerId &gt; this.maxWorkerId || workerId &lt; 0) &#123; String message = String.format(&quot;worker Id can&apos;t be greater than %d or less than 0&quot;, this.maxWorkerId); throw new IllegalArgumentException(message); &#125; this.workerId = workerId; &#125; /** * Snowflake Builder * @param workerId workerId * @return Snowflake Instance */ public static Snowflake create(long workerId) &#123; return new Snowflake(workerId); &#125; /** * 批量获取ID * @param size 获取大小，最多10万个 * @return SnowflakeId */ public long[] nextId(int size) &#123; if (size &lt;= 0 || size &gt; HUNDRED_K) &#123; String message = String.format(&quot;Size can&apos;t be greater than %d or less than 0&quot;, HUNDRED_K); throw new IllegalArgumentException(message); &#125; long[] ids = new long[size]; for (int i = 0; i &lt; size; i++) &#123; ids[i] = nextId(); &#125; return ids; &#125; /** * 获得ID * @return SnowflakeId */ public synchronized long nextId() &#123; long timestamp = timeGen(); // 如果上一个timestamp与新产生的相等，则sequence加一(0-4095循环); if (this.lastTimestamp == timestamp) &#123; // 对新的timestamp，sequence从0开始 this.sequence = this.sequence + 1 &amp; this.sequenceMask; // 毫秒内序列溢出 if (this.sequence == 0) &#123; // 阻塞到下一个毫秒,获得新的时间戳 timestamp = this.tilNextMillis(this.lastTimestamp); &#125; &#125; else &#123; // 时间戳改变，毫秒内序列重置 this.sequence = 0; &#125; // 如果当前时间小于上一次ID生成的时间戳，说明系统时钟回退过这个时候应当抛出异常 if (timestamp &lt; this.lastTimestamp) &#123; String message = String.format(&quot;Clock moved backwards. Refusing to generate id for %d milliseconds.&quot;, (this.lastTimestamp - timestamp)); logger.error(message); throw new RuntimeException(message); &#125; this.lastTimestamp = timestamp; // 移位并通过或运算拼到一起组成64位的ID return timestamp - this.epoch &lt;&lt; this.timestampLeftShift | this.workerId &lt;&lt; this.workerIdShift | this.sequence; &#125; /** * 等待下一个毫秒的到来, 保证返回的毫秒数在参数lastTimestamp之后 * @param lastTimestamp 上次生成ID的时间戳 * @return */ private long tilNextMillis(long lastTimestamp) &#123; long timestamp = timeGen(); while (timestamp &lt;= lastTimestamp) &#123; timestamp = timeGen(); &#125; return timestamp; &#125; /** * 获得系统当前毫秒数 */ private long timeGen() &#123; return System.currentTimeMillis(); &#125;&#125; 那让我们看一下代码来理解一下算法的细节。 代码理解我们从关键的代码段来理解，如下： this.sequence = this.sequence + 1 &amp; this.sequenceMask;private final long maxWorkerId = -1L ^ -1L &lt;&lt; this.workerIdBits;return ((timestamp - this.epoch) &lt;&lt; this.timestampLeftShift) | (this.workerId &lt;&lt; this.workerIdShift) | this.sequence; ps. 我这里取消了datacenterId，将datacenterId和workerid合并到workerIdBits 负数的二进制表示在计算机中，负数的二进制是用补码来表示的。假设我是用Java中的int类型来存储数字的，int类型的大小是32个二进制位（bit），即4个字节（byte）。（1 byte = 8 bit）那么十进制数字3在二进制中的表示应该是这样的： 00000000 00000000 00000000 00000011// 3的二进制表示，就是原码 那数字-3在二进制中应该如何表示？我们可以反过来想想，因为-3+3=0，在二进制运算中把-3的二进制看成未知数x来求解，求解算式的二进制表示如下： 00000000 00000000 00000000 00000011 //3，原码+ xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx //-3，补码----------------------------------------------- 00000000 00000000 00000000 00000000 反推x的值，3的二进制加上什么值才使结果变成00000000 00000000 00000000 00000000？： 00000000 00000000 00000000 00000011 //3，原码 + 11111111 11111111 11111111 11111101 //-3，补码----------------------------------------------- 1 00000000 00000000 00000000 00000000 反推的思路是3的二进制数从最低位开始逐位加1，使溢出的1不断向高位溢出，直到溢出到第33位。然后由于int类型最多只能保存32个二进制位，所以最高位的1溢出了，剩下的32位就成了（十进制的）0。 补码的意义就是可以拿补码和原码（3的二进制）相加，最终加出一个“溢出的0” 以上是理解的过程，实际中记住公式就很容易算出来： 补码 = 反码 + 1补码 = （原码 - 1）再取反码因此-1的二进制应该这样算： 00000000 00000000 00000000 00000001 //原码：1的二进制11111111 11111111 11111111 11111110 //取反码：1的二进制的反码11111111 11111111 11111111 11111111 //加1：-1的二进制表示（补码） 具体对位运算以及二进制的计算理解可以看看这篇文章https://blog.csdn.net/cj2580/article/details/80980459","tags":[{"name":"snowflake","slug":"snowflake","permalink":"https://ningyu1.github.io/tags/snowflake/"}]},{"title":"[Enhancement]Support to select provider from zookeeper, Dubbo Plugin for Apache JMeter - V1.3.7","date":"2018-11-13T10:51:21.000Z","path":"20181113/104-jmeter-plugin-dubbo-1.3.7.html","text":"项目地址github: jmeter-plugin-dubbo 码云: jmeter-plugin-dubbo V1.3.7What is new: Support to select provider from zookeeper. issue: #31 Upgrade dubbo version to v2.6.4. 新版改进： 支持从zookeeper选择服务提供者，降低手动输入出错概率，issue: #31 升级dubbo版本到v2.6.4 截图","tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://ningyu1.github.io/tags/dubbo/"},{"name":"jmeter","slug":"jmeter","permalink":"https://ningyu1.github.io/tags/jmeter/"},{"name":"test","slug":"test","permalink":"https://ningyu1.github.io/tags/test/"},{"name":"Dubbo可视化测试工具","slug":"Dubbo可视化测试工具","permalink":"https://ningyu1.github.io/tags/Dubbo可视化测试工具/"},{"name":"Jmeter对Dubbo接口进行可视化压力测试","slug":"Jmeter对Dubbo接口进行可视化压力测试","permalink":"https://ningyu1.github.io/tags/Jmeter对Dubbo接口进行可视化压力测试/"},{"name":"Dubbo Jmeter插件","slug":"Dubbo-Jmeter插件","permalink":"https://ningyu1.github.io/tags/Dubbo-Jmeter插件/"}]},{"title":"Trouble Shooting —— jms:listener-container配置queue的concurrency数量与预期不一致","date":"2018-10-30T10:40:00.000Z","path":"20181030/103-activemq-listener-concurrency.html","text":"问题描述 现象一 现象二 测试消费者 测试后结论 问题描述测试程序时发现queue的consumer数量配置与预期不一致，具体如何不一致看下面的测试。 现象一当我们使用下面配置，listener使用同一个task-executor并且监听三个queue时，consumer使用20-20，只会有一个queue能达到20个consumer，其余两个queue的consumer=0 &lt;bean id=&quot;queueMessageExecutor1&quot; class=&quot;org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor&quot;&gt; &lt;property name=&quot;corePoolSize&quot; value=&quot;20&quot; /&gt; &lt;property name=&quot;maxPoolSize&quot; value=&quot;20&quot; /&gt; &lt;property name=&quot;daemon&quot; value=&quot;true&quot; /&gt; &lt;property name=&quot;keepAliveSeconds&quot; value=&quot;120&quot; /&gt;&lt;/bean&gt;&lt;jms:listener-container task-executor=&quot;queueMessageExecutor1&quot; destination-type=&quot;queue&quot; container-type=&quot;default&quot; connection-factory=&quot;pooledConnectionFactory&quot; concurrency=&quot;20-20&quot; acknowledge=&quot;auto&quot; receive-timeout=&quot;60000&quot;&gt; &lt;jms:listener destination=&quot;QUEUE.EMAIL&quot; ref=&quot;mailMessageListener&quot; /&gt; &lt;jms:listener destination=&quot;QUEUE.SMS&quot; ref=&quot;smsMessageListener&quot; /&gt; &lt;jms:listener destination=&quot;QUEUE.WECHAT&quot; ref=&quot;wechatMessageListener&quot; /&gt;&lt;/jms:listener-container&gt; 效果如下图： 现象二当我们去掉listener-container的receive-timeout=&quot;60000&quot;的配置，三个queue的consumer都等于20。 &lt;bean id=&quot;queueMessageExecutor1&quot; class=&quot;org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor&quot;&gt; &lt;property name=&quot;corePoolSize&quot; value=&quot;20&quot; /&gt; &lt;property name=&quot;maxPoolSize&quot; value=&quot;20&quot; /&gt; &lt;property name=&quot;daemon&quot; value=&quot;true&quot; /&gt; &lt;property name=&quot;keepAliveSeconds&quot; value=&quot;120&quot; /&gt;&lt;/bean&gt;&lt;jms:listener-container task-executor=&quot;queueMessageExecutor1&quot; destination-type=&quot;queue&quot; container-type=&quot;default&quot; connection-factory=&quot;pooledConnectionFactory&quot; concurrency=&quot;20-20&quot; acknowledge=&quot;auto&quot;&gt; &lt;jms:listener destination=&quot;QUEUE.EMAIL&quot; ref=&quot;mailMessageListener&quot; /&gt; &lt;jms:listener destination=&quot;QUEUE.SMS&quot; ref=&quot;smsMessageListener&quot; /&gt; &lt;jms:listener destination=&quot;QUEUE.WECHAT&quot; ref=&quot;wechatMessageListener&quot; /&gt;&lt;/jms:listener-container&gt; 效果如下图： 这两种现象之间的差异就在receive-timeout=&quot;60000&quot;这个属性上，接下来让我们看一下“现象一”、“现象二”的jvm启动的consumer线程的具体信息，如下图： 现象一的线程信息： 现象二的线程信息： 从线程的信息上看，线程的数量与线程池的配置信息吻合，具体开多少个线程取决于线程池的大小，这个与预期一致，拿为什么两种现象锁显示的queue的consumer数量不同呢？ 同样是20个线程，但是在现象二中三个queue的consumer分别都是20个，那总数就是60个完全超过了线程的数量，从这点能看的出来consumer的数量是逻辑数量，也就是说20个线程来承接60个逻辑消费者，每个线程会随机的去拿某一个queue里的消息。 测试消费者当我们在“现象一”中只有一个queue有consumer，其他queue没有consumer，我们往没有consumer的q中写消息，看些消息的这个q是否有会consumer出现？ 当消息积压到一定的时间（测试下来时间为：14:18分积压消息，14:27分增加了20个consumer消费掉了积压消息） 我们再往wechat中发送积压消息，看看wechat的consumer是否会增加？ 当消息积压到一定的时间（测试下来时间为：14:34分积压消息，14:38分增加了20个consumer消费掉了积压消息） 一旦增加上来了consumer目前看下来不会自动消失 测试后结论当listener-container使用同一个task-executor并且监听多个q时： listener-container设置了receive-timeout=&quot;60000（接受超时时间），线程数会优先处理配置中第一个q上，其他q不会有consumer数量，当其他q有消息积压时会自动增加consumer数量，但是增加的时间不太规律。 listener-container没有设置receive-timeout=&quot;60000（接受超时时间），线程数会处理多个q的消息接收，随机接收某个q的消息，或者是那个q的消息积压的多会优先接受那个q的消息。 ps. 同一个listener-container监听多个q，线程会接收多个q的消息（多个q共享接收消息线程），只不过q的consumer数量初始化的时间不同，如果不配置receive-timeout=&quot;60000（接受超时时间）这个参数，q的consumer数量在启动时就会初始化。 当listener-container使用不同的task-executor并且只监听一个q时： 设不设置receive-timeout=&quot;60000（接受超时时间）没有区别，一个线程池中的线程只会处理一个q的消息接收，对于消息量大存在积压的情况下，可以独立配置线程池和监听器让这个q的处理线程资源独享。","tags":[{"name":"activemq","slug":"activemq","permalink":"https://ningyu1.github.io/tags/activemq/"}]},{"title":"Trouble Shooting —— 莫名其妙的java.lang.NoClassDefFoundError: org.springframework.beans.FatalBeanException异常","date":"2018-09-29T07:30:00.000Z","path":"20180929/102-NoClassDefFoundError.html","text":"问题描述 问题分析 尝试一 尝试二 尝试三 尝试四 解决方法 问题描述最近运维在部署应用的时候偶尔会碰到下面的异常： Exception in thread &quot;main&quot; java.lang.NoClassDefFoundError: org.springframework.beans.FatalBeanException at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:547) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:700) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482) at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:139) at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:93) at com.alibaba.dubbo.container.spring.SpringContainer.start(SpringContainer.java:50) at com.alibaba.dubbo.container.Main.main(Main.java:80) 这个异常看上去是org.springframework.beans.FatalBeanException在运行时找不到class，但是调试起来很懵逼。 问题分析尝试一怀疑这个类org.springframework.beans.FatalBeanException在classloader的时候无法找到。 这个类org.springframework.beans.FatalBeanException在spring-beans包下，查看打包的lib下存在spring-beans包，查看运行jar中的META-INF下的MANIFEST.MF文件中也有lib/spring-beans-4.0.0.RELEASE.jar 因此排除了这个怀疑。 ps.这里要区分一下NoClassDefFoundError和ClassNotFoundException异常看这篇文章 尝试二这个类在spring-beans包中，那是不是这个jar包损坏无法读取？ 查看了jar包信息以及打开与解压也排除了jar包损坏的可能性。 尝试三修改log级别改为debug看会不会有更多的日志输出。 通过日志级别的调整为debug后，除了都了一些debug的常规日志以外，错误相关的日志还是跟上面的输出一样，因此也是无济于事。 尝试四通过arthas观察org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory这个类的doCreateBean这个方法异常的输出。 arthas $&#123;pid&#125; watch org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory doCreateBean &quot;&#123;params, throwExp&#125;&quot; -e -x 2 发现如下更多的日志： ts=2018-09-25 18:06:37;result=@ArrayList[ @Object[][ @String[xxxMapper], @RootBeanDefinition[Root bean: class [org.mybatis.spring.mapper.MapperFactoryBean]; scope=singleton; abstract=false; lazyInit=false; autowireMode=2; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in URL [jar:file:/E:/user/desktop/ningyu/Desktop/xxx-main-1.0.0-SNAPSHOT-201809251509/lib/xxx-service-JD-1.0.0-SNAPSHOT.jar!/com/xxx/xxx/order/mapper/xxxMapper.class]], null, ], java.lang.NoClassDefFoundError: org.springframework.beans.FatalBeanException at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:547) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300) at org.springframework.beans.factory.support.AbstractBeanFactory.getTypeForFactoryBean(AbstractBeanFactory.java:1420) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getTypeForFactoryBean(AbstractAutowireCapableBeanFactory.java:788) at org.springframework.beans.factory.support.AbstractBeanFactory.isTypeMatch(AbstractBeanFactory.java:543) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doGetBeanNamesForType(DefaultListableBeanFactory.java:384) at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:361) at org.springframework.beans.factory.BeanFactoryUtils.beanNamesForTypeIncludingAncestors(BeanFactoryUtils.java:187) at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:999) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:957) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:855) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:480) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:289) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1185) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:700) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482) at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:139) at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:93) at com.alibaba.dubbo.container.spring.SpringContainer.start(SpringContainer.java:50) at com.alibaba.dubbo.container.Main.main(Main.java:80),] 而且这个信息不停的打，并且看到的全是xxxMapper？ 难道是mybatis的mapper代理类的创建出现了问题？ 尝试本地通过代码的方式启动服务，没有任何问题。 又尝试本地通过打出的zip包，通过java -jar的方式启动，也没有任何问题。 这个时候就很头疼了，定位不到问题，而且问题不能重现。 网上能搜索到关于mybatis启动报Stack overflow的错误，难道我们这个问题跟他也有关系？于是尝试看一下mybatis的mapper代理自动创建的相关资料。 通过这篇文章 当MapperFactoryBean实例生成之后，Spring给它注入SqlSessionTemplate。而注入SqlSessionTemplate的过程中会向容器获取所有的Dao，对于已经在容器中的Dao所对应的bean可以直接获取返回，若还没有创建bean，则Spring又会先创建这个Dao的MapperFactoryBean。创建MapperFactoryBean的时候会再次注入SqlSessionTemplate。就这样一直循环下去，直到所有的Dao都已经创建完毕，这个过程才算结束。 看来跟mybatis的关系应该很大，网上有有说mybatis Mapper有导致过stack overflow的错误，新想如果是stack overflow肯定应该是有明确的异常抛出，于是也是抱着尝试调整一下jvm的参数看看是否有惊喜。 -Xms1024m -Xmx1024m -XX:PermSize=256m -XX:MaxPermSize=256m -Xss256k stack overflow应该调整Xss参数大小（-Xss512k）调整后重启，竟然成功了！竟然成功了！竟然成功了！ 太不可思议了难道是stack overflow异常被吃掉了？而且mapper在创建的时候是递归，递归的层次越深越消耗stack大小，然后具体搜索mybatis导致stack异常的信息看到了这篇文章，上面就是说mybatis-spring工具包有问题将异常吃掉了，具体mybatis-spring中的那段代码我还在定位，定位好了在更新文章 解决方法调整xss参数，从xss256k调整为xss512k","tags":[{"name":"mybatis","slug":"mybatis","permalink":"https://ningyu1.github.io/tags/mybatis/"}]},{"title":"zookeeper数据迁移及恢复","date":"2018-09-28T03:20:00.000Z","path":"20180928/101-zookeeper-data-migrate.html","text":"在做环境迁移的时候经常会遇到中间件的数据迁移，今天我们说一下zookeeper的数据如何迁移与恢复。 比如说我们使用prd环境数据迁移到st环境为例来叙述一下具体的步骤。 第一步：从prd环境zookeeper服务器的数据目录下复制最新的日志和快照文件。 先去zookeeper的安装目录下找到zookeeper的conf文件，例如： $&gt; cd /usr/local/zookeeper/conf$&gt; cat zoo.cfg 打开zoo.cfg文件找到具体配置的zookeeper的data目录，例如： # the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just# example sakes.dataDir=/var/zookeeper 进入到dataDir下的version-2文件夹，version-2文件夹下存放的是zookeeper的日志和镜像文件，我们找到最新的日志和镜像文件，例如： $&gt; cd /var/zookeeper/version-2$&gt; ls -ah-rw-r--r-- 1 zookeeper zookeeper 67108880 Sep 27 17:20 log.909e2d252-rw-r--r-- 1 zookeeper zookeeper 10408329 Sep 27 17:01 snapshot.909e2d250 找到最新的日志和快照文件，例如上面的：log.909e2d252和snapshot.909e2d250 日志文件存放zookeeper全部数据记录 ，快照文件则是内存增量文件。 ps.这里要注意找最新的日志和快照文件 zookeeper的日志和镜像文件的清理可以看这篇文章：Zookeeper事务日志和snapshot清理方式 第二步：传输日志和快照文件 如果st和prd网络是通的话可以通过scp的方式复制过去，如果网络不通通过中转站来过渡。 第三步：停掉需要恢复数据的zk服务，删除数据目录下的文件，复制刚才的两个文件到数据目录下 假设需要恢复数据的服务器上zookeeper数据目录也是在/var/zookeeper下 $&gt; rm -fr /var/zookeeper/*$&gt; cp log.909e2d252 snapshot.909e2d250 /var/zookeeper$&gt; cd /usr/local/zookeeper/bin$&gt; ./zkServer.sh start 如果是三台需要全部服务停掉，恢复其中的一台，然后等数据恢复完成后，再启动其余的两台服务让zk自己同步数据过去 第四步：验证数据是否真的恢复了 $&gt; cd /usr/local/zookeeper/bin$&gt; ./zkCli.sh$&gt; ls / ls查看zk中的数据. Zookeeper日志与镜像文件的分析可以参考这篇文章：ZooKeeper日志与快照文件简单分析","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://ningyu1.github.io/tags/zookeeper/"}]},{"title":"Git常用开发流程 —— 中心化的工作流","date":"2018-09-26T12:50:00.000Z","path":"20180926/100-git-centralized-workflow.html","text":"一、中心化的工作流 为什么会有冲突，冲突的原因 举例说明 rebase实操记录 示例总结以及注意事项 一、中心化的工作流中心化的工作流又叫做SVN-style,适用于熟悉svn的管理流程来过渡到git（分布式版本控制系统），如果你的开发团队成员已经很熟悉svn，集中式工作流让你无需去适应一个全新流程就可以体验Git带来的收益。这个工作流也可以作为向更Git风格工作流迁移的友好过渡，入下图所示： 像SVN一样，集中式工作流以中央仓库作为项目所有修改的单点实体。相比SVN缺省的开发分支trunk，Git叫做master，所有修改提交到这个分支上。该工作流只用到master这一个分支。开发者开始先克隆中央仓库。在自己的项目拷贝中，像SVN一样的编辑文件和提交修改；但修改是存在本地的，和中央仓库是完全隔离的。开发者可以把和上游的同步延后到一个方便时间点。要发布修改到正式项目中时，开发者要把本地master分支的修改『推（push）』到中央仓库中。这相当于svn commit操作，但push操作会把所有还不在中央仓库的本地提交都推上去，下图所示： 为什么会有冲突，冲突的原因使用svn-style的方式避免不了会遇到冲突，冲突的解决尤为重要，中央仓库代表了正式项目（git里是master，svn里是trunk），所以提交历史应该被尊重且是稳定不变的。如果开发者本地的提交历史和中央仓库有分歧，Git会拒绝push提交否则会覆盖已经在中央库的正式提交。 在开发者提交自己功能修改到中央库前，需要先fetch在中央库的新增提交，rebase自己提交到中央库提交历史之上。这样做的意思是在说，我要把自己的修改加到别人已经完成的修改上，最终的结果是一个完美的线性历史，就像以前的SVN的工作流中一样。如果本地修改和上游提交有冲突，Git会暂停rebase过程，给你手动解决冲突的机会。 举例说明让我们举一个例子来理解一下中心化工作流-svn-style 比如说：wms项目组有两个开发人员：小明、小健，看他们是如何开发自己的功能并提交到中央仓库上的。 第一步：小明、小健从中央仓库克隆代码 git clone http://gitlab.xxx.com/demo/gitflow-demo.git ps.克隆仓库时Git会自动添加远程别名origin指向中央仓库，不动请参考：git clone --help 克隆代码入下图示例： 小明开发新功能： 小明使用标准的Git过程开发功能：编辑、暂存（Stage）和提交，这里注意不进行push操作，只做本地commit提交到本地仓库 git status # 查看本地仓库的修改状态git add # 暂存文件git commit # 提交文件 这些操作都是本地的提交操作，小明可以反复的按照需求来进行代码修改，不需要担心中央仓库的改变和小健自己本地的改变。 小明开发功能都在本地上进行就如下图示例： 小健开发新功能 小健也是一样使用标准的Git过程开发功能，编辑、暂存、提交，他和小明一样不需要关系中央仓库的改变和小明自己本地的改变，所有的提交都是私有的，都是在自己的本地仓库中。 小健开发功能都在本地上进行就如下图所示： 小明开发好了功能想发布了 小明把他的本地仓库修改的代码push到中央仓库，使用下面命令 git push origin master ps. origin是在小明克隆仓库时Git创建的远程中央仓库别名。master参数告诉Git推送的分支 ps. 我们这里假设团队中只有两个人（小明、小健），由于中央仓库自从小明克隆以来还没有被更新过，所以push操作不会有冲突，成功完成。 小明把他自己的本地代码push到中央仓库就如下图所示： 小健开发好了功能也想发布了 小健也是使用git push命令来推送自己本地仓库的改动到中央仓库，使用下面命令 git push origin master 但是此时origin已经由于小明在之前推送了小明本地的代码上去，因此已经和小健本地的代码产生了分歧，推送会被拒绝，入下图所示： 拒绝的信息如下： $ git push origin masterTo http://gitlab.xxx.com/demo/gitflow-demo.git ! [rejected] master -&gt; master (fetch first)error: failed to push some refs to &apos;http://gitlab.xxx.com/demo/gitflow-demo.git&apos;hint: Updates were rejected because the remote contains work that you dohint: not have locally. This is usually caused by another repository pushinghint: to the same ref. You may want to first integrate the remote changeshint: (e.g., &apos;git pull ...&apos;) before pushing again.hint: See the &apos;Note about fast-forwards&apos; in &apos;git push --help&apos; for details. 遇到这种问题我们该怎么解决了？ 小健可以使用pull操作合并上游的修改到自己的仓库中，git的pull操作类似于svn的update操作，拉取所有上游小明提交命令到小健的本地仓库，但是要加上–rebase参数，例如下面命令： git pull --rebase origin master 这里特别解释一下上面命令的实际操作原理 –rebase选项告诉git把小健的提交移到（同步了中央仓库修改后的master分支）的顶部（head），也就是说它会先把小健本地分支的本地提交先移除掉，移动到一旁，然后把小健的本地分支同步中央仓库的最新版本（小明提交的记录），然后把刚刚移除了（小健本地的修改）再提交回小健的本地分支（已同步了最新中央仓库的代码，也就是说小明的代码）。 不加rebase的话git会在xiaoming和xiaojian的提交后再进行一次merge操作从而就会多了一个merge的提交记录，加了rebase的话xiaojian的提交已经包含了与xiaoming代码的冲突，因此不会多一个merge操作。 rebase（没有冲突）操作的过程例如下图所示： rebase（存在冲突）操作的过程例如下图所示： ps. git会暂定rebase操作直到你去解决了冲突之后执行git rebase --continue来继续进行操作. rebase实操记录下面是rebase的操作实践，xiaojian执行git pull --rebase origin master，比如说xiaoming和xiaojian冲突到了同一个文件上会显示出下面的信息，例如： $ git pull --rebase origin masterremote: Counting objects: 3, done.remote: Compressing objects: 100% (2/2), done.remote: Total 3 (delta 0), reused 0 (delta 0)Unpacking objects: 100% (3/3), done.From http://gitlab.xxx.com/demo/gitflow-demo * branch master -&gt; FETCH_HEAD 788c7f3..9c7c9d2 master -&gt; origin/masterFirst, rewinding head to replay your work on top of it...Applying: xiaojian 提交error: Failed to merge in the changes.Using index info to reconstruct a base tree...M README.mdFalling back to patching base and 3-way merge...Auto-merging README.mdCONFLICT (content): Merge conflict in README.mdPatch failed at 0001 xiaojian 提交The copy of the patch that failed is found in: .git/rebase-apply/patchResolve all conflicts manually, mark them as resolved with&quot;git add/rm &lt;conflicted_files&gt;&quot;, then run &quot;git rebase --continue&quot;.You can instead skip this commit: run &quot;git rebase --skip&quot;.To abort and get back to the state before &quot;git rebase&quot;, run &quot;git rebase --abort&quot;. 如果装了小乌龟或者sourcetree目录下文件会显示冲突警告图标 根据上面的警告我们需要手动的解决冲突，解决完冲突使用git add/rm &lt;conflicted_files&gt;命令标记解决冲突完毕，再执行git rebase --continue继续下一步操作。 ps. 如果这个时候后悔执行了git pull --rebase origin master想撤销怎么办？可以执行git rebase --abort撤销rebase操作。 接下来是xiaojian执行push到中央仓库并且解决冲突的脚本记录如下： 手动解决冲突$ git add README.md$ git rebase --continueApplying: xiaojian 提交$ git push origin masterCounting objects: 3, done.Delta compression using up to 4 threads.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 305 bytes | 305.00 KiB/s, done.Total 3 (delta 1), reused 0 (delta 0)To http://gitlab.xxx.com/demo/gitflow-demo.git 9c7c9d2..87aed2d master -&gt; master 然后我们去gitlab上看我们的提交记录是个什么样子的，例如下图： ps.提交记录非常的清晰明了而且是按照push仓库的顺序来显示的提交记录，这个样子也是我们希望看到的。 但是往往并没有这么顺利，理想很好现实确实各种问题。 比如说git pull的时候忘记添加--rebase参数了怎么办？ 如果忘加了--rebase这个选项，pull操作仍然可以完成，但每次pull操作在同步中央仓库中别人的修改时，需要提交合并代码的记录从而导致提交历史中会多一个『合并提交』的记录。 例如下面所示： $ git pull origin masterFrom http://gitlab.xxx.com/demo/gitflow-demo * branch master -&gt; FETCH_HEADAuto-merging README.mdCONFLICT (content): Merge conflict in README.mdAutomatic merge failed; fix conflicts and then commit the result.手动解决完冲突$ git add .$ git commit -m &quot;合并冲突&quot;[master 9fab0c8] 合并冲突$ git push origin masterCounting objects: 6, done.Delta compression using up to 4 threads.Compressing objects: 100% (4/4), done.Writing objects: 100% (6/6), 581 bytes | 290.00 KiB/s, done.Total 6 (delta 2), reused 0 (delta 0)To http://gitlab.xxx.com/demo/gitflow-demo.git f862f27..9fab0c8 master -&gt; master 然后我们去gitlab上看我们的提交记录是个什么样子的，例如下图： ps. 会多出一个合并的提交，而且查看tree型图会发现不是一个线性的轨迹 如果使用的是小乌龟sourcetree这种工具合并冲突会是什么样子？让我们演示一下： 首先 手动解决完冲突，选择标记为已经解决 我们需要把解决的冲突提交上去 自动生成的comment是Merge branchmasterxxxxxxx 提交完成后右键菜单选择git push 这个时候我们去gitlab上看我们的提交记录是个什么样子的，例如下图： 示例总结以及注意事项所以我们建议对于集中式工作流，最好是使用rebase，而不是使用merge生成一个合并提交","tags":[{"name":"git-svn-style","slug":"git-svn-style","permalink":"https://ningyu1.github.io/tags/git-svn-style/"}]},{"title":"如何编写高性能的 RPC 框架","date":"2018-09-19T04:01:00.000Z","path":"20180919/99-rpc-benchmark1.html","text":"最近看相关rpc-benchmark相关的东西发现这篇文章挺好的，所以转载出来，下面是文章出处。 作者：鲁小憨链接：https://www.jianshu.com/p/7182b8751e75來源：简书简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。 在 RPC Benchmark Round 1 中，Turbo 性能炸裂表现强悍，并且在 listUser 这一项目中，取得了 10x dubbo 性能的好成绩。本文将介绍 Turbo 强悍性能背后的原理，并探讨如何编写高性能的 RPC 框架。 过早的优化是万恶之源？这句话是 The Art of Computer Programming 作者，图领奖得主 Donald Knuth 大神说的。不过对于框架设计者而言，这句话并不正确。在设计一款高性能的基础框架时，必须始终重视性能优化，并将性能测试贯穿于整个设计开发过程中。这方面做到极致的类库有 Disruptor JCTools Agrona DSL-JSON 等等，这几个高性能类库都坚持一个原则：不了解性能的外部类库坚决不用，如果现有的类库不能满足性能要求，那就重新设计一个。作为 Turbo 的设计者，我也尽量坚持这一原则，努力做到 Benchmark 驱动开发。 JMH 让 Benchmark 驱动开发成为可能在 JMH 出现之前，要对某个类库进行微基准性能测试是一件非常困难的事情。很难保证公平的测试条件，预热次数难以确定，预热效果也不好观察。JMH 的出现让性能测试变得 标准化 简单化，也让 Benchmark 驱动开发成为可能。Turbo 在开发过程中用 JMH 进行了充分的 Benchmark，以确定核心环节的性能开销，选择合适的实现方案。更多关于 JMH 的介绍请参考下面的链接： OpenJDK: jmh JMH - Java Microbenchmark Harness ImportNew JMH简介 RPC 的主要流程 客户端 获取到 UserService 接口的 Refer: userServiceRefer 客户端 调用 userServiceRefer.verifyUser(email, pwd) 客户端 获取到 请求方法 和 请求数据 客户端 把 请求方法 和 请求数据 序列化为 传输数据 进行网络传输 服务端 获取到 传输数据 服务端 反序列化获取到 请求方法 和 请求数据 服务端 获取到 UserService 的 Invoker: userServiceInvoker 服务端 userServiceInvoker 调用 userServiceImpl.verifyUser(email, pwd) 获取到 响应结果 服务端 把 响应结果 序列化为 传输数据 进行网络传输 客户端 接收到 传输数据 客户端 反序列化获取到 响应结果 客户端 userServiceRefer.verifyUser(email, pwd) 返回 响应结果 整个流程中对性能影响比较大的环节有：序列化[4, 7, 10, 13]，方法调用[2, 3, 8, 9, 14]，网络传输[5, 6, 11, 12]。本文后续内容将着重介绍这3个部分。 序列化方案Java 世界最常用的几款高性能序列化方案有 Kryo Protostuff FST Jackson Fastjson。只需要进行一次 Benchmark，然后从这5种序列化方案中选出性能最高的那个就行了。DSL-JSON 使用起来过于繁琐，不在考虑之列。Colfer Protocol Thrift 因为必须预先定义描述文件，使用起来太麻烦，所以不在考虑之列。至于 Java 自带的序列化方案，早就因为性能问题被大家所抛弃，所以也不考虑。下面的表格列出了在考虑之列的5种序列化方案的性能。 User 序列化+反序列化 性能 framework thrpt (ops/ms) size protostuff 1654 240 kryo 1288 296 fst 1101 263 jackson 959 385 fastjson 603 378 包含15个 User 的 Page 序列化+反序列化 性能 framework thrpt (ops/ms) size kryo 143 2080 fst 118 3495 protostuff 98 3920 jackson 71 5711 fastjson 40 5606 从这个 benchmark 中可以得出明确的结论：二进制协议的 protostuff kryo fst 要比文本协议的 jackson fastjson 有明显优势；文本协议中，jackson(开启了afterburner) 要比 fastjson 有明显的优势。 无法确定的是：3个二进制协议到底哪个更好一些，毕竟 速度 和 size 对于 RPC 都很重要。直观上 kryo 或许是最佳选择，而且 kryo 也广受各大型系统的青睐。不过最终还是决定把这3个类库都留作备选，通过集成传输模块后的 Benchmark 来决定选用哪个。 framework exist op/ms create op/ms get op/ms list op/ms proto 103.92 89.50 83.33 21.17 kryo 99.23 76.71 73.89 25.68 fst 102.33 76.24 78.81 23.30 最终的结果也还是各有千秋难以抉择，所以 Turbo 保留了 protostuff 和 kryo 的实现，并允许用户自行替换为自己的实现。 方法调用可用的 动态方法调用 方案有：Reflection ClassGeneration MethodHandle。Reflection 是最古老的技术，据说性能不佳。ClassGeneration 动态类生成，从原理上说应该是跟直接调用一样的性能。MethodHandle 是从 Java 7 开始出现的技术，据说能达到跟直接调用一样的性能。实际结果如下： type thrpt (ops/us) direct 1062 javassist 920 methodHandle 430 reflection 337 结论非常明显：使用类生成技术的 javassist 跟直接调用几乎一样的性能，就用 javassist 了。 MethodHandle 表现并没有宣传的那么好，怎么回事？原来 MethodHandle 只有在明确知道调用 参数数量 参数类型 的情况下才能调用高性能的 invokeExact(Object… args)，所以它并不适合作为动态调用的方案。 As is usual with virtual methods, source-level calls to invokeExact and invoke compile to an invokevirtual instruction. More unusually, the compiler must record the actual argument types, and may not perform method invocation conversions on the arguments. Instead, it must push them on the stack according to their own unconverted types. The method handle object itself is pushed on the stack before the arguments. The compiler then calls the method handle with a symbolic type descriptor which describes the argument and return types.refer: https://docs.oracle.com/javase/7/docs/api/java/lang/invoke/MethodHandle.html 网络传输Netty 已经成为事实上的标准，所有主流的项目现在使用的都是 Netty。Mina Grizzly 已经失去市场，所以也就不用考虑了。还好也不至于这么无聊，Aeron 的闪亮登场让 Netty 多了一个有力的竞争对手。Aeron 是一个可靠高效的 UDP 单播 UDP 多播和 IPC 消息传递工具。性能是消息传递中的关键。Aeron 的设计旨在达到 高吞吐量 低开销 和 低延迟。实际效果到底如何呢？很遗憾，在 RPC Benchmark Round 1 中的表现一般。跟他们开发团队沟通后，最终确认其无法对超过 64k 的消息进行 zero-copy 处理，我觉得这可能是 Aeron 表现不佳的一个原因。Aeron 或许更适合 微小消息 极端低延迟 的场景，而不适用于更加通用的 RPC 场景。所以暂时还没有出现能够跟 Netty 一争高下的通用网络传输框架，现阶段 Netty 依然是 RPC 系统的最佳选择。 existUser 判断某个 email 是否存在 framework thrpt (ops/ms) avgt (ms) p90 (ms) p99 (ms) turbo-rpc 107.05 0.28 0.40 0.87 netty 99.81 0.32 0.40 0.52 jupiter 73.07 0.44 0.66 1.49 undertow 70.38 0.45 1.16 2.17 turbo-rest 68.49 0.44 1.17 2.15 undertow-async 62.65 0.49 1.14 2.41 dubbo-kryo 57.35 0.53 0.67 1.02 rapidoid 52.96 0.61 1.32 2.51 dubbo 52.12 0.54 0.67 0.92 motan 44.96 0.71 1.15 2.47 aeron 43.46 0.90 1.32 5.10 grpc 38.97 0.84 1.07 1.31 thrift 27.25 1.59 0.16 64.87 hprose 26.24 1.26 1.53 2.01 springwebflux 22.39 1.42 2.27 3.19 springboot 12.54 1.68 2.38 13.63 消息格式我们先来看一下 Dubbo 的消息格式 public class RpcInvocation implements Invocation, Serializable &#123; private String methodName; private Class&lt;?&gt;[] parameterTypes; private Object[] arguments; ...&#125; 可以说是非常经典的设计，Client 必须告知 Server 要调用的 方法名称 参数类型 参数。Server 获取到这3个参数后，通过 方法名称 com.alibaba.service.auth.UserService.verifyUser 和参数类型 (String, String) 获取到 Invoker，然后通过 Invoker 实际调用 userServiceImpl 的 verifyUser(String, String) 方法。其他的众多 RPC 框架也都采取了这一经典设计。 但是，这是正确的做法吗？当然不是，这种做法非常浪费空间，每次请求消息体的大概内存布局应该是下面的样子： public boolean verifyUser(String email, String pwd);|com.alibaba.service.auth.UserService.verifyUser|java.lang.String,java.lang.String|实际的参数| 啰里啰嗦的，浪费了 80 byte 来定义 方法 和 参数，并没有比 http+json 的方式高效多少。实际的 性能测试 也证明了这一点，undertow+jackson 要比 dubbo motan 的成绩都要好。 那什么才是正确的做法？Turbo 在消息格式上做出了非常大的改变。 public class Request implements Serializable &#123; private int requestId; private int serviceId; private MethodParam methodParam; ...&#125; 大致的内存布局： public boolean verifyUser(String email, String pwd);|int|int|实际的参数| 高效多了，只用了 4 byte 就做到了 方法 和 参数 的定义。大大减小了 传输数据 的 size，同时 int 类型的 serviceId 也降低了 Invoker 的查找开销。 看到这里，有同学可能会问：那岂不是要为每个方法定义一个唯一 id ？答案是不需要的，Turbo 解决了这一问题，详情参考 TurboConnectService 。 MethodParam 简介MethodParam 才是 Turbo 性能炸裂的真正原因。其基本原理是利用 ClassGeneration 对每个 Method 都生成一个 MethodParam 类，用于对方法参数的封装。这样做的好处有： 减少基本数据类型的 装箱 拆箱 开销 序列化时可以省略掉很多类型描述，大大减小 传输消息 的 size 使 Invoker 可以高效调用 被代理类 的方法 统一 RPC 和 REST 的数据模型，简化 序列化 反序列化 实现 大大加快 json 格式数据 反序列化 速度 //方法 test(long id, int value) 将会生成下面的 MethodParam 类: public class TestService_test_2_MethodParam implements MethodParam &#123; private long id; private int value; public long $param0() &#123; return this.id; &#125; public int $param1() &#123; return this.value; &#125; //... getters and setters public TestService_test_2_MethodParam(long id, int value) &#123; this.id = id; this.value= value; &#125;&#125; 序列化的进一步优化大部分 RPC 框架的 序列化 反序列化 过程都需要一个中间的 bytes 序列化过程：User &gt; bytes &gt; ByteBuf反序列化过程：ByteBuf &gt; bytes &gt; User 而 Turbo 砍掉了中间的 bytes，直接操作 ByteBuf，实现了 序列化 反序列化 的 zero-copy，大大减少了 内存分配 内存复制 的开销。具体实现请参考 ProtostuffSerializer 和 Codec。 对于已知类型和已知字段，Turbo 都尽量采用 手工序列化 手工反序列化 的方式来处理，以进一步减少性能开销。 ObjectPool常见的几个 ObjectPool 实现性能都很差，反而很容易成为性能瓶颈。Stormpot 性能强悍，不过存在偶尔死锁的问题，而且作者也停止维护了。HikariCP 性能不错，不过其本身是一款数据库连接池，用作 ObjectPool 并不称手。我的建议是尽量避免使用 ObjectPool，转而使用替代技术。更重要的是 Netty 的 Channel 是线程安全的，并不需要使用 ObjectPool 来管理。只需要一个简单的容器来存储 Channel，用的时候使用 负载均衡策略 选出一个 Channel 出来就行了。 framework thrpt (ops/us) ThreadLocal 685.418 Stormpot 272.934 HikariCP 139.126 SegmentLock 19.415 Vibur 4.668 CommonsPool2 1.107 CommonsPool 0.276 基础类库优化除了上述的关键流程优化，Turbo 还做了大量基础类库的优化 AtomicMuiltInteger 多个 int 的原子性操作 ConcurrentArrayList 无锁并发 List 实现，比 CopyOnWriteArrayList 的写入开销低，O(1) vs O(n) ConcurrentIntToObjectArrayMap 以 int 数组为底层实现的无锁并发 Map，读多写少情况下接近直接访问字段的性能，读多写多情况下是 ConcurrentHashMap 性能的 5x ConcurrentIntegerSequencer 快速序号生成器，并发环境下是 AtomicInteger 性能的10x ObjectId 全局唯一 id 生成器，是 Java 自带 UUID 性能的 200x HexUtils 查表 + 批量操作，是 Netty 和 Guava 实现的 2x~5x URLEncodeUtils 基于 HexUtils 实现，是 Java 和 Commons 实现的 2x，Guava 实现的 1.1x (Guava 只有 urlEncode 实现，无 urlDecode 实现) ByteBufUtils 实现了高效的 ZigZag 写入操作，最高可达通常实现的 4x 上面的内容仅介绍了作者认为重要的东西，更多内容请直接查看 Turbo 源码 不足之处 有很多优化是毫无价值的，Donald Knuth 大神说得很对 强制必须使用 CompletableFuture 作为返回值导致了一些性能开销 滥用 ClassGeneration，而且并没有考虑类的卸载，这方面需要改进 实现了 UnsafeStringUtils，这是个危险的黑魔法实现，需要重新思考下 对性能的追求有点走火入魔，导致了很多地方的设计过于复杂","tags":[{"name":"rpc-benchmark","slug":"rpc-benchmark","permalink":"https://ningyu1.github.io/tags/rpc-benchmark/"}]},{"title":"怎样对RPC进行有效的性能测试","date":"2018-09-18T10:16:00.000Z","path":"20180918/98-rpc-benchmark.html","text":"最近看相关rpc-benchmark相关的东西发现这篇文章挺好的，所以转载出来，下面是文章出处。 作者：鲁小憨链接：https://www.jianshu.com/p/cbcdf05eaa5c來源：简书简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。 在 RPC Benchmark Round 1 中 turbo 的成绩一骑绝尘，实力碾压众 rpc 框架。对此，很多人表示不服气，认为作者既是运动员又是裁判员有失公平。所以我认为有必要解释一下 rpc-benchmark 的公正性，以及为什么 turbo 能够如此强悍。 参考对象rpc-benchmark 灵感源自 techempower-benchmarks，为了能够评测众多服务器框架，techempower-benchmarks 提供了6个测试用例： JSON serialization This test exercises the framework fundamentals including keep-alive support, request routing, request header parsing, object instantiation, JSON serialization, response header generation, and request count throughput. Single database query This test exercises the framework’s object-relational mapper (ORM), random number generator, database driver, and database connection pool. Multiple database queries This test is a variation of Test #2 and also uses the World table. Multiple rows are fetched to more dramatically punish the database driver and connection pool. At the highest queries-per-request tested (20), this test demonstrates all frameworks’ convergence toward zero requests-per-second as database activity increases. Fortunes This test exercises the ORM, database connectivity, dynamic-size collections, sorting, server-side templates, XSS countermeasures, and character encoding. Database updates This test is a variation of Test #3 that exercises the ORM’s persistence of objects and the database driver’s performance at running UPDATE statements or similar. The spirit of this test is to exercise a variable number of read-then-write style database operations. Plaintext This test is an exercise of the request-routing fundamentals only, designed to demonstrate the capacity of high-performance platforms in particular. Requests will be sent using HTTP pipelining. The response payload is still small, meaning good performance is still necessary in order to saturate the gigabit Ethernet of the test environment. techempower-benchmarks 规则都是公开的，代码都是开放的。任何人觉得xx框架写得不好，配置有问题，都可以来提交自己的 Pull Request 。一句话，不服气的话就来提交代码。 测试用例不过 techempower-benchmarks 对比的都是服务器框架，并不能用来测试 rpc 的性能，作为学习模仿者，我创建了 rpc-benchmark 这个项目。 rpc-benchmark 提供了4个测试用例： boolean existUser(String email), 判断某个 email 是否存在输入是很短的字符串，输出是 bool 值，这个测试用例用于衡量小 Request 小Response 的性能。 boolean createUser(User user), 添加一个 用户输入是一个 User 的对象，输出是 bool 值，这个测试用例用于衡量大 Request 小 Response 的性能。 User getUser(long id), 根据 id 获取一个用户输入是一个 long 类型的值，输出是 User 对象，这个测试用例用于衡量小 Request 大 Response 的性能。 Page listUser(int pageNo), 获取用户列表输入是 int 类型的值，输出是一个包含15个 User 的列表，这个测试用例用于衡量小 Request 超大 Response 的性能。 这4个测试用例构成了一个基本的业务逻辑： 用户注册管理。非常具有代表性，并且没有脱离现实使用场景。有些测试用例可能会注重衡量字符串的传输速度，从4字节 64字节 … 64k字节 依次测起，这样的测试用例就过于脱离现实，没有太多的实际意义。毕竟作为 rpc 框架，除了传输速度，序列化速度其实也是非常重要的。而仅仅用字符串来测试仅能测试出框架的传输速度，并不能有效衡量序列化的性能，也不能衡量整体的 rpc 性能。 测试工具因为每个 rpc 框架都有自己的 序列化协议 传输协议，所以 rpc-benchmark 不能像 techempower-benchmarks 一样直接使用 wrk 作为测试工具，只能每个框架都编写测试用的 客户端实现。 客户端实现 使用的工具是JMH，这个工具 Java 开发团队自己也在使用。正确的性能测试在之前并不是一件简单的事情，JMH 的出现让性能测试真正的 标准化 简单化。更多关于 JMH 的介绍可以参考下面的链接。 JMH - Java Microbenchmark Harness ImportNew JMH简介 测试方法测试的过程是先进行10次预热，然后才开始真正的3次测试（JMH的“每次”执行实际上是执行很多次，更好的翻译其实应该是“每轮”）。刚开始使用的是5次预热，但是后来发现 http 传输协议的 undertow grpc 等框架都比较慢热，需要更多的预热次数。完整的测试要跑起来依然有点费劲，需要配置很多环境。不过如果你只是想研究下某个框架的代码实现的话，完全可以更简单一些。拉下代码来直接导入到 Eclipse/IDEA ，配置好hosts，启动 Server，然后启动相应的 Client 就好了。 为什么把 undertow springboot netty 也作为了测试对象按照 wiki 的定义，这三个确实不能认为是 rpc ，不过简单封装之后他们都可以作为 rpc 使用。加入这几个更多的是为给 rpc 框架的实现者提供一个参考，作为基础的协议层性能是怎么样的？作为springcloud 的底层实现，springboot 其实代表了springcloud 的性能。undertow 证明了 http+json 并不比 tcp+binary 慢太多，其速度甚至比 dubbo motan 还要快不少。同时也是为了告诉喷子们，并不是说你用了高性能的 netty+protopuff 就能比 turbo 快，turbo 能碾压众框架并不只是靠简单的拼积木就能做到的。 不足之处仅1个客户端32个线程其实是非常不严谨的，正确的做法应该是从1个线程一直到32k个线程逐步增加，从1台客户端机器到1000台客户端机器逐步增加（客户端数量 线程数量 应该是一个笛卡尔积）。不过每轮测试实在都太耗费时间了，而且阿里云的服务器也不便宜，所以只能作罢。后续如果有云服务器厂商赞助的话，可以考虑把这块给做起来。 turbo为什么如此强悍篇幅有限写不开了，下篇再说吧。","tags":[{"name":"rpc-benchmark","slug":"rpc-benchmark","permalink":"https://ningyu1.github.io/tags/rpc-benchmark/"}]},{"title":"Trouble Shooting —— MyBatis的PropertyTokenizer抛NPE异常","date":"2018-08-20T09:48:00.000Z","path":"20180820/97-mybatis-npe.html","text":"这个文章转自公司内网WIKI，同事调试的问题以及问题分析过程，我觉得挺好的所以转载出来。 问题描述多任务同时处理时会报出如下NPE异常，堆栈信息如下： 2018-08-10 18:16:10.938 [xxxExecutor-2] ERROR c.j.bmc.mq.listener.xxxResultListener org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException:### Error querying database. Cause: java.lang.NullPointerException### Cause: java.lang.NullPointerException at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75) ~[mybatis-spring-1.2.2.jar:1.2.2] at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:371) ~[mybatis-spring-1.2.2.jar:1.2.2] at com.sun.proxy.$Proxy21.selectList(Unknown Source) ~[na:na] at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:198) ~[mybatis-spring-1.2.2.jar:1.2.2] at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:119) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:63) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:52) ~[mybatis-3.2.7.jar:3.2.7] at com.sun.proxy.$Proxy49.findBillBillingTask(Unknown Source) ~[na:na] at com.xxx.service.impl.XXXServiceImpl.findBillBillingTask(XXXServiceImpl.java:118) ~[bmc-service-0.0.1-SNAPSHOT.jar:na] at com.xxx.service.impl.XXXServiceImpl$$FastClassByCGLIB$$7d4463f0.invoke(&lt;generated&gt;) ~[spring-core-4.0.0.RELEASE.jar:na] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ~[spring-core-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:713) ~[spring-aop-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) ~[spring-aop-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:98) ~[spring-tx-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:262) ~[spring-tx-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:95) ~[spring-tx-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:646) ~[spring-aop-4.0.0.RELEASE.jar:4.0.0.RELEASE] at com.xxx.service.impl.XXXServiceImpl$$EnhancerByCGLIB$$32d6287d.findBillBillingTask(&lt;generated&gt;) ~[spring-core-4.0.0.RELEASE.jar:na] at com.xxx.service.impl.XXXResultServiceImpl.saveBillBillingTask(XXXResultServiceImpl.java:213) ~[bmc-service-0.0.1-SNAPSHOT.jar:na] at com.xxx.service.impl.XXXResultServiceImpl.disposeBillBillingResult(XXXResultServiceImpl.java:193) ~[bmc-service-0.0.1-SNAPSHOT.jar:na] at com.xxx.service.impl.XXXResultServiceImpl$$FastClassByCGLIB$$5e8db258.invoke(&lt;generated&gt;) ~[spring-core-4.0.0.RELEASE.jar:na] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ~[spring-core-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:713) ~[spring-aop-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) ~[spring-aop-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:98) ~[spring-tx-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:262) ~[spring-tx-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:95) ~[spring-tx-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:646) ~[spring-aop-4.0.0.RELEASE.jar:4.0.0.RELEASE] at com.xxx.service.impl.XXXResultServiceImpl$$EnhancerByCGLIB$$8d251e5.disposeBillBillingResult(&lt;generated&gt;) ~[spring-core-4.0.0.RELEASE.jar:na] at com.xxx.XXXListener.receiveMessage(BillBillingResultListener.java:92) ~[bmc-main-0.0.1-SNAPSHOT.jar:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_79] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_79] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_79] at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_79] at org.springframework.util.MethodInvoker.invoke(MethodInvoker.java:273) [spring-core-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.jms.listener.adapter.MessageListenerAdapter.invokeListenerMethod(MessageListenerAdapter.java:466) [spring-jms-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.jms.listener.adapter.MessageListenerAdapter.onMessage(MessageListenerAdapter.java:357) [spring-jms-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.jms.listener.adapter.MessageListenerAdapter.onMessage(MessageListenerAdapter.java:332) [spring-jms-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.jms.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:537) [spring-jms-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.jms.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:497) [spring-jms-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.jms.listener.AbstractMessageListenerContainer.doExecuteListener(AbstractMessageListenerContainer.java:468) [spring-jms-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.jms.listener.AbstractPollingMessageListenerContainer.doReceiveAndExecute(AbstractPollingMessageListenerContainer.java:325) [spring-jms-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.jms.listener.AbstractPollingMessageListenerContainer.receiveAndExecute(AbstractPollingMessageListenerContainer.java:263) [spring-jms-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.jms.listener.DefaultMessageListenerContainer$AsyncMessageListenerInvoker.invokeListener(DefaultMessageListenerContainer.java:1104) [spring-jms-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.jms.listener.DefaultMessageListenerContainer$AsyncMessageListenerInvoker.run(DefaultMessageListenerContainer.java:998) [spring-jms-4.0.0.RELEASE.jar:4.0.0.RELEASE] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_79] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_79] at java.lang.Thread.run(Thread.java:745) [na:1.7.0_79]Caused by: org.apache.ibatis.exceptions.PersistenceException:### Error querying database. Cause: java.lang.NullPointerException### Cause: java.lang.NullPointerException at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:26) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:111) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:102) ~[mybatis-3.2.7.jar:3.2.7] at sun.reflect.GeneratedMethodAccessor203.invoke(Unknown Source) ~[na:na] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_79] at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_79] at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:358) ~[mybatis-spring-1.2.2.jar:1.2.2] ... 48 common frames omittedCaused by: java.lang.NullPointerException: null at org.apache.ibatis.reflection.property.PropertyTokenizer.&lt;init&gt;(PropertyTokenizer.java:30) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.reflection.MetaObject.getValue(MetaObject.java:107) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.scripting.xmltags.DynamicContext$ContextMap.get(DynamicContext.java:97) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.scripting.xmltags.DynamicContext$ContextAccessor.getProperty(DynamicContext.java:116) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.ognl.OgnlRuntime.getProperty(OgnlRuntime.java:1657) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.ognl.ASTProperty.getValueBody(ASTProperty.java:92) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:170) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:210) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.ognl.ASTNotEq.getValueBody(ASTNotEq.java:49) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:170) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:210) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:333) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:413) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:395) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.scripting.xmltags.OgnlCache.getValue(OgnlCache.java:48) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.scripting.xmltags.ExpressionEvaluator.evaluateBoolean(ExpressionEvaluator.java:32) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.scripting.xmltags.IfSqlNode.apply(IfSqlNode.java:33) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.scripting.xmltags.MixedSqlNode.apply(MixedSqlNode.java:32) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.scripting.xmltags.DynamicSqlSource.getBoundSql(DynamicSqlSource.java:40) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.mapping.MappedStatement.getBoundSql(MappedStatement.java:278) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:75) ~[mybatis-3.2.7.jar:3.2.7] at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source) ~[na:na] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_79] at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_79] at org.apache.ibatis.plugin.Invocation.proceed(Invocation.java:49) ~[mybatis-3.2.7.jar:3.2.7] at com.github.pagehelper.util.SqlUtil.doIntercept(SqlUtil.java:175) ~[pagehelper-4.2.1.jar:na] at com.github.pagehelper.util.SqlUtil.intercept(SqlUtil.java:84) ~[pagehelper-4.2.1.jar:na] at com.github.pagehelper.PageHelper.intercept(PageHelper.java:50) ~[pagehelper-4.2.1.jar:na] at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:60) ~[mybatis-3.2.7.jar:3.2.7] at com.sun.proxy.$Proxy53.query(Unknown Source) ~[na:na] at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:108) ~[mybatis-3.2.7.jar:3.2.7] ... 53 common frames omitted 分析过程通常，有堆栈数据的时候就很容分析出问题的原因。但是经过查看相关代码后发现触发点操作逻辑非常简单，不太会出现该异常。 于是就考虑从日志的细节分析问题。 先查看业务代码。该代码使用一个非空的VO对象作为查询条件，提交给Mapper。 Mapper中，判断各个参数是否为null或者空，然后拼接到SQL中。整个过程非常简单，而且大部分是成功执行的。 通过以上判断，可以认为不是业务代码的问题，极有可能是mybatis的问题。于是上网进行搜索，得到一些关于偶发NPE问题的描述。 mybatis-3/issues/313 mybatis-3/issues/199 以下问题提及了偶发返回null的情况。 issues-OGNL-121 于是我们又观察反编译代码和日志执行情况，可以看到在SimpleNode.java中的确有非安全的逻辑操作。 日志也有相关的执行过程。 由于没有源代码，所以无法有效的进行Debug，模拟并发操作。因此该问题只能怀疑是这个原因导致的，具体可以在后续 有条件的情况下进行模拟测试。 深入并发测试在Idea中可以反编译代码，且还原度较高，因此我们做了一次测试。 测试环境两个Consumer调用Provider，Provider只做数据库查询，且查询中带条件判断。 这里使用Spring test进行测试，以下是Consumer端调用 Provider端定义 查询条件判断 准备好测试环境后，就可以进行测试了。此处还需要注意如何在IntellJ Idea中Debug多线程，具体设置方法请找度娘。 测试过程同时启动两个Consumer，然后在Provider中的SimpleNode.java中设置断点。 根据之前分析，如果要出现null，则说明getProperty会返回null。 而getValue方法实际调用的逻辑是以下代码： 说明以下的代码返回了null 从代码上及Debug分析，如果要返回null，则很有可能在hasConstantValue=true且constantValue为null。 当然此处的数据已经是我们模拟出并发问题后的结果，也验证了是有可能的。 如果没有出问题的情况时，正常的结果应该是constantValue=id，hasConstantValue=true。 测试过程中，我们发现多个线程调用的对象实际是同一个，如下图中的ASTConst@6075。 根据多线程常见问题处理经验来看，如果多线程操作同一个对象，则要注意其是否存在成员变量。如果有，那还要注意是否做了并发可见性处理。 于是我们看下代码 那我们指导了这里有并发问题，那就好容易模拟了。我们只要在第一个线程中保持一种状态，然后暂停操作。再在另外一个线程中去特定的操作 步骤中正常变更数据。最后再放开第一个线程继续往下执行。由于第一个线程的成员变量已经发生了变化，所以后续的结果就不再是预想的那样 了。 于是就有了如下结果 模拟的关键在于： 多线程操作同一个服务 第一个线程在判断语句处等待第二个线程变更条件值，this.constantValueCalculated变量初始化为false，等第二个线程变更后变为true 第一个线程继续往下执行 第二个线程变更了成员变量的值，this.hasConstantValue变量初始化为false，但是被变更为true，然后等待第一个线程执行 第一个线程用刚更新的值去判断，返回了null值，也就导致了后续的NPE异常 注意：以上说的“等待”只是模拟说法，实际情况会由CPU控制，执行顺序不定。恰巧出现了以上执行流程，则会出现NPE问题。 升级版处理逻辑在Mybatis的3.4.5版本中，程序采用了volatile修饰符来定义变量，并且在使用上面也注意了赋值的先后顺序。 结论建议升级mybatis，版本是3.3.0+，提及到新的ognl处理逻辑修复此问题，但是我们要考虑在经过充分测试的前提下进行升级。","tags":[{"name":"mybatis","slug":"mybatis","permalink":"https://ningyu1.github.io/tags/mybatis/"}]},{"title":"为什么手机浏览器打开word、excel文件部分文件能预览，部分文件不能预览？","date":"2018-08-09T01:48:00.000Z","path":"20180809/96-word-xml.html","text":"最近公司合同项目中有很多附件是excel和word的格式，这些文件有用户直接导入的，也有程序自动生成的，合同项目中有结合钉钉来做工作流，所以会有pc端和钉钉移动端的互动。 问题现象pc端的附件列表可以正常的下载word、excel文件，并且可以成功的打开，但是当流程流转到钉钉时，在钉钉审批的时候可以通过连接跳转h5来显示附件列表，项目的功能设计初衷是可以在手机端打开预览word、excel文件。 但是发现了奇怪的问题，部分word可以在钉钉中显示，部分word无法显示，例如下图所示： 我们的期望效果如下图所示： 问题分析我们分别使用手机浏览器（safari）、postman、微信内嵌浏览器、qq内嵌浏览器分别测试无法正常预览的word链接 手机浏览器、微信内嵌浏览器、qq内嵌浏览器均无法打开 使用postman下载在移动端无法打开的word链接，返回的是一段xml，如下： &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;&lt;?mso-application progid=&quot;Word.Document&quot;?&gt;&lt;pkg:package xmlns:pkg=&quot;http://schemas.microsoft.com/office/2006/xmlPackage&quot;&gt;&lt;pkg:part pkg:name=&quot;/_rels/.rels&quot;.... 这是个什么鬼？是word的xml格式，问题原因就在这里手机浏览器无法识别word的xml格式，因此再次尝试excel excel使用的是poi生成直接写的是二级制格式，没有使用xml格式，因此excel是可以在移动端打开预览的。 询问开发word是如何生成的？ 生成过程是这样的：使用word编辑好模版，然后另存为xml格式，导入到系统中去，通过FreeMarker替换内容，再将xml写到fastdfs中去后缀给成 ‘.doc’ ,这样下载下来使用office word可以直接打开xml格式的来进行无损渲染。 解决方案询问业务是否必须要使用word格式文件？我的理解合同项目大多都是给用户只读的文件，建议使用pdf来做，使用jasper生成word模版，通过jasper的java api直接生成pdf，合同后期还要考虑添加水印，pdf更加方便一些。 建议使用pdf来替换word，如果非要使用word，建议生成word二进制格式来替换xml格式，除非不考虑移动端渲染可以使用xml格式的word。 目前java生成word的方式有如下六种方式： Jacob是Java-COM Bridge的缩写，它在Java与微软的COM组件之间构建一座桥梁。使用Jacob自带的DLL动态链接库，并通过JNI的方式实现了在Java平台上对COM程序的调用。DLL动态链接库的生成需要windows平台的支持。该方案只能在windows平台实现，是其局限性。 Apache POI包括一系列的API，它们可以操作基于MicroSoft OLE 2 Compound Document Format的各种格式文件，可以通过这些API在Java中读写Excel、Word等文件。他的excel处理很强大，对于word还局限于读取，目前只能实现一些简单文件的操作，不能设置样式。 Java2word是一个在java程序中调用 MS Office Word 文档的组件(类库)。该组件提供了一组简单的接口，以便java程序调用他的服务操作Word 文档。 这些服务包括： 打开文档、新建文档、查找文字、替换文字，插入文字、插入图片、插入表格，在书签处插入文字、插入图片、插入表格等。填充数据到表格中读取表格数据 ，1.1版增强的功能： 指定文本样式，指定表格样式。如此，则可动态排版word文档。是一种不错的解决方案。 iText是著名的开放源码的站点sourceforge一个项目，是用于生成PDF文档的一个java类库。通过iText不仅可以生成PDF或rtf的文档，而且可以将XML、Html文件转化为PDF文件。功能强大。 JSP输出样式，该方案实现简单，但是处理样式有点缺陷，简单的导出可以使用。 用XML做就很简单了。Word从2003开始支持XML格式，大致的思路是先用office2003或者2007编辑好word的样式，然后另存为xml，将xml翻译为FreeMarker模板，最后用java来解析FreeMarker模板并输出Doc。经测试这样方式生成的word文档完全符合office标准，样式、内容控制非常便利，打印也不会变形，生成的文档和office中编辑文档完全一样。 总结伴随着手机的兴起，不管是传统行业还是互联网行业对系统都有在移动端使用的要求，不管是从用户体验上还是从移动系统兼容性以及浏览器兼容性上都会遇到各种问题，当然也有工具可以解决这些问题，例如：RN、flutter都可以很好的解决系统兼容问题，vue.js、angularjs都可以很好的解决浏览器兼容问题，而且这些都有大厂的支持，关于以上的问题这种解决方法并不是最好的，但是可以做为一种参考，重点是对问题的总结，只要解决问题的方法符合自己的业务场景我个人认为就是正（有）确（效）的方法，如果有更好的方式可以在下放留言一起讨论。","tags":[{"name":"word-xml","slug":"word-xml","permalink":"https://ningyu1.github.io/tags/word-xml/"}]},{"title":"使用downloadjs下载并且重命名文件名称引发的跨域问题","date":"2018-08-02T06:50:00.000Z","path":"20180802/95-downloadjs-cors.html","text":"我们有一部分静态资源放在fastdfs文件服务器上，并且文件名称是生成的随机数，直接浏览器下载是可以正常下载文件的，但是我们需要修改下载文件的名称，直接a标签href是无法修改下载文件名称的。 使用a标签的download属性又有浏览器兼容问题，而且download属性有一个弊端，只有点击右键另存为才会生效，直接点击是不生效的。 因此我们这里借助了一个组件downloadjs来进行文件下载，它可以修改下载文件的名称，并且也没有浏览器兼容问题，原理呢很简单那，使用ajax请求去下载文件，在发起请求时构造请求header来重命名下载文件名。 但是这里会存在一个问题？我们的fastdfs和应用程序是独立的两个域，因此存在跨域的问题，直接使用a标签的href是不存在跨域的问题，按关于这个跨域的问题我们如何解决？ 先来看一下使用downloadjs下载fastdfs的文件时报出的跨域错误信息如下 Failed to load http://192.168.0.48:8079/group1/M00/03/35/wKgAMFtgB2SAFjibAAX3egrfUI8922.doc: No &apos;Access-Control-Allow-Origin&apos; header is present on the requested resource. Origin &apos;http://localhost:8080&apos; is therefore not allowed access. 本地使用是通过vue的proxyTable绕过跨域的问题，其实就是前端的proxy方式虚拟一个context然后pass转发，虽然这样可以解决目前的问题，但是我们在uat和prd环境又要增加相同的context path的映射，这不是我们想要的，我们想直接访问下载地址来进行下载，因此我们需要修改fastdfs的nginx模块配置。 跨域的配置这里就不多说了，其实就是添加一系列的Access-Control-Allow-X的header即可，不会的可以参考我以前的文章跨域踩坑经验总结》，唯一需要注意的是，当使用Access-Control-Allow-Credentials=true时Access-Control-Allow-Origin不允许使用* 必须使用具体的域名多个可以使用,分割。 修改后我们可以直接的请求地址下载文件即可。","tags":[{"name":"js","slug":"js","permalink":"https://ningyu1.github.io/tags/js/"},{"name":"downloadjs","slug":"downloadjs","permalink":"https://ningyu1.github.io/tags/downloadjs/"},{"name":"cors","slug":"cors","permalink":"https://ningyu1.github.io/tags/cors/"}]},{"title":"使用Embedded RedisServer写UT","date":"2018-07-17T10:11:00.000Z","path":"20180717/94-embedded-redisServer.html","text":"当我们在进行开发的时候经常会用到Redis，但是在写junit的时候往往引用了Redis造成test case很难写，我们需要mock一个localhost的Redis server来进行测试，因此我们可以借助embedded redisServer来实现，下面我们就看一下具体使用的示例 代码示例@Beforepublic void setUp() throws IOException &#123; initMocks(this); final Random random = new SecureRandom(); redisServer = new RedisServer(); redisServer.start(); pool = new JedisPool(); repository = new RedisKeyRepository(pool); manager = new RedisKeyManager(random, pool, repository); manager.setMaxActiveKeys(3); clearData(); manager.initialiseNewRepository(); resource = new ProtectedResource(repository, random);&#125; 这是一个非常简单的使用示例，我们还可以更改配置以及增加密码 @Beforepublic void setUpRedis() throws IOException, SchedulerConfigException &#123; port = getPort(); logger.debug(&quot;Attempting to start embedded Redis server on port &quot; + port); redisServer = RedisServer.builder() .port(port) .build(); redisServer.start(); final short database = 1; JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); jedisPoolConfig.setTestOnBorrow(true); jedisPool = new JedisPool(jedisPoolConfig, host, port, Protocol.DEFAULT_TIMEOUT, null, database); jobStore = new RedisJobStore(); jobStore.setHost(host); jobStore.setLockTimeout(2000); jobStore.setPort(port); jobStore.setInstanceId(&quot;testJobStore1&quot;); jobStore.setDatabase(database); mockScheduleSignaler = mock(SchedulerSignaler.class); jobStore.initialize(null, mockScheduleSignaler); schema = new RedisJobStoreSchema(); jedis = jedisPool.getResource(); jedis.flushDB();&#125; 使用RedisServerBuilder构建Redis server，并且指定port @Test//Note the try/finally is to ensure that the server is shutdown so other tests do not have to//provide auth informationpublic void testAuth() throws Exception &#123; RedisServer server = RedisServer.builder().port(6381).setting(&quot;requirepass foobar&quot;).build(); server.start(); RedisOptions job = new RedisOptions() .setHost(&quot;localhost&quot;) .setPort(6381); RedisClient rdx = RedisClient.create(vertx, job); rdx.auth(&quot;barfoo&quot;, reply -&gt; &#123; assertFalse(reply.succeeded()); rdx.auth(&quot;foobar&quot;, reply2 -&gt; &#123; assertTrue(reply2.succeeded()); try &#123; server.stop(); &#125; catch (Exception ignore) &#123; &#125; testComplete(); &#125;); &#125;); await();&#125; 设置一个需要密码访问的Redis server，setting可以设置redis conf中的所有属性 更多用法还有很多用法，具体查看下面的代码示例 @Testpublic void testDebugSegfault() throws Exception &#123; RedisServer server = RedisServer.builder().port(6381).build(); server.start(); RedisOptions job = new RedisOptions() .setHost(&quot;localhost&quot;) .setPort(6381); RedisClient rdx = RedisClient.create(vertx, job); rdx.debugSegfault(reply -&gt; &#123; // this should fail, since we crashed the server on purpose assertTrue(reply.failed()); rdx.info(reply2 -&gt; &#123; assertFalse(reply2.succeeded()); server.stop(); testComplete(); &#125;); &#125;); await();&#125;public RedisServerResource(int port, String password) &#123; this.port = port; try &#123; RedisExecProvider redisExecProvider = RedisExecProvider.defaultProvider(); this.redisServer = RedisServer .builder() .redisExecProvider(redisExecProvider) .port(port) .setting(&quot;requirepass &quot; + password) .build(); &#125; catch (Throwable error) &#123; String message = String.format(&quot;failed creating Redis server (port=%d)&quot;, port); throw new RuntimeException(message, error); &#125;&#125;@Beforepublic void before() throws Exception &#123; mockTracer.reset(); redisServer = RedisServer.builder().setting(&quot;bind 127.0.0.1&quot;).build(); redisServer.start();&#125; private void startServer(TestContext testContext) &#123; EmbeddedRedis embeddedRedis = AnnotationUtils.findAnnotation(testContext.getTestClass(), EmbeddedRedis.class); int port = embeddedRedis.port(); try &#123; server = new RedisServer(port); server.start(); &#125; catch (IOException e) &#123; if (logger.isErrorEnabled()) &#123; logger.error(e.getMessage(), e); &#125; &#125;&#125;private RedisServer createRedisServer() &#123; final RedisServerBuilder redisServerBuilder = RedisServer.builder() .port(redisPort) .setting(&quot;appendonly yes&quot;) .setting(&quot;appendfsync everysec&quot;); settings.stream().forEach(s -&gt; redisServerBuilder.setting(s)); final RedisServer redisServer = redisServerBuilder.build(); return redisServer;&#125; 有可能我们启动会遇到下面的错误：java.lang.RuntimeException: Can&apos;t start redis server. Check logs for details. at redis.embedded.AbstractRedisInstance.awaitRedisServerReady(AbstractRedisInstance.java:66) at redis.embedded.AbstractRedisInstance.start(AbstractRedisInstance.java:37) at redis.embedded.RedisServer.start(RedisServer.java:11) at com.bignibou.configuration.session.EmbeddedRedisConfiguration$RedisServerBean.afterPropertiesSet(EmbeddedRedisConfiguration.java:26) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1633) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1570) ... 15 more 这个是什么原因呢？我们进一步debug输出redis server的log看是什么问题，redis log如下： The windows version of redis allocates a large memory mapped file for sharing the heap with the forked process used in persistence operations. This file will be created in the current working directory or the directory specified by the &apos;heapdir&apos; directive in the.conf file. Windows is reporting that there is insufficient disk space available for this file (Windows error 0x70).You may fix this probilem by either reducing the size of the Redis heap with the --maxheap flag, or by moving the heap file to a local drive with sufficient space.Please see the documentation included with the binary distributions for more details on the --maxheap and --heapdir flags.Redis can not continue, Exiting. 这里的原因是我们启动的时候heap不够，redis server默认的maxheap:1024000000，创建.conf文件时硬盘不够，那如何解决这个错误呢？ @Testpublic void testAuth() throws Exception &#123; RedisServer server = RedisServer.builder().port(6381).setting(&quot;maxheap 51200000&quot;).build(); server.start();&#125; 关于redis maxheap的详细描述如下： # The Redis heap must be larger than the value specified by the maxmemory# flag, as the heap allocator has its own memory requirements and# fragmentation of the heap is inevitable. If only the maxmemory flag is# specified, maxheap will be set at 1.5*maxmemory. If the maxheap flag is# specified along with maxmemory, the maxheap flag will be automatically# increased if it is smaller than 1.5*maxmemory.# # maxheap &lt;bytes&gt;maxheap 51200000 注意：修改时需要考虑可用量，常规情况都无需修改这个参数 更多查看官方文档","tags":[{"name":"test","slug":"test","permalink":"https://ningyu1.github.io/tags/test/"},{"name":"redis","slug":"redis","permalink":"https://ningyu1.github.io/tags/redis/"},{"name":"Can't start redis server. Check logs for details.","slug":"Can-t-start-redis-server-Check-logs-for-details","permalink":"https://ningyu1.github.io/tags/Can-t-start-redis-server-Check-logs-for-details/"}]},{"title":"通过对Maven的依赖分析剔除无用的jar引用","date":"2018-07-11T06:11:00.000Z","path":"20180711/93-maven-depenpency-analyze.html","text":"当项目开发维护了一段时间时，经常会有项目打包速度慢，jar依赖多，依赖关系错综复杂，这种问题是项目维护最常见的问题，由于开发人员在bugfix或者feature开发时往往只是往项目中添加jar依赖，那我们如何分析出项目中哪些依赖是用到的，哪些依赖是不用的？ 使用Maven analyze来进行分析 使用如下命令： mvn dependency:analyze 会输出如下的日志： [INFO] --- maven-dependency-plugin:2.8:analyze (default-cli) @ xxxproject ---[WARNING] Used undeclared dependencies found:[WARNING] org.springframework:spring-beans:jar:4.0.0.RELEASE:compile[WARNING] org.springframework:spring-context:jar:4.0.0.RELEASE:compile[WARNING] Unused declared dependencies found:[WARNING] com.alibaba:dubbo:jar:2.5.3:compile[WARNING] com.baidu.disconf:disconf-client:jar:2.6.32:compile[WARNING] org.mybatis:mybatis:jar:3.2.7:compile[WARNING] org.mybatis:mybatis-spring:jar:1.2.2:compile[WARNING] mysql:mysql-connector-java:jar:5.1.41:compile[WARNING] com.alibaba:druid:jar:1.0.9:compile[WARNING] com.github.sgroschupf:zkclient:jar:0.1:compile[WARNING] org.apache.zookeeper:zookeeper:jar:3.4.6:compile[WARNING] org.springframework:spring-jdbc:jar:4.0.0.RELEASE:compile[WARNING] org.slf4j:log4j-over-slf4j:jar:1.7.5:compile[WARNING] org.slf4j:jcl-over-slf4j:jar:1.7.5:runtime[WARNING] ch.qos.logback:logback-classic:jar:1.0.13:compile 我们就来说一下日志中的Used undeclared dependencies found和Unused declared dependencies found Used undeclared dependencies found这个是指某些依赖的包在代码中有用到它的代码，但是它并不是直接的依赖（就是说没有在pom中直接声明），是通过引入传递下来的包。 举个例子： project在pom中声明了A.jar的依赖（没有声明B.jar的依赖）A.jar的依赖关系：A.jar -&gt; B.jar通过mvn dependency:analyze出现[WARNING] Used undeclared dependencies found: B.jar就说明project中的代码用到了B.jar的代码这个时候你就可以把B.jar直接声明在pom中 Unused declared dependencies found这个是指我们在pom中声明了依赖，但是在实际代码中并没有用到这个包！也就是多余的包。这个时候我们就可以把这个依赖从pom中剔除。 但是这里我们需要注意：这里说的实际代码没有用到，指的是在main/java和test里没有用的，但是并不是意味着真的没有用到这些包，有可能配置文件中引用或者其他扩展点自动加载这些包，所以我们在删除依赖的时候一定要小心，做好备份，因为这类引用maven是分析不出来的。","tags":[{"name":"maven","slug":"maven","permalink":"https://ningyu1.github.io/tags/maven/"},{"name":"dependency:analyze","slug":"dependency-analyze","permalink":"https://ningyu1.github.io/tags/dependency-analyze/"}]},{"title":"跨域踩坑经验总结（内涵：跨域知识科普）","date":"2018-06-27T04:20:00.000Z","path":"20180627/92-CORS-ajax.html","text":"跨域问题是我们非常常见的问题，尤其在跨系统页面间的调用经常会遇到，解决的方式在网上一搜一大把，这里整理出我遇到跨域问题解决的方式以及思路，如何安全的解决跨域调用请继续往下看。 什么是跨域？ 跨域使用的场景？ 解决跨域的方式？ 前端、后端如何配合处理跨域？ 跨域常见错误 突如其来的OPTIONS请求？ 后端需要返回的Header有哪些？ 前端如何配合发起请求？ Ajax跨域请求跨平台兼容性问题 什么是跨域？什么是Cross-origin_resource_sharing?跨域请求存在的原因：由于浏览器的同源策略，即属于不同域的页面之间不能相互访问各自的页面内容。 跨域使用的场景？ 域名不同 www.jiuyescm.com和www.jiuye.com即为不同的域名 二级域名相同，子域名不同 a.jiuyescm.com和b.jiuyescm.com为子域不同 端口不同，协议不同 http://www.jiuyescm.com和https://www.jiuyescm.com www.jiuyescm.com:8888和www.jiuyescm.com:8080 解决跨域的方式？ jsonp 安全性差，已经不推荐 CORS（W3C标准，跨域资源共享 - Cross-origin resource sharing） 服务端设置，安全性高，推荐使用 websocke 特殊场景时使用，不属于常规跨域操作 代理服务（nginx） 可作为服务端cors配置的一种方式，推荐使用 前端、后端如何配合处理跨域？ps. 我们这里只介绍：CORS处理方式。 跨域常见错误首先让我们看一下前端报出的跨域错误信息 第一种：No &#39;Access-Control-Allow-Origin&#39; header is present on the requested resource，并且The response had HTTP status code 404 XMLHttpRequest cannot load http://b.domain.com, Response to preflinght request doesn&apos;t pass access control check: No &apos;Access-Control-Allow-Origin&apos; header is present on the requested resource. Origin &apos;http://a.domain.com&apos; is therefore not allowed access. The Response had HTTP status code 404. ps.并且The response had HTTP status code 404 问题原因：服务器端后台没有允许OPTIONS请求 第二种：No &#39;Access-Control-Allow-Origin&#39; header is present on the requested resource，并且The response had HTTP status code 405 XMLHttpRequest cannot load http://b.domain.com, Response to preflinght request doesn&apos;t pass access control check: No &apos;Access-Control-Allow-Origin&apos; header is present on the requested resource. Origin &apos;http://a.domain.com&apos; is therefore not allowed access. The Response had HTTP status code 405. ps.并且The response had HTTP status code 405 问题原因：服务器端后台允许了OPTIONS请求，但是某些安全配置阻止了OPTIONS请求 第三种：No &#39;Access-Control-Allow-Origin&#39; header is present on the requested resource，并且The response had HTTP status code 200 XMLHttpRequest cannot load http://b.domain.com, Response to preflinght request doesn&apos;t pass access control check: No &apos;Access-Control-Allow-Origin&apos; header is present on the requested resource. Origin &apos;http://a.domain.com&apos; is therefore not allowed access. ps.并且The response had HTTP status code 200 问题原因：服务器端后台允许了OPTIONS请求，并且OPTIONS请求没有被阻止，但是头部不匹配。 第四种：heade contains multiple values &#39;*,*&#39;，并且The response had HTTP status code 200 XMLHttpRequestcannot load http://b.domain.com. The &apos;Access-Control-Allow-Origin&apos; header contains multiple values&apos;*, *&apos;, but only one is allowed. Origin &apos;http://a.domain.com&apos; is therefore notallowed access. ps.并且The response had HTTP status code 200 问题原因：设置多次Access-Control-Allow-Origin=*，可能是配置的人对CORS实现原理和机制不了解导致。 突如其来的OPTIONS请求？有时你会发现明明请求的是POST、GET、PUT、DELETE，但是浏览器中看到的确实OPTION，，为什么会变成OPTION？ 原因：因为本次Ajax请求是“非简单请求”,所以请求前会发送一次预检请求(OPTIONS)，这个操作由浏览器自己进行。如果服务器端后台接口没有允许OPTIONS请求,将会导致无法找到对应接口地址，因此需要服务端提供相应的信息到response header中，继续往下看。 后端需要返回的Header有哪些？# 服务端允许访问的域名Access-Control-Allow-Origin=https://idss-uat.jiuyescm.com# 服务端允许访问Http MethodAccess-Control-Allow-Methods=GET, POST, PUT, DELETE, PATCH, OPTIONS# 服务端接受跨域带过来的Cookie,当为true时,origin必须是明确的域名不能使用*Access-Control-Allow-Credentials=true# Access-Control-Allow-Headers 表明它允许跨域请求包含content-type头，我们这里不设置，有需要的可以设置#Access-Control-Allow-Headers=Content-Type,Accept# 跨域请求中预检请求(Http Method为Option)的有效期,20天,单位秒Access-Control-Max-Age=1728000 ps. 如果跨域需要携带cookie去请求，Access-Control-Allow-Credentials必须为true，但是需要注意当Access-Control-Allow-Credentials=true时，Access-Control-Allow-Origin就不能为” * “ ，必须是明确的域名，当然可以多个域名使用 “,” 分割 前端如何配合发起请求？如果是浏览器直接访问跨域请求url，只要服务端返回 “Access-Control-Allow-X” 系列header在response中即可成功访问。 如果是ajax发起的请求该如何处理？ 第一种：请求不需要携带cookie $.ajax(&#123; url : &apos;url&apos;, data : data, dataType: &apos;json&apos;, type : &apos;POST&apos;, crossDomain: true, contentType: &quot;application/json&quot;, success: function (data) &#123; var a=JSON.stringify(data); if(data.result==true)&#123; ........... &#125;else&#123; ........... &#125; &#125;, error:function (data) &#123; var a=JSON.stringify(data); alert(a); &#125;&#125;); ps. 增加crossDomain=true 第二种：请求需要携带cookie $.ajax(&#123; url : &apos;url&apos;, data : data, dataType: &apos;json&apos;, type : &apos;POST&apos;, xhrFields: &#123; withCredentials: true &#125;, crossDomain: true, contentType: &quot;application/json&quot;, success: function (data) &#123; var a=JSON.stringify(data); if(data.result==true)&#123; ........... &#125;else&#123; ........... &#125; &#125;, error:function (data) &#123; var a=JSON.stringify(data); alert(a); &#125;&#125;); ps. 增加crossDomain与xhr.withCredentials，发送Ajax时，Request header中便会带上 Cookie 信息。 到这里你以为跨域的相关都介绍完毕了？太天真 最后还有一个终极boss问题，是什么问题呢？ 上面的第二种携带cookie的跨域请求调用方式在IOS下可以正常工作，但是在Android下无法正常工作并且还报错，额。。。。。 Ajax跨域请求跨平台兼容性问题问题原因：因为Android下的webview不兼容这个写法，使用标准的 beforeSend(XHR)) 替换 xhrFields: &#123; withCredentials: true&#125; ps. webview不兼容的写法，firefox下也不兼容 标准的写法： $.ajax(&#123; type: &quot;POST&quot;, url: &quot;url&quot;, data:datatosend, dataType:&quot;json&quot;, beforeSend: function(xhr) &#123; xhr.withCredentials = true; &#125; crossDomain:true, success: function (data) &#123; var a=JSON.stringify(data); if(data.result==true)&#123; ........... &#125;else&#123; ........... &#125; &#125;, error:function (data) &#123; var a=JSON.stringify(data); alert(a); &#125;&#125;); 到这跨域的相关使用就介绍完毕，这次是真的结束了。Keep Real!","tags":[{"name":"cors","slug":"cors","permalink":"https://ningyu1.github.io/tags/cors/"},{"name":"xhr.withCredentials","slug":"xhr-withCredentials","permalink":"https://ningyu1.github.io/tags/xhr-withCredentials/"},{"name":"crossDomain","slug":"crossDomain","permalink":"https://ningyu1.github.io/tags/crossDomain/"},{"name":"Ajax跨域","slug":"Ajax跨域","permalink":"https://ningyu1.github.io/tags/Ajax跨域/"}]},{"title":"Docker启动的容器如何清理日志？看这里","date":"2018-06-19T07:10:00.000Z","path":"20180619/90-docker-container-cleanlog.html","text":"Docker run起来的容器随着时间久了，容器内的服务输出的日志也在日积月累，需要定期的进行日志清理。 如果公司使用DevOps的话更加需要对容器内的日志进行定期清理，业务的镜像服务或许还好一些，因为开发同学每天都在用、每天都会upgrade服务，在upgrade的时候会删除老的容器，再重新run一个新容器去替换掉老的，但是有一些长期run的服务就很少有人关注了，比如说rancher、还有一些基础服务，可能很长时间也不会去做upgrade操作，因此容器内的日志就越来越多，如果不清理总有一天会撑爆服务器硬盘，到那个时候再去清理恢复服务的话，有可能会有磁盘文件损坏的风险。 因此我们需要定期的对Docker容器内的日志进行清理。 如何查看Docker内容器的日志？可以参考文章：《如何直接操作Docker容器？》 在清理容器日志前，我们首先要知道Docker将容器的日志放在那里？ Docker将容器的日志放在/var/lib/docker/containers/containerid/containerid-json.log ps. containerid是容器id一般是82bbc....这个风格，64位字符 当然找不到的话也可以使用文件搜索的方式去查找Docker的容器日志放在那里，查找的时候按照上面的名称风格去查找，例如： find / -type f -name &quot;*-json.log&quot; 容器的id怎么查看呢？ docker ps 通过ps找到容器id，也找到日志所在的位置后，接下来就是清理日志的操作了，日志文件不能直接删除，直接删除会影响正在运行的容器，可以通过清空文件内容的方式来处理。 清空文件的方式有很多种如下： $ : &gt; filename $ &gt; filename $ echo &quot;&quot; &gt; filename $ echo &gt; filename $ cat /dev/null &gt; filename 选一种即可 cat /dev/null &gt;/var/lib/docker/containers/containerid/containerid-json.log","tags":[{"name":"docker","slug":"docker","permalink":"https://ningyu1.github.io/tags/docker/"}]},{"title":"Zookeeper事务日志和snapshot清理方式","date":"2018-06-15T09:15:00.000Z","path":"20180615/89-zookeeper-cleanlog.html","text":"Zookeeper运行过程会产生大量的事务日志和snapshot镜像文件，文件的目录是通过zoo.conf的datadir参数指定的，下面我们就说一下如何清理事务日志和snapshot。 清理的方式有如下三种： 一、zookeeper配置自动清理 二、使用自定义清理脚本 三、使用zkCleanup.sh清理 下面我们一一介绍每种清理方式是如何使用的。 zookeeper配置自动清理zookeeper在3.4.0版本以后提供了自动清理snapshot和事务日志的功能通过配置 autopurge.snapRetainCount 和 autopurge.purgeInterval 这两个参数能够实现定时清理了。这两个参数都是在zoo.cfg中配置的： 我们使用的zk版本是：3.4.6，因此可以使用自带的清理功能 autopurge.purgeInterval 这个参数指定了清理频率，单位是小时，需要填写一个1或更大的整数，默认是0，表示不开启自己清理功能。 autopurge.snapRetainCount 这个参数和上面的参数搭配使用，这个参数指定了需要保留的文件数目。默认是保留3个。 示例： autopurge.snapRetainCount=60 autopurge.purgeInterval=48 保留48小时内的日志，并且保留60个文件 ps.但是修改conf需要重启服务，生产可能不会考虑重启服务因此使用其他方法。 使用自定义清理脚本clean_zook_log.sh脚本内容如下 #!/bin/bash #snapshot file dirdataDir=/var/zookeeper/version-2#tran log dirdataLogDir=/var/zookeeper/version-2logDir=/usr/local/zookeeper/logs#Leave 60 filescount=60count=$[$count+1]ls -t $dataLogDir/log.* | tail -n +$count | xargs rm -fls -t $dataDir/snapshot.* | tail -n +$count | xargs rm -fls -t $logDir/zookeeper.log.* | tail -n +$count | xargs rm -f 这个脚本保留最新的60个文件，可以将他写到 将这个脚本添加到crontab中，设置为每天凌晨2点？或者其他时间执行即可。 crontab -e 2 2 * * * /bin/bash /usr/local/zookeeper/bin/clean_zook_log.sh &gt; /dev/null 2&gt;&amp;1 ps.不用修改配置，不需要重启zk集群，推荐使用 使用zkCleanup.sh清理这个脚本是使用的zookeeper.jar里的org.apache.zookeeper.server.PurgeTxnLog这个class的main函数清理的，因此需要启动一个java进程，比shell清理要重一些。 org.apache.zookeeper.server.PurgeTxnLog文档 sh /usr/local/zookeeper/bin/zkCleanup.sh 数据目录 -n 20 参数说明 数据目录： /var/zookeeper20: 保留快照日志的数量 ps.因为zookeeper从3.4.0版本之后提供了对历史事务日志和快照文件的自动清理，所以这个脚本很少使用，另外在生产环境中我们一般采取自动脚本来定点定量清除指定日期的日志文件 到这里三种清理方式都介绍完毕了，根据自己的实际情况选择一种使用就可以了。祝大家周末愉快以及端午节快乐，ok 收工 回家。","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://ningyu1.github.io/tags/zookeeper/"}]},{"title":"如何扩展个人微信号来实现群组管理的功能？","date":"2018-06-08T05:38:00.000Z","path":"20180608/85-wechat.html","text":"最近在思考一个问题，如何能在系统中集成微信群组管理的功能，比如说邀请好友进群、对群组进行管理、创建群组、删除群组之类的操作，说白了就是将微信的功能嵌入到自己的程序里面去。这样就可以有效的管理多个群组来扩展一些客服的功能。 于是查找关于微信API的资料，第一反应就是先去官方的开放文档中查看是否有类似API开放。 翻了一圈资料，看了微信服务号、订阅号、小程序、以及企业微信的开放文档后整理出来目前官方开放的API的功能现状如下： 官方是没有提供任何个人群管理接口API，只有一些类似外挂类的工具可以对个人群组进行管理。 但是外挂类的工具又怕有风险，说不定哪天就over了。 在资料翻阅的过程，发现了可以通过微友助手在群组里添加机器人，但是这个方式可能不是我们想要的。 官方开放的客服API可以与客服系统进行对接，它是将微信端作为客服的入口与客服系统对接，生成客诉工单或者是跟客服对话，这也不是我们想要的方式。 在没有官方API可用的情况下我们想使用这方面的功能该如何操作呢？ 发现曙光微信目前官方提供的终端，除了手机端以外还有电脑端和WEB网页端。 咦，有WEB网页端那不就有API可以操作么？只是可能我们要写类似于外挂一样的东西模拟官方的微信网页端操作。 于是开始搜索这方面的资料，很幸运找到了ItChat这个类库。 这个类库的实现方式就是我们刚才说到的模拟网页版本的rest请求去扩展的一些接口。 那已经有人做好了轮子那我们就可以直接使用了。 ItChat的实现方式第一部分，分析微信协议，开始获取并模拟扩展个人微信号所需要的协议。第二部分，利用上面分析出来的协议第三部分，包装成扩展功能API 网页端微信协议分析思路可以查看：手把手教你扩展个人微信号（1） 接口的使用可以查看：手把手教你扩展个人微信号（2） 有兴趣的可以进去看一下。 Github链接：ItChat 总结这个库的实现方式还是很有趣的，使用网页版微信调用的rest接口，跟常规外挂一样模拟网页微信的操作，只要网页版本微信不关闭应该都能用，只是可能需要紧跟着网页版本的微信rest接口持续升级 github上有1w多star，很明显说明了这个扩展功能还是很多人迫切想使用的，后面我会尝试一下然后把遇到的问题和使用经验会再分享出来。Keep Real！","tags":[{"name":"wechat","slug":"wechat","permalink":"https://ningyu1.github.io/tags/wechat/"}]},{"title":"如何使用抓包调试工具 —— Charles","date":"2018-06-04T09:28:00.000Z","path":"20180604/84-charles.html","text":"以下信息转自公司内网资料，觉得很实用就转载出来提供参考。 一、Charles是什么？ Charles是在 Mac或Windows下常用的http协议网络包截取工具，在平常的测试与调式过程中，掌握此工具就基本可以不用其他抓包工具了。 二、为什么是Charles？为什么要用抓包工具？大家在平常移动App调试测试中是如何进行抓包的？ 主要特点如下： 支持SSL代理，可以截取分析SSL的请求 支持流量控制。可以模拟慢速网络(2G,3G)，以及等待时间较长的请求。 支持AJAX调试。可以自动把JSON或者XML数据格式化，方便查看。 支持重发网络请求，方便后端调试。 支持修改网络请求参数。 支持网络请求的截取和动态修改。 最重要的一个优点就是有不同平台的版本（Mac，Windows、Linux）即学一个打遍天下。 三、Charles基本工作原理charles是通过网络代理来进行抓包的，下面先了解一下http代理的原理： 普通http请求过程 一般情况下的HTTP请求与响应 加入了Charles的HTTP代理的请求与响应过程 中间的代理服务器就是Charles 四、Charles的下载与安装过程 官网下载地址：http://www.charlesproxy.com/download/ Mac下安装 是一个安装包是一个dmg后缀的文件。打开后将Charles拖到Application目录下即完成安装。 在Mac下你打开Launchpad即可看到一个像花瓶一样的Charles程序图标 Windows下安装 下载后直接双击根据安装向导一步一步安装即可 五、Http抓包操作步骤Step 1: 开启Charleshttp代理 设置Charles代理 第一次启动默认会开启本机的系统代理，因为我们只是监控移动端的所以将此选去除（去掉选项前面的小钩） 激活http代理功能 Step 2: 手机端Wifi添加代理Android端 在手机端打开你的Wifi设置然后长按已经连接的Wifi在弹出来的菜单中选择【修改网络】 沟上[显示高级]选项–【手动】 输入代理服务器的IP与端口，IP即安装了Charles的电脑IP地址，端口就是前面一步设置Charles时所设置的端口。 注意：手机所连接Wifi要与电脑在同一个LAN(局域网) iOS端 点击你所连接的wifi 输入代理服务器的IP与端口， IP即安装了Charles的电脑IP地址，端口就是前面一步设置Charles时所设置的端口。 注意：手机所连接Wifi要与电脑在同一个LAN(局域网) Step 3:开启Charles录制功能 当手机连接上代理后Charles会弹出相应的提示框，点击Allow即可 点击工具栏上的开始录制按钮，即启动了Charles的抓包功能了。 Step 4：启动应用开始抓包 在手机上操作相应的App进行抓包。 在Charles的主界面上就可看到相应的请求内容。 Step 5：分析抓取的数据包 Charles 主要提供两种查看封包的视图，分别名为 “Structure”和 “Sequence”： Structure 视图将网络请求按访问的域名分类； Sequence 视图将网络请求按访问的时间排序。 大家可以根据具体的需要在这两种视图之前来回切换。请求多了有些时候会看不过来，Charles提供了一个简单的Filter功能，可以输入关键字来快速筛选出URL 中带指定关键字的网络请求。 对于某一个具体的网络请求，你可以查看其详细的请求内容和响应内容。如果请求内容是POST 的表单，Charles 会自动帮你将表单进行分项显示。如果响应内容是 JSON 格式的，那么 Charles可以自动帮你将JSON 内容格式化，方便你查看。如果响应内容是图片，那么 Charles可以显示出图片的预览。 六、Https抓包操作步骤Step 1：了解一下https的基本原理； HTTPS其实是有两部分组成：HTTP+ SSL / TLS，也就是在HTTP上又加了一层处理加密信息的模块。服务端和客户端的信息传输都会通过TLS进行加密，所以传输的数据都是加密后的数据。具体是如何进行加密，解密，验证的，且看图,下面这个图的解说详细说明，请参考：http://blog.csdn.net/clh604/article/details/22179907 Step 2：在手机端安装SSL证书 将证书文件从Charles导出 然后通过adb或者其他工具将其复制到手机的SD卡中。 从Charles导出证书文件 将证书文件导入Android手机 在手机的设置界面找到【安全】—》【从内部存储设备或SD卡安装】—-》选择SD卡上的证书—》弹出设置证书名对话框，输入一个易记的名字，然后根据提示进行导入即可 将证书文件导入iOS手机 在iPhone手机上打开Safari浏览器，然后在地址栏中输入www.charlesproxy.com/getssl。 稍后会弹出安装描述文件提示，点击右上角的【安装】按钮进行证书安装即可。 在iOS 10.3之后,需要手动打开开关以信任证书，设置-&gt;通用-&gt;关于本机-&gt;证书信任设置-&gt; 找到charles proxy custom root certificate然后信任该证书即可. Step 3：激活Charles的SSL代理 选择【Proxy】—&gt;【SSL Proxying Settings..】设置。 在弹出来的对话框中沟选【Enable SSL Proxying】。 Step 4：将指定的URL请求开启SSL代理功能 选择抓取的https链接，然后右键选择【Enable SSL Proxying】。 如果不激活SSL代理，所以https请求都是乱码无法查看。 再次请求这个Https时，其请求内容已经一目了然了。 七、Charles进阶—修改请求也响应的内容Step 1：设置Charless断点 选择【Breakpoint Settings…】—&gt;勾选【Enable Breakpoints】来激活断点功能 Step 2：对指定的URL开启断点功能 选择一个URL链接-à右键开启菜单—》选择【Breakpoints】即可开启此请求的断点。 这样Charles会遇到此请求时会弹出中断对话框。 Step 3：编辑请求与响应的内容。 编辑请求内容，在中断对话框中，用户可以点击Edit Request来编辑请求的内容，编辑完成后然后点击【Execute】发出去这个请求给服务端 编辑服务器响应的内容，在【Edit Request】对话中点击【Execute】发出请求后，服务端返回来数据后，用户点击【Edit Response】可对响应内容进行编辑完成后然后点击【Execute】发出去这个数据给客户端。 八、Charles进阶—弱网模拟 菜单中选择【Proxy】—&gt;【Throttle Settings..】-à激活【Enable Throttling】。 在Throttle Configuration设置弱网的参数。 以下是各种网制式的速率参考文档： 移动网络制式与网速的参考文档 弱网模拟设置","tags":[{"name":"Charles","slug":"Charles","permalink":"https://ningyu1.github.io/tags/Charles/"},{"name":"移动端测试","slug":"移动端测试","permalink":"https://ningyu1.github.io/tags/移动端测试/"}]},{"title":"Trouble Shooting —— Docker Pull Image : error pulling image configuration: unexpected EOF错误","date":"2018-05-29T04:09:00.000Z","path":"20180529/83-docker-pull-error.html","text":"问题现象执行docker pull命令报错： docker@rancher-192:~$ docker pull 192.168.0.34:5000/imageName:latestlatest: Pulling from imageName75a822cd7888: Pulling fs layer046e44ee6057: Download complete8c47541cb10b: Waitinge17edf9a1bd4: Waitingerror pulling image configuration: unexpected EOF 查看日志错误如下： docker@rancher-192:~$ journalctl -u docker.service-- Logs begin at Mon 2018-05-14 04:14:07 CST, end at Tue 2018-05-29 11:31:02 CST. --May 29 11:28:22 rancher-192.168.0.83 docker[993]: time=&quot;2018-05-29T11:28:22.601383366+08:00&quot; level=error msg=&quot;Not continuing with pull after error: error pulling image configuration: unexpected EOF&quot;May 29 11:30:36 rancher-192.168.0.83 docker[993]: time=&quot;2018-05-29T11:30:36.987345560+08:00&quot; level=error msg=&quot;Not continuing with pull after error: error pulling image configuration: unexpected EOF&quot; 随便找一台其他机器上进行pull操作，一样报错，但是pull其他镜像确实正常的，查看其他机器上日志如下： docker@devserver1:~/messer/public$ journalctl -u docker.service-- Logs begin at Fri 2018-05-25 23:29:13 CST, end at Tue 2018-05-29 11:34:24 CST. --May 29 11:34:24 devserver1 docker[893]: time=&quot;2018-05-29T11:34:24.167053102+08:00&quot; level=error msg=&quot;Not continuing with pull after error: error pulling image configuration: unexpected EOF&quot;May 29 11:34:24 devserver1 docker[893]: time=&quot;2018-05-29T11:34:24.212480193+08:00&quot; level=info msg=&quot;Layer sha256:3fc67fe0621339e8f025cb429eecee5db64025673f3eafb02d12b512f07bbba5 cleaned up&quot; 这个问题让我们想到了之前我写过一篇文章《Trouble Shooting —— Docker Pull Image : Filesystem layer verification failed for digest sha256错误》也是docker pull的时候报错： 8b7054...: Verifying ChecksumFilesystem layer verification failed for digest sha256: 8b7054..... 通过使用之前文章的解决方案依然可以解决这个问题。 这类问题可以使用绕过校验重新build后push刷新digest值后，恢复原始build参数再重新push恢复默认操作来进行解决。","tags":[{"name":"docker","slug":"docker","permalink":"https://ningyu1.github.io/tags/docker/"},{"name":"docker pull","slug":"docker-pull","permalink":"https://ningyu1.github.io/tags/docker-pull/"},{"name":"error pulling image configuration: unexpected EOF","slug":"error-pulling-image-configuration-unexpected-EOF","permalink":"https://ningyu1.github.io/tags/error-pulling-image-configuration-unexpected-EOF/"}]},{"title":"如何免费的让你的网站变得更加安全 - HTTPS","date":"2018-05-28T07:57:00.000Z","path":"20180528/82-ssl-lets-encrypt.html","text":"在这个数据不安全的世界里，很有可能你早上买了个东西下午就会有类似的推销电话打过来骚扰你，这些数据信息从哪里来的呢？当然很多时候是人为的贩卖信息造成的，但是数据来源很大一部分是来自于互联网。因此站点使用https已经是最基本的防护，当我去访问一个站点它如果不是https的我可能都不想访问它更别提输入一些个人信息了。那怎么才能让我们提供的网站安全的服务你的用户呢？当然是使用证书来保护网站来往的数据。 如果不差钱的话还是使用收费的证书去给你的网站开启https。当然国内也有很多免费的证书，去谷哥或者度娘能检索到一大把的免费证书信息，各大云服务商上面也有免费的证书可以申请使用，我下面就介绍一个免费的使用方式。 Let’s Encrypt Let&#39;s Encrypt是一个于2015年三季度推出的数字证书认证机构，旨在以自动化流程消除手动创建和安装证书的复杂流程，并推广使万维网服务器的加密连接无所不在，为安全网站提供免费的SSL/TLS证书。 Let&#39;s Encrypt由互联网安全研究小组（缩写ISRG）提供服务。主要赞助商包括电子前哨基金会、Mozilla基金会、Akamai以及思科。2015年4月9日，ISRG与Linux基金会宣布合作。 通过官网我们能看到赞助商还是蛮多的，赞助商列表 上述来自于维基百科，查看原文 从介绍中能了解到它是为了解决，以自动化流程消除手动创建和安装证书的复杂流程，让证书使用更加简单。 我们通过Let&#39;s Encrypt官网的Getting Started中可以查看具体的使用说明 下面我们简单介绍一下使用步骤： 使用步骤安装证书非常简单，只需要使用Certbot，就可以完成。 打开Certbot，选择你的网站使用的应用服务器和操作系统。如下图： 选择完后会生成安装教程，不用想太多Step by step就好了，如下图： 安装基础环境$ sudo apt-get update$ sudo apt-get install software-properties-common$ sudo add-apt-repository ppa:certbot/certbot$ sudo apt-get update$ sudo apt-get install python-certbot-nginx 安装证书安装完之后直接运行sudo certbot --nginx即可 certbot 会自动修改nginx配置文件(nginx.conf)并且列出你的虚拟站点让你选择是否开启HTTPS，当然你只用选择是否开启即可，选择完后它会自动下载证书并且修改nginx配置文件 修改后的nginx.conf是什么样的？让我们看一下 listen 443 ssl; # managed by Certbotssl_certificate /etc/letsencrypt/live/your.domain/fullchain.pem; # managed by Certbotssl_certificate_key /etc/letsencrypt/live/your.domain/privkey.pem; # managed by Certbotinclude /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot 还会很贴心的帮你生成http跳转到https的配置，如下： # Redirect non-https traffic to httpsif ($scheme != &quot;https&quot;) &#123; return 301 https://$host$request_uri;&#125; # managed by Certbot 到这里就完成了证书安装，是不是很简单。当然我们之前也说过证书是有有效期的，那过期了之后我们如何操作？再根据上面的操作执行一次？ 当然不是了，我们可以使用自动检测的方式来进行自动的更新证书与nginx配置。具体看下面操作： 证书自动更新下面是官方对于证书续订的说明： Automating renewalThe Certbot packages on your system come with a cron job that will renew your certificates automatically before they expire. Since Let&apos;s Encrypt certificates last for 90 days, it&apos;s highly advisable to take advantage of this feature. You can test automatic renewal for your certificates by running this command:$ sudo certbot renew --dry-run 首先Let’s Encrypt 的证书只有90天的有效期，所以我们可以使用crontab来进行定时自动更新。 crontab如何使用这里就不多做介绍了，可以查看crontab使用说明 使用下面的表达式让其在每个月的一号强制更新证书，但是证书的强制更新不能太频繁，太频繁会提前进入证书授权限制。 0 0 1 * * /usr/bin/certbot renew --force-renewal10 0 1 * * /usr/sbin/service nginx restart renew的使用说明 到这里证书安装以及自动更新就介绍完毕了，当然我们的站点中有很多静态资源或超链接的地方，在启用https后可能也要进行一轮的检查由http修改为https，主要就是那些hard code的地方需要找出来进行修改掉。 为了保护你服务的用户信息安全，我强烈建议开启HTTPS，只要是个站点服务就应该开启HTTPS这才是负责任的的体现，Keep Real。","tags":[{"name":"https","slug":"https","permalink":"https://ningyu1.github.io/tags/https/"},{"name":"lets-encrypt","slug":"lets-encrypt","permalink":"https://ningyu1.github.io/tags/lets-encrypt/"}]},{"title":"Mysql数据库字符集utf8mb4使用问题","date":"2018-05-14T06:38:00.000Z","path":"20180514/81-mysql-utf8mb4.html","text":"问题发生在 这个字上，首先先让我们看这个字的字符信息 utf8字符集信息 Utf-8 CharacterSymbol information table|Name: |Utf-8 Character||:–:|:–:||Unicode Subset:|CJK Extension B||Unicode HEX:|U+20046||ASCII value:|131142||HTML:|&#131142;||CSS:|\\20046|它属于utf8的字符集，具体可参考：传送门既然属于utf8的字符集那为什么数据库保存这个字会出现非法字符的错误呢？错误如下：### Cause: java.sql.SQLException: Incorrect string value: &apos;\\xF0\\xA5\\x8A\\x8D&apos; for column &apos;DESCRIPTION&apos; at row 1; uncategorized SQLException for SQL []; SQL state [HY000]; error code [1366]; Incorrect string value: &apos;\\xF0\\xA5\\x8A\\x8D&apos; for column &apos;DESCRIPTION&apos; at row 1; nested exception is java.sql.SQLException: Incorrect string value: &apos;\\xF0\\xA5\\x8A\\x8D&apos; for column &apos;DESCRIPTION&apos; at row 1 at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:84) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:73) 让我们先了解一下utf8的编码，UTF-8编码是U+2528D，属于CJK Unified Ideographs Extension B（中日韩统一表意文字扩充B）字符集的字符，处于第二辅助平面（SIP，表意文字补充平面），不属于我们通常所见的基本多文种平面（BMP，即Unicode编码范围在0000-FFFF之内）的字符。保存一个字；相比之下，在BMP范围之内的字符只需要占用3 Bytes。仅仅就因为字符保存位数不同，就让程序开发出现了难题。 来自wikipedia的Unicode字符平面映射 目前的Unicode字符分为17组编排，每组称为平面（Plane），而每平面拥有65536（即216）个代码点。然而目前只用了少数平面。 平面 始末字符值 中文名称 英文名称 0号平面 U+0000 - U+FFFF 基本多文种平面 Basic Multilingual Plane，简称BMP 1号平面 U+10000 - U+1FFFF 多文种补充平面 Supplementary Multilingual Plane，简称SMP 2号平面 U+20000 - U+2FFFF 表意文字补充平面 Supplementary Ideographic Plane，简称SIP 3号平面 U+30000 - U+3FFFF 表意文字第三平面 （未正式使用[1]） Tertiary Ideographic Plane，简称TIP 4号平面 至 13号平面 U+40000 - U+DFFFF （尚未使用） 14号平面 U+E0000 - U+EFFFF 特别用途补充平面 Supplementary Special-purpose Plane，简称SSP 15号平面 U+F0000 - U+FFFFF 保留作为私人使用区（A区）[2] Private Use Area-A，简称PUA-A 16号平面 U+100000 - U+10FFFF 保留作为私人使用区（B区）[2] Private Use Area-B，简称PUA-B 具体可查看：传送门 究其原因就是这个字保存需要占4 Bytes的字节，mysql在MySQL 5.6+版本之后支持4Bytes字节（utf8mb4）的存储，首先先看一下mysql编码如何设置？ 数据库字符集设置建库语句中需要指定字符集编码为：utf8mb4 建库语句中需要指定字符集校对规则为：utf8mb4_general_ci 建表语句中需要指定字符集编码为：utf8mb4 表字段需要指定字符集编码为：utf8mb4 表字段collation需要指定字符集校验规则：utf8mb4_general_ci 如下图： CREATE TABLE `t_application` ( `ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &apos;ID&apos;, `APP_ID` bigint(20) NOT NULL COMMENT &apos;应用编号&apos;, `NAME` varchar(100) NOT NULL COMMENT &apos;应用名称&apos;, `DESCRIPTION` varchar(200) DEFAULT NULL COMMENT &apos;应用描述&apos;, PRIMARY KEY (`ID`) ) ENGINE=InnoDB AUTO_INCREMENT=31 DEFAULT CHARSET=utf8mb4 CHECKSUM=1 DELAY_KEY_WRITE=1 ROW_FORMAT=DYNAMIC utf8mb4不生效问题分析完成上面的字符集设置之后我们使用程序保存 字符来进行测试，还是提示非法的字符集错误，那这又是为什么呢？ 让我们来看回数据库charset设置，SHOW VARIABLES LIKE &#39;CHARACTER%&#39;，关注character_set_server这个字符设置 character_set_server在默认情况下为latin1 /*character_set_server: 服务器安装时指定的默认字符集设定。character_set_database: 数据库服务器中某个库使用的字符集设定，如果建库时没有指明，将使用服务器安装时指定的字符集设置。 建表时候，字段字符集的选取方式如下： 1. * if 字段指定的字符集2. * else if 表指定的字符集3. * else if @@character_set_database4. * else @@character_set_server (如果没有设定，这个值为latin1) */ 按照上面的说法，如果character_set_server和character_set_database变量的值不同，则新建数据库的字符集以character_set_server为准，而不是按照character_set_database。 我的理解是character_set_database指定了utf8mb4后目标库应该按照设置的字符集格式走才对，只有没有设置的库才会走默认的，但是现在测试下来，character_set_server必须修改为utf8mb4,否则保存这种字符依然提示非法字符集，不太清楚具体什么原因。 如果数据库按照上面设置了以后还是无法保存的话，应该就是mysql驱动的问题和数据库连接串字符集的问题。下面让我们看一下从mysql server到mysql驱动到数据源再到应用所有的utf8mb4设置。 完整的正确设置Mysql服务端配置建库语句中需要指定字符集编码为：utf8mb4 建库语句中需要指定字符集校对规则为：utf8mb4_general_ci 建表语句中需要指定字符集编码为：utf8mb4 表字段需要指定字符集编码为：utf8mb4 表字段collation需要指定字符集校验规则：utf8mb4_general_ci mysql ini配置文件指定character_set_server [client]default-character-set=utf8mb4[mysql]default-character-set=utf8mb4[mysqld]character-set-server=utf8mb4collation-server=utf8mb4_general_ci ps. character_set_server设置成utf8或使用默认latin1，在直接使用sql插入特殊字符和emoji表情时数据库显示？？？？？乱码，使用程序（mybatis）插入特殊字符和emoji表情时报错：java.sql.SQLException: Incorrect string value: ‘\\xF0\\xA5\\x8A\\x8D’ for column ‘某某列’ at row 1 java连接mysql驱动版本mysql-connector-java版本在5.1.13+才支持utf8mb4，因此在选用连接驱动时应注意这个问题，我们使用的驱动是mysql-connector-java-5.1.41。 数据源配置我们使用的druid数据源配置上需要加上connectionInitSqls属性配置，具体如下： &lt;bean id=&quot;dataSource&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; destroy-method=&quot;close&quot;&gt; ....此处省略其他属性..... &lt;property name=&quot;connectionInitSqls&quot; value=&quot;set names utf8mb4;&quot; /&gt;&lt;/bean&gt; ps.但是我实际测试下来，这个参数不加也没有什么问题，可以正常保存这种特殊字符和emoji表情，官方建议配置。 数据库连接串配置我们的配置如下： jdbc.url=jdbc:mysql://ip:port/databaseName?useUnicode=true&amp;characterEncoding=UTF-8&amp;noAccessToProcedureBodies=true&amp;autoReconnect=true 建议去掉useUnicode和characterEncoding的配置，使用如下配置： jdbc.url=jdbc:mysql://ip:port/databaseName?noAccessToProcedureBodies=true&amp;autoReconnect=true ps.但是我实际测试下来，连接串上增加useUnicode=true&amp;characterEncoding=utf8也没有什么问题，可以正常保存这种特殊字符和emoji表情。 总结最主要的是mysql服务端的character_set_server需要和character_set_database保持一致修改为utf8mb4，因此我们先不考虑数据库连接串和druid数据源配置修改，但是mysql-connector-java版本必须使用5.1.13+","tags":[{"name":"mysql","slug":"mysql","permalink":"https://ningyu1.github.io/tags/mysql/"},{"name":"utf8mb4","slug":"utf8mb4","permalink":"https://ningyu1.github.io/tags/utf8mb4/"}]},{"title":"ActiveMQ消息消费慢问题排查","date":"2018-05-09T07:38:00.000Z","path":"20180509/80-activemq-consumer-slow-speed.html","text":"问题现象有的时候会发现ActiveMQ中某个个队列的消息在写入后，不是立刻就被调度消费，而是需要等待一小会才能被调度消费（大概时间是1分钟），而且还伴随着这样的现象，当消息写入速度很快时消费很快，当消息写入消息速度很慢时反而消费很慢，我们的理解就是当写入慢的时候很多消费者都是闲置的那为什么消费反而会变慢？ 问题原因跟了一下代码发现了跟我们的设置有很大关系，因为我们设置的receiveTimeout=6000（1分钟）接受阻塞时间为1分钟。 ActiveMQ在消费时每个consumer会独占一个Thread，Thead中通过consumer.receive()去阻塞，只有当consumer消费了maxMessagesPerTask个消息后，才会退出线程，由taskExecutor重新调度，maxMessagesPerTask这个值默认为10，可以通过下面代码得知： @Overridepublic void initialize() &#123; // Adapt default cache level. if (this.cacheLevel == CACHE_AUTO) &#123; this.cacheLevel = (getTransactionManager() != null ? CACHE_NONE : CACHE_CONSUMER); &#125; // Prepare taskExecutor and maxMessagesPerTask. synchronized (this.lifecycleMonitor) &#123; if (this.taskExecutor == null) &#123; this.taskExecutor = createDefaultTaskExecutor(); &#125; else if (this.taskExecutor instanceof SchedulingTaskExecutor &amp;&amp; ((SchedulingTaskExecutor) this.taskExecutor).prefersShortLivedTasks() &amp;&amp; this.maxMessagesPerTask == Integer.MIN_VALUE) &#123; // TaskExecutor indicated a preference for short-lived tasks. According to // setMaxMessagesPerTask javadoc, we&apos;ll use 10 message per task in this case // unless the user specified a custom value. this.maxMessagesPerTask = 10; &#125; &#125; // Proceed with actual listener initialization. super.initialize();&#125; ps. 我们使用的taskExecutor为：org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor，因此上面代码走到else if中设置this.maxMessagesPerTask = 10; 如果消息写入很快的时候，你会发现消费的很快，只有当消息写入很慢的时候（比如说：1分钟写入不到10条）的时候，才会发现消息消费的有些慢 解决方案如果有这类情况，可以调整receiveTime这个参数，具体参数设置多少合理自己去结合业务场景去权衡，可以根据消息写入的速度和写入量来设置该参数（maxMessagesPerTask 和 receiveTimeout），调整这个参数有两种方式： 第一种使用JMS消费消息：使用JMS消费消息时调整：jmsTemplate的receiveTimeout参数（以毫秒为单位，0表示阻塞接收不超时，默认值为0毫秒表示阻塞接受没有超时） 第二种使用listener-container消费消息：使用jms:listener-container消费消息时调整：receive-timeout参数（以毫秒为单位， 默认值为1000毫秒（1秒）; -1指示器根本没有超时。）","tags":[{"name":"activemq","slug":"activemq","permalink":"https://ningyu1.github.io/tags/activemq/"},{"name":"activemq slow speed","slug":"activemq-slow-speed","permalink":"https://ningyu1.github.io/tags/activemq-slow-speed/"}]},{"title":"Trouble Shooting —— Docker Pull Image : Filesystem layer verification failed for digest sha256错误","date":"2018-04-27T09:46:00.000Z","path":"20180427/79-docker-registry-pull-filesystem-layer.html","text":"问题现象除了打包镜像的服务器上可以执行docker pull 192.168.0.34:5000/sample:latest以外，其它任何服务器执行此命令时，都会出现以下错误信息： 8b7054...: Verifying ChecksumFilesystem layer verification failed for digest sha256: 8b7054..... 这使得无法正常使用最新的sample镜像文件。 如果是按分析过程中的方式把8b7054文件夹迁移的话，docker会不断重试去拉取此文件信息，大概结果如下： 8b7054...: (..Retry 10 seconds)Filesystem layer verification failed for digest sha256: 8b7054..... 分析过程尝试在服务器上找日志，结果没有可用的日志。 在/var/lib/registry下找该sha256的数据，能够找到，尝试移走该文件夹数据。结果执行docker pull命令时，依旧是报错。只好迁移回文件夹。 尝试在网络上寻找解决方案，有的说与源有关系，有的说与docker版本有关系，需要升级版本，大多都没有很好的解决。如果实在搞不定，估计 需要考虑这些方案了。 尝试删除所有sample开发版本相关的image，并重新打包镜像，结果问题依旧。 解决方案docker build的过程中有很多选项可以使用，尝试将缓存关闭（默认否）、签名关闭（默认否）、清理过程文件（默认是）。 因此切换到jenkins的workspace下，找到sample文件夹，执行以下命令: docker build --rm=true --no-cache --disable-content-trust=true -t sample .docker tag sample 192.168.0.34:5000/sampledocker push --disable-content-trust=true 192.168.0.34:5000/sample 编译打包过程没有任何错误，可以正常发布镜像到registry上。 于是，切换到其他服务器上去执行docker pull，结果一切正常。 没有checksum？ 且没有原来失败的sha256 digest。 看了下其他镜像成功过的pull日志，也是没有checksum。看来只有出现异常的时候，才会去checksum（待考证） 既然已经成功过，那还是用正常的方式去打包编译及下载。于是删除现有镜像文件，在jenkins上进行工程打包（原始逻辑）。 docker build -t sample:latest .docker tag sample:latest 192.168.0.34:5000/sample:latestdocker push 192.168.0.34:5000/sample:latest 打包好后，在其它服务器上执行docker pull，一样可以正常使用了。 总结问题最终通过docker创建镜像时增加了关闭缓存、关闭校验的参数（--rm=true --no-cache --disable-content-trust=true），然后构建出来的镜像push到registry去重写这个镜像的最新digest值，再重新去掉这些参数再次构建镜像（恢复成正常构建镜像命令）后重新push到registry。这个问题看样子是由于新构建的镜像无法修改registry上的digest值导致pull的时候报错。","tags":[{"name":"docker","slug":"docker","permalink":"https://ningyu1.github.io/tags/docker/"},{"name":"docker pull","slug":"docker-pull","permalink":"https://ningyu1.github.io/tags/docker-pull/"},{"name":"Filesystem layer verification failed for digest sha256","slug":"Filesystem-layer-verification-failed-for-digest-sha256","permalink":"https://ningyu1.github.io/tags/Filesystem-layer-verification-failed-for-digest-sha256/"}]},{"title":"Dubbo使用jsr303框架hibernate-validator遇到的问题","date":"2018-04-23T05:25:00.000Z","path":"20180423/78-dubbo-validation-jsr303-pit.html","text":"Dubbo可以集成jsr303标准规范的验证框架，作为验证框架不二人选的hibernate-validator是大家都会经常在项目中使用的，但是在Dubbo使用是会发生下面这个问题。 问题描述背景：使用springmvc做restful，使用dubbo做rpc，restful中调用大量的rpc，数据验证会在这两个地方，一个是restful层面，一个是rpc层面，restful层面使用springmvc默认的集成hibernate-validator来实现，参数开启验证只需要加入@Validated param。 rpc层面也使用hibernate-validator实现，dubbo中开启validation也有两个方式，一个是在consumer端，一个是在provider端。 当我们在consumer端开启验证时:&lt;dubbo:reference id=&quot;serviceName&quot; interface=&quot;com.domain.package.TestService&quot; registry=&quot;registry&quot; validation=&quot;true&quot;/&gt; 没有任何问题，可以拿到所有的数据校验失败数据。 当我们在provider端开启验证时：&lt;dubbo:service interface=&quot;com.domain.package.TestService&quot; ref=&quot;serviceName&quot; validation=&quot;true&quot; /&gt; 会发生如下异常： com.alibaba.dubbo.rpc.RpcException: Failed to invoke remote method: sayHello, provider: dubbo://127.0.0.1:20831/com.domain.package.TestService?application=dubbo-test-rest&amp;default.check=false&amp;default.cluster=failfast&amp;default.retries=0&amp;default.timeout=1200000&amp;default.version=1.0.0&amp;dubbo=2.6.1&amp;interface=com.domain.package.TestService&amp;methods=sayHello&amp;pid=29268&amp;register.ip=192.168.6.47&amp;side=consumer&amp;timestamp=1524453157718, cause: com.alibaba.com.caucho.hessian.io.HessianFieldException: org.hibernate.validator.internal.engine.ConstraintViolationImpl.constraintDescriptor: &apos;org.hibernate.validator.internal.metadata.descriptor.ConstraintDescriptorImpl&apos; could not be instantiatedcom.alibaba.com.caucho.hessian.io.HessianFieldException: org.hibernate.validator.internal.engine.ConstraintViolationImpl.constraintDescriptor: &apos;org.hibernate.validator.internal.metadata.descriptor.ConstraintDescriptorImpl&apos; could not be instantiated at com.alibaba.com.caucho.hessian.io.JavaDeserializer.logDeserializeError(JavaDeserializer.java:167) at com.alibaba.com.caucho.hessian.io.JavaDeserializer$ObjectFieldDeserializer.deserialize(JavaDeserializer.java:408) at com.alibaba.com.caucho.hessian.io.JavaDeserializer.readObject(JavaDeserializer.java:273) at com.alibaba.com.caucho.hessian.io.JavaDeserializer.readObject(JavaDeserializer.java:200) at com.alibaba.com.caucho.hessian.io.SerializerFactory.readObject(SerializerFactory.java:525) at com.alibaba.com.caucho.hessian.io.Hessian2Input.readObjectInstance(Hessian2Input.java:2791) at com.alibaba.com.caucho.hessian.io.Hessian2Input.readObject(Hessian2Input.java:2731) at com.alibaba.com.caucho.hessian.io.Hessian2Input.readObject(Hessian2Input.java:2260) at com.alibaba.com.caucho.hessian.io.Hessian2Input.readObject(Hessian2Input.java:2705) at com.alibaba.com.caucho.hessian.io.Hessian2Input.readObject(Hessian2Input.java:2260) at com.alibaba.com.caucho.hessian.io.CollectionDeserializer.readLengthList(CollectionDeserializer.java:119) at com.alibaba.com.caucho.hessian.io.Hessian2Input.readObject(Hessian2Input.java:2186) at com.alibaba.com.caucho.hessian.io.Hessian2Input.readObject(Hessian2Input.java:2057) at com.alibaba.com.caucho.hessian.io.JavaDeserializer$ObjectFieldDeserializer.deserialize(JavaDeserializer.java:404) at com.alibaba.com.caucho.hessian.io.JavaDeserializer.readObject(JavaDeserializer.java:273) at com.alibaba.com.caucho.hessian.io.JavaDeserializer.readObject(JavaDeserializer.java:200) at com.alibaba.com.caucho.hessian.io.SerializerFactory.readObject(SerializerFactory.java:525) at com.alibaba.com.caucho.hessian.io.Hessian2Input.readObjectInstance(Hessian2Input.java:2791) at com.alibaba.com.caucho.hessian.io.Hessian2Input.readObject(Hessian2Input.java:2731) at com.alibaba.com.caucho.hessian.io.Hessian2Input.readObject(Hessian2Input.java:2260) at com.alibaba.com.caucho.hessian.io.Hessian2Input.readObject(Hessian2Input.java:2705) at com.alibaba.com.caucho.hessian.io.Hessian2Input.readObject(Hessian2Input.java:2260) at com.alibaba.dubbo.common.serialize.hessian2.Hessian2ObjectInput.readObject(Hessian2ObjectInput.java:74) at com.alibaba.dubbo.rpc.protocol.dubbo.DecodeableRpcResult.decode(DecodeableRpcResult.java:90) at com.alibaba.dubbo.rpc.protocol.dubbo.DecodeableRpcResult.decode(DecodeableRpcResult.java:110) at com.alibaba.dubbo.rpc.protocol.dubbo.DubboCodec.decodeBody(DubboCodec.java:88) at com.alibaba.dubbo.remoting.exchange.codec.ExchangeCodec.decode(ExchangeCodec.java:121) at com.alibaba.dubbo.remoting.exchange.codec.ExchangeCodec.decode(ExchangeCodec.java:82) at com.alibaba.dubbo.rpc.protocol.dubbo.DubboCountCodec.decode(DubboCountCodec.java:44) at com.alibaba.dubbo.remoting.transport.netty.NettyCodecAdapter$InternalDecoder.messageReceived(NettyCodecAdapter.java:133) at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:109) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:90) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178) at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:744)Caused by: com.alibaba.com.caucho.hessian.io.HessianProtocolException: &apos;org.hibernate.validator.internal.metadata.descriptor.ConstraintDescriptorImpl&apos; could not be instantiated at com.alibaba.com.caucho.hessian.io.JavaDeserializer.instantiate(JavaDeserializer.java:313) at com.alibaba.com.caucho.hessian.io.JavaDeserializer.readObject(JavaDeserializer.java:198) at com.alibaba.com.caucho.hessian.io.Hessian2Input.readObjectInstance(Hessian2Input.java:2789) at com.alibaba.com.caucho.hessian.io.Hessian2Input.readObject(Hessian2Input.java:2128) at com.alibaba.com.caucho.hessian.io.Hessian2Input.readObject(Hessian2Input.java:2057) at com.alibaba.com.caucho.hessian.io.Hessian2Input.readObject(Hessian2Input.java:2101) at com.alibaba.com.caucho.hessian.io.Hessian2Input.readObject(Hessian2Input.java:2057) at com.alibaba.com.caucho.hessian.io.JavaDeserializer$ObjectFieldDeserializer.deserialize(JavaDeserializer.java:404) ... 43 moreCaused by: java.lang.reflect.InvocationTargetException at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:526) at com.alibaba.com.caucho.hessian.io.JavaDeserializer.instantiate(JavaDeserializer.java:309) ... 50 moreCaused by: java.lang.NullPointerException at org.hibernate.validator.internal.metadata.descriptor.ConstraintDescriptorImpl.&lt;init&gt;(ConstraintDescriptorImpl.java:158) at org.hibernate.validator.internal.metadata.descriptor.ConstraintDescriptorImpl.&lt;init&gt;(ConstraintDescriptorImpl.java:211) ... 55 more 问题分析上面的问题从异常面来看已经很直观了，&#39;org.hibernate.validator.internal.metadata.descriptor.ConstraintDescriptorImpl&#39; could not be instantiated，这个类无法实例化，那是什么原因导致它无法实例化呢？ Dubbo的序列化协议，默认是hessian，如果没有进行其他协议配置的话，默认使用的就是hessian，hessian在反序列化时有个特点需要注意一下，它会在反序列化时取参数最少的构造器来创建对象，有的时候会有很多重载的构造器，因此会有一些参数直接给null，因此可能就会造成一些莫名其妙的问题，就像我们这个问题一样。 那这个问题如何解决呢？接着往下看 解决方案由于这个是Hessian反序列化问题，因此与Dubbo的版本关系不大，为了验证这个我还专门使用apache dubbo 2.6.1版本测试了一下，问题依旧存在。 方法一：使用无参构造方法来创建对象既然是hessian反序列化问题，而且它在反序列化时根据构造函数参数个数优先级来取参数最少的，那我们就可以增加一个无参的构造方法来解决这个问题。 但是有的时候我们使用的是第三方的包，不太好增加无参的构造方法，那怎么办的，我们能不能使用其他方法，继续往下看。 方法二：替换jsr303实现框架既然hibernate-validator的org.hibernate.validator.internal.metadata.descriptor.ConstraintDescriptorImpl这个类在使用hessian反序列化存在问题，那我们使用其他jsr303的框架来试试。 jsr303的实现框架有哪些？ org.hibernate : hibernate-validator : 5.2.4.Final org.apache.bval : bval-jsr303 : 0.5 jersery bval是apache的一个bean validator的实现，jersery是一个restful的框架为了满足自身的数据验证功能因此增加了jsr303的实现。 由于我们使用的springmvc构建restful因此这里就不考虑jersery，我们就从bval下手来试一试。 在进行了一番配置后（都有哪些配置？） 增加bval包，现在版本是：0.5 &lt;dependency&gt; &lt;groupId&gt;org.apache.bval&lt;/groupId&gt; &lt;artifactId&gt;bval-jsr303&lt;/artifactId&gt; &lt;version&gt;0.5&lt;/version&gt;&lt;/dependency&gt; 将bval集成到spring框架中，作为spring的验证框架 这里有两种方式，一种xml配置，一种java config xml方式： &lt;mvc:annotation-driven validator=&quot;validator&quot;/&gt; &lt;!-- 数据验证 Validator bean --&gt; &lt;bean id=&quot;validator&quot; class=&quot;org.springframework.validation.beanvalidation.LocalValidatorFactoryBean&quot;&gt; &lt;property name=&quot;providerClass&quot; value=&quot;org.apache.bval.jsr.ApacheValidationProvider&quot; /&gt; &lt;/bean&gt; java config方式:重写mvcValidator方法 @Overridepublic Validator mvcValidator() &#123; Validator validator = super.mvcValidator(); if (validator instanceof LocalValidatorFactoryBean) &#123; LocalValidatorFactoryBean lvfb = (LocalValidatorFactoryBean) validator; try &#123; String className = &quot;org.apache.bval.jsr303.ApacheValidationProvider&quot;; Class&lt;?&gt; clazz = ClassUtils.forName(className, WebMvcConfigurationSupport.class.getClassLoader()); lvfb.setProviderClass(clazz); &#125; catch (ClassNotFoundException e) &#123; //没有找到bval验证框架，走spring默认整合的验证框架：hibernate-validator //这里异常没有必要跑出去，直接吃掉 &#125; &#125; return validator;&#125; 启动后验证功能 但是不好的事情发生了，无法启动报错，错误如下： java.lang.AbstractMethodError: org.apache.bval.jsr303.ConfigurationImpl.getDefaultParameterNameProvider()Ljavax/validation/ParameterNameProvider; 经过对spring的资料查找，发现spring从4.0版本往后不在支持集成其他jsr303的框架了，只能使用hibernate-validator，我擦这个有点暴力了。即使自己实现一个jsr303框架也无法再spring中使用，除非不使用spring validator功能，直接使用自己的验证框架来进行验证，这样就无法使用@Validated param方式。 那这种方法只能放弃了。 方法三：修改hibernate-validator的原声类，修改Dubbo ValidationFilter，这也是我最终采用的方法其实替换jsr303框架不能成功，替换序列化协议应该也可以避免这个问题，只不过替换协议这个一般在维护的项目中不太会选择这样的方式来动刀子，现在开发很多都是分布式服务，序列化反序列化已经无处不在了，因此我建议编写代码时都增加一个无参数的构造方法，养成这样的一个好习惯可以避免很多序列化反序列化框架的坑。而且还有那些有匿名内部类的这种在序列化反序列化也需要注意，不是所有的序列化反序列化框架都支持有匿名类，gson是支持的这个为测试过，我前面也写过一篇博文里面就主要说这个问题，可以查看：《Java中内部类使用注意事项，内部类对序列化与反序列化的影响》 有兴趣的可以看一下我们常用的序列化反序列化类库的一些使用中的注意事项，可以参考这篇文章：《java常用JSON库注意事项总结》 回归话题，上面的问题我们如何解决，最终我们采用重写javax.validation.ConstraintViolation&lt;T&gt;的实现类，替换掉hibernate-validation的org.hibernate.validator.internal.engine.ConstraintViolationImpl，因为ConstraintViolationImpl中有部分对象无法通过hessian反序列化。 我们最终的目标是不管是validation开启在provider端还是consumer端，调用方接收到的参数校验异常数据是一致的。 修改的代码已经提交到apache dubbo，具体查看Pull request：https://github.com/apache/incubator-dubbo/pull/1708 大概的代码如下： 增加类：DubboConstraintViolation实现javax.validation.ConstraintViolation接口import java.io.Serializable;import javax.validation.ConstraintViolation;import javax.validation.Path;import javax.validation.ValidationException;import javax.validation.metadata.ConstraintDescriptor;import com.alibaba.dubbo.common.logger.Logger;import com.alibaba.dubbo.common.logger.LoggerFactory;public class DubboConstraintViolation&lt;T&gt; implements ConstraintViolation&lt;T&gt;, Serializable &#123; static final Logger logger = LoggerFactory.getLogger(DubboConstraintViolation.class.getName()); private static final long serialVersionUID = -8901791810611051795L; private String interpolatedMessage; private Object value; private Path propertyPath; private String messageTemplate; private Object[] executableParameters; private Object executableReturnValue; private int hashCode; public DubboConstraintViolation() &#123; &#125; public DubboConstraintViolation(ConstraintViolation&lt;T&gt; violation) &#123; this(violation.getMessageTemplate(), violation.getMessage(), violation.getInvalidValue(), violation.getPropertyPath(), violation.getExecutableParameters(), violation.getExecutableReturnValue()); &#125; public DubboConstraintViolation(String messageTemplate, String interpolatedMessage, Object value, Path propertyPath, Object[] executableParameters, Object executableReturnValue) &#123; this.messageTemplate = messageTemplate; this.interpolatedMessage = interpolatedMessage; this.value = value; this.propertyPath = propertyPath; this.executableParameters = executableParameters; this.executableReturnValue = executableReturnValue; // pre-calculate hash code, the class is immutable and hashCode is needed often this.hashCode = createHashCode(); &#125; @Override public final String getMessage() &#123; return interpolatedMessage; &#125; @Override public final String getMessageTemplate() &#123; return messageTemplate; &#125; @Override public final T getRootBean() &#123; return null; &#125; @Override public final Class&lt;T&gt; getRootBeanClass() &#123; return null; &#125; @Override public final Object getLeafBean() &#123; return null; &#125; @Override public final Object getInvalidValue() &#123; return value; &#125; @Override public final Path getPropertyPath() &#123; return propertyPath; &#125; @Override public final ConstraintDescriptor&lt;?&gt; getConstraintDescriptor() &#123; return null; &#125; @Override public &lt;C&gt; C unwrap(Class&lt;C&gt; type) &#123; if ( type.isAssignableFrom( ConstraintViolation.class ) ) &#123; return type.cast( this ); &#125; throw new ValidationException(&quot;Type &quot; + type.toString() + &quot; not supported for unwrapping.&quot;); &#125; @Override public Object[] getExecutableParameters() &#123; return executableParameters; &#125; @Override public Object getExecutableReturnValue() &#123; return executableReturnValue; &#125; @Override // IMPORTANT - some behaviour of Validator depends on the correct implementation of this equals method! (HF) // Do not take expressionVariables into account here. If everything else matches, the two CV should be considered // equals (and because of the scary comment above). After all, expressionVariables is just a hint about how we got // to the actual CV. (NF) public boolean equals(Object o) &#123; if ( this == o ) &#123; return true; &#125; if ( o == null || getClass() != o.getClass() ) &#123; return false; &#125; DubboConstraintViolation&lt;?&gt; that = (DubboConstraintViolation&lt;?&gt;) o; if ( interpolatedMessage != null ? !interpolatedMessage.equals( that.interpolatedMessage ) : that.interpolatedMessage != null ) &#123; return false; &#125; if ( propertyPath != null ? !propertyPath.equals( that.propertyPath ) : that.propertyPath != null ) &#123; return false; &#125; if ( messageTemplate != null ? !messageTemplate.equals( that.messageTemplate ) : that.messageTemplate != null ) &#123; return false; &#125; if ( value != null ? !value.equals( that.value ) : that.value != null ) &#123; return false; &#125; return true; &#125; @Override public int hashCode() &#123; return hashCode; &#125; @Override public String toString() &#123; final StringBuilder sb = new StringBuilder(); sb.append( &quot;DubboConstraintViolation&quot; ); sb.append( &quot;&#123;interpolatedMessage=&apos;&quot; ).append( interpolatedMessage ).append( &apos;\\&apos;&apos; ); sb.append( &quot;, propertyPath=&quot; ).append( propertyPath ); sb.append( &quot;, messageTemplate=&apos;&quot; ).append( messageTemplate ).append( &apos;\\&apos;&apos; ); sb.append( &quot;, value=&apos;&quot; ).append( value ).append( &apos;\\&apos;&apos; ); sb.append( &apos;&#125;&apos; ); return sb.toString(); &#125; // Same as for equals, do not take expressionVariables into account here. private int createHashCode() &#123; int result = interpolatedMessage != null ? interpolatedMessage.hashCode() : 0; result = 31 * result + ( propertyPath != null ? propertyPath.hashCode() : 0 ); result = 31 * result + ( value != null ? value.hashCode() : 0 ); result = 31 * result + ( messageTemplate != null ? messageTemplate.hashCode() : 0 ); return result; &#125;&#125; 修改com.alibaba.dubbo.validation.filter.ValidationFilter异常处理的部分这里的变更为捕捉javax.validation.ConstraintViolationException异常，对异常中的Set&lt;ConstraintViolation&lt;String&gt;&gt;数据进行转换，去掉无法反序列化的对象,具体代码如下： public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; if (validation != null &amp;&amp; !invocation.getMethodName().startsWith(&quot;$&quot;) &amp;&amp; ConfigUtils.isNotEmpty(invoker.getUrl().getMethodParameter(invocation.getMethodName(), Constants.VALIDATION_KEY))) &#123; try &#123; Validator validator = validation.getValidator(invoker.getUrl()); if (validator != null) &#123; validator.validate(invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments()); &#125; &#125; catch (ConstraintViolationException e) &#123; Set&lt;ConstraintViolation&lt;?&gt;&gt; set = null; //验证set中如果是hibernate-validation实现的类就处理，其他的实现类放过 Set&lt;ConstraintViolation&lt;?&gt;&gt; constraintViolations = e.getConstraintViolations(); for (ConstraintViolation&lt;?&gt; v : constraintViolations) &#123; if (!v.getClass().getName().equals(&quot;org.hibernate.validator.internal.engine.ConstraintViolationImpl&quot;)) &#123; return new RpcResult(e); &#125; else &#123; if (set == null) set = new HashSet&lt;ConstraintViolation&lt;?&gt;&gt;(); set.add(new DubboConstraintViolation&lt;&gt;(v)); &#125; &#125; return new RpcResult(new ConstraintViolationException(e.getMessage(), set)); &#125; catch (RpcException e) &#123; throw e; &#125; catch (Throwable t) &#123; return new RpcResult(t); &#125; &#125; return invoker.invoke(invocation);&#125; 使用这个方法后，在provider端设置validation=true，consumer端可以正常拿到所有校验数据的异常信息。 总结我觉得这个方法并不是完美的方法，虽然这个问题是hibernate-validator框架的问题，hibernate-validator出生的年代分布式还不是特别的完善因此没有充分的考虑序列化反序列化问题也很正常，但是作为Dubbo框架在集成jsr303的时候也需要考虑这些问题。具体可以查看Apache Dubbo的Pull Request：https://github.com/apache/incubator-dubbo/pull/1708","tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://ningyu1.github.io/tags/dubbo/"},{"name":"jsr303","slug":"jsr303","permalink":"https://ningyu1.github.io/tags/jsr303/"},{"name":"hibernate-validator","slug":"hibernate-validator","permalink":"https://ningyu1.github.io/tags/hibernate-validator/"}]},{"title":"单元测试以及代码覆盖率——Jenkins集成SonarQube、JaCoCo、Junit使用问题汇总","date":"2018-04-12T09:03:00.000Z","path":"20180412/77-jenkins-sonarqube-jacoco-junit.html","text":"当我们使用持续集成Jenkins的时候经常会结合一系列的插件使用，这里就说一下Jenkins集成Sonar做代码质量管理以及Junit（testng）、JaCoCo做单元测试和覆盖率的时候遇到的问题。 前提首先我们的工程使用maven构建，单元测试使用testng编写，在使用jenkins之前我们应该在本地使用maven调通所有的单元测试以及test coverage的问题。 我们使用maven-surefire-plugin来生成单元测试报告，使用jacoco-maven-plugin来生成test coverage报告。下面我给出以下我使用的标准配置 maven工程调通单元测试以及测试覆盖率报告生成pom.xml的标准配置 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.testng&lt;/groupId&gt; &lt;artifactId&gt;testng&lt;/artifactId&gt; &lt;version&gt;6.4&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.jacoco&lt;/groupId&gt; &lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.8.1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;configuration&gt; &lt;skipTests&gt;false&lt;/skipTests&gt; &lt;argLine&gt;$&#123;argLine&#125; -Dfile.encoding=UTF-8&lt;/argLine&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;skip&gt;false&lt;/skip&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.jacoco&lt;/groupId&gt; &lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.8.1&lt;/version&gt; &lt;configuration&gt; &lt;skip&gt;false&lt;/skip&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;prepare-agent&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;configuration&gt; &lt;outputDirectory&gt;$&#123;basedir&#125;/target/coverage-reports&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;id&gt;report&lt;/id&gt; &lt;phase&gt;test&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;report&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 根据上面配置执行下来的报告生成的目录结构如下: classes是源代码编译生成的字节码目录 coverage-reports是单元测试覆盖率报告生成目录 surefire-reports是单元测试报告生成目录 test-classes是单元测试代码编译生成的字节码目录 jacoco.exec是用于生成单元测试可执行文件 下面我说一下我们会遇到的常规问题 上步操作会遇到的常规问题问题一：Tests are skipped.[INFO] --- maven-surefire-plugin:2.5:test (default-test) @ tools ---[INFO] Tests are skipped. 单元测试被跳过，这个可以通过maven-surefire-plugin插件的configuration来配置不跳过，如下配置： &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;configuration&gt; &lt;skipTests&gt;false&lt;/skipTests&gt; &lt;/configuration&gt;&lt;/plugin&gt; 配置skipTests属性而不是skip属性这里需要注意一下，有很多人配置的skip属性 问题二：单元测试输出乱码------------------------------------------------------- T E S T S-------------------------------------------------------Running TestSuiteSLF4J: Failed to load class &quot;org.slf4j.impl.StaticLoggerBinder&quot;.SLF4J: Defaulting to no-operation (NOP) logger implementationSLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.=====��һ��====================��һ��====================���¼���=============== 单元测试输出信息乱码，这个可以通过maven-surefire-plugin插件的configuration来配置字符编码，如下配置： &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;configuration&gt; &lt;skipTests&gt;false&lt;/skipTests&gt; &lt;argLine&gt;-Dfile.encoding=UTF-8&lt;/argLine&gt; &lt;/configuration&gt;&lt;/plugin&gt; 到这里我们就可以去taget/surefire-reports目录下查看单元测试报告。 问题三：Skipping JaCoCo execution due to missing execution data file.[INFO] --- jacoco-maven-plugin:0.8.1:report (report) @ tools ---[INFO] Skipping JaCoCo execution due to missing execution data file. jacoco执行被跳过，原因是没有找到jacoco可执行文件jacoco.exec。 这个时候我们去target目录下是看不到jacoco.exec文件的，有的版本名字叫jacoco-junit.exec。 理论上执行的时候会自动生成exec文件，但是为什么没有生成？我们看一下执行日志 [INFO] --- jacoco-maven-plugin:0.8.1:prepare-agent (default) @ tools ---[INFO] argLine set to -javaagent:D:\\\\javatools\\\\mvnrepository\\\\org\\\\jacoco\\\\org.jacoco.agent\\\\0.8.1\\\\org.jacoco.agent-0.8.1-runtime.jar=destfile=D:\\\\javatools\\\\workspace\\\\framework\\\\tools\\\\target\\\\jacoco.exec jacoco.exec的生成是根据-javaagent的方式来生成的，我们有可以看到jacoco-maven-plugin指定了argLine参数，但是为什么没有生效？ 原因是我们上面指定过单元测试编码，使用的就是argLine参数，因此这个问题应该是上面的编码参数指定后没有带入插件添加的-javaagent参数，那如何解决？查看下面配置： &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;configuration&gt; &lt;skipTests&gt;false&lt;/skipTests&gt; &lt;argLine&gt;$&#123;argLine&#125; -Dfile.encoding=UTF-8&lt;/argLine&gt; &lt;/configuration&gt;&lt;/plugin&gt; 在argLine中增加变量${argLine}后面再增加自动以的参数 如果通过配置手动的指定jacoco.exec文件的生成路径也需要注意也可能会出现这个问题，生成exec的路径指定在哪里，report执行的时候就需要通过dataFile来指定exec的路径，让程序知道正确的exec路径，比如说： &lt;plugin&gt; &lt;groupId&gt;org.jacoco&lt;/groupId&gt; &lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.8.1&lt;/version&gt; &lt;configuration&gt; &lt;skip&gt;false&lt;/skip&gt; &lt;destFile&gt;$&#123;basedir&#125;/target/coverage-reports/jacoco.exec&lt;/destFile&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;prepare-agent&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;configuration&gt; &lt;dataFile&gt;$&#123;basedir&#125;/target/coverage-reports/jacoco.exec&lt;/dataFile&gt; &lt;outputDirectory&gt;$&#123;basedir&#125;/target/coverage-reports&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;id&gt;report&lt;/id&gt; &lt;phase&gt;test&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;report&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 上面通过configuration的destFile来自定义jacoco.exec的生成路径，下面在report的时候需要通过dataFile来指定对应的jacoco.exec的路径。 Jenkins使用JaCoCo plugin插件首先去Jenkins上安装JaCoCo plugin插件，插件的安装就跳过了，插件安装好后，在job中如何配置? 这里需要注意的配置 Path to exec files: **/jacoco.exec 可执行文件路径 Path to class directories: 这个配置的是源代码编译后的字节码目录，也就是classes目录不是test-classes目录，如果有多个可以指定多个 Path to source directories: 这个配置的是源代码的目录，也就是src/main/java目录，如果有多个可以指定多个。 配置好之后执行job会看到如下的日志： INFO: ------------------------------------------------------------------------Injecting SonarQube environment variables using the configuration: SonarQube[JaCoCo plugin] Collecting JaCoCo coverage data...[JaCoCo plugin] **/jacoco.exec;**/classes;src/main/java; locations are configuredInjecting SonarQube environment variables using the configuration: SonarQubeInjecting SonarQube environment variables using the configuration: SonarQube[JaCoCo plugin] Number of found exec files for pattern **/jacoco.exec: 1[JaCoCo plugin] Saving matched execfiles: /var/lib/jenkins/workspace/cc-framework-tools/target/coverage-reports/jacoco.exec[JaCoCo plugin] Saving matched class directories for class-pattern: **/classes: [JaCoCo plugin] - /var/lib/jenkins/workspace/cc-framework-tools/target/classes 5 files[JaCoCo plugin] Saving matched source directories for source-pattern: src/main/java: [JaCoCo plugin] - /var/lib/jenkins/workspace/cc-framework-tools/src/main/java 5 files[JaCoCo plugin] Loading inclusions files..[JaCoCo plugin] inclusions: [][JaCoCo plugin] exclusions: [][JaCoCo plugin] Thresholds: JacocoHealthReportThresholds [minClass=0, maxClass=0, minMethod=0, maxMethod=0, minLine=0, maxLine=0, minBranch=0, maxBranch=0, minInstruction=0, maxInstruction=0, minComplexity=0, maxComplexity=0][JaCoCo plugin] Publishing the results..[JaCoCo plugin] Loading packages..[JaCoCo plugin] Done.[JaCoCo plugin] Overall coverage: class: 50, method: 54, line: 48, branch: 40, instruction: 55Finished: SUCCESS 出现上面日志就证明配置成功并且可以看到报告，如果出现下面的日志就证明配置的目录没有扫到classes，需要修改Path to class directories目录的配置 Overall coverage: class: 0, method: 0, line: 0, branch: 0, instruction: 0 最终结果如下图： Jenkins使用Sonarqube plugin插件首先去Jenkins上安装SonarQube plugin插件，插件的安装就跳过了，插件安装好后，在jenkins的系统配置中配置sonar服务器信息，如下 配置好后在job的配置中增加SonarQube的支持，如下 在构建环境下添加Prepare SonarQube Scanner environment 在构建下添加Execute SonarQube Scanner 在Execute SonarQube Scanner中增加Analysis properties # required metadata# 项目keysonar.projectKey=com.domian.package:projectName# 项目名称sonar.projectName=tools# 项目版本，可以写死，也可以引用变量sonar.projectVersion=$&#123;VER&#125;# 源文件编码sonar.sourceEncoding=UTF-8# 源文件语言sonar.language=java# path to source directories (required)# 源代码目录，如果多个使用&quot;,&quot;分割 例如：mode1/src/main,mode2/src/mainsonar.sources=src/main# 单元测试目录，如果多个使用&quot;,&quot;分割 例如：mode1/src/test,mode2/src/testsonar.tests=src/test# Exclude the test source# 忽略的目录#sonar.exclusions=*/src/test/**/*# 单元测试报告目录sonar.junit.reportsPath=target/surefire-reports# 代码覆盖率插件sonar.java.coveragePlugin=jacoco# jacoco.exec文件路径sonar.jacoco.reportPath=target/coverage-reports/jacoco.exec# 这个没搞懂，官方示例是配置成jacoco.exec文件路径sonar.jacoco.itReportPath=target/coverage-reports/jacoco.exec 具体的参数可以查看官方文档:《Analysis Parameters》 配置好之后执行job后去Sonar上只看到了单元测试的信息，没有看到单元测试覆盖率的信息，关于这个问题我们分析job执行的日志，如下: 问题一：No JaCoCo analysis of project coverage can be done since there is no class files.16:01:17.455 INFO - Sensor JaCoCoOverallSensor16:01:17.470 INFO - Analysing /var/lib/jenkins/workspace/cc-framework-tools/target/coverage-reports/jacoco.exec16:01:17.481 INFO - No JaCoCo analysis of project coverage can be done since there is no class files.16:01:17.481 INFO - Sensor JaCoCoOverallSensor (done) | time=26ms16:01:17.482 INFO - Sensor JaCoCoSensor16:01:17.482 INFO - No JaCoCo analysis of project coverage can be done since there is no class files.16:01:17.482 INFO - Sensor JaCoCoSensor (done) | time=0ms16:01:17.482 INFO - Sensor Code Colorizer Sensor 说的是没找到class文件所以jacoco不能进行分析，问题很明显是没有找到class类，难道它不是去maven标准的target/classes下找文件么？ 但是找到了这篇文章：《Jenkins, JaCoCo, and SonarQube Integration With Maven》，看到里面在pom.xml中配置了一些参数给我了启发，发现有个参数sonar.binaries指定的是classes目录，可以插件的有些参数不兼容maven，在官方的配置中可以看到这样的字样: Not compatible with Mave和Compatible with Maven，能看到有写参数兼容maven默认路径有些不兼容。 随后再官方文档中也找到了与jenkins继承的properties配置说明：《Triggering Analysis on Hudson Job》 # path to project binaries (optional), for example directory of Java bytecode# java字节码目录sonar.binaries=binDir 最终给出Execute SonarQube Scanner中的Analysis properties完成配置参数如下： # required metadata# 项目keysonar.projectKey=com.domian.package:projectName# 项目名称sonar.projectName=tools# 项目版本，可以写死，也可以引用变量sonar.projectVersion=$&#123;VER&#125;# 源文件编码sonar.sourceEncoding=UTF-8# 源文件语言sonar.language=java# path to source directories (required)# 源代码目录，如果多个使用&quot;,&quot;分割 例如：mode1/src/main,mode2/src/mainsonar.sources=src/main/java# 单元测试目录，如果多个使用&quot;,&quot;分割 例如：mode1/src/test,mode2/src/testsonar.tests=src/test/java# java字节码目录sonar.binaries=target/classes# 单元测试报告目录sonar.junit.reportsPath=target/surefire-reports# 代码覆盖率插件sonar.java.coveragePlugin=jacoco# jacoco插件版本jacoco.version=0.8.1# jacoco.exec文件路径sonar.jacoco.reportPath=target/coverage-reports/jacoco.exec 全部配置修改完后执行job后去Sonar上查看具体的信息如下：","tags":[{"name":"jenkins","slug":"jenkins","permalink":"https://ningyu1.github.io/tags/jenkins/"},{"name":"sonar","slug":"sonar","permalink":"https://ningyu1.github.io/tags/sonar/"},{"name":"sonarqube","slug":"sonarqube","permalink":"https://ningyu1.github.io/tags/sonarqube/"},{"name":"jacoco","slug":"jacoco","permalink":"https://ningyu1.github.io/tags/jacoco/"},{"name":"junit","slug":"junit","permalink":"https://ningyu1.github.io/tags/junit/"},{"name":"testng","slug":"testng","permalink":"https://ningyu1.github.io/tags/testng/"}]},{"title":"TiDB使用笔记 —— 测试环境集群部署","date":"2018-04-10T12:13:00.000Z","path":"20180410/76-tidb-notes.html","text":"TiDB是一个NewSql的分布式数据库，具体介绍我们引用官方的简介 简介TiDB 是 PingCAP 公司受 Google Spanner / F1 论文启发而设计的开源分布式 NewSQL 数据库。 TiDB 具备如下 NewSQL 核心特性： SQL支持（TiDB 是 MySQL 兼容的）水平弹性扩展（吞吐可线性扩展）分布式事务跨数据中心数据强一致性保证故障自恢复的高可用海量数据高并发实时写入与实时查询（HTAP 混合负载）TiDB 的设计目标是 100% 的 OLTP 场景和 80% 的 OLAP 场景，更复杂的 OLAP 分析可以通过 TiSpark 项目来完成。 TiDB 对业务没有任何侵入性，能优雅的替换传统的数据库中间件、数据库分库分表等 Sharding 方案。同时它也让开发运维人员不用关注数据库 Scale 的细节问题，专注于业务开发，极大的提升研发的生产力。 我们来看一下TiDB的架构图 架构图 从架构图中可以看出TiDB的三大组件都支持水平扩展而且内部通信使用的是gRPC，关于TiDB和gRPC的那些事可以查看InfoQ的文章：《TiDB与gRPC的那点事》 TiDB使用的TiKV作为存储，官方建议至少TiKV使用ssd硬盘，如果条件好pd模块最好也使用ssd硬盘。 下来我们具体看一下三大组件分别都是干什么的 TiDB ServerTiDB Server 负责接收 SQL 请求，处理 SQL 相关的逻辑，并通过 PD 找到存储计算所需数据的 TiKV 地址，与 TiKV 交互获取数据，最终返回结果。 TiDB Server 是无状态的，其本身并不存储数据，只负责计算，可以无限水平扩展，可以通过负载均衡组件（如LVS、HAProxy 或 F5）对外提供统一的接入地址。 PD ServerPlacement Driver (简称 PD) 是整个集群的管理模块，其主要工作有三个： 一是存储集群的元信息（某个 Key 存储在哪个 TiKV 节点）；二是对 TiKV 集群进行调度和负载均衡（如数据的迁移、Raft group leader 的迁移等）；三是分配全局唯一且递增的事务 ID。 PD 是一个集群，需要部署奇数个节点，一般线上推荐至少部署 3 个节点。 TiKV ServerTiKV Server 负责存储数据，从外部看 TiKV 是一个分布式的提供事务的 Key-Value 存储引擎。存储数据的基本单位是 Region，每个 Region 负责存储一个 Key Range （从 StartKey 到 EndKey 的左闭右开区间）的数据，每个 TiKV 节点会负责多个 Region 。TiKV 使用 Raft 协议做复制，保持数据的一致性和容灾。副本以 Region 为单位进行管理，不同节点上的多个 Region 构成一个 Raft Group，互为副本。数据在多个 TiKV 之间的负载均衡由 PD 调度，这里也是以 Region 为单位进行调度。 特性可以无限水平扩展而且三大组件都是高可用，TiDB/TiKV/PD 这三个组件都能容忍部分实例失效，不影响整个集群的可用性。关于三大组件出现问题后如何恢复可以查看：《tidb-整体架构中的高可用章节》 官方的部署建议TiDB使用的TiKV作为存储，官方建议至少TiKV使用ssd硬盘，如果条件好pd模块最好也使用ssd硬盘。 建议 4 台及以上，TiKV 至少 3 实例，且与 TiDB、PD 模块不位于同一主机。 组件 CPU 内存 本地存储 网络 实例数量(最低要求) TiDB 8核+ 16 GB+ SAS, 200 GB+ 千兆网卡 1（可与 PD 同机器） PD 8核+ 16 GB+ SAS, 200 GB+ 千兆网卡 1（可与 TiDB 同机器） TiKV 8核+ 32 GB+ SSD, 200 GB+ 千兆网卡 3 - - - - 服务器总计 4 个人觉得这个使用的成本还是蛮高的。具体可以看《软、硬件环境要求》 测试部署TiDB的部署方式还是蛮丰富的，可以使用Ansible在线以及离线的部署集群，TiDB-Ansible 是 PingCAP 基于 Ansible playbook 功能编写的集群部署工具。使用 TiDB-Ansible 可以快速部署一个完整的 TiDB 集群（包括 PD、TiDB、TiKV 和集群监控模块)。 TiDB同时也支持Docker部署方案，由于我们公司内网使用docker容器的方式管理所有服务，所以我这里使用docker方式部署。 我们使用Rancher来做企业级的容器管理平台，没有使用k8s、mesos来进行编排管理，使用的是Rancher自带的Cattle，Cattle不光有编排管理还包含了应用、服务、卷、负载均衡、健康检查、服务升级、dns服务、等功能，有兴趣的可以查看：《Rancher官方文档-Cattle》 在进行部署之前需要先去Docker官方镜像库中拉TiDB集群所需要的三大组件的镜像： Docker 官方镜像仓库 docker pull pingcap/tidb:latestdocker pull pingcap/tikv:latestdocker pull pingcap/pd:latest 这三个组件的镜像都不大，TiKV只有54MB，PD只有21MB，TiDB只有17MB 这个我需要说一下他们这块做的还是很不错的，将镜像压缩的都比较小，去除了很多无用的东西。 我们需要创建7个容器来部署一个TiDB集群： 容器 容器IP 宿主机IP 部署服务 数据盘挂载 PD1 10.42.59.28 192.168.18.108 PD1 /home/docker/TiDB PD2 10.42.202.152 192.168.18.108 PD2 /home/docker/TiDB PD3 10.42.214.245 192.168.18.108 PD3 /home/docker/TiDB TiDB 10.42.188.35 192.168.18.109 TiDB /home/docker/TiDB TiKV1 10.42.106.167 192.168.18.109 TiKV1 /home/docker/TiDB TiKV2 10.42.34.97 192.168.18.109 TiKV2 /home/docker/TiDB TiKV3 10.42.170.152 192.168.18.109 TiKV3 /home/docker/TiDB 用docker的好处就是资源可以压缩到最小，我6个容器可以放在一到两台虚机上 查看pd集群信息 http://192.168.18.108:2379/v2/membershttp://192.168.18.108:2479/v2/membershttp://192.168.18.108:2579/v2/members 返回信息以json格式，三台pd返回集群信息都是一样的 &#123;&quot;members&quot;:[&#123;&quot;id&quot;:&quot;969b7171b723b804&quot;,&quot;name&quot;:&quot;pd3&quot;,&quot;peerURLs&quot;:[&quot;http://192.168.18.108:2580&quot;],&quot;clientURLs&quot;:[&quot;http://192.168.18.108:2579&quot;]&#125;,&#123;&quot;id&quot;:&quot;d141f07798663b47&quot;,&quot;name&quot;:&quot;pd2&quot;,&quot;peerURLs&quot;:[&quot;http://192.168.18.108:2480&quot;],&quot;clientURLs&quot;:[&quot;http://192.168.18.108:2479&quot;]&#125;,&#123;&quot;id&quot;:&quot;e5e987f33a60e672&quot;,&quot;name&quot;:&quot;pd1&quot;,&quot;peerURLs&quot;:[&quot;http://192.168.18.108:2380&quot;],&quot;clientURLs&quot;:[&quot;http://192.168.18.108:2379&quot;]&#125;]&#125; 具体的docker容器创建命令可以参考官方文档：《Docker部署方案》 TiDB支持mysql协议可以使用任意mysql客户端连接，默认安装好的集群使用mysql登录，端口：4000，用户名：root，密码为空，修改密码跟mysql修改密码方式完全一样。 SET PASSWORD FOR &apos;root&apos;@&apos;%&apos; = &apos;xxx&apos;; 下面说几个我们必须要关心的东西。 事务隔离级别可以查看：《TiDB 事务隔离级别》 SQL语法没有什么变化，具体可以查看：《SQL语句语法》 SQL执行计划什么的都有跟使用mysql几乎一样，还增加了json的支持，可以设置字段列存储类型为json格式。 具体与MySQL有什么差异可以查看：《与MySQL兼容性对比》 历史数据回溯问题可以查看：《TiDB 历史数据回溯》 Binlog可以使用：《TiDB-Binlog 部署方案》 还有《备份与恢复》 和 《数据迁移》。 好了今天的大致介绍和测试环境集群搭建都到这里，后面会总结使用中遇到的问题。","tags":[{"name":"TiDB","slug":"TiDB","permalink":"https://ningyu1.github.io/tags/TiDB/"},{"name":"TiKV","slug":"TiKV","permalink":"https://ningyu1.github.io/tags/TiKV/"},{"name":"pd","slug":"pd","permalink":"https://ningyu1.github.io/tags/pd/"}]},{"title":"MySql Lock wait timeout exceeded该如何处理？","date":"2018-04-08T10:02:00.000Z","path":"20180408/75-mysql-lock-wait-timeout-exceeded.html","text":"这个问题我相信大家对它并不陌生，但是有很多人对它产生的原因以及处理吃的不是特别透，很多情况都是交给DBA去定位和处理问题，接下来我们就针对这个问题来展开讨论。 Mysql造成锁的情况有很多，下面我们就列举一些情况： 执行DML操作没有commit，再执行删除操作就会锁表。 在同一事务内先后对同一条数据进行插入和更新操作。 表索引设计不当，导致数据库出现死锁。 长事物，阻塞DDL，继而阻塞所有同表的后续操作。 但是要区分的是Lock wait timeout exceeded与Dead Lock是不一样。 Lock wait timeout exceeded：后提交的事务等待前面处理的事务释放锁，但是在等待的时候超过了mysql的锁等待时间，就会引发这个异常。 Dead Lock：两个事务互相等待对方释放相同资源的锁，从而造成的死循环，就会引发这个异常。 还有一个要注意的是innodb_lock_wait_timeout与lock_wait_timeout也是不一样的。 innodb_lock_wait_timeout：innodb的dml操作的行级锁的等待时间 lock_wait_timeout：数据结构ddl操作的锁的等待时间 如何查看innodb_lock_wait_timeout的具体值？ SHOW VARIABLES LIKE &apos;innodb_lock_wait_timeout&apos; 如何修改innode lock wait timeout的值？ 参数修改的范围有Session和Global，并且支持动态修改，可以有两种方法修改： 方法一： 通过下面语句修改 set innodb_lock_wait_timeout=100;set global innodb_lock_wait_timeout=100; ps. 注意global的修改对当前线程是不生效的，只有建立新的连接才生效。 方法二： 修改参数文件/etc/my.cnfinnodb_lock_wait_timeout = 50 ps. innodb_lock_wait_timeout指的是事务等待获取资源等待的最长时间，超过这个时间还未分配到资源则会返回应用失败； 当锁等待超过设置时间的时候，就会报如下的错误；ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction。其参数的时间单位是秒，最小可设置为1s(一般不会设置得这么小)，最大可设置1073741824秒，默认安装时这个值是50s(默认参数设置)。 下面介绍在遇到这类问题该如何处理 问题现象 数据更新或新增后数据经常自动回滚。 表操作总报 Lock wait timeout exceeded 并长时间无反应 解决方法 应急方法：show full processlist; kill掉出现问题的进程。 ps.有的时候通过processlist是看不出哪里有锁等待的，当两个事务都在commit阶段是无法体现在processlist上 根治方法：select * from innodb_trx;查看有是哪些事务占据了表资源。 ps.通过这个办法就需要对innodb有一些了解才好处理 说起来很简单找到它杀掉它就搞定了，但是实际上并没有想象的这么简单，当问题出现要分析问题的原因，通过原因定位业务代码可能某些地方实现的有问题，从而来避免今后遇到同样的问题。 innodb_*表的解释Mysql的InnoDB存储引擎是支持事务的，事务开启后没有被主动Commit。导致该资源被长期占用，其他事务在抢占该资源时，因上一个事务的锁而导致抢占失败！因此出现 Lock wait timeout exceeded 下面几张表是innodb的事务和锁的信息表，理解这些表就能很好的定位问题。 innodb_trx ## 当前运行的所有事务innodb_locks ## 当前出现的锁innodb_lock_waits ## 锁等待的对应关系 下面对 innodb_trx 表的每个字段进行解释： trx_id：事务ID。trx_state：事务状态，有以下几种状态：RUNNING、LOCK WAIT、ROLLING BACK 和 COMMITTING。trx_started：事务开始时间。trx_requested_lock_id：事务当前正在等待锁的标识，可以和 INNODB_LOCKS 表 JOIN 以得到更多详细信息。trx_wait_started：事务开始等待的时间。trx_weight：事务的权重。trx_mysql_thread_id：事务线程 ID，可以和 PROCESSLIST 表 JOIN。trx_query：事务正在执行的 SQL 语句。trx_operation_state：事务当前操作状态。trx_tables_in_use：当前事务执行的 SQL 中使用的表的个数。trx_tables_locked：当前执行 SQL 的行锁数量。trx_lock_structs：事务保留的锁数量。trx_lock_memory_bytes：事务锁住的内存大小，单位为 BYTES。trx_rows_locked：事务锁住的记录数。包含标记为 DELETED，并且已经保存到磁盘但对事务不可见的行。trx_rows_modified：事务更改的行数。trx_concurrency_tickets：事务并发票数。trx_isolation_level：当前事务的隔离级别。trx_unique_checks：是否打开唯一性检查的标识。trx_foreign_key_checks：是否打开外键检查的标识。trx_last_foreign_key_error：最后一次的外键错误信息。trx_adaptive_hash_latched：自适应散列索引是否被当前事务锁住的标识。trx_adaptive_hash_timeout：是否立刻放弃为自适应散列索引搜索 LATCH 的标识。 下面对 innodb_locks 表的每个字段进行解释： lock_id：锁 ID。lock_trx_id：拥有锁的事务 ID。可以和 INNODB_TRX 表 JOIN 得到事务的详细信息。lock_mode：锁的模式。有如下锁类型：行级锁包括：S、X、IS、IX，分别代表：共享锁、排它锁、意向共享锁、意向排它锁。表级锁包括：S_GAP、X_GAP、IS_GAP、IX_GAP 和 AUTO_INC，分别代表共享间隙锁、排它间隙锁、意向共享间隙锁、意向排它间隙锁和自动递增锁。lock_type：锁的类型。RECORD 代表行级锁，TABLE 代表表级锁。lock_table：被锁定的或者包含锁定记录的表的名称。lock_index：当 LOCK_TYPE=’RECORD’ 时，表示索引的名称；否则为 NULL。lock_space：当 LOCK_TYPE=’RECORD’ 时，表示锁定行的表空间 ID；否则为 NULL。lock_page：当 LOCK_TYPE=’RECORD’ 时，表示锁定行的页号；否则为 NULL。lock_rec：当 LOCK_TYPE=’RECORD’ 时，表示一堆页面中锁定行的数量，亦即被锁定的记录号；否则为 NULL。lock_data：当 LOCK_TYPE=’RECORD’ 时，表示锁定行的主键；否则为NULL。 下面对 innodb_lock_waits 表的每个字段进行解释： requesting_trx_id：请求事务的 ID。requested_lock_id：事务所等待的锁定的 ID。可以和 INNODB_LOCKS 表 JOIN。blocking_trx_id：阻塞事务的 ID。blocking_lock_id：某一事务的锁的 ID，该事务阻塞了另一事务的运行。可以和 INNODB_LOCKS 表 JOIN。 锁等待的处理步骤 直接查看 innodb_lock_waits 表 SELECT * FROM innodb_lock_waits; innodb_locks 表和 innodb_lock_waits 表结合： SELECT * FROM innodb_locks WHERE lock_trx_id IN (SELECT blocking_trx_id FROM innodb_lock_waits); innodb_locks 表 JOIN innodb_lock_waits 表: SELECT innodb_locks.* FROM innodb_locks JOIN innodb_lock_waits ON (innodb_locks.lock_trx_id = innodb_lock_waits.blocking_trx_id); 查询 innodb_trx 表: SELECT trx_id, trx_requested_lock_id, trx_mysql_thread_id, trx_query FROM innodb_trx WHERE trx_state = &apos;LOCK WAIT&apos;; trx_mysql_thread_id 即kill掉事务线程 ID SHOW ENGINE INNODB STATUS ;SHOW PROCESSLIST ; 从上述方法中得到了相关信息，我们可以得到发生锁等待的线程 ID，然后将其 KILL 掉。KILL 掉发生锁等待的线程。 kill ID;","tags":[{"name":"mysql","slug":"mysql","permalink":"https://ningyu1.github.io/tags/mysql/"},{"name":"Lock wait timeout exceeded","slug":"Lock-wait-timeout-exceeded","permalink":"https://ningyu1.github.io/tags/Lock-wait-timeout-exceeded/"}]},{"title":"RediSearch基于Redis的高性能全文搜索引擎，资料整理","date":"2018-03-30T04:24:00.000Z","path":"20180330/74-redisearch.html","text":"最近在参考CQRS DDD架构来进行公司的库存中心重构设计，在CQRS架构中需要一个in-memory的方式快速修改库存在通过消息驱动异步更新到DB，也就是说内存的数据是最新的，DB的数据是异步持久化的，在某一个时刻内存和DB的数据是存在不一致的，但是满足最终一致性。 这样我们就需要内存当作前置DB在使用，因此不单纯的只满足修改数据，还需要满足Query的要求，内存结构的数据Query是比较麻烦的，它不像DB那样已经实现好了索引检索，需要我们自己来设计Key的机构和搜索索引的构建。 当然行业里也有这样的做法，对数据修改的时候双写到内存(Redis)和ElasticSearch再异步到DB，这样Query全部走向ElasticSearch，但是我觉得这样做的复杂度会增加很多，所以就在看如何基于Redis来设计一个搜索引擎。 看到了RedisLabs团队开发的基于Redis的搜索引擎：RediSearch RediSearchGithub: RediSearch 官方站点 官方给出的描述 Redisearch implements a search engine on top of redis, but unlike other redis search libraries, it does not use internal data structures like sorted sets.Inverted indexes are stored as a special compressed data type that allows for fast indexing and search speed, and low memory footprint.This also enables more advanced features, like exact phrase matching and numeric filtering for text queries, that are not possible or efficient with traditional redis search approaches. 主要特点高性能的全文搜索引擎（Faster, in-memory, highly available full text search），可作为Redis Module运行在Redis上。但是它与其他Redis搜索库不同的是，它不使用Redis内部数据结构，例如：集合、排序集（ps.后面会写一篇基于Redis的数据结构来设计搜索引擎），Redis原声的搜索还是有很大的局限性，简单的分词搜索是可以满足，但是应用到复杂的场景就不太适合。 Full-Text indexing of multiple fields in documents. Incremental indexing without performance loss. Document ranking (provided manually by the user at index time). Field weights. Complex boolean queries with AND, OR, NOT operators between sub-queries. Prefix matching in full-text queries. Auto-complete suggestions (with fuzzy prefix suggestions) Exact Phrase Search. Stemming based query expansion in many languages (using Snowball). Support for logographic (Chinese, etc.) tokenization and querying (using Friso) Limiting searches to specific document fields (up to 128 fields supported). Numeric filters and ranges. Geographical search utilizing redis’ own GEO commands. Supports any utf-8 encoded text. Retrieve full document content or just ids. Automatically index existing HASH keys as documents. Document Deletion (Update can be done by deletion and then re-insertion). Sortable properties (i.e. sorting users by age or name). 下面是中文版本 多个字段的文档的全文索引。 没有性能损失增量索引。 文档排名(由用户提供手动指数时间)。 字段权重。 在子查询之间使用AND，OR，NOT运算符进行复杂的布尔查询。 前缀匹配全文查询。 自动完成建议以模糊前缀(建议) 准确短语搜索。 阻止基于查询扩展多种语言(使用Snowball)。 支持语标的(中国等)标记和查询(使用Friso) 将搜索限制在特定的文档字段(128字段支持)。 数字过滤器和范围。 利用redis自己的GEO命令进行地理搜索。 支持任何utf-8编码的文本。 获取完整的文档内容或者只是id。 自动索引现有HASH keys文件。 文档删除(更新可以通过删除然后re-insertion)。 可排序属性（即按年龄或名称对用户进行排序）。 集群当然还支持分布式集群，只不过集群还是试验阶段还不建议正式应用到企业级应用上。 暂不支持 Spelling correction（拼写更正） Aggregations（集合） 支持的Client类库Official (Redis Labs) and community Clients: Language Library Author License Comments Python redisearch-py Redis Labs BSD Usually the most up-to-date client library Java JRediSearch Redis Labs BSD - Go redisearch-go Redis Labs BSD Incomplete API JavaScript RedRediSearch Kyle J. Davis MIT Partial API, compatible with Reds C# NRediSearch Marc Gravell MIT Part of StackExchange.Redis PHP redisearch-php Ethan Hann MIT - Ruby on Rails redi_search_rails Dmitry Polyakovsky MIT - Ruby redisearch-rb Victor Ruiz MIT - 类库支持的还算丰富，可以尝试使用一下。 性能性能对比是以ElasticSearch、Solr来进行对比，官方的benchmark数据，benchmark程序地址 总结：从数据上看，使用RediSearch的吞吐量高、延迟低，但是相比于ElasticSearch和Solr支持的特性上还有些欠缺比如：中文的模糊搜索支持的不是很好，但是其性能很高在某些场景是可以作为搜索引擎的替代方案来试用。 案例资料： 利用RediSearch构建高效实时搜索案例 一步步实现 Redis 搜索引擎 我们做了一个支持全文搜索和关系查询的 Redis 上述就是关于RediSearch的资料整理，后面会尝试使用它来构建搜索引擎，会记录使用过程经历。","tags":[{"name":"redisearch","slug":"redisearch","permalink":"https://ningyu1.github.io/tags/redisearch/"},{"name":"redis","slug":"redis","permalink":"https://ningyu1.github.io/tags/redis/"},{"name":"in-memory","slug":"in-memory","permalink":"https://ningyu1.github.io/tags/in-memory/"},{"name":"highly available full text search","slug":"highly-available-full-text-search","permalink":"https://ningyu1.github.io/tags/highly-available-full-text-search/"}]},{"title":"Trouble Shooting —— CAS Server集群环境下报错：Server redirected too many  times (20)","date":"2018-03-23T08:01:00.000Z","path":"20180323/73-cas-server-pit1.html","text":"当我们使用cas做单点登录的时候往往会使用集群方式部署，不管是cas server或者是接入的app server都会采用集群的方式部署。 在对cas server做集群实现无状态化，需要注意一下几点，也是我上一篇cas遇到的TGC验证问题中总结出来的： cas的ticket需要做到集中存储，可以使用redis、jpa、或者其他方式，这个官方文章上有详细介绍：ticket-registry cas的session信息需要做到集中存储，如果使用的是tomcat可以使用TomcatRedisSessionMananger插件来通过redis做session集中存储。 还有一个就是上面遇到的问题，客户端cookie信息：TGC，TGC采用cookie方式存在客户端，因此需要开启会话保持，使得相同客户端每次都会被路由到同一个cas server上去做TGC验证。 最后一个就是需要接入sso的client应用端的session信息也需要做集中存储，因此cas server会和client进行通信去验证ticket，验证完后会生成信息并存储到sesson中，因此也需要使用TomcatRedisSessionMananger插件来通过redis做session集中存储。 cas server端和接入的app服务端需要保证网络通畅。 cas使用总结博文目录最近cas遇到的问题我都总结到了blog中，这里整理一下目录如下： 《CAS使用经验总结，纯干货》 《CAS Server强制踢人功能实现方式》 《Trouble Shooting —— CAS Server集群环境下TGC验证问题排查，需要开启会话保持》 接下来我们就说一下这次遇到的问题。 问题现象通过上面的方式可以将cas server做到集群无状态化，但是避免不了其他的问题，下面就是最近与到的问题，现象是这样的，一部分人可以正常登陆，一部分人登陆时报错，错误如下： 2018-03-23 10:33:22.768 [http-nio-7051-exec-1] ERROR org.jasig.cas.client.util.CommonUtils - Server redirected too many times (20)java.net.ProtocolException: Server redirected too many times (20) at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1637) ~[na:1.7.0_79] at sun.net.www.protocol.https.HttpsURLConnectionImpl.getInputStream(HttpsURLConnectionImpl.java:254) ~[na:1.7.0_79] at org.jasig.cas.client.util.CommonUtils.getResponseFromServer(CommonUtils.java:393) ~[cas-client-core-3.3.3.jar:3.3.3] at org.jasig.cas.client.validation.AbstractCasProtocolUrlBasedTicketValidator.retrieveResponseFromServer(AbstractCasProtocolUrlBasedTicketValidator.java:45) [cas-client-core-3.3.3.jar:3.3.3] at org.jasig.cas.client.validation.AbstractUrlBasedTicketValidator.validate(AbstractUrlBasedTicketValidator.java:200) [cas-client-core-3.3.3.jar:3.3.3] at org.springframework.security.cas.authentication.CasAuthenticationProvider.authenticateNow(CasAuthenticationProvider.java:140) [spring-security-cas-3.1.7.RELEASE.jar:3.1.7.RELEASE] at org.springframework.security.cas.authentication.CasAuthenticationProvider.authenticate(CasAuthenticationProvider.java:126) [spring-security-cas-3.1.7.RELEASE.jar:3.1.7.RELEASE] at org.springframework.security.authentication.ProviderManager.authenticate(ProviderManager.java:156) [spring-security-core-3.1.7.RELEASE.jar:3.1.7.RELEASE] at org.springframework.security.cas.web.CasAuthenticationFilter.attemptAuthentication(CasAuthenticationFilter.java:242) [spring-security-cas-3.1.7.RELEASE.jar:3.1.7.RELEASE] at org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:195) [spring-security-web-3.1.7.RELEASE.jar:3.1.7.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:342) [spring-security-web-3.1.7.RELEASE.jar:3.1.7.RELEASE] at org.jasig.cas.client.session.SingleSignOutFilter.doFilter(SingleSignOutFilter.java:100) [cas-client-core-3.3.3.jar:3.3.3] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:342) [spring-security-web-3.1.7.RELEASE.jar:3.1.7.RELEASE] at com.bstek.bdf2.core.security.filter.PreAuthenticatedProcessingFilter.doFilter(PreAuthenticatedProcessingFilter.java:41) [scm-bdf2-core-1.1.0-SNAPSHOT.jar:na] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:342) [spring-security-web-3.1.7.RELEASE.jar:3.1.7.RELEASE] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:105) [spring-security-web-3.1.7.RELEASE.jar:3.1.7.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:342) [spring-security-web-3.1.7.RELEASE.jar:3.1.7.RELEASE] at org.springframework.security.web.session.ConcurrentSessionFilter.doFilter(ConcurrentSessionFilter.java:125) [spring-security-web-3.1.7.RELEASE.jar:3.1.7.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:342) [spring-security-web-3.1.7.RELEASE.jar:3.1.7.RELEASE] at com.bstek.bdf2.core.security.filter.ContextFilter.doFilter(ContextFilter.java:36) [scm-bdf2-core-1.1.0-SNAPSHOT.jar:na] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:342) [spring-security-web-3.1.7.RELEASE.jar:3.1.7.RELEASE] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:87) [spring-security-web-3.1.7.RELEASE.jar:3.1.7.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:342) [spring-security-web-3.1.7.RELEASE.jar:3.1.7.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:192) [spring-security-web-3.1.7.RELEASE.jar:3.1.7.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160) [spring-security-web-3.1.7.RELEASE.jar:3.1.7.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:344) [spring-web-4.0.0.RELEASE.jar:4.0.0.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:261) [spring-web-4.0.0.RELEASE.jar:4.0.0.RELEASE] 从异常的描述来看是服务器端多次redirected超过了20次导致的问题，什么原因会造成这个问题？ cas单点登录过程剖析cas的单点登录的过程大致是这样的。 第一步：访问app地址，例如：https://app.domain.com，app端的cas-client-core会判断是否已经登录，如果没有登录会重定向到如下地址：https://login.domain.com/login?service=https%3A%2F%2Fapp.domain.com%2Fcas_security_check_ 第二步：当重定向到cas登录页面后，我们输入用户名密码，cas server端会进行如下操作 先进行AUTHENTICATION过程，这个过程是验证我们的用户名密码是否正确，会输出如下日志： 2018-03-23 14:58:01,429 INFO [org.apereo.inspektr.audit.support.Slf4jLoggingAuditTrailManager] - &lt;Audit trail record BEGIN=============================================================WHO: adminWHAT: Supplied credentials: [admin]ACTION: AUTHENTICATION_SUCCESSAPPLICATION: CASWHEN: Fri Mar 23 14:58:01 HKT 2018CLIENT IP ADDRESS: xx.xx.xx.xxSERVER IP ADDRESS: xx.xx.xx.xx============================================================= 当AUTHENTICATION通过以后会生成TGT（TICKET_GRANTING_TICKET），这个是换取服务票据的预授票据，并且将TGT保存起来，我这里使用的是jpa方式保存到db，会输出如下日志： =============================================================WHO: adminWHAT: TGT-***********************************************1VX72iaQBZ-077adac8d80fACTION: TICKET_GRANTING_TICKET_CREATEDAPPLICATION: CASWHEN: Fri Mar 23 14:58:01 HKT 2018CLIENT IP ADDRESS: 10.42.37.135SERVER IP ADDRESS: 10.42.185.88=============================================================&gt;Hibernate: insert into TICKETGRANTINGTICKET (NUMBER_OF_TIMES_USED, CREATION_TIME, EXPIRATION_POLICY, LAST_TIME_USED, PREVIOUS_LAST_TIME_USED, AUTHENTICATION, EXPIRED, PROXIED_BY, SERVICES_GRANTED_ACCESS_TO, ticketGrantingTicket_ID, TYPE, ID) values (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, &apos;TGT&apos;, ?) 当TGT生成完后会生成ST（SERVICE_TICKET），这个是服务票据，是授权这个服务的票据，并且会将ST保存起来和更新TGT信息，我这里使用的是jpa方式保存到db，会输出如下日志： 2018-03-23 14:58:01,504 INFO [org.apereo.inspektr.audit.support.Slf4jLoggingAuditTrailManager] - &lt;Audit trail record BEGIN=============================================================WHO: adminWHAT: ST-153-RfpK0ACJHtPsSdnbYhVf-077adac8d80f for https://app.domain.com/cas_security_check_ACTION: SERVICE_TICKET_CREATEDAPPLICATION: CASWHEN: Fri Mar 23 14:58:01 HKT 2018CLIENT IP ADDRESS: xx.xx.xx.xxSERVER IP ADDRESS: xx.xx.xx.xx=============================================================&gt;Hibernate: insert into SERVICETICKET (NUMBER_OF_TIMES_USED, CREATION_TIME, EXPIRATION_POLICY, LAST_TIME_USED, PREVIOUS_LAST_TIME_USED, FROM_NEW_LOGIN, TICKET_ALREADY_GRANTED, SERVICE, ticketGrantingTicket_ID, TYPE, ID) values (?, ?, ?, ?, ?, ?, ?, ?, ?, &apos;ST&apos;, ?)Hibernate: update TICKETGRANTINGTICKET set NUMBER_OF_TIMES_USED=?, CREATION_TIME=?, EXPIRATION_POLICY=?, LAST_TIME_USED=?, PREVIOUS_LAST_TIME_USED=?, AUTHENTICATION=?, EXPIRED=?, PROXIED_BY=?, SERVICES_GRANTED_ACCESS_TO=?, ticketGrantingTicket_ID=? where ID=? 这个时候服务端生成的票据就完成了，会将ST信息生成TGC（TICKET_GRANTING_COOKIE）返回给app端。 第三步：app端接收到cas server端的返回，TGC会直接写入到浏览器cookie中，app端会再发起一次ST验证，这个过程是在app的后端发起请求的，url如下： https://login.domain.com/serviceValidate?ticket=ST-153-RfpK0ACJHtPsSdnbYhVf-077adac8d80f&amp;service=https%3A%2F%2Fapp.domain.com%2Fcas_security_check_ 第四步：cas server端收到service validate请求后会验证ST和TGC是否合法，并且验证TGC的时候cas server需要开启会话保持，让请求发送到生成TGC的机器上去，因为TGC中保存生成的服务端地址，具体问题我前面分析过查看：《Trouble Shooting —— CAS Server集群环境下TGC验证问题排查，需要开启会话保持》，cas server验证成功后会输出如下的日志： 2018-03-23 14:58:01,578 INFO [org.apereo.inspektr.audit.support.Slf4jLoggingAuditTrailManager] - &lt;Audit trail record BEGIN=============================================================WHO: adminWHAT: ST-153-RfpK0ACJHtPsSdnbYhVf-077adac8d80fACTION: SERVICE_TICKET_VALIDATEDAPPLICATION: CASWHEN: Fri Mar 23 14:58:01 HKT 2018CLIENT IP ADDRESS: xx.xx.xx.xxSERVER IP ADDRESS: xx.xx.xx.xx============================================================= ps.出现下面日志表示验证失败 2018-03-23 14:58:01,580 INFO [org.apereo.inspektr.audit.support.Slf4jLoggingAuditTrailManager] - &lt;Audit trail record BEGIN=============================================================WHO: audit:unknownWHAT: ST-154-YA6KibaqHpOMGXbluz7V-077adac8d80fACTION: SERVICE_TICKET_VALIDATE_FAILEDAPPLICATION: CASWHEN: Fri Mar 23 14:58:01 HKT 2018CLIENT IP ADDRESS: xx.xx.xx.xxSERVER IP ADDRESS: xx.xx.xx.xx============================================================= 第五步：app后端接收到cas server端service验证成功的返回后，会生成session并且与TG进行关系绑定，绑定信息会保存起来，这里需要注意的是如果是集群环境需要保存到redis或者其他统一存储的地方。，app后端接收验证成功后的输出日志如下： 2018-03-23 14:58:01.531 [http-apr-8080-exec-1] DEBUG o.j.c.c.validation.Cas20ServiceTicketValidator - Constructing validation url: https://login.domain.com/serviceValidate?ticket=ST-153-RfpK0ACJHtPsSdnbYhVf-077adac8d80f&amp;service=https%3A%2F%2Fapp.domain.com%2Fcas_security_check_2018-03-23 14:58:01.531 [http-apr-8080-exec-1] DEBUG o.j.c.c.validation.Cas20ServiceTicketValidator - Retrieving response from server.2018-03-23 14:58:01.602 [http-apr-8080-exec-1] DEBUG o.j.c.c.validation.Cas20ServiceTicketValidator - Server response: &lt;cas:serviceResponse xmlns:cas=&apos;http://www.yale.edu/tp/cas&apos;&gt; &lt;cas:authenticationSuccess&gt; &lt;cas:user&gt;admin&lt;/cas:user&gt; &lt;/cas:authenticationSuccess&gt;&lt;/cas:serviceResponse&gt; 输出以上信息就是验证成功。到这里cas server端的所有验证都完成了。 ps.出现下面日志表示app后端接收到的是验证失败返回信息 2018-03-23 14:58:02.295 [http-bio-7051-exec-6] DEBUG o.j.c.c.validation.Cas20ServiceTicketValidator - Constructing validation url: https://login.domain.com/serviceValidate?ticket=ST-154-YA6KibaqHpOMGXbluz7V-077adac8d80f&amp;service=https%3A%2F%2Fapp.domain.com%2Fcas_security_check_2018-03-23 14:58:02.295 [http-bio-7051-exec-6] DEBUG o.j.c.c.validation.Cas20ServiceTicketValidator - Retrieving response from server.2018-03-23 14:58:02.830 [http-bio-7051-exec-6] DEBUG o.j.c.c.validation.Cas20ServiceTicketValidator - Server response: &lt;cas:serviceResponse xmlns:cas=&apos;http://www.yale.edu/tp/cas&apos;&gt; &lt;cas:authenticationFailure code=&quot;INVALID_TICKET&quot;&gt;Ticket &amp;#39;ST-154-YA6KibaqHpOMGXbluz7V-077adac8d80f&amp;#39; not recognized&lt;/cas:authenticationFailure&gt;&lt;/cas:serviceResponse&gt; 第六步：app端登录成功进入主页面。 根据这个流程我们再来分析上面的异常是那个环节出现了问题。 问题分析首先上面的异常是app的后端出现的异常，app后端发起请求是在cas server生成完ticket之后才发起的，并且发起的是service validate验证请求，这个请求导致重定向超过20次。 而且还有一个重要的信息就是，一部分人可以正常登录，一部分人不能登录，我们部署的结构是2台cas server，2台app服务。 通过日志排查，2台app服务，其中一台没有出现过一场，另外一台爆出异常。这个时候问题已经有些明朗了，当负载均衡路由到出错的这台服务时，后台服务发起service validate验证时出现了问题，那接下来就让我们对比两台服务器上的配置。 我们采用的是阿里云的SLB映射到后台的nginx，app的后台服务要和cas server通信那首先网络需要是通的，理论上网络应该是没问题的，但是为了验证问题，我们就从网络这块开始排查。 因为我们使用的是阿里云而且app服务没有开通外网，app后天和cas服务通信走的是内网的SLB，接下来我们就ping一下登录地址看一下返回的slb地址是否相同。 两台机器上ping login.domain.com ，果然返回的ip不一致，其中报错的那台机器返回的是本机ip，奥这就是问题的根源，cat /etc/hosts果然域名映射的ip不一致，应该是运维配置失误导致的问题。 通过修改host配置之后再次验证错误解决。 问题总结最终定位的到的问题感觉很白痴的问题，是因为运维配置失误导致，但是值得回味的是，通过这个问题我们对cas的单点登录机制理解的更加深刻，这就是一种收获，往往通过繁琐的分析后定位到的问题都很easy，所以当我们分析问题、定位问题的时候一定要先理解其中的原理，再结合现象去一步一步分析，这是仔细和关注度是否全面的一种考验。好了问题就说到这里，希望能够帮助到需要的人。 世界和平、Keep Real！","tags":[{"name":"trouble shooting","slug":"trouble-shooting","permalink":"https://ningyu1.github.io/tags/trouble-shooting/"},{"name":"CAS","slug":"CAS","permalink":"https://ningyu1.github.io/tags/CAS/"},{"name":"iphash","slug":"iphash","permalink":"https://ningyu1.github.io/tags/iphash/"},{"name":"TomcatRedisSessionManager","slug":"TomcatRedisSessionManager","permalink":"https://ningyu1.github.io/tags/TomcatRedisSessionManager/"},{"name":"Server redirected too many  times (20)","slug":"Server-redirected-too-many-times-20","permalink":"https://ningyu1.github.io/tags/Server-redirected-too-many-times-20/"}]},{"title":"Subversion库如何全文检索代码？","date":"2018-03-23T02:44:53.000Z","path":"20180323/72-svn-query.html","text":"现在是Git流行的年代，在Git的套件里想要全文检索代码也有很多方案，Git也支持命令直接检索代码，但是当使用svn的用户代码检索应该如何处理呢？ 在回答前面问题之前我们还要搞清楚另外一个问题，我们为什么要检索代码？ 有的时候我们想从所有的代码库去寻找使用相同方法的代码，常规做法就是checkout下来所有的项目，然后通过IDE工具去关联检索使用到某个方法的代码，但是这样做比较耗费时间而且当项目过多IDE不一定能扛得住。还有的时候我们想从规范角度去check开发人员写的代码是否有违规的或者有问题的，就可以通过检索去寻找，当然规范的check有更好的工具，可以使用scm工具sonar去check代码它整合了很多check模版。 鉴于上面种种的原因对代码做检索还是很有必要的，接下来我们就说一下使用svn时如何全文检索代码。 我们可以先说一个思路，把代码灌入elasticsearch、lucene、solr，然后通过ui去搜索这是一条可行的路子。 这两天发现了一个工具svnquery很好用，它使用ASP.net开发，采用Lucene生成索引，提供GUI和WEB工具通过索引文件来检索代码。 svnquery官网 它提供三个程序，一个svnindex用于通过svn库生成索引目录 SvnIndex.exe %aciton% %index_path% %svn_path% -u 用户名 -p 密码 ps. action包括create、update，更新和修改 执行后会生成一个索引目录，可以通过svnfind工具可以选择索引目录来进行代码搜索，svnfind是一个GUI工具。 还可以通过SvnWebQuery来进行代码搜索，SvnWebQuery是一个.NET的web程序需要放入IIS服务器来使用 引用官网的两张图 唯一的缺点就是需要一个库一个库的生成索引，没有批量生成svn路径下所有有权限的库，如果有这个功能我个人觉得就完美了。 好了工具介绍到这里，如果有用svn的想对代码进行检索的可以使用这个工具。","tags":[{"name":"svn","slug":"svn","permalink":"https://ningyu1.github.io/tags/svn/"},{"name":"subversion","slug":"subversion","permalink":"https://ningyu1.github.io/tags/subversion/"},{"name":"svnquery","slug":"svnquery","permalink":"https://ningyu1.github.io/tags/svnquery/"}]},{"title":"Zookeeper常用命令与注意事项","date":"2018-03-21T07:26:53.000Z","path":"20180321/71-zookeeper-considerations.html","text":"Zookeeper在互联网行业和分布式环境下是最常用的集群协调工具，那我们今天就对Zookeeper的常用命令和使用注意事项进一步说明，在这之前我们先看一下Zookeeper是什么，它能做什么？ Zookeeper是什么？ZooKeeper是一个开源的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。 它的这些特性可以让我们在很多场景下使用它，可以用它做注册中心、分布式锁、选举、队列等。 Zookeeper的原理ZooKeeper是以Fast Paxos算法为基础的，Paxos 算法存在活锁的问题，即当有多个proposer交错提交时，有可能互相排斥导致没有一个proposer能提交成功，而Fast Paxos作了一些优化，通过选举产生一个leader (领导者)，只有leader才能提交proposer，具体算法可见Fast Paxos。因此，要想弄懂ZooKeeper首先得对Fast Paxos有所了解 ZooKeeper的基本运转流程： 选举Leader。 同步数据。 选举Leader过程中算法有很多，但要达到的选举标准是一致的。 Leader要具有最高的执行ID，类似root权限。 集群中大多数的机器得到响应并接受选出的Leader。 Zookeeper数据结构与普通的文件系统极其类似，如下： 其中每个节点称为一个znode. 每个znode由3部分组成: stat. 此为状态信息, 描述该znode的版本, 权限等信息. data. 与该znode关联的数据. children. 该znode下的子节点. Zookeeper节点类型 persistent： persistent节点不和特定的session绑定, 不会随着创建该节点的session的结束而消失, 而是一直存在, 除非该节点被显式删除. ephemeral： ephemeral节点是临时性的, 如果创建该节点的session结束了, 该节点就会被自动删除. ephemeral节点不能拥有子节点. 虽然ephemeral节点与创建它的session绑定, 但只要该该节点没有被删除, 其他session就可以读写该节点中关联的数据. 使用-e参数指定创建ephemeral节点. sequence： 严格的说, sequence并非节点类型中的一种. sequence节点既可以是ephemeral的, 也可以是persistent的. 创建sequence节点时, ZooKeeper server会在指定的节点名称后加上一个数字序列, 该数字序列是递增的. 因此可以多次创建相同的sequence节点, 而得到不同的节点. 使用-s参数指定创建sequence节点. Zookeeper常用命令启动服务[app@iZbp1dijzcfg8m0bcqfv9yZ zookeeper]$ ./bin/zkServer.sh startZooKeeper JMX enabled by defaultUsing config: /usr/local/servers/zookeeper/zookeeper/bin/../conf/zoo.cfgStarting zookeeper ... STARTED 查看当前zk节点状态[zk@iZbp1dijzcfg8m0bcqfv9yZ bin]$ ./zkServer.sh statusJMX enabled by defaultUsing config: /usr/local/servers/zookeeper/zookeeper/bin/../conf/zoo.cfgMode: standalone ps. standalone代表单机模式， [zk@iZ23np2fk60Z bin]$ ./zkServer.sh statusJMX enabled by defaultUsing config: /usr/local/zookeeper/bin/../conf/zoo.cfgMode: leader ps. 集群模式下会显示的状态，leader节点，集群中其他机器会从leader节点同步数据 [zk@iZ237ydkhyiZ bin]$ ./zkServer.sh statusJMX enabled by defaultUsing config: /usr/local/zookeeper/bin/../conf/zoo.cfgMode: follower ps. 集群模式下会显示的状态，follower节点在启动过程中会从leader节点同步所有数据 连接服务[app@iZbp1dijzcfg8m0bcqfv9yZ zookeeper]$ ./bin/zkCli.sh -server ip:port ps. 不写ip端口默认连接本机服务. 查看节点信息[zk: localhost:2181(CONNECTED) 0] ls /[seq, dubbo, disconf, otter, pinpoint-cluster, zookeeper] 查看指定node的子node[zk: localhost:2181(CONNECTED) 3] ls /zookeeper[quota] 创建一个普通节点[zk: localhost:2181(CONNECTED) 6] create /hello worldCreated /hello 获取hello节点的数据与状态[zk: localhost:2181(CONNECTED) 8] get /helloworldcZxid = 0x262ea76ctime = Wed Mar 21 14:39:12 CST 2018mZxid = 0x262ea76mtime = Wed Mar 21 14:39:12 CST 2018pZxid = 0x262ea76cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 5numChildren = 0 删除hello节点[zk: localhost:2181(CONNECTED) 9] delete /hello[zk: localhost:2181(CONNECTED) 10] get /helloNode does not exist: /hello ps. 使用delete命令可以删除指定znode. 当该znode拥有子znode时, 必须先删除其所有子znode, 否则操作将失败. rmr命令可用于代替delete命令, rmr是一个递归删除命令, 如果发生指定节点拥有子节点时, rmr命令会首先删除子节点. znode节点的状态信息使用get命令获取指定节点的数据时, 同时也将返回该节点的状态信息, 称为Stat. 其包含如下字段: czxid. 节点创建时的zxid. mzxid. 节点最新一次更新发生时的zxid. ctime. 节点创建时的时间戳. mtime. 节点最新一次更新发生时的时间戳. dataVersion. 节点数据的更新次数. cversion. 其子节点的更新次数. aclVersion. 节点ACL(授权信息)的更新次数. ephemeralOwner. 如果该节点为ephemeral节点, ephemeralOwner值表示与该节点绑定的session id. 如果该节点不是ephemeral节点, ephemeralOwner值为0. 至于什么是ephemeral节点, 请看后面的讲述. dataLength. 节点数据的字节数. numChildren. 子节点个数. zxidznode节点的状态信息中包含czxid和mzxid, 那么什么是zxid呢?ZooKeeper状态的每一次改变, 都对应着一个递增的Transaction id, 该id称为zxid. 由于zxid的递增性质, 如果zxid1小于zxid2, 那么zxid1肯定先于zxid2发生. 创建任意节点, 或者更新任意节点的数据, 或者删除任意节点, 都会导致Zookeeper状态发生改变, 从而导致zxid的值增加. session在client和server通信之前, 首先需要建立连接, 该连接称为session. 连接建立后, 如果发生连接超时, 授权失败, 或者显式关闭连接, 连接便处于CLOSED状态, 此时session结束. 创建不同类型的节点节点的类型前面已经讲过。 创建一个临时节点 [zk: localhost:2181(CONNECTED) 12] create -e /hello world Created /hello[zk: localhost:2181(CONNECTED) 13] get /helloworldcZxid = 0x262ea78ctime = Wed Mar 21 14:45:23 CST 2018mZxid = 0x262ea78mtime = Wed Mar 21 14:45:23 CST 2018pZxid = 0x262ea78cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x15c150a650f066cdataLength = 5numChildren = 0 创建一个序列节点 [zk: localhost:2181(CONNECTED) 14] create -s /hello1 worldCreated /hello10000000007[zk: localhost:2181(CONNECTED) 15] create -s /hello1 worldCreated /hello10000000008[zk: localhost:2181(CONNECTED) 16] ls /[hello, dubbo, otter, zookeeper, seq, disconf, hello10000000007, hello10000000008, pinpoint-cluster][zk: localhost:2181(CONNECTED) 17] get /hello10000000007worldcZxid = 0x262ea7ectime = Wed Mar 21 14:47:51 CST 2018mZxid = 0x262ea7emtime = Wed Mar 21 14:47:51 CST 2018pZxid = 0x262ea7ecversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 5numChildren = 0 watchwatch的意思是监听感兴趣的事件. 在命令行中, 以下几个命令可以指定是否监听相应的事件. ls命令ls命令. ls命令的第一个参数指定znode, 第二个参数如果为true, 则说明监听该znode的子节点的增减, 以及该znode本身的删除事件. [zk: localhost:2181(CONNECTED) 27] create /hello worldCreated /hello[zk: localhost:2181(CONNECTED) 28] ls /hello true[][zk: localhost:2181(CONNECTED) 29] create /hello/test item001WATCHER::WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/helloCreated /hello/test get命令get命令. get命令的第一个参数指定znode, 第二个参数如果为true, 则说明监听该znode的更新和删除事件. [zk: localhost:2181(CONNECTED) 30] get /hello trueworldcZxid = 0x262ef5dctime = Wed Mar 21 14:52:16 CST 2018mZxid = 0x262ef5dmtime = Wed Mar 21 14:52:16 CST 2018pZxid = 0x262ef5ecversion = 1dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 5numChildren = 1[zk: localhost:2181(CONNECTED) 31] create /hello/test1 item001Created /hello/test1[zk: localhost:2181(CONNECTED) 32] rmr /helloWATCHER::WatchedEvent state:SyncConnected type:NodeDeleted path:/hello stat命令stat命令. stat命令用于获取znode的状态信息. 第一个参数指定znode, 如果第二个参数为true. [zk: localhost:2181(CONNECTED) 35] create /hello worldWATCHER::WatchedEvent state:SyncConnected type:NodeCreated path:/helloCreated /hello[zk: localhost:2181(CONNECTED) 36] stat /hello truecZxid = 0x262f0f0ctime = Wed Mar 21 14:56:31 CST 2018mZxid = 0x262f0f0mtime = Wed Mar 21 14:56:31 CST 2018pZxid = 0x262f0f0cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 5numChildren = 0","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://ningyu1.github.io/tags/zookeeper/"}]},{"title":"Trouble Shooting —— CAS Server集群环境下TGC验证问题排查，需要开启会话保持","date":"2018-03-16T04:02:53.000Z","path":"20180316/70-cas-server-pit.html","text":"问题现象CAS部署结构： 两台cas server通过nginx做负载均衡，两个cas server的ticket registry配置的jpa方式，指向同一个库。两个cas server的tomcat做了TomcatRedisSessionManager，使用redis集中存储session。 目前的现象： 页面上请求cas登录地址，登录过后频繁刷新登录页面，有时返回已登录，有时返回未登录，当返回未登录时去后台查看日志发现有如下错误，验证cookie发现请求的源IP与第一次访问的源IP不一致。这个很明显是cas集群环境下的问题。 2018-03-16 10:02:44,418 DEBUG [org.apereo.cas.web.support.TGCCookieRetrievingCookieGenerator] - &lt;Invalid cookie. Required remote address does not match $&#123;ip&#125;&gt;java.lang.IllegalStateException: Invalid cookie. Required remote address does not match $&#123;ip&#125; at org.apereo.cas.web.support.DefaultCasCookieValueManager.obtainCookieValue(DefaultCasCookieValueManager.java:84) ~[cas-server-support-cookie-5.0.4.jar:5.0.4] at org.apereo.cas.web.support.CookieRetrievingCookieGenerator.retrieveCookieValue(CookieRetrievingCookieGenerator.java:93) ~[cas-server-support-cookie-5.0.4.jar:5.0.4] at org.apereo.cas.web.support.CookieRetrievingCookieGenerator$$FastClassBySpringCGLIB$$25dba342.invoke(&lt;generated&gt;) ~[cas-server-support-cookie-5.0.4.jar:5.0.4] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ~[spring-core-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:720) ~[spring-aop-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) ~[spring-aop-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.springframework.aop.support.DelegatingIntroductionInterceptor.doProceed(DelegatingIntroductionInterceptor.java:133) ~[spring-aop-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.springframework.aop.support.DelegatingIntroductionInterceptor.invoke(DelegatingIntroductionInterceptor.java:121) ~[spring-aop-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:655) ~[spring-aop-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.apereo.cas.web.support.CookieRetrievingCookieGenerator$$EnhancerBySpringCGLIB$$10d36968.retrieveCookieValue(&lt;generated&gt;) ~[cas-server-support-cookie-5.0.4.jar:5.0.4] at org.apereo.cas.logging.web.ThreadContextMDCServletFilter.doFilter(ThreadContextMDCServletFilter.java:83) ~[cas-server-core-logging-5.0.4.jar:5.0.4] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) ~[catalina.jar:7.0.85] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) ~[catalina.jar:7.0.85] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) ~[catalina.jar:7.0.85] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) ~[catalina.jar:7.0.85] at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:89) ~[spring-web-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) ~[catalina.jar:7.0.85] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) ~[catalina.jar:7.0.85] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77) ~[spring-web-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) ~[catalina.jar:7.0.85] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) ~[catalina.jar:7.0.85] at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:107) ~[spring-boot-actuator-1.4.2.RELEASE.jar:1.4.2.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) ~[catalina.jar:7.0.85] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) ~[catalina.jar:7.0.85] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) ~[catalina.jar:7.0.85] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) ~[catalina.jar:7.0.85] at org.springframework.boot.web.support.ErrorPageFilter.doFilter(ErrorPageFilter.java:117) ~[spring-boot-1.4.2.RELEASE.jar:1.4.2.RELEASE] at org.springframework.boot.web.support.ErrorPageFilter.access$000(ErrorPageFilter.java:61) ~[spring-boot-1.4.2.RELEASE.jar:1.4.2.RELEASE] at org.springframework.boot.web.support.ErrorPageFilter$1.doFilterInternal(ErrorPageFilter.java:92) ~[spring-boot-1.4.2.RELEASE.jar:1.4.2.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.springframework.boot.web.support.ErrorPageFilter.doFilter(ErrorPageFilter.java:110) ~[spring-boot-1.4.2.RELEASE.jar:1.4.2.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) ~[catalina.jar:7.0.85] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) ~[catalina.jar:7.0.85] at org.apache.logging.log4j.web.Log4jServletFilter.doFilter(Log4jServletFilter.java:71) ~[log4j-web-2.6.2.jar:2.6.2] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) ~[catalina.jar:7.0.85] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) ~[catalina.jar:7.0.85] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:219) ~[catalina.jar:7.0.85] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:110) ~[catalina.jar:7.0.85] at com.r.tomcat.session.management.RequestSessionHandlerValve.invoke(RequestSessionHandlerValve.java:30) ~[TomcatRedisSessionManager-1.0.jar:?] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:169) ~[catalina.jar:7.0.85] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103) ~[catalina.jar:7.0.85] at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:962) ~[catalina.jar:7.0.85] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116) ~[catalina.jar:7.0.85] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:445) ~[catalina.jar:7.0.85] at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1115) ~[tomcat-coyote.jar:7.0.85] at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:637) ~[tomcat-coyote.jar:7.0.85] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1775) ~[tomcat-coyote.jar:7.0.85] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1734) ~[tomcat-coyote.jar:7.0.85] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_162] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_162] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) ~[tomcat-coyote.jar:7.0.85] at java.lang.Thread.run(Thread.java:748) [?:1.8.0_162] 网上查询资料：google group，相同的问题，但是没有看到具体的解决方法。 看到的tomcat RemoteIpValue也只是tomcat请求ip限制的方法，跟我们要的不匹配 根据异常查看CAS代码，如下： public String obtainCookieValue(Cookie cookie, HttpServletRequest request) &#123; String cookieValue = (String)this.cipherExecutor.decode(cookie.getValue()); LOGGER.debug(&quot;Decoded cookie value is [&#123;&#125;]&quot;, cookieValue); if (StringUtils.isBlank(cookieValue)) &#123; LOGGER.debug(&quot;Retrieved decoded cookie value is blank. Failed to decode cookie [&#123;&#125;]&quot;, cookie.getName()); return null; &#125; String[] cookieParts = cookieValue.split(String.valueOf(&apos;@&apos;)); if (cookieParts.length != 3) &#123; throw new IllegalStateException(&quot;Invalid cookie. Required fields are missing&quot;); &#125; String value = cookieParts[0]; String remoteAddr = cookieParts[1]; String userAgent = cookieParts[2]; if ((StringUtils.isBlank(value)) || (StringUtils.isBlank(remoteAddr)) || (StringUtils.isBlank(userAgent))) &#123; throw new IllegalStateException(&quot;Invalid cookie. Required fields are empty&quot;); &#125; if (!remoteAddr.equals(request.getRemoteAddr())) &#123; throw new IllegalStateException(&quot;Invalid cookie. Required remote address does not match &quot; + request.getRemoteAddr()); &#125; String agent = WebUtils.getHttpServletRequestUserAgent(request); if (!userAgent.equals(agent)) &#123; throw new IllegalStateException(&quot;Invalid cookie. Required user-agent does not match &quot; + agent); &#125; return value; &#125; TGC中包含了user-agent信息，会根据request的user-agent去跟decode后的cookie中的user-agent对比，而且这个验证是在cas 4.1版本就已经加了这个验证信息了，如果我们修改源码去掉这个user-agent验证可能还会引发其他问题。 解决方案采用负载均衡的粘性配置，nginx中可以是ip_hash或者sticky。 如果使用的是阿里云的SLB需要开启会话保持的选项。 如果使用nginx需要在upstream中增加ip_hash保持会话。 这样就可以让相同的客户端ip将会话永远路由到相同的一台后端cas server上去。 现在不建议使用上面的方法解决，这个会丢失集群的特性，建议采用配置来关闭cas.tgc的加解密或者修改cas源代码解决问题，查看这篇文章《Trouble Shooting —— CAS Server集群环境下TGC验证问题》中的解决办法 经过验证解决了上述的问题。 所以这里需要说明一下，在对cas server做集群实现无状态化，需要注意一下几点： cas的ticket需要做到集中存储，可以使用redis、jpa、或者其他方式，这个官方文章上有详细介绍：ticket-registry cas的session信息需要做到集中存储，如果使用的是tomcat可以使用TomcatRedisSessionMananger插件来通过redis做session集中存储。 需解决集群环境和springwebflow框架下CAS登录流程数据加密秘钥统一（或去除登录流程数据加密）-&gt; cas.webflow.encryption.key，cas.webflow.signing.key 需解决集群环境和springwebflow框架下CAS登录票据加密秘钥统一（或去除票据数据加密）-&gt; cas.tgc.cipherEnabled，cas.tgc.signingKey，cas.tgc.encryptionKey 最后一个就是需要接入sso的client应用端的session信息也需要做集中存储，因此cas server会和client进行通信去验证ticket，验证完后会生成信息并存储到sesson中，因此也需要使用TomcatRedisSessionMananger插件来通过redis做session集中存储。 世界和平、Keep Real！","tags":[{"name":"trouble shooting","slug":"trouble-shooting","permalink":"https://ningyu1.github.io/tags/trouble-shooting/"},{"name":"CAS","slug":"CAS","permalink":"https://ningyu1.github.io/tags/CAS/"},{"name":"iphash","slug":"iphash","permalink":"https://ningyu1.github.io/tags/iphash/"},{"name":"TomcatRedisSessionManager","slug":"TomcatRedisSessionManager","permalink":"https://ningyu1.github.io/tags/TomcatRedisSessionManager/"},{"name":"Invalid cookie. Required remote address does not match ip","slug":"Invalid-cookie-Required-remote-address-does-not-match-ip","permalink":"https://ningyu1.github.io/tags/Invalid-cookie-Required-remote-address-does-not-match-ip/"}]},{"title":"Json序列化、反序列化支持泛型，Dubbo对泛型参数方法进行反射调用","date":"2018-03-13T07:31:53.000Z","path":"20180313/69-java-reflect.html","text":"最近在对Dubbo接口进行反射调用时，遇到了参数类型较为复杂的情况下，使用反射方式无法调用的问题。 由于Dubbo使用了proxy代理对象，因此在反射上调用是存在一定的问题，从反射对象上获取的方法和参数类型可能会导致无法正常的调用。 首先先让我们看一个复杂参数的接口定义 public String testMethod(Map&lt;String,ResourceVo&gt; map, List&lt;Map&lt;String,ResourceVo&gt;&gt; list) throws BizException; Gson反序列化复杂类型在对参数进行反序列化时，内部的类型容易丢失，我们可以使用gson的Type进行反序列化得到正确的参数值，让我们看一下gson反序列化的两个方法 /** * This method deserializes the specified Json into an object of the specified class. It is not * suitable to use if the specified class is a generic type since it will not have the generic * type information because of the Type Erasure feature of Java. Therefore, this method should not * be used if the desired type is a generic type. Note that this method works fine if the any of * the fields of the specified object are generics, just the object itself should not be a * generic type. For the cases when the object is of generic type, invoke * &#123;@link #fromJson(String, Type)&#125;. If you have the Json in a &#123;@link Reader&#125; instead of * a String, use &#123;@link #fromJson(Reader, Class)&#125; instead. * * @param &lt;T&gt; the type of the desired object * @param json the string from which the object is to be deserialized * @param classOfT the class of T * @return an object of type T from the string. Returns &#123;@code null&#125; if &#123;@code json&#125; is &#123;@code null&#125;. * @throws JsonSyntaxException if json is not a valid representation for an object of type * classOfT */ public &lt;T&gt; T fromJson(String json, Class&lt;T&gt; classOfT) throws JsonSyntaxException &#123; Object object = fromJson(json, (Type) classOfT); return Primitives.wrap(classOfT).cast(object); &#125;/** * This method deserializes the specified Json into an object of the specified type. This method * is useful if the specified object is a generic type. For non-generic objects, use * &#123;@link #fromJson(String, Class)&#125; instead. If you have the Json in a &#123;@link Reader&#125; instead of * a String, use &#123;@link #fromJson(Reader, Type)&#125; instead. * * @param &lt;T&gt; the type of the desired object * @param json the string from which the object is to be deserialized * @param typeOfT The specific genericized type of src. You can obtain this type by using the * &#123;@link com.google.gson.reflect.TypeToken&#125; class. For example, to get the type for * &#123;@code Collection&lt;Foo&gt;&#125;, you should use: * &lt;pre&gt; * Type typeOfT = new TypeToken&amp;lt;Collection&amp;lt;Foo&amp;gt;&amp;gt;()&#123;&#125;.getType(); * &lt;/pre&gt; * @return an object of type T from the string. Returns &#123;@code null&#125; if &#123;@code json&#125; is &#123;@code null&#125;. * @throws JsonParseException if json is not a valid representation for an object of type typeOfT * @throws JsonSyntaxException if json is not a valid representation for an object of type */ @SuppressWarnings(&quot;unchecked&quot;) public &lt;T&gt; T fromJson(String json, Type typeOfT) throws JsonSyntaxException &#123; if (json == null) &#123; return null; &#125; StringReader reader = new StringReader(json); T target = (T) fromJson(reader, typeOfT); return target; &#125; 让我们测试一下复杂接口参数在使用这两个方法反序列化会有什么不同 String json = &quot;&#123;\\&quot;name\\&quot;:\\&quot;name\\&quot;,\\&quot;value\\&quot;:&#123;\\&quot;service\\&quot;:\\&quot;test1\\&quot;,\\&quot;url\\&quot;:\\&quot;test\\&quot;,\\&quot;action\\&quot;:\\&quot;GET\\&quot;,\\&quot;enabled\\&quot;:true,\\&quot;isPublic\\&quot;:false,\\&quot;appId\\&quot;:8,\\&quot;menuId\\&quot;:30001&#125;&#125;&quot;;Class clazz = Map.class;Map map = gson.fromJson(json, clazz); 上面代码反序列化后的map对象实际是com.google.gson.internal.LinkedTreeMap&lt;K, V&gt;，这个是gson中自定义的Map实现类，而且内部的对象也都是LinkedTreeMap，当我们换成HashMap时，返回的结果都是HashMap，但是我们的方法上使用的是Map&lt;String,ResourceVo&gt;，如何才能反序列化得到这个类型的对象呢？让我们看一下使用Type后的情况。 String json = &quot;&#123;\\&quot;name\\&quot;:\\&quot;name\\&quot;,\\&quot;value\\&quot;:&#123;\\&quot;service\\&quot;:\\&quot;test1\\&quot;,\\&quot;url\\&quot;:\\&quot;test\\&quot;,\\&quot;action\\&quot;:\\&quot;GET\\&quot;,\\&quot;enabled\\&quot;:true,\\&quot;isPublic\\&quot;:false,\\&quot;appId\\&quot;:8,\\&quot;menuId\\&quot;:30001&#125;&#125;&quot;;Type type = new TypeToken&lt;ResourceVo&gt;()&#123;&#125;.getType();Map&lt;ResourceVo&gt; map = gson.fromJson(json, type); 通过使用TypeToken生成的Type对象可以得到Map&lt;String,ResourceVo&gt;这个类型的实例，但是当我们在反射调用方法时，由于不知道参数是什么类型，也不能够import自定义的对象来使用TypeToken来获取type对象，那我们应该怎么做呢？接着往下看 ps.类型：List&#60;ResourceVo&gt;和List&#60;Map&#60;Object,ResourceVo&gt;&gt;这样的类型一样使用Type来进行反序列化 String json = &quot;&#123;\\&quot;name\\&quot;:\\&quot;name\\&quot;,\\&quot;value\\&quot;:&#123;\\&quot;service\\&quot;:\\&quot;test1\\&quot;,\\&quot;url\\&quot;:\\&quot;test\\&quot;,\\&quot;action\\&quot;:\\&quot;GET\\&quot;,\\&quot;enabled\\&quot;:true,\\&quot;isPublic\\&quot;:false,\\&quot;appId\\&quot;:8,\\&quot;menuId\\&quot;:30001&#125;&#125;&quot;;Class clazz = Class.forName(&quot;com.package.JavaBean&quot;);String methodName = &quot;testMethod&quot;;Method[] methods = clazz.getMethods();for (Method m : methods) &#123; if (m.getName().equals(methodName)) &#123; Type[] paramTypes = m.getGenericParameterTypes(); for (int j = 0; j &lt; paramTypes.length; j++) &#123; gson.fromJson(json, paramTypes[j]); &#125; &#125;&#125; 可以通过method.getGenericParameterTypes()获取参数的Type对象。 但是需要注意的是，当使用Proxy代理对象通过上面的方式获取的Type对象全都是java.lang.Class 那如何解决代理对象获取的Type不正确的问题呢？ 正确的做法就是放弃通过Proxy对象来进行反射，使用Class.forName获取Class对象进行反射。 可以通过Class.forName的方式获取Class对象，再获取Method对象，最后通过Method.getGenericParameterTypes()获取正确的Type对象，这个步骤是构造方法的参数类型和参数值。但是通过这个方式构造出来的参数类型和参数值，无法通过proxy对象来进行method.invoke，其原因就是原始接口的方法参数定义和代理对象的方法参数定义不同导致。这让我们如何是好。 继续往下看。 Dubbo泛化调用通过Dubbo的官网文档找到Dubbo支持GenericService泛化调用，什么是泛化调用？ 泛化接口调用方式主要用于客户端没有 API 接口及模型类元的情况，参数及返回值中的所有 POJO 均用 Map 表示，通常用于框架集成，比如：实现一个通用的服务测试框架，可通过 GenericService 调用所有服务实现。 ps. GenericService实际上是Dubbo提供的通用接口，解决使用通用接口调用任何服务方法 这样我们就可以使用前面说到的参数反序列化方式来获取方法的参数类型和参数值，传入GenericService通用接口来对目标方法进行调用。 首先先让我们看一下Dubbo的泛化调用如何使用。 import com.alibaba.dubbo.rpc.config.ApplicationConfig;import com.alibaba.dubbo.rpc.config.RegistryConfig;import com.alibaba.dubbo.rpc.config.ConsumerConfig;import com.alibaba.dubbo.rpc.config.ReferenceConfig;Class clazz = Class.forName(&quot;com.package.JavaBean&quot;);String method = &quot;testMethod&quot;// 当前应用配置ApplicationConfig application = new ApplicationConfig();application.setName(&quot;yyy&quot;);// 连接注册中心配置RegistryConfig registry = new RegistryConfig();registry.setAddress(&quot;10.20.130.230:9090&quot;);// 注意：ReferenceConfig为重对象，内部封装了与注册中心的连接，以及与服务提供方的连接// 引用远程服务ReferenceConfig reference = new ReferenceConfig(); // 此实例很重，封装了与注册中心的连接以及与提供者的连接，请自行缓存，否则可能造成内存和连接泄漏reference.setApplication(application);reference.setRegistry(registry); // 多个注册中心可以用setRegistries()reference.setInterface(clazz);reference.setVersion(&quot;1.0.0&quot;);reference.setRetries(0);reference.setCluster(&quot;failfast&quot;);reference.setTimeout(12001);reference.setGeneric(true);GenericService genericService = (GenericService) reference.get();Object result = genericService.$invoke(method, parameterTypes, parameterValues); 只要给reference设置generic为true就可以使用GenericService通用接口来进行方法调用。 这样我们就可以顺利的完成任何参数类型方法的反射调用。 从而避免了通过Proxy代理类获取到不正确的参数Type导致反序列化参数失败，这个原因前面也说了是因为原始接口的方法参数定义和代理对象的方法参数定义不同导致。 接下来让我们看一下具体的实现 @SuppressWarnings(&#123;&quot;unchecked&quot;, &quot;rawtypes&quot;, &quot;static-access&quot;&#125;)private Object callDubbo(SampleResult res) &#123; ApplicationConfig application = new ApplicationConfig(); application.setName(&quot;DubboSample&quot;); // 此实例很重，封装了与注册中心的连接以及与提供者的连接，请自行缓存，否则可能造成内存和连接泄漏 ReferenceConfig reference = new ReferenceConfig(); // 引用远程服务 reference.setApplication(application); RegistryConfig registry = null; String protocol = getProtocol(); if (&quot;zookeeper&quot;.equals(protocol)) &#123; // 连接注册中心配置 registry = new RegistryConfig(); registry.setProtocol(&quot;zookeeper&quot;); registry.setAddress(getAddress()); reference.setRegistry(registry); // 多个注册中心可以用setRegistries() &#125; else &#123; StringBuffer sb = new StringBuffer(); sb.append(protocol).append(&quot;://&quot;).append(getAddress()).append(&quot;/&quot;).append(getInterface()); log.info(&quot;rpc invoker url : &quot; + sb.toString()); reference.setUrl(sb.toString()); &#125; try &#123; Class clazz = Class.forName(getInterface()); reference.setInterface(clazz); reference.setRetries(Integer.valueOf(getRetries())); reference.setCluster(getCluster()); reference.setVersion(getVersion()); reference.setTimeout(Integer.valueOf(getTimeout())); reference.setGeneric(true); GenericService genericService = (GenericService) reference.get(); Method method = null; String[] parameterTypes = null; Object[] parameterValues = null; List&lt;MethodArgument&gt; args = getMethodArgs(); List&lt;String&gt; paramterTypeList = null; List&lt;Object&gt; parameterValuesList = null; Method[] methods = clazz.getMethods(); for (int i = 0; i &lt; methods.length; i++) &#123; Method m = methods[i]; Type[] paramTypes = m.getGenericParameterTypes(); paramterTypeList = new ArrayList&lt;String&gt;(); parameterValuesList = new ArrayList&lt;Object&gt;(); log.info(&quot;paramTypes.length=&quot;+paramTypes.length+&quot;|args.size()=&quot;+args.size()); if (m.getName().equals(getMethod()) &amp;&amp; paramTypes.length == args.size()) &#123; //名称与参数数量匹配，进行参数类型转换 for (int j = 0; j &lt; paramTypes.length; j++) &#123; paramterTypeList.add(args.get(j).getParamType()); ClassUtils.parseParameter(paramTypes[j], parameterValuesList, args.get(j)); &#125; if (parameterValuesList.size() == paramTypes.length) &#123; //没有转换错误，数量应该一致 method = m; break; &#125; &#125; &#125; if (method == null) &#123; res.setSuccessful(false); return &quot;Method[&quot;+getMethod()+&quot;] Not found!&quot;; &#125; //发起调用 parameterTypes = paramterTypeList.toArray(new String[paramterTypeList.size()]); parameterValues = parameterValuesList.toArray(new Object[parameterValuesList.size()]); Object result = null; try &#123; result = genericService.$invoke(getMethod(), parameterTypes, parameterValues); res.setSuccessful(true); &#125; catch (Throwable e) &#123; log.error(&quot;接口返回异常：&quot;, e); res.setSuccessful(false); result = e; &#125; return result; &#125; catch (Exception e) &#123; log.error(&quot;调用dubbo接口出错：&quot;, e); res.setSuccessful(false); return e; &#125; finally &#123; if (registry != null) &#123; registry.destroyAll(); &#125; reference.destroy(); &#125;&#125;## ClassUtils.parseParameter方法代码public static void parseParameter(Type type, List&lt;Object&gt; parameterValuesList, MethodArgument arg) throws ClassNotFoundException &#123; String className = getClassName(type); if (className.equals(&quot;int&quot;)) &#123; parameterValuesList.add(Integer.parseInt(arg.getParamValue())); &#125; else if (className.equals(&quot;double&quot;)) &#123; parameterValuesList.add(Double.parseDouble(arg.getParamValue())); &#125; else if (className.equals(&quot;short&quot;)) &#123; parameterValuesList.add(Short.parseShort(arg.getParamValue())); &#125; else if (className.equals(&quot;float&quot;)) &#123; parameterValuesList.add(Float.parseFloat(arg.getParamValue())); &#125; else if (className.equals(&quot;long&quot;)) &#123; parameterValuesList.add(Long.parseLong(arg.getParamValue())); &#125; else if (className.equals(&quot;byte&quot;)) &#123; parameterValuesList.add(Byte.parseByte(arg.getParamValue())); &#125; else if (className.equals(&quot;boolean&quot;)) &#123; parameterValuesList.add(Boolean.parseBoolean(arg.getParamValue())); &#125; else if (className.equals(&quot;char&quot;)) &#123; parameterValuesList.add(arg.getParamValue().charAt(0)); &#125; else if (className.equals(&quot;java.lang.String&quot;) || className.equals(&quot;String&quot;) || className.equals(&quot;string&quot;)) &#123; parameterValuesList.add(String.valueOf(arg.getParamValue())); &#125; else if (className.equals(&quot;java.lang.Integer&quot;) || className.equals(&quot;Integer&quot;) || className.equals(&quot;integer&quot;)) &#123; parameterValuesList.add(Integer.valueOf(arg.getParamValue())); &#125; else if (className.equals(&quot;java.lang.Double&quot;) || className.equals(&quot;Double&quot;)) &#123; parameterValuesList.add(Double.valueOf(arg.getParamValue())); &#125; else if (className.equals(&quot;java.lang.Short&quot;) || className.equals(&quot;Short&quot;)) &#123; parameterValuesList.add(Short.valueOf(arg.getParamValue())); &#125; else if (className.equals(&quot;java.lang.Long&quot;) || className.equals(&quot;Long&quot;)) &#123; parameterValuesList.add(Long.valueOf(arg.getParamValue())); &#125; else if (className.equals(&quot;java.lang.Float&quot;) || className.equals(&quot;Float&quot;)) &#123; parameterValuesList.add(Float.valueOf(arg.getParamValue())); &#125; else if (className.equals(&quot;java.lang.Byte&quot;) || className.equals(&quot;Byte&quot;)) &#123; parameterValuesList.add(Byte.valueOf(arg.getParamValue())); &#125; else if (className.equals(&quot;java.lang.Boolean&quot;) || className.equals(&quot;Boolean&quot;)) &#123; parameterValuesList.add(Boolean.valueOf(arg.getParamValue())); &#125; else &#123; parameterValuesList.add(JsonUtils.formJson(arg.getParamValue(), type)); &#125;&#125;## JsonUtils.formJson方法代码public static &lt;T&gt; T formJson(String json, Type type) &#123; try &#123; return gson.fromJson(json, type); &#125; catch (JsonSyntaxException e) &#123; logger.error(&quot;json to class[&quot; + type.getClass().getName() + &quot;] is error!&quot;, e); &#125; return null;&#125; 总结 复杂参数类型：Map&lt;Object, ResourceVo&gt;、List&lt;ResourceVo&gt;、List&lt;Map&lt;Object,ResourceVo&gt;&gt;使用gson.fromJson(json, classOfT)反序列化会丢失内部的类型。通过使用gson.fromJson(json, type)方式可以得到正确的类型。 通过Proxy对象的method.getGenericParameterTypes()获取的Type值全部为java.lang.Class，我们需要的是java.util.Map&lt;com.package.ResourceVo&gt;。 使用Class.forName得到Class，再获取Method，再通过method.getGenericParameterTypes()获取我们想要的参数Type是：java.util.Map&lt;com.package.ResourceVo&gt; 通过Class.forName得到Class，再获取Method，再通过method.getGenericParameterTypes()构造出来的参数类型和参数值，无法通过Proxy代理对象来进行method.invoke，其原因是：原始接口的方法参数定义和代理对象的方法参数定义不同导致。 放弃通过Proxy对象的method.invoke方式调用接口，通过Dubbo的通用服务接口（GenericService）来调用任何服务接口方法：GenericService.$invoke(method, parameterTypes, args) 参数对照参考表如下 Java类型 paramType paramValue int int 1 double double 1.2 short short 1 float float 1.2 long long 1 byte byte 字节 boolean boolean true或false char char A，如果字符过长取值为：”STR”.charAt(0) java.lang.String java.lang.String或String或string 字符串 java.lang.Integer java.lang.Integer或Integer或integer 1 java.lang.Double java.lang.Double或Double 1.2 java.lang.Short java.lang.Short或Short 1 java.lang.Long java.lang.Long或Long 1 java.lang.Float java.lang.Float或Float 1.2 java.lang.Byte java.lang.Byte或Byte 字节 java.lang.Boolean java.lang.Boolean或Boolean true或false JavaBean com.package.Bean {“service”:”test1”,”url”:”test”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001} java.util.Map以及子类 java.util.Map以及子类 {“service”:”test1”,”url”:”test”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001} java.util.Map&#60;String,JavaBean&gt; java.util.Map {“name”:{“service”:”test1”,”url”:”test”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001},”value”:{“service”:”test1”,”url”:”test”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001}} java.util.HashMap&#60;Object,Object&gt; java.util.HashMap {“name”:{“service”:”test1”,”url”:”test”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001},”value”:{“service”:”test1”,”url”:”test”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001}} java.util.Collection以及子类 java.util.Collection以及子类 [“a”,”b”] java.util.List&#60;String&gt; java.util.List [“a”,”b”] java.util.List&#60;JavaBean&gt; java.util.List [{“service”:”test1”,”url”:”test”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001},{“service”:”test1”,”url”:”test”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001}] java.util.List&#60;Map&#60;Object, JavaBean&gt;&gt; java.util.List [{“name”:{“service”:”test1”,”url”:”test”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001},”value”:{“service”:”test1”,”url”:”test”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001}},{“name”:{“service”:”test1”,”url”:”test”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001},”value”:{“service”:”test1”,”url”:”test”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001}}] java.util.List&#60;Long&gt; java.util.List [1,2,3] java.util.ArrayList&#60;Object&gt; java.util.ArrayList [“ny”,1,true]","tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://ningyu1.github.io/tags/dubbo/"},{"name":"gson","slug":"gson","permalink":"https://ningyu1.github.io/tags/gson/"},{"name":"json","slug":"json","permalink":"https://ningyu1.github.io/tags/json/"},{"name":"GenericService","slug":"GenericService","permalink":"https://ningyu1.github.io/tags/GenericService/"}]},{"title":"New Version V1.2.0, Dubbo Plugin for Apache JMeter","date":"2018-03-13T05:18:21.000Z","path":"20180313/68-jmeter-plugin-dubbo-1.2.0.html","text":"项目地址jmeter-plugin-dubbo项目已经transfer到dubbo group下 github: jmeter-plugin-dubbo 码云: jmeter-plugin-dubbo V1.2.0 使用gson进行json序列化、反序列化 使用dubbo泛化调用方式重构反射调用方式 支持复杂类型、支持泛型，例如：”java.lang.List,Map&lt;String,ResourceVo&gt; map,List&lt;Map&lt;String, ResourceVo&gt;&gt; list” 本次版本主要对反射参数类型进行了增强，支持复杂类型、支持参数泛型，可以参考如下的参数对照表： Java类型 paramType paramValue int int 1 double double 1.2 short short 1 float float 1.2 long long 1 byte byte 字节 boolean boolean true或false char char A，如果字符过长取值为：”STR”.charAt(0) java.lang.String java.lang.String或String或string 字符串 java.lang.Integer java.lang.Integer或Integer或integer 1 java.lang.Double java.lang.Double或Double 1.2 java.lang.Short java.lang.Short或Short 1 java.lang.Long java.lang.Long或Long 1 java.lang.Float java.lang.Float或Float 1.2 java.lang.Byte java.lang.Byte或Byte 字节 java.lang.Boolean java.lang.Boolean或Boolean true或false JavaBean com.package.Bean {“service”:”test1”,”url”:”test-${__RandomString(5,12345,ids)}”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001} java.util.Map以及子类 java.util.Map以及子类 {“service”:”test1”,”url”:”test-${__RandomString(5,12345,ids)}”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001} java.util.Map&#60;String,JavaBean&gt; java.util.Map {“name”:{“service”:”test1”,”url”:”test-${__RandomString(5,12345,ids)}”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001},”value”:{“service”:”test1”,”url”:”test”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001}} java.util.HashMap&#60;Object,Object&gt; java.util.HashMap {“name”:{“service”:”test1”,”url”:”test-${__RandomString(5,12345,ids)}”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001},”value”:{“service”:”test1”,”url”:”test”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001}} java.util.Collection以及子类 java.util.Collection以及子类 [“a”,”b”] java.util.List&#60;String&gt; java.util.List [“a”,”b”] java.util.List&#60;JavaBean&gt; java.util.List [{“service”:”test1”,”url”:”test-${RandomString(5,12345,ids)}”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001},{“service”:”test1”,”url”:”test-${RandomString(5,12345,ids)}”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001}] java.util.List&#60;Map&#60;Object, JavaBean&gt;&gt; java.util.List [{“name”:{“service”:”test1”,”url”:”test-${RandomString(5,12345,ids)}”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001},”value”:{“service”:”test1”,”url”:”test”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001}},{“name”:{“service”:”test1”,”url”:”test-${RandomString(5,12345,ids)}”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001},”value”:{“service”:”test1”,”url”:”test”,”action”:”GET”,”enabled”:true,”isPublic”:false,”appId”:8,”menuId”:30001}}] java.util.List&#60;Long&gt; java.util.List [1,2,3] java.util.ArrayList&#60;Object&gt; java.util.ArrayList [“ny”,1,true]","tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://ningyu1.github.io/tags/dubbo/"},{"name":"jmeter","slug":"jmeter","permalink":"https://ningyu1.github.io/tags/jmeter/"},{"name":"test","slug":"test","permalink":"https://ningyu1.github.io/tags/test/"},{"name":"Dubbo可视化测试工具","slug":"Dubbo可视化测试工具","permalink":"https://ningyu1.github.io/tags/Dubbo可视化测试工具/"},{"name":"Jmeter对Dubbo接口进行可视化压力测试","slug":"Jmeter对Dubbo接口进行可视化压力测试","permalink":"https://ningyu1.github.io/tags/Jmeter对Dubbo接口进行可视化压力测试/"},{"name":"Dubbo Jmeter插件","slug":"Dubbo-Jmeter插件","permalink":"https://ningyu1.github.io/tags/Dubbo-Jmeter插件/"}]},{"title":"Python项目生成requirements.txt的多种方式，用于类库迁移必备","date":"2018-03-09T06:19:54.000Z","path":"20180309/67-python-requirements.html","text":"我相信任何软件程序都会有依赖的类库，尤其现在开源如此的火爆，很多轮子可以拿来直接使用不再需要自己再去开发（拿来主义者），这样大大的提高开发效率。NPM就是轮子最多的地方，哈哈！开个玩笑！ 我们做开发时为何需要对依赖库进行管理？当依赖类库过多时，如何管理类库的版本？ 我相信大家都知道怎么回答这个问题，为了更加规范管理项目结构，提高开发效率所以我们需要对依赖库进行管理，不管使用任何开发语言，如今都有依赖库的管理工具。 例如：Java有Maven、Gradle，JS有NPM，Python有pip、easy_install，Linux有apt-get、yun 等。 我们这里就对Python的依赖库管理来进一步说一说。 Python提供通过requirements.txt文件来进行项目中依赖的三方库进行整体安装导入。 那首先让我们看一下requirements.txt的格式 requests==1.2.0Flask==0.10.1 Python安装依赖库使用pip可以很方便的安装，如果我们需要迁移一个项目，那我们就需要导出项目中依赖的所有三方类库的版本、名称等信息。 接下来就看Python项目如何根据requirements.txt文件来安装三方类库 方法一：pip freezepip freeze &gt; requirements.txt pip freeze命令输出的格式和requirements.txt文件内容格式完全一样，因此我们可以将pip freeze的内容输出到文件requirements.txt中。在其他机器上可以根据导出的requirements.txt进行包安装。 如果要安装requirements.txt中的类库内容，那么你可以执行 pip install -r requirements.txt 注意：pip freeze输出的是本地环境中所有三方包信息，但是会比pip list少几个包，因为pip，wheel，setuptools等包，是自带的而无法(un)install的，如果要显示所有包可以加上参数-all，即pip freeze -all 方法二：pipreqs使用pipreqs生成requirements.txt 首先先安装pipreqs pip install pipreqs 使用pipreqs生成requirements.txt pipreqs requirements.txt 注意：pipreqs生成指定目录下的依赖类库 上面两个方法的区别？使用pip freeze保存的是当前Python环境下所有的类库，如果你没有用virtualenv来对Python环境做虚拟化的话，类库就会很杂很多，在对项目进行迁移的时候我们只需关注项目中使用的类库，没有必要导出所有安装过的类库，因此我们一般迁移项目不会使用pipreqs，pip freeze更加适合迁移整个python环境下安装过的类库时使用。 不知道virtualenv是什么或者不会使用它的可以查看：《构建Python多个虚拟环境来进行不同版本开发之神器-virtualenv》 使用pipreqs它会根据当前目录下的项目的依赖来导出三方类库，因此常用与项目的迁移中。 这就是pip freeze、pipreqs的区别，前者是导出Python环境下所有安装的类库，后者导出项目中使用的类库。","tags":[{"name":"python","slug":"python","permalink":"https://ningyu1.github.io/tags/python/"},{"name":"pip","slug":"pip","permalink":"https://ningyu1.github.io/tags/pip/"},{"name":"freeze","slug":"freeze","permalink":"https://ningyu1.github.io/tags/freeze/"},{"name":"pipreqs","slug":"pipreqs","permalink":"https://ningyu1.github.io/tags/pipreqs/"}]},{"title":"Bug Fix Version V1.1.0, Dubbo Plugin for Apache JMeter","date":"2018-03-07T10:00:54.000Z","path":"20180307/66-jmeter-plugin-dubbo-bugfix.html","text":"首先先感谢网友 @流浪的云 提的bug，让我感觉到写这个工具没有白费还有点价值，非常感谢， 他在使用jmeter-plugin-dubbo插件时发现GUI中输入的信息无法使用Jmeter变量${var}与函数来进行参数化，以下是我修复这个问题的记录。 项目地址jmeter-plugin-dubbo项目已经transfer到dubbo group下 github: jmeter-plugin-dubbo 码云: jmeter-plugin-dubbo 问题描述 jmeter-plugin-dubbo插件GUI输入的信息无法使用${var}变量来进行参数化 问题修复Jmeter的输出要想使用用户自定义变量、CSV变量、BeanShell、函数来进行参数化，必须将输入的参数通过JMeterProperty的子类add到Jmeter管理。如果使用的是Swing的Bean绑定机制可以很好的支持变量与函数参数化，如果是手写的GUI与Sample就需要注意这一点，可能写出来的插件不能使用变量${var}参数化。 我之前在处理参数值在GUI和Sample之间传递时，没有使用org.apache.jmeter.testelement.property.JMeterProperty系列子类来处理参数，因此变量无法支持，让我们来看一下区别。 先让我们看一下org.apache.jmeter.testelement.property.JMeterProperty都有哪些子类。 我们之前使用的参数赋值是这样的： public String getVersion() &#123; return this.getPropertyAsString(FIELD_DUBBO_VERSION, DEFAULT_VERSION);&#125;public void setVersion(String version) &#123; this.setProperty(FIELD_DUBBO_VERSION, version);&#125; 这种方式是无法支持使用${var}变量来参数化赋值的（也就是动态赋值）。 我们应该给setProperty传入JMeterProperty的子类来支持变量参数化，如下： public String getVersion() &#123; return this.getPropertyAsString(FIELD_DUBBO_VERSION, DEFAULT_VERSION);&#125;public void setVersion(String version) &#123; this.setProperty(new StringProperty(FIELD_DUBBO_VERSION, version));&#125; ps.注意setProperty的使用不一样，这里使用的是new StringProperty 上面的参数还相对简单的普通字符串参数，当我们遇到集合或更加复杂的参数类型时如何处理？ 我本以为使用JMeterProperty的子类CollectionProperty是可以让集合参数支持变量参数化的，结果测试下来没有任何用，传入的${var}变量，在运行的时候还是变量没有变成相应的值。 于是又换成MapProperty和ObjectProperty一样无法支持变量参数化。 查看Jmeter Plugins的Http Sample源码，看他是如何处理的。 org.apache.jmeter.protocol.http.util.HTTPArgument源码package org.apache.jmeter.protocol.http.util;import java.io.Serializable;import java.io.UnsupportedEncodingException;import java.net.URLDecoder;import java.util.LinkedList;import java.util.List;import org.apache.jmeter.config.Argument;import org.apache.jmeter.config.Arguments;import org.apache.jmeter.testelement.property.BooleanProperty;import org.apache.jmeter.testelement.property.JMeterProperty;import org.apache.jorphan.logging.LoggingManager;import org.apache.log.Logger;public class HTTPArgument extends Argument implements Serializable&#123; private static final Logger log = ; private static final long serialVersionUID = 240L; private static final String ALWAYS_ENCODE = &quot;HTTPArgument.always_encode&quot;; private static final String USE_EQUALS = &quot;HTTPArgument.use_equals&quot;; private static final EncoderCache cache = new EncoderCache(1000); public HTTPArgument(String name, String value, String metadata) &#123; this(name, value, false); setMetaData(metadata); &#125; public void setUseEquals(boolean ue) &#123; if (ue) &#123; setMetaData(&quot;=&quot;); &#125; else &#123; setMetaData(&quot;&quot;); &#125; setProperty(new BooleanProperty(&quot;HTTPArgument.use_equals&quot;, ue)); &#125; public boolean isUseEquals() &#123; boolean eq = getPropertyAsBoolean(&quot;HTTPArgument.use_equals&quot;); if ((getMetaData().equals(&quot;=&quot;)) || ((getValue() != null) &amp;&amp; (getValue().length() &gt; 0))) &#123; setUseEquals(true); return true; &#125; return eq; &#125; public void setAlwaysEncoded(boolean ae) &#123; setProperty(new BooleanProperty(&quot;HTTPArgument.always_encode&quot;, ae)); &#125; public boolean isAlwaysEncoded() &#123; return getPropertyAsBoolean(&quot;HTTPArgument.always_encode&quot;); &#125; public HTTPArgument(String name, String value) &#123; this(name, value, false); &#125; public HTTPArgument(String name, String value, boolean alreadyEncoded) &#123; this(name, value, alreadyEncoded, &quot;UTF-8&quot;); &#125; public HTTPArgument(String name, String value, boolean alreadyEncoded, String contentEncoding) &#123; setAlwaysEncoded(true); if (alreadyEncoded) &#123; try &#123; if (log.isDebugEnabled()) &#123; log.debug(&quot;Decoding name, calling URLDecoder.decode with &apos;&quot; + name + &quot;&apos; and contentEncoding:&quot; + &quot;UTF-8&quot;); &#125; name = URLDecoder.decode(name, &quot;UTF-8&quot;); if (log.isDebugEnabled()) &#123; log.debug(&quot;Decoding value, calling URLDecoder.decode with &apos;&quot; + value + &quot;&apos; and contentEncoding:&quot; + contentEncoding); &#125; value = URLDecoder.decode(value, contentEncoding); &#125; catch (UnsupportedEncodingException e) &#123; log.error(contentEncoding + &quot; encoding not supported!&quot;); throw new Error(e.toString(), e); &#125; &#125; setName(name); setValue(value); setMetaData(&quot;=&quot;); &#125; public HTTPArgument(String name, String value, String metaData, boolean alreadyEncoded) &#123; this(name, value, metaData, alreadyEncoded, &quot;UTF-8&quot;); &#125; public HTTPArgument(String name, String value, String metaData, boolean alreadyEncoded, String contentEncoding) &#123; this(name, value, alreadyEncoded, contentEncoding); setMetaData(metaData); &#125; public HTTPArgument(Argument arg) &#123; this(arg.getName(), arg.getValue(), arg.getMetaData()); &#125; public HTTPArgument() &#123;&#125; public void setName(String newName) &#123; if ((newName == null) || (!newName.equals(getName()))) &#123; super.setName(newName); &#125; &#125; public String getEncodedValue() &#123; try &#123; return getEncodedValue(&quot;UTF-8&quot;); &#125; catch (UnsupportedEncodingException e) &#123; throw new Error(&quot;Should not happen: &quot; + e.toString()); &#125; &#125; public String getEncodedValue(String contentEncoding) throws UnsupportedEncodingException &#123; if (isAlwaysEncoded()) &#123; return cache.getEncoded(getValue(), contentEncoding); &#125; return getValue(); &#125; public String getEncodedName() &#123; if (isAlwaysEncoded()) &#123; return cache.getEncoded(getName()); &#125; return getName(); &#125; public static void convertArgumentsToHTTP(Arguments args) &#123; List&lt;Argument&gt; newArguments = new LinkedList(); for (JMeterProperty jMeterProperty : args.getArguments()) &#123; Argument arg = (Argument)jMeterProperty.getObjectValue(); if (!(arg instanceof HTTPArgument)) &#123; newArguments.add(new HTTPArgument(arg)); &#125; else &#123; newArguments.add(arg); &#125; &#125; args.removeAllArguments(); args.setArguments(newArguments); &#125;&#125; org.apache.jmeter.protocol.http.gui.HTTPArgumentsPanel源码package org.apache.jmeter.protocol.http.gui;import java.awt.event.ActionEvent;import java.awt.event.ActionListener;import java.util.Iterator;import javax.swing.JMenuItem;import javax.swing.JPopupMenu;import javax.swing.JTable;import org.apache.commons.lang3.BooleanUtils;import org.apache.commons.lang3.StringUtils;import org.apache.jmeter.config.Argument;import org.apache.jmeter.config.Arguments;import org.apache.jmeter.config.gui.ArgumentsPanel;import org.apache.jmeter.protocol.http.util.HTTPArgument;import org.apache.jmeter.testelement.TestElement;import org.apache.jmeter.testelement.property.JMeterProperty;import org.apache.jmeter.util.JMeterUtils;import org.apache.jorphan.gui.GuiUtils;import org.apache.jorphan.gui.ObjectTableModel;import org.apache.jorphan.reflect.Functor;public class HTTPArgumentsPanel extends ArgumentsPanel&#123; private static final long serialVersionUID = 240L; private static final String ENCODE_OR_NOT = &quot;encode?&quot;; private static final String INCLUDE_EQUALS = &quot;include_equals&quot;; protected void initializeTableModel() &#123; this.tableModel = new ObjectTableModel(new String[] &#123; &quot;name&quot;, &quot;value&quot;, &quot;encode?&quot;, &quot;include_equals&quot; &#125;, HTTPArgument.class, new Functor[] &#123; new Functor(&quot;getName&quot;), new Functor(&quot;getValue&quot;), new Functor(&quot;isAlwaysEncoded&quot;), new Functor(&quot;isUseEquals&quot;) &#125;, new Functor[] &#123; new Functor(&quot;setName&quot;), new Functor(&quot;setValue&quot;), new Functor(&quot;setAlwaysEncoded&quot;), new Functor(&quot;setUseEquals&quot;) &#125;, new Class[] &#123; String.class, String.class, Boolean.class, Boolean.class &#125;); &#125; public static boolean testFunctors() &#123; HTTPArgumentsPanel instance = new HTTPArgumentsPanel(); instance.initializeTableModel(); return instance.tableModel.checkFunctors(null, instance.getClass()); &#125; protected void sizeColumns(JTable table) &#123; GuiUtils.fixSize(table.getColumn(&quot;include_equals&quot;), table); GuiUtils.fixSize(table.getColumn(&quot;encode?&quot;), table); &#125; protected HTTPArgument makeNewArgument() &#123; HTTPArgument arg = new HTTPArgument(&quot;&quot;, &quot;&quot;); arg.setAlwaysEncoded(false); arg.setUseEquals(true); return arg; &#125; public HTTPArgumentsPanel() &#123; super(JMeterUtils.getResString(&quot;paramtable&quot;)); init(); &#125; public TestElement createTestElement() &#123; Arguments args = getUnclonedParameters(); super.configureTestElement(args); return (TestElement)args.clone(); &#125; public Arguments getParameters() &#123; Arguments args = getUnclonedParameters(); return (Arguments)args.clone(); &#125; private Arguments getUnclonedParameters() &#123; stopTableEditing(); Iterator&lt;HTTPArgument&gt; modelData = this.tableModel.iterator(); Arguments args = new Arguments(); while (modelData.hasNext()) &#123; HTTPArgument arg = (HTTPArgument)modelData.next(); args.addArgument(arg); &#125; return args; &#125; public void configure(TestElement el) &#123; super.configure(el); if ((el instanceof Arguments)) &#123; this.tableModel.clearData(); HTTPArgument.convertArgumentsToHTTP((Arguments)el); for (JMeterProperty jMeterProperty : ((Arguments)el).getArguments()) &#123; HTTPArgument arg = (HTTPArgument)jMeterProperty.getObjectValue(); this.tableModel.addRow(arg); &#125; &#125; checkButtonsStatus(); &#125; protected boolean isMetaDataNormal(HTTPArgument arg) &#123; return (arg.getMetaData() == null) || (arg.getMetaData().equals(&quot;=&quot;)) || ((arg.getValue() != null) &amp;&amp; (arg.getValue().length() &gt; 0)); &#125; protected Argument createArgumentFromClipboard(String[] clipboardCols) &#123; HTTPArgument argument = makeNewArgument(); argument.setName(clipboardCols[0]); if (clipboardCols.length &gt; 1) &#123; argument.setValue(clipboardCols[1]); if (clipboardCols.length &gt; 2) &#123; argument.setAlwaysEncoded(Boolean.parseBoolean(clipboardCols[2])); if (clipboardCols.length &gt; 3) &#123; Boolean useEqual = BooleanUtils.toBooleanObject(clipboardCols[3]); argument.setUseEquals(useEqual != null ? useEqual.booleanValue() : true); &#125; &#125; &#125; return argument; &#125; private void init() &#123; JTable table = getTable(); JPopupMenu popupMenu = new JPopupMenu(); JMenuItem variabilizeItem = new JMenuItem(JMeterUtils.getResString(&quot;transform_into_variable&quot;)); variabilizeItem.addActionListener(new ActionListener() &#123; public void actionPerformed(ActionEvent e) &#123; HTTPArgumentsPanel.this.transformNameIntoVariable(); &#125; &#125;); popupMenu.add(variabilizeItem); table.setComponentPopupMenu(popupMenu); &#125; private void transformNameIntoVariable() &#123; int[] rowsSelected = getTable().getSelectedRows(); for (int selectedRow : rowsSelected) &#123; String name = (String)this.tableModel.getValueAt(selectedRow, 0); if (StringUtils.isNotBlank(name)) &#123; name = name.trim(); name = name.replaceAll(&quot;\\\\$&quot;, &quot;_&quot;); name = name.replaceAll(&quot;\\\\&#123;&quot;, &quot;_&quot;); name = name.replaceAll(&quot;\\\\&#125;&quot;, &quot;_&quot;); this.tableModel.setValueAt(&quot;$&#123;&quot; + name + &quot;&#125;&quot;, selectedRow, 1); &#125; &#125; &#125;&#125; 能发现它使用的是继承Argument来处理和GUI之间的参数传递，使用继承ArgumentsPanel来处理GUI页面，这个就是我们上面说的，通过Swing的Bean绑定机制来进行开发，很遗憾我们没有使用这种方式，如果要改成这种方式，整个代码结构都要修改，成本太大。 但是我们发现像String，Integer等这种普通类型的参数通过使用JMeterProperty的子类可以很好的支持变量参数化，那我们能不能将集合参数拉平来直接使用普通类型的参数来处理，我承认这种方式有点恶心。 解决方式首先我们的集合参数有索引下标和总行数，每一行有两列，那就修改集合参数的赋值，代码如下： //标记集合参数前缀public static String FIELD_DUBBO_METHOD_ARGS = &quot;FIELD_DUBBO_METHOD_ARGS&quot;;//集合参数总数public static String FIELD_DUBBO_METHOD_ARGS_SIZE = &quot;FIELD_DUBBO_METHOD_ARGS_SIZE&quot;;public List&lt;MethodArgument&gt; getMethodArgs() &#123; int paramsSize = this.getPropertyAsInt(FIELD_DUBBO_METHOD_ARGS_SIZE, 0); List&lt;MethodArgument&gt; list = new ArrayList&lt;MethodArgument&gt;(); for (int i = 1; i &lt;= paramsSize; i++) &#123; String paramType = this.getPropertyAsString(FIELD_DUBBO_METHOD_ARGS + &quot;_PARAM_TYPE&quot; + i); String paramValue = this.getPropertyAsString(FIELD_DUBBO_METHOD_ARGS + &quot;_PARAM_VALUE&quot; + i); MethodArgument args = new MethodArgument(paramType, paramValue); list.add(args); &#125; return list;&#125;public void setMethodArgs(List&lt;MethodArgument&gt; methodArgs) &#123; int size = methodArgs == null ? 0 : methodArgs.size(); this.setProperty(new IntegerProperty(FIELD_DUBBO_METHOD_ARGS_SIZE, size)); if (size &gt; 0) &#123; for (int i = 1; i &lt;= methodArgs.size(); i++) &#123; this.setProperty(new StringProperty(FIELD_DUBBO_METHOD_ARGS + &quot;_PARAM_TYPE&quot; + i, methodArgs.get(i-1).getParamType())); this.setProperty(new StringProperty(FIELD_DUBBO_METHOD_ARGS + &quot;_PARAM_VALUE&quot; + i, methodArgs.get(i-1).getParamValue())); &#125; &#125;&#125; 上面的代码就是将集合参数拉平来进行传递，大致的结果如下： FIELD_DUBBO_METHOD_ARGS_SIZE = 2FIELD_DUBBO_METHOD_ARGS_SIZE_PARAM_TYPE_1 = xx$&#123;var1&#125;xx FIELD_DUBBO_METHOD_ARGS_SIZE__PARAM_VALUE_1 = xx$&#123;var2&#125;xx FIELD_DUBBO_METHOD_ARGS_SIZE_PARAM_TYPE_2 = xx$&#123;var3&#125;xx FIELD_DUBBO_METHOD_ARGS_SIZE__PARAM_VALUE_2 = xx$&#123;var4&#125;xx 让我们测试一下是否可用。 测试结果GUI上所有的输入框均可以支持Jmeter变量${var}参数化. 我觉得应该还是更加完美的解决办法只不过我没有找到，有空了再细致研究一下Jmeter的插件开发的细节看看能否找到突破口。 再次感谢网友 @流浪的云 提的bug，非常感谢！感谢使用插件的朋友多提rp和bug，让我们来一起完善起来，感谢这个开放的世界，最后还是一句老话：世界和平，Keep Real!","tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://ningyu1.github.io/tags/dubbo/"},{"name":"jmeter","slug":"jmeter","permalink":"https://ningyu1.github.io/tags/jmeter/"},{"name":"test","slug":"test","permalink":"https://ningyu1.github.io/tags/test/"},{"name":"Dubbo可视化测试工具","slug":"Dubbo可视化测试工具","permalink":"https://ningyu1.github.io/tags/Dubbo可视化测试工具/"},{"name":"Jmeter对Dubbo接口进行可视化压力测试","slug":"Jmeter对Dubbo接口进行可视化压力测试","permalink":"https://ningyu1.github.io/tags/Jmeter对Dubbo接口进行可视化压力测试/"},{"name":"Dubbo Jmeter插件","slug":"Dubbo-Jmeter插件","permalink":"https://ningyu1.github.io/tags/Dubbo-Jmeter插件/"}]},{"title":"Java中内部类使用注意事项，内部类对序列化与反序列化的影响","date":"2018-03-06T08:50:17.000Z","path":"20180306/65-java-inner-class.html","text":"现在很多服务架构都是微服务、分布式架构，开发模式也都是模块化开发，在分布式的开发方式下服务之间的调用不管是RPC还是RESTful或是其他SOA方案，均离不开序列化与反序列化，尤其是使用Java开发，Bean实现序列化接口几乎已经是必备的要求，而且这个要求已经纳入到很多大厂公司的开发规范中，开发规范中强制要求实现序列化接口和重写toString、hashCode方法。 前面提到了序列化与反序列化，那序列化与反序列化的对象就是开发人员写的java bean，不同的java bean会给序列化反序列化带来什么问题呢？接下来就让我们看一下内部类对序列化反序列化的影响。 在这之前我们先看一下常用的序列化工具： JavaSerialize fastjson dubbo json google gson google protoBuf hessian kryo Avro fast-serialization jboss-serialization jboss-marshalling-river protostuff msgpack-databind json/jackson/databind json/jackson/db-afterburner xml/xstream+c xml/jackson/databind-aalto 工具太多了这里就不列了，让我们先做一个测试。 测试常规java bean测试类： import java.io.Serializable;public class Test implements Serializable &#123; private static final long serialVersionUID = 2010307013874058143L; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 调用序列化与反序列化: public static String toJson(Object obj) &#123; try &#123; return JSON.json(obj); &#125; catch (IOException e) &#123; log.error(&quot;class to json is error!&quot;, e); &#125; return null;&#125;public static &lt;T&gt; T formJson(String json, Class&lt;T&gt; classOfT) &#123; try &#123; return JSON.parse(json, classOfT); &#125; catch (ParseException e) &#123; log.error(&quot;json to class is error! &quot;+classOfT.getName(), e); &#125; return null;&#125;public static void main(String[] args) &#123; Test test = new Test(); System.out.println(toJson(test)); String json = &quot;&#123;\\&quot;name\\&quot;:\\&quot;test\\&quot;&#125;&quot;; test = formJson(json, Test.class); System.out.println(test.getName());&#125; 输出： &#123;&quot;name&quot;:null&#125;test 我们能看到不管是序列化还是反序列化都没有任何问题，我们这里测试使用了常用的fastjson、dubbo json做了测试。 有内部类的java bean测试类： import java.io.Serializable;public class Test implements Serializable &#123; private static final long serialVersionUID = 2010307013874058143L; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public C1 c1; public C1 getC1() &#123; return c1; &#125; public void setC1(C1 c1) &#123; this.c1 = c1; &#125; public class C1 &#123; public String name; public C1() &#123; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; &#125;&#125; 调用序列化与反序列化: public static String toJson(Object obj) &#123; try &#123; return JSON.json(obj); &#125; catch (IOException e) &#123; log.error(&quot;class to json is error!&quot;, e); &#125; return null;&#125;public static &lt;T&gt; T formJson(String json, Class&lt;T&gt; classOfT) &#123; try &#123; return JSON.parse(json, classOfT); &#125; catch (ParseException e) &#123; log.error(&quot;json to class is error! &quot;+classOfT.getName(), e); &#125; return null;&#125;public static void main(String[] args) &#123; Test test = new Test(); System.out.println(toJson(test)); String json = &quot;&#123;\\&quot;name\\&quot;:\\&quot;test\\&quot;,\\&quot;c1\\&quot;:&#123;\\&quot;name\\&quot;:\\&quot;c1\\&quot;&#125;&#125;&quot;; test = formJson(json, Test.class); System.out.println(test.getC1().getName());&#125; 输出： &#123;&quot;c1&quot;:null,&quot;name&quot;:null,&quot;C1&quot;:null&#125;Exception in thread &quot;main&quot; java.lang.NullPointerExceptionERROR 2018-03-06 15:19:05.418 [xxx] (): json to class is error! Testcom.alibaba.dubbo.common.json.ParseException: java.lang.InstantiationException: Test$C1java.lang.InstantiationException: Test$C1 at java.lang.Class.newInstance(Class.java:359) at com.alibaba.dubbo.common.json.J2oVisitor.objectBegin(J2oVisitor.java:119) at com.alibaba.dubbo.common.json.JSON.parse(JSON.java:745) at com.alibaba.dubbo.common.json.JSON.parse(JSON.java:227) at com.alibaba.dubbo.common.json.JSON.parse(JSON.java:210) 可以成功序列化，但是反序列化报错了：无法创建实例Test$C1，这是什么问题？为什么会有这个错误？接下来我们分析一下 错误分析（java.lang.InstantiationException: Test$C1）通过使用fastjson和dubbo json的错误代码跟踪，找到了J2oVisitor.objectBegin(J2oVisitor.java:119)这个地方，代码如下： //下面是com.alibaba.dubbo.common.json.J2oVisitor的方法public void objectBegin() throws ParseException&#123; mStack.push(mValue); mStack.push(mType); mStack.push(mWrapper); if( mType == Object.class || Map.class.isAssignableFrom(mType) ) &#123; if (! mType.isInterface() &amp;&amp; mType != Object.class) &#123; try &#123; mValue = mType.newInstance(); &#125; catch (Exception e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; &#125; else if (mType == ConcurrentMap.class) &#123; mValue = new ConcurrentHashMap&lt;String, Object&gt;(); &#125; else &#123; mValue = new HashMap&lt;String, Object&gt;(); &#125; mWrapper = null; &#125; else &#123; try &#123; mValue = mType.newInstance(); mWrapper = Wrapper.getWrapper(mType); &#125; catch(IllegalAccessException e)&#123; throw new ParseException(StringUtils.toString(e)); &#125; catch(InstantiationException e)&#123; throw new ParseException(StringUtils.toString(e)); &#125; &#125;&#125;//下面是Class的方法public T newInstance() throws InstantiationException, IllegalAccessException&#123; if (System.getSecurityManager() != null) &#123; checkMemberAccess(Member.PUBLIC, Reflection.getCallerClass(), false); &#125; // NOTE: the following code may not be strictly correct under // the current Java memory model. // Constructor lookup if (cachedConstructor == null) &#123; if (this == Class.class) &#123; throw new IllegalAccessException( &quot;Can not call newInstance() on the Class for java.lang.Class&quot; ); &#125; try &#123; Class&lt;?&gt;[] empty = &#123;&#125;; final Constructor&lt;T&gt; c = getConstructor0(empty, Member.DECLARED); // Disable accessibility checks on the constructor // since we have to do the security check here anyway // (the stack depth is wrong for the Constructor&apos;s // security check to work) java.security.AccessController.doPrivileged( new java.security.PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; c.setAccessible(true); return null; &#125; &#125;); cachedConstructor = c; &#125; catch (NoSuchMethodException e) &#123; throw new InstantiationException(getName()); &#125; &#125; Constructor&lt;T&gt; tmpConstructor = cachedConstructor; // Security check (same as in java.lang.reflect.Constructor) int modifiers = tmpConstructor.getModifiers(); if (!Reflection.quickCheckMemberAccess(this, modifiers)) &#123; Class&lt;?&gt; caller = Reflection.getCallerClass(); if (newInstanceCallerCache != caller) &#123; Reflection.ensureMemberAccess(caller, this, null, modifiers); newInstanceCallerCache = caller; &#125; &#125; // Run constructor try &#123; return tmpConstructor.newInstance((Object[])null); &#125; catch (InvocationTargetException e) &#123; Unsafe.getUnsafe().throwException(e.getTargetException()); // Not reached return null; &#125;&#125; 代码中使用的是tmpConstructor.newInstance((Object[])null)不带参数的构造器，查看我们的原类，我们的内部类也是无参数的构造器，那为什么无法实例化呢？ 我们来看一下我们的java源代码中内部类生成的class字节码文件，通过反编译工具查看如下： public class Test$C1&#123; public String name; public Test$C1(Test paramTest) &#123;&#125; public String getName() &#123; return this.name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 我们是空构造器为什么生成的确是带参数的构造器而且参数paramTest的类型是Test，这是为什么呢？ 我们来看一下JDK doc关于Constructor.newInstance它的解释 Uses the constructor represented by this Constructor object to create and initialize a new instance of the constructor&apos;s declaring class, with the specified initialization parameters. Individual parameters are automatically unwrapped to match primitive formal parameters, and both primitive and reference parameters are subject to method invocation conversions as necessary. If the number of formal parameters required by the underlying constructor is 0, the supplied initargs array may be of length 0 or null. If the constructor&apos;s declaring class is an inner class in a non-static context, the first argument to the constructor needs to be the enclosing instance; see The Java Language Specification, section 15.9.3. If the required access and argument checks succeed and the instantiation will proceed, the constructor&apos;s declaring class is initialized if it has not already been initialized. If the constructor completes normally, returns the newly created and initialized instance. 具体关注这句：If the constructor’s declaring class is an inner class in a non-static context, the first argument to the constructor needs to be the enclosing instance; see The Java Language Specification, section 15.9.3 意思是说：如果构造函数的声明类是一个非静态（non-static）上下文中的内部类，则构造函数的第一个参数需要是封闭实例;参见Java语言规范，第15.9.3节。 15.9.3节具体看：15.9.3. Choosing the Constructor and its Arguments的说明 到这里我们应该清楚内部类在没有修饰符static和有修饰符static的区别了吧，就是non-static的内部类在生成的时候构造器第一个参数是parent实例，用来共享parent的属性访问的，那让我们将内部类修改为static再做一次测试验证。 验证测试类： import java.io.Serializable;public class Test implements Serializable &#123; private static final long serialVersionUID = 2010307013874058143L; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public C1 c1; public C1 getC1() &#123; return c1; &#125; public void setC1(C1 c1) &#123; this.c1 = c1; &#125; public static class C1 &#123; public String name; public C1() &#123; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; &#125;&#125; ps.内部类C1增加了static修饰符 调用序列化与反序列化: public static String toJson(Object obj) &#123; try &#123; return JSON.json(obj); &#125; catch (IOException e) &#123; log.error(&quot;class to json is error!&quot;, e); &#125; return null;&#125;public static &lt;T&gt; T formJson(String json, Class&lt;T&gt; classOfT) &#123; try &#123; return JSON.parse(json, classOfT); &#125; catch (ParseException e) &#123; log.error(&quot;json to class is error! &quot;+classOfT.getName(), e); &#125; return null;&#125;public static void main(String[] args) &#123; Test test = new Test(); System.out.println(toJson(test)); String json = &quot;&#123;\\&quot;name\\&quot;:\\&quot;test\\&quot;,\\&quot;c1\\&quot;:&#123;\\&quot;name\\&quot;:\\&quot;c1\\&quot;&#125;&#125;&quot;; test = formJson(json, Test.class); System.out.println(test.getC1().getName());&#125; 输出： &#123;&quot;c1&quot;:null,&quot;name&quot;:null,&quot;C1&quot;:null&#125;c1 结果可以正常的序列化了，以上测试使用的是fastjson与dubbo json进行测试。 总结按照规范内部类是不太推荐使用的，如果要用尽量使用static修饰符修饰内部类，这个问题其实就是Java的基本功，尽量一个Java文件中只保留一个类，这样在大多数序列化与反序列化工具中都不会出现问题，也比较符合当下模块化开发的规范，内部类改为static修饰符修饰还可以有效的避免内存泄漏，很多大厂的性能建议文档与Java开发规范文档都可以看到对内部类使用的注意事项，有空多看看大厂的经验总结。 使用Google的gson进行测试，non-static的内部类可以正常序列化，Google出的工具包就是强大兼容了各种使用方式，从gson的api还发现可以通过参数来disable或enable对inner class序列化的支持，具体查看如下代码： 测试类： import java.io.Serializable;public class Test implements Serializable &#123; private static final long serialVersionUID = 2010307013874058143L; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public C1 c1; public C1 getC1() &#123; return c1; &#125; public void setC1(C1 c1) &#123; this.c1 = c1; &#125; public class C1 &#123; public String name; public C1() &#123; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; &#125;&#125; ps.注意我这里的内部类C1是non-static的 gson开启内部类序列化public static void main(String[] args) &#123; Gson gson = new GsonBuilder().serializeNulls().create(); Test test = new Test(); test.setName(&quot;序列化参数name&quot;); System.out.println(gson.toJson(test)); String json = &quot;&#123;\\&quot;name\\&quot;:\\&quot;test\\&quot;,\\&quot;c1\\&quot;:&#123;\\&quot;name\\&quot;:\\&quot;c1\\&quot;&#125;&#125;&quot;; test = gson.fromJson(json, Test.class); System.out.println(test.getC1() == null ? &quot;null&quot; : test.getC1().getName());&#125; ps.默认InnerClassSerialization就是开启的 输出： &#123;&quot;name&quot;:&quot;序列化参数name&quot;,&quot;c1&quot;:null&#125;c1 gson禁用内部类序列化public static void main(String[] args) &#123; Gson gson = new GsonBuilder().serializeNulls().disableInnerClassSerialization().create(); Test test = new Test(); test.setName(&quot;序列化参数name&quot;); System.out.println(gson.toJson(test)); String json = &quot;&#123;\\&quot;name\\&quot;:\\&quot;test\\&quot;,\\&quot;c1\\&quot;:&#123;\\&quot;name\\&quot;:\\&quot;c1\\&quot;&#125;&#125;&quot;; test = gson.fromJson(json, Test.class); System.out.println(test.getC1() == null ? &quot;null&quot; : test.getC1().getName());&#125; ps.调用GsonBuilder.disableInnerClassSerialization()禁用InnerClassSerialization 输出： &#123;&quot;name&quot;:&quot;序列化参数name&quot;&#125;null 从而能看出Google出的工具包就是强大兼容各种使用方式，Google出的都是精品，从guava就可以看出。 好了到这里整个文章就介绍完了，最后还是一句老话：世界和平、Keep Real！","tags":[{"name":"inner class","slug":"inner-class","permalink":"https://ningyu1.github.io/tags/inner-class/"},{"name":"static","slug":"static","permalink":"https://ningyu1.github.io/tags/static/"},{"name":"non-static","slug":"non-static","permalink":"https://ningyu1.github.io/tags/non-static/"},{"name":"innerClassSerialization","slug":"innerClassSerialization","permalink":"https://ningyu1.github.io/tags/innerClassSerialization/"},{"name":"fastjson","slug":"fastjson","permalink":"https://ningyu1.github.io/tags/fastjson/"},{"name":"gson","slug":"gson","permalink":"https://ningyu1.github.io/tags/gson/"},{"name":"dubbo json","slug":"dubbo-json","permalink":"https://ningyu1.github.io/tags/dubbo-json/"}]},{"title":"Trouble Shooting —— Docker rancher/agent-instance cannot start automatically","date":"2018-03-05T09:23:11.000Z","path":"20180305/64-rancher-agent-instance.html","text":"今天发现一个docker机器莫名其妙的无工作了，于是进入宿主机查看信息如下： docker@xxx:~$ docker psbe4238200956 rancher/agent:v1.0.2 &quot;/run.sh run&quot; 5 months ago Up 34 minutes rancher-agent 发现只有一个rancher/agent容器是启动的，其余的都没有启动，查看rancher控制台，服务都在转圈圈Restaring状态，而且长时间一直这个状态没有变化。 这是什么问题呢？ 查看机器上所有的容器 docker@xxx:~$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESd9da7f16ef2d 192.168.0.34:5000/saas-erp:latest &quot;./entrypoint.sh&quot; 4 days ago Exited (0) 50 minutes ago r-erp_erp-dubbo_179e8e475db19 192.168.0.34:5000/tms2job:latest &quot;./entrypoint.sh&quot; 4 weeks ago Exited (0) 50 minutes ago r-tms_tms2-job_10995dabe324b 192.168.0.34:5000/customer-mq:latest &quot;catalina.sh run&quot; 8 weeks ago Exited (143) 7 weeks ago r-customer_customer-mq_165492930b132 192.168.0.34:5000/saas-account:latest &quot;./entrypoint.sh&quot; 9 weeks ago Exited (0) 50 minutes ago r-account_account-dubbo_1248514cd635a 192.168.0.34:5000/saas-erp-http-main:latest &quot;./entrypoint.sh&quot; 4 months ago Exited (0) 50 minutes ago r-erp_erp-http-main_194e51332cc40 192.168.0.34:5000/zookeeper:elevy &quot;/entrypoint.sh zkSer&quot; 5 months ago Exited (0) 50 minutes ago db61a2f2-9b47-4d97-97a3-b6e0764208cad72c359c2d5e 192.168.0.34:5000/mysql:5.6.30 &quot;docker-entrypoint.sh&quot; 5 months ago Exited (0) 50 minutes ago c7638fa0-f263-45bd-85d7-2e3b7407ad2f0c8d3edbc53d rancher/agent-instance:v0.8.3 &quot;/etc/init.d/agent-in&quot; 5 months ago Exited (128) 50 minutes ago e505b911-a391-4d1c-8ef2-7bbb306df8ebbe4238200956 rancher/agent:v1.0.2 &quot;/run.sh run&quot; 5 months ago Up 11 minutes rancher-agent 发现服务全都是Exited状态，Rancher控制台上Network Agent容器也是一直转圈圈Restarting状态。 因此断定应该是Network Agent服务没有启动导致的所有服务无法恢复自动启动。 那为什么会出现这个问题？这个问题是什么原因导致的呢？ 在解决这个问题之前先看一下Rancher的网络+负载均衡 实现与说明 Rancher网络+负载均衡的实现与说明依赖镜像：rancher/agent-instance:v0.8.3 Rancher网络是采用SDN技术所建容器为虚拟ip地址，各host之间容器采用ipsec隧道实现跨主机通信，使用的是udp的500和4500端口。 启动任务时，在各个host部署容器之前会起一个Network Agent容器，负责组建网络环境。 网络全都靠agent-instance容器实现，网络没有准备好其余的容器当然也不会自动恢复。 那我们的这个问题就是agent-instance容器没有起来导致的，那让我们启动agent-instance容器。 docker@xxx:~$ docker start 0c8d3edbc53dError response from daemon: rpc error: code = 2 desc = &quot;oci runtime error: exec format error&quot;Error: failed to start containers: 0c8d3edbc53d 很遗憾提示错误无法启动，那让我们看一下日志中的错误是什么？ docker@xxx:~$ docker logs --tail=200 -f 0c8d3edbc53d.......省略其他的INFO: Sending agent-instance-startup applied 3-0f669dbfe83bbb7389a0c2129247f633575904e41d665e311051de2ce1b85737Starting monit daemon with http interface at [localhost:2812]The system is going down NOW!Sent SIGTERM to all processesSent SIGKILL to all processesRequesting system rebootINFO: Downloading agent http://192.168.0.34:8080/v1/configcontent/configscripts 发现The system is going down NOW!这个错误，什么情况？无法启动要求重启系统。 于是查看rancher官方相关这个问题的issues，也没看出个所以然来，跟我的系统版本和agent、agent-instance版本都一致也有很多人无法启动或者启动报错。 agent-instance cannot start automatically on Ubuntu 16.04.X #5951 Rancher network agent stuck in restart loop - DNS lookup issue #4237 最终无解尝试暴力做法，删除以前的agent-instance容器，然后重新创建重启 删除rancher/agent-instance:v0.8.3容器 docker@xxx:~$ docker rm 0c8d3edbc53d0c8d3edbc53d 查看有没有rancher/agent-instance:v0.8.3这个镜像 docker@xxx:~$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZE192.168.0.34:5000/saas-erp latest 0ad78488245a 4 days ago 275.4 MB192.168.0.34:5000/tms2job latest caa888ff603f 4 weeks ago 236.8 MB192.168.0.34:5000/customer-mq latest db319e29bd7f 8 weeks ago 431.8 MB192.168.0.34:5000/saas-account latest 004999746d2c 9 weeks ago 181.9 MB192.168.0.34:5000/saas-erp-http-main latest 9a5f8be5ef8d 4 months ago 200.8 MB192.168.0.34:5000/messer 1.0 74e9ec4742cc 7 months ago 184.8 MB192.168.0.34:5000/tomcat 7 830387a4274c 19 months ago 357.8 MBrancher/agent-instance v0.8.3 b6b013f2aa85 20 months ago 331 MB192.168.0.34:5000/rancher/agent v1.0.2 860ed2b2e8e3 20 months ago 454.3 MBrancher/agent v1.0.2 860ed2b2e8e3 20 months ago 454.3 MB192.168.0.34:5000/mysql 5.6.30 2c0964ec182a 21 months ago 329 MB192.168.0.34:5000/zookeeper elevy d2805d0326a9 2 years ago 131.8 MB 有镜像，根据镜像重新创建rancher/agent-instance:v0.8.3容器 docker@xxx:~$ docker run -d b6b013f2aa850060edfa2594 ps.-d, –detach Run container in background and print container ID，后台运行容器并且打印出容器ID OK创建好了，再ps查看一下其余的容器是否都自动恢复了 docker@xxx:~$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES854fa1039e76 192.168.0.34:5000/zookeeper:elevy &quot;/entrypoint.sh zkSer&quot; 33 minutes ago Up 33 minutes 2888/tcp, 3888/tcp, 0.0.0.0:2181-&gt;2181/tcp, 9010/tcp r-zookeeper_zookeeper-2_147c189dbd5c6 b6b013f2aa85 &quot;/etc/init.d/agent-in&quot; 37 minutes ago Up 37 minutes drunk_tesla0060edfa2594 rancher/agent-instance:v0.8.3 &quot;/etc/init.d/agent-in&quot; 37 minutes ago Up 37 minutes 0.0.0.0:500-&gt;500/udp, 0.0.0.0:4500-&gt;4500/udp e505b911-a391-4d1c-8ef2-7bbb306df8ebd9da7f16ef2d 192.168.0.34:5000/saas-erp:latest &quot;./entrypoint.sh&quot; 4 days ago Up 37 minutes 0.0.0.0:20833-&gt;20833/tcp r-erp_erp-dubbo_179e8e475db19 192.168.0.34:5000/tms2job:latest &quot;./entrypoint.sh&quot; 4 weeks ago Up 37 minutes 0.0.0.0:50831-&gt;50831/tcp r-tms_tms2-job_165492930b132 192.168.0.34:5000/saas-account:latest &quot;./entrypoint.sh&quot; 9 weeks ago Up 37 minutes 0.0.0.0:20834-&gt;20834/tcp r-account_account-dubbo_1248514cd635a 192.168.0.34:5000/saas-erp-http-main:latest &quot;./entrypoint.sh&quot; 4 months ago Up 37 minutes 0.0.0.0:20902-&gt;20902/tcp r-erp_erp-http-main_1d72c359c2d5e 192.168.0.34:5000/mysql:5.6.30 &quot;docker-entrypoint.sh&quot; 5 months ago Up 37 minutes 0.0.0.0:3306-&gt;3306/tcp c7638fa0-f263-45bd-85d7-2e3b7407ad2fbe4238200956 rancher/agent:v1.0.2 &quot;/run.sh run&quot; 5 months ago Up About an hour rancher-agent 很好全都恢复了，Status全都是Up。早知道删除重建就不需要这么麻烦去Issues中找答案，以后记住了只要Network Agent容器（rancher/agent-instance:v0.8.3）出问题先尝试start，如果无法start就删除了重新创建容器。","tags":[{"name":"docker","slug":"docker","permalink":"https://ningyu1.github.io/tags/docker/"},{"name":"rancher","slug":"rancher","permalink":"https://ningyu1.github.io/tags/rancher/"},{"name":"trouble shooting","slug":"trouble-shooting","permalink":"https://ningyu1.github.io/tags/trouble-shooting/"},{"name":"rancher/agent:v1.0.2","slug":"rancher-agent-v1-0-2","permalink":"https://ningyu1.github.io/tags/rancher-agent-v1-0-2/"},{"name":"rancher/agent-instance:v0.8.3","slug":"rancher-agent-instance-v0-8-3","permalink":"https://ningyu1.github.io/tags/rancher-agent-instance-v0-8-3/"}]},{"title":"构建Python多个虚拟环境来进行不同版本开发之神器-virtualenv","date":"2018-03-02T03:22:28.000Z","path":"20180302/63-python-virtualenv.html","text":"我们都知道Python的类库很多，但是大多支持的版本还是Python2.x系列，Python3支持的类库相对较少，因此我们在开发的时候经常还使用的Python2系列的版本，Python3对语法进行了比较大的重构，Python3中将一些Python2的模块名称做了修改，虽然兼容Python2但还是需要我们做一些处理来保证代码在不同Python版本中能够正常运作，如果我们想同时使用Python2 和 Python3，这个时候大家最常用的做法就是机器上配置多个版本，虽然可以解决问题但是配合多个项目的各种杂乱的包依赖情况，问题就变的非常复杂了，可能升级某一个第三方依赖库会对很多项目产生影响。 我们都知道在安装Python类库的时候它默认会安装到Python的目录下，有编程洁癖的人都会因此苦恼，因为它污染了Python的目录，并且在开发的时候不同的项目使用的类库差异也蛮大，为了使多个项目之间互相不影响，我们能不能根据项目来区分开Python环境目录？ 当然可以，virtualenv就能帮助我们解决上面的苦恼，它是一个可以创建多个隔绝Python环境的工具，virtualenv可以创建一个包含所有必要的可执行的文件夹，用来使用Python工程所需要的包，同时还不污染Python的原安装目录。 这个工具简直就是给有开发洁癖的人送福音的。画外音：专业送快递 上面大致说了一下我们使用virtualenv的初衷，接下来让我们看一下virtualenv如何使用，在使用之前先正式的了解一下virtualenv 什么是virtualenv?Virtualenv是一个用来创建独立的Python环境的工具 为什么我们需要一个独立的Python环境？引用virtualenv的文档 virtualenv is a tool to create isolated Python environments.The basic problem being addressed is one of dependencies and versions, and indirectly permissions. Imagine you have an application that needs version 1 of LibFoo, but another application requires version 2. How can you use both these applications? If you install everything into /usr/lib/python2.7/site-packages (or whatever your platform’s standard location is), it’s easy to end up in a situation where you unintentionally upgrade an application that shouldn’t be upgraded.Or more generally, what if you want to install an application and leave it be? If an application works, any change in its libraries or the versions of those libraries can break the application.Also, what if you can’t install packages into the global site-packages directory? For instance, on a shared host.In all these cases, virtualenv can help you. It creates an environment that has its own installation directories, that doesn’t share libraries with other virtualenv environments (and optionally doesn’t access the globally installed libraries either). 上面这段话的意思大致是这样的，我们需要处理的基本问题是包的依赖、版本和间接权限问题。想象一下，你有两个应用，一个应用需要libfoo的版本1，而另一应用需要版本2。如何才能同时使用这些应用程序？如果您安装到的/usr/lib/python2.7/site-packages（或任何平台的标准位置）的一切，在这种情况下，您可能会不小心升级不应该升级的应用程序。或者更广泛地说，如果您想要安装一个应用程序并离开它呢?如果应用程序工作，其库中的任何更改或这些库的版本都可以破坏应用程序。另外，如果您不能将包安装到全局站点包目录中，该怎么办?例如，在共享主机上。在所有这些情况下，virtualenv可以帮助您。它创建了一个有自己的安装目录的环境，它不与其他virtualenv环境共享库(也不可能访问全局安装的库)。 简单地说，你可以为每个项目建立不同的/独立的Python环境，你将为每个项目安装所有需要的软件包到它们各自独立的环境中。 到这里我相信我们已经很清晰的知道了virtualenv是什么，能做什么，那接下来就让我们来用一用它。 使用virtualenv安装pip install virtualenv 画外音：pip安装非常简单，简直就是傻瓜式的 使用virtualenv安装完毕后，可以通过运行下面的命令来为你的项目创建独立的Python环境： mkdir my_project_dircd my_project_dirvirtualenv --distribute my_venv# my_venv为虚拟环境目录名，目录名自定义 OK，执行成功，上面发生了什么？ 它会在my_project_dir目录中创建一个文件夹（my_venv），包含了Python可执行文件，以及 pip 库的一份拷贝，这样就能安装其他包了。虚拟环境的名字（my_venv）可以是任意的；不写名字会使用当前目录创建。 我们再来看看输出： 1 New python executable in my_venv/bin/python2.72 Also creating executable in my_venv/bin/python3 Installing Setuptools......done.4 Installing Pip...........done. --distribute 选项使virtualenv使用新的基于发行版的包管理系统而不是 setuptools 获得的包。 你现在需要知道的就是 --distribute 选项会自动在新的虚拟环境中安装 pip ，这样就不需要手动安装了。 当你成为一个更有经验的Python开发者，你就会明白其中细节。 当然还有很多参数配置，例如：-p参数指定Python解释器程序路径，这里就过多介绍了，通过help去查看。 到这里这个虚拟环境就创建好了，但是要真正使用还需要激活，通过如下命令激活。 my_project_dir\\my_venv\\Scripts\\activate 激活后输出如下： # window下(my_venv) yourpath\\venv\\Scripts&gt;# linux下(my_venv)[root@docker-x my_venv]# 从现在起，任何你使用pip安装的包将会放在 my_venv文件夹中，与全局安装的Python隔绝开，是不是很赞，想怎么装怎么装。 就像平常一样安装包，例如： pip install flask 上面启用激活，有激活那就有停用，如果你在当前虚拟环境中暂时完成了工作，可以使用如下命令停用它： my_project_dir\\my_venv\\Scripts\\deactivate 这将会回到系统默认的Python解释器，包括已安装的库也会回到默认的。要删除一个虚拟环境，只需删除它的文件夹。（执行 rm -rf venv ）。 思考让我们看看激活与停用virtualenv，调用python/pip命令有什么不一样。先停用virtualenv，如下： [root@docker-x ~]# which python/usr/bin/python[root@docker-x ~]# which pip/usr/local/bin/pip 让我们激活virtualenv后，再来一次！看看有什么不同。如下：[root@docker-x ~]# which python/usr/local/my_venv/bin/python[root@docker-x ~]# which pip/usr/local/my_venv/bin/pip virtualenv拷贝了Python可执行文件的副本，并创建一些有用的脚本和安装了项目需要的软件包，你可以在项目的整个生命周期中安装/升级/删除这些包。 它也修改了一些搜索路径，例如PYTHONPATH，以确保： 当安装包时，它们被安装在当前活动的virtualenv里，而不是系统范围内的Python路径。 当import代码时，virtualenv将优先采取本环境中安装的包，而不是系统Python目录中安装的包。 还有一点比较重要，在默认情况下，所有安装在系统范围内的包对于virtualenv是可见的。这意味着如果你将simplejson安装在您的系统Python目录中，它会自动提供给所有的virtualenvs使用。这种行为可以被更改，在创建virtualenv时增加 --no-site-packages 选项,virtualenv就不会读取系统包，如下： virtualenv my_venv --no-site-packages virtualenvwrapper有的时候virtualenv也会带来一些问题，由于virtualenv的启动、停止脚本都在特定文件夹，可能一段时间后，你可能会有很多个虚拟环境散落在系统各处，你可能忘记它们的名字甚至忘记它的位置。怎么来管理virtualenv? 鉴于virtualenv不便于对虚拟环境集中管理，所以推荐直接使用virtualenvwrapper。 virtualenvwrapper提供了一系列命令使得和虚拟环境工作变得便利。它把你所有的虚拟环境都放在一个地方。 安装pip install virtualenvwrapperpip install virtualenvwrapper-win #Windows使用该命令 注意：安装virtualenvwrapper之前首先确保virtualenv已安装 安装完成后，在~/.bashrc写入以下内容 export WORKON_HOME=~/Envssource /usr/local/bin/virtualenvwrapper.sh#读入配置文件，立即生效source ~/.bashrc 说明：第一行：virtualenvwrapper存放虚拟环境目录，第二行：virtrualenvwrapper会安装到python的bin目录下，所以该路径是python安装目录下bin/virtualenvwrapper.sh 使用使用如下命令创建虚拟环境: mkvirtualenv my_venv_py3 这样会在WORKON_HOME变量指定的目录下新建名为 my_venv_py3 的虚拟环境。 若想指定Python版本，可通过--python指定Python解释器 mkvirtualenv --python=/usr/local/python3.5.3/bin/python my_venv_py3 查看当前的虚拟环境目录 [root@docker-x ~]# workonmy_venv_py2my_venv_py3 切换到虚拟环境 [root@docker-x ~]# workon my_venv_py3(my_venv_py3) [root@docker-x ~]# 退出虚拟环境 (my_venv_py3) [root@docker-x ~]# deactivate[root@docker-x ~]# 删除虚拟环境 rmvirtualenv my_venv_py3 到这里 virtualenvs 和 virtualenvwrapper 就讲完了，是不是 so easy！跟着步骤来，一切都是顺理成章的。而且功能也很强大，使Python的开发环境配置起来变得非常简单。尤其是扩展工具virtualenvwrapper 使得构建出来的虚拟环境可以更好的管理起来。感谢这个世界，世界和平，Keep Real！","tags":[{"name":"python","slug":"python","permalink":"https://ningyu1.github.io/tags/python/"},{"name":"virtualenv","slug":"virtualenv","permalink":"https://ningyu1.github.io/tags/virtualenv/"},{"name":"virtualenvwrapper","slug":"virtualenvwrapper","permalink":"https://ningyu1.github.io/tags/virtualenvwrapper/"}]},{"title":"RESTful访问权限管理实现思路，采用路径匹配神器之AntPathMatcher","date":"2018-02-27T08:15:49.000Z","path":"20180227/62-ant-path-matcher.html","text":"我们经常在写程序时需要对路径进行匹配，比如说：资源的拦截与加载、RESTful访问控制、审计日志采集、等，伟大的SpringMVC在匹配Controller路径时是如何实现的？全都归功于ant匹配规则。 Spring源码之AntPathMatcher，这个工具类匹配很强大，采用的是ant匹配规则。 什么是ant匹配规则？ 字符wildcard 描述 ? 匹配一个字符（matches one character） * 匹配0个及以上字符（matches zero or more characters ） ** 匹配0个及以上目录directories（matches zero or more ‘directories’ in a path ） 这个匹配规则很简单，采用简洁明了的方式来进行匹配解析，简化版本的正则。 结合官方的示例来理解一下 Pattern 匹配说明 com/t?st.jsp 匹配: com/test.jsp , com/tast.jsp , com/txst.jsp com/*.jsp 匹配: com文件夹下的全部.jsp文件 com/**/test.jsp 匹配: com文件夹和子文件夹下的全部.jsp文件 org/springframework/*/.jsp 匹配: org/springframework文件夹和子文件夹下的全部.jsp文件 org/**/servlet/bla.jsp 匹配: org/springframework/servlet/bla.jsp , org/springframework/testing/servlet/bla.jsp , org/servlet/bla.jsp 如何实现RESTful访问权限管理？在微服务和前后端分离的开发模式下，往往会使用RESTful来开发后端服务，那服务的访问权限控制就是一个问题，那下来我们就说一下如何实现RESTful访问权限管理。 权限资源类型资源分为如下两种类型： public（公有）：public为不控制访问的资源 private（私有）：private为需要被控制访问的资源 ps.这种方式资源管理的相对严格一些，如果想管理的粗矿一些，可以不需要public，只要在private中未找到的资源就是不控制访问的资源即可，实现时可以根据自己的业务场景来调整。 匹配原则基础匹配规则：使用ant匹配规则 在SpringMVC的路径匹配原则中有一个原则是：最长匹配原则(has more characters) 什么是最长匹配原则(has more characters)？ 最长匹配原则(has more characters)简单的理解就是目标URL有多个pattern都可以匹配上就取最长的那个pattern 例如：请求的URL为/app/dir/file.jsp，有两个pattern /**/*.jsp和/app/dir/*.jsp都可以匹配成功，那么会根据pattern的长度来控制是否采用哪一个，这里使用/app/dir/*.jsp来匹配。 为什么要使用最长匹配原则？我的理解是长的pattern更符合目标URL格式，短的pattern往往是范围较广的，匹配取最适合的pattern也是比较符合预期的。 根据服务名分类在做资源访问权限时往往会有多个服务可能会出现相同的资源路径，因此增加一级服务名来对资源进行分类。 例如：GET /v1/service1/product/1 和 GET /v1/service2/product/1，根据二级目录service名称来对服务进行模块化分割。/v1为RESTful版本号 ps.服务名就是为了做资源分类 权限验证逻辑 验证public资源 去除末尾&quot;/&quot; 验证service服务名，服务名为空返回没有权限 获取服务名下enabled=true的资源表，结果进行cache，结果为空没有权限 根据pattern长度倒序 匹配method，匹配成功进行下一步匹配 匹配请求的url，匹配成功返回有权限，反之返回没有权限 验证private资源 去除末尾&quot;/&quot; 验证service服务名，服务名为空返回没有权限 获取服务名下用户角色对应的资源列表聚合结果，结果进行cache，结果为空返回没有权限 根据pattern长度倒序 匹配method，匹配成功进行下一步匹配，反之continue 匹配请求的url，匹配成功进行下一步匹配，反之continue 检查匹配成功的url是否为禁用状态，如果禁用返回无权限，反之进行下一步匹配 匹配成功的url对应的角色列表进行登录用户的角色匹配 角色匹配成功返回有权限，反之返回没有权限 ps.method是GET、POST、PUT、PATCH、DELETE，service是服务模块名 缓存结构 private资源数据 结构：hash cache key=${APPNAME}.METADATA.RESOURCE，field=${RESOURCE_ID}，value=Resource对象 public资源数据 结构：hash cache key=${APPNAME}.METADATA.RESOURCE.PUBLIC，field=${SERVICE}，value=List&lt;Resource&gt; 用户关联角色数据 结构：hash cache key=${APPNAME}.METADATA.ROLE，field=${USER_ID}，value=List&lt;ROLE_ID&gt; 角色关联的资源数据 结构：hash cache key=${APPNAME}.METADATA.MAPPING，field=${SERVICE}，value=List&lt;Metadata&lt;Resource,List&lt;ROLE_ID&gt;&gt;&gt; 这里存储的数据结构是反向的，获取服务下的资源列表，每个资源数据中会有拥有这个资源的角色列表。 ps.缓存可以使用分布式的redis、redisson、如果单机可以使用jvm cache。 缓存控制 private资源数据发生变更时 调用MetadataCache.invalidResources()，失效cache key=${APPNAME}.METADATA.RESOURCE下所有数据 public资源数据发生变更时 调用MetadataCache.invalidPublicResource(service)失效服务名下的public资源集合，失效cache key=${APPNAME}.METADATA.RESOURCE.PUBLIC下的某个${SERVICE}数据 调用MetadataCache.invalidPublicResource()失效所有服务名下的public资源集合，失效cache key=${APPNAME}.METADATA.RESOURCE.PUBLIC下所有数据 用户关联角色数据发生变更时 调用MetadataCache.invalidUserRoles(userId)失效用户下的角色集合，失效cache key=${APPNAME}.METADATA.ROLE下所有数据 角色关联的资源数据发生变更时 调用MetadataCache.invalidMetadata(service)失效服务名下的资源角色聚合对象，失效cache key=${APPNAME}.METADATA.MAPPING下的某个${SERVICE}数据 调用MetadataCache.invalidMetadata()失效所有服务名下的资源角色聚合对象，失效cache key=${APPNAME}.METADATA.MAPPING下所有数据 ps.在以上触发点上对缓存数据进行更新，这里采用失效再加载方式 缓存加载 private资源数据，在系统启动加载，加载所有私有资源，如果失效了，会在private匹配的时再进行加载 public资源数据，在public匹配时加载，通过服务名加载，如果失效了，会在public匹配时再进行加载 用户关联角色数据，在private匹配时加载，如果失效了，会在private匹配时再进行加载 角色关联的资源数据，在private匹配时加载，如果失效了，会在private匹配时再进行加载 ps.资源数据加载触发点 pattern配置建议 配置资源时，将不需要配置权限的url配置为public资源 每个服务名下建议配置一个**（双星）通配符给超级管理员使用，例如：/v1/products/** 每个url的第二级目录要与服务名一致，例如：/v1/products/{pid}，服务名为products url的目录结构必须大于两级目录，例如：/v1/products/{pid}，不允许为：/v1/{pid} url与权限通配符映射关系，前面url，后面pattern 例如：/v1/products/{pid} -&gt; /v1/products/* 例如：/v1/products/{pid}/skus/{sid} -&gt; /v1/products/*/skus/* 例如：/v1/products/enabled -&gt; /v1/products/enabled 例如：/v1/products/**，匹配products目录下所有目录 以上就是一种RESTful资源管理的实现思路，能控制到RESTful的方法级别，在前后端分离的项目可以使用这种方式来控制访问权限。","tags":[{"name":"restful","slug":"restful","permalink":"https://ningyu1.github.io/tags/restful/"},{"name":"antPathMatcher","slug":"antPathMatcher","permalink":"https://ningyu1.github.io/tags/antPathMatcher/"}]},{"title":"扩展Disconf支持Global共享配置，简化业务应用参数配置","date":"2018-02-11T03:26:49.000Z","path":"20180211/61-disconf-ext.html","text":"当我们使用统一配置中心（UCM）后或许都会出现这种烦恼，项目中的配置项目多，当项目引用到基础中间件时都要增加基础中间件的配置，例如：zk参数、redis参数、rpc参数、loadbalance参数、mq参数、等。这些配置都是基础的中间件配置，应该做成共享的方式让所有APP都共享，而并不是在用的时候再去APP中添加，Global的配置基础中间件团队维护即可。 为什么要有公共共享的配置？因为在APP配置中有很多是公共的配置，如果没有Global就需要在自己的APP中配置这些配置信息，导致APP中配置信息过多不好维护，公共的配置信息修改需要通知各业务APP修改自己APP中的配置，没有达到一处修改，各处使用的目标。 这时候有朋友就会问我了如果做成全局共享配置，那不同项目需要修改全局某个参数怎么办呢？这个需求也很正常，比如loadbalance参数确实需要根据不同项目的具体情况去配置参数，对于这种问题其实很好解决，我们可以使用APP中的配置去覆盖Global配置，也就是说当APP中的配置项与Global配置项相同的情况下，以APP的配置为主即可。 这样一来APP的配置生效的优先级为：Local conf &gt; Project conf &gt; Global conf，当出现相同配置项以APP自身的配置为主去覆盖。 增加了Global的支持后，APP中的配置减少了，避免了一些由于配置导致的错误，也可以通过Global的方式去规范APP的配置，让业务开发不关心公共配置的细节，在使用的时候直接使用无需维护。 Disconf作为一个比较老牌的UCM在这方面支持的并不好，它并没有共享配置这个概念，这样一来公共的配置就需要在每个APP中都要配置一份，操作起来很烦人。 那我们如何来解决这个问题？我们能否扩展Disconf让其支持Global共享配置呢？扩展思路在加载properties的时候，也就是ReloadablePropertiesFactoryBean的locations，给前面默认加一个GlobalProp项目的索引项：global（使用disconf的新建配置项，而不是配置文件），这个索引项的值是所有global配置文件的名称，使用”,”分隔，例如： global-dubbo.properties,global-redis.properties,global-zookeeper.properties,global-sso.properties,global-mq.properties,global-fastdfs.properties,global-elasticsearch.properties 让disconf下载配置文件的时候优先下载global的配置文件，在properties加载的时候优先加载global的配置，这样当发生重复项时后加载的会覆盖前面的信息，从而达到了我们上面的需求，当APP中修改了某个global配置应该以APP的配置项为主。 接下来就让我们看一下具体扩展了哪些类？ Disconf的扩展点做的不是那么的好，因此扩展起来有些麻烦，我使用的是比较暴力的方式，直接使用原包的类在名称后加Ext然后修改代码，使用的时候使用Ext的类替代即可，这种方式的弊端是升级Disconf的时候很麻烦。 Disconf扫描管理com.baidu.disconf.client.DisconfMgrBean扩展一个com.baidu.disconf.client.DisconfMgrBeanExtcom.baidu.disconf.client.DisconfMgrBeanSecond扩展一个com.baidu.disconf.client.DisconfMgrBeanSecondExt Reloadable Propertiescom.baidu.disconf.client.addons.properties.ReloadablePropertiesFactoryBean扩展一个com.baidu.disconf.client.addons.properties.ReloadablePropertiesFactoryBeanExt 可以增加一个开关从而支持启用global的自由度，默认是开启的。 下面来看一下扩展后的具体使用方法如下 项目地址disconf-client-ext &nbsp;&nbsp;&nbsp; disconf-client-ext的使用 依赖disconf版本：2.6.32 pom中引入disconf-client-ext依赖 修改disconf配置 替换com.baidu.disconf.client.DisconfMgrBean –&gt; com.baidu.disconf.client.DisconfMgrBeanExt 替换com.baidu.disconf.client.DisconfMgrBeanSecond –&gt; com.baidu.disconf.client.DisconfMgrBeanSecondExt 替换com.baidu.disconf.client.addons.properties.ReloadablePropertiesFactoryBean –&gt; com.baidu.disconf.client.addons.properties.ReloadablePropertiesFactoryBeanExt 修改locations中配置文件，只保留项目自己的配置文件，例如 &lt;bean id=&quot;disconfNotReloadablePropertiesFactoryBean&quot; class=&quot;com.baidu.disconf.client.addons.properties.ReloadablePropertiesFactoryBeanExt&quot;&gt; &lt;property name=&quot;locations&quot;&gt; &lt;list&gt; &lt;value&gt;classpath:/jdbc.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; 关闭global共享配置（默认是开启的） &lt;bean id=&quot;disconfNotReloadablePropertiesFactoryBean&quot; class=&quot;com.baidu.disconf.client.addons.properties.ReloadablePropertiesFactoryBeanExt&quot;&gt; &lt;property name=&quot;locations&quot;&gt; &lt;list&gt; &lt;value&gt;classpath:/jdbc.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name=&quot;globalShareEnable&quot; value=&quot;false&quot; /&gt;&lt;/bean&gt; 最后一步添加global项目到Disconf 世界和平，Keep Real!","tags":[{"name":"disconf","slug":"disconf","permalink":"https://ningyu1.github.io/tags/disconf/"},{"name":"ucm","slug":"ucm","permalink":"https://ningyu1.github.io/tags/ucm/"}]},{"title":"Dubbo接口如何在Jmeter中测试，自研Dubbo Plugin for Apache JMeter","date":"2018-02-09T07:39:49.000Z","path":"20180209/60-jmeter-plugins-dubbo-support.html","text":"最近公司测试需要对Dubbo的RPC接口进行测试，测试工具使用的是Jmeter，按照常规的做法需要包装一个Java请求，再配合Jmeter的Java Sample去做测试，这种做法是最简单最普遍的，但是这个方法不够灵活和方便，那我们能不能写一个Jmeter Plugin来解决这个问题？让Dubbo RPC接口测试更为方便一些？ 那我们先了解一下Jmeter的插件机制 Jmeter Plugin先来看一下Jmeter的核心组件 Sample 取样器，这个是最主要的组件，测试的内容主要是靠Sample来实现，我们常见的Sample有，HttpSample、FTPSample、JavaSample、SMTPSample、LDAPSample等。 Timer 定时器，主要用于配置sample之间的等待时间，可以查看：org.apache.jmeter.timers.RandomTimer ConfigElement 配置组件，主要用于定义前置配置。如数据库连接，csv输入数据集等。主要功能是将配置转换为变量设置到JMeter context中。 Assertion 验证Sampler的结果是否符合预期 PostProcessor 一般用于对Sampler结果进行二次加工 Visualizer 将sampler的结果进行可视化展示。 Controller 对sampler进行逻辑控制。 SampleListener 负责处理监听，基于事件机制。一般用于保存sampler的结果等耗费时间的操作。 Jmeter的插件机制比较简单，Jmeter提供了扩展类来支持自定义插件的开发。继承org.apache.jmeter.samplers.gui.AbstractSamplerGui和org.apache.jmeter.samplers.AbstractSampler就可以完成一个插件开发。 JMeter的GUI机制由于Jmeter是一个基于Swing的GUI工具,所以开发插件需要对Java Swing GUI框架有一定了解。 JMeter内部有两种GUI的实现方式。 第一种方式：直接继承JMeterGUIComponent接口的抽象实现类: org.apache.jmeter.config.gui.AbstractConfigGuiorg.apache.jmeter.assertions.gui.AbstractAssertionGuiorg.apache.jmeter.control.gui.AbstractControllerGuiorg.apache.jmeter.timers.gui.AbstractTimerGuiorg.apache.jmeter.visualizers.gui.AbstractVisualizerorg.apache.jmeter.samplers.gui.AbstractSamplerGui 通过Swing的Bean绑定机制前者的好处是自由度高，可定制性强，但需要开发者关心GUI控件布局,以及从控件到Model的转换。后者基本不需要开发者接触到GUI层的东西，定义好Bean以及BeanInfo即可。但SampleListener不支持BeanInfo方式定义。 ps.如果java swing比较熟悉的话推荐使用第一种方式，自由度高。 下面是我写的插件DubboSample，主要用于Dubbo RPC接口测试。 Dubbo Plugin for Apache JMeterjmeter-plugin-dubbo项目已经transfer到dubbo group下 github: jmeter-plugin-dubbo 码云: jmeter-plugin-dubbo DubboSample使用支持Jmeter版本Jmeter版本：3.0 插件安装插件包可以去github上下载。将插件包放入Jmeter的lib的ext下。 $&#123;Path&#125;\\apache-jmeter-3.0\\lib\\ext 如果使用的是:jmeter-plugins-dubbo-1.0.0-SNAPSHOT-jar-with-dependencies.jar包含所有依赖。 如果使用的是：jmeter-plugins-dubbo-1.0.0-SNAPSHOT.jar需要自定添加插件的依赖包，推荐使用上面的包，依赖包版本如下： dubbo-2.5.3.jarjavassist-3.15.0-GA.jarzookeeper-3.4.6.jarzkclient-0.1.jarjline-0.9.94.jarnetty-3.7.0-Final.jarslf4j-api-1.7.5.jarlog4j-over-slf4j-1.7.5.jar 插件使用启动Jmeter添加DubboSample如下图： 添加后能看到DubboSample的具体操作页面，如下图： 根据上图提示传入值即可。 接口以及接口依赖包请添加到classpath下，可以放在apache-jmeter-3.0\\lib\\ext下，也可以通过下图方式添加： 运行结果 注意事项 当使用zk，address填入zk地址（集群地址使用”,”分隔）,使用dubbo直连，address填写直连地址和服务端口 timeout：服务方法调用超时时间(毫秒) version：服务版本，与服务提供者的版本一致 retries：远程服务调用重试次数，不包括第一次调用，不需要重试请设为0 cluster：集群方式，可选：failover/failfast/failsafe/failback/forking 接口需要填写类型完全名称，含包名 参数支持任何类型，包装类直接使用java.lang下的包装类，小类型使用：int、float、shot、double、long、byte、boolean、char，自定义类使用类完全名称。 参数值，基础包装类和基础小类型直接使用值，例如：int为1，boolean为true等，自定义类与List或者Map等使用json格式数据。 更多dubbo参数查看官方文档：http://dubbo.io/books/dubbo-user-book/references/xml/dubbo-reference.html 到这里插件的就介绍完了。世界和平、keep real！","tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://ningyu1.github.io/tags/dubbo/"},{"name":"jmeter","slug":"jmeter","permalink":"https://ningyu1.github.io/tags/jmeter/"},{"name":"test","slug":"test","permalink":"https://ningyu1.github.io/tags/test/"},{"name":"Dubbo可视化测试工具","slug":"Dubbo可视化测试工具","permalink":"https://ningyu1.github.io/tags/Dubbo可视化测试工具/"},{"name":"Jmeter对Dubbo接口进行可视化压力测试","slug":"Jmeter对Dubbo接口进行可视化压力测试","permalink":"https://ningyu1.github.io/tags/Jmeter对Dubbo接口进行可视化压力测试/"},{"name":"Dubbo Jmeter插件","slug":"Dubbo-Jmeter插件","permalink":"https://ningyu1.github.io/tags/Dubbo-Jmeter插件/"}]},{"title":"如何将Python脚本打包成可执行文件？","date":"2018-02-07T03:57:49.000Z","path":"20180207/59-py2exe-pyinstaller.html","text":"我们有时候经常会使用python写一些小工具，在Linux环境下可以很方便运行，因为Linux默认都会有python环境，我们只需要添加python脚本依赖的类库即可执行。但是有的时候我们需要把小工具给到一些麻瓜去用的时候就会出现一些问题，他们大多是在Windows上运行工具，那就必须要先准备python的可运行环境才行，这就给麻瓜们带来了使用成本，我们能否将python脚本打包成windows下可执行文件呢？ 接下来让我们先了解一下python有哪些类库可以帮助我们解决这个问题。 这是一个来自Freezing Your Code的统计 Solution Windows Linux OS X Python 3 License One-file mode Zipfile import Eggs pkg_resources support bbFreeze yes yes yes no MIT no yes yes yes py2exe yes no no yes MIT yes yes no no pyInstaller yes yes yes yes GPL yes no yes no cx_Freeze yes yes yes yes PSF no yes yes no py2app no no yes yes MIT no yes yes yes 我们能看到有很多类库都可以解决我们的问题，其中pyInstaller、cx_Freeze、bbFreeze都不错，pkg_resources新版的pyInstaller貌似是支持的。 我们这里选用pyInstaller尝试一下，因为它各方面支持的是最好的。 PyInstaller原理介绍PyInstaller其实就是把python解析器和脚本以及脚本的依赖库打包成一个可执行的文件，这和编译成真正的机器码是两回事，所以通过PyInstaller打包成一个可执行文件可能不会提高运行效率，相反可能会降低运行效率，但是它带来的好处就是在运行者的机器上不用安装python和你的脚本依赖的库。在Linux操作系统下，它主要用的binutil工具包里面的ldd和objdump命令。 PyInstaller输入你指定的的脚本，首先分析脚本所依赖的其他脚本，然后去查找，复制，把所有相关的脚本收集起来，包括Python解析器，然后把这些文件放在一个目录下，再打包进一个可执行文件里。 这样就可以直接发布输出整个文件夹里面的文件，或者生成可执行文件。你只需要告诉用户，你的App是自我包含的，不需要安装其他包，或某个版本的Python，就可以直接运行。 但是需要注意的是，PyInstaller打包的执行文件，只能在和打包机器系统同样的环境下运行。它不具备可移植性，若需要在不同系统上运行，就必须针对不同平台进行打包。 安装PyInstaller网络情况可以的话使用pip安装还是很方便的。 pip install pyinstaller 如果网络不稳定，尤其在天朝访问墙外站点是很痛苦的，我们还可以通过下载源码包来安装。 # 在源码包的根目录下执行python setup.py install 安装完成后，检查安装版本。 pyinstaller --version 使用PyInstaller进行打包pyinstaller的语法 pyinstaller [options] script [script ...] | specfile 具体命令如何使用可以通过help或官方文档去查询具体的用法。 我这里只说几个注意的点。 -F, --onefile Create a one-file bundled executable.创建一个可执行文件 -w, --windowed, --noconsole去除黑框 # A path to search for imports (like using PYTHONPATH). Multiple paths are allowed, separated by ‘:’, or use this option multiple times-p DIR, --paths DIR 设置一个可搜索的入口路径，怎么理解呢？如果不指定这个参数打包出来的文件只能在生成它的目录下运行，如果打包时指定参数为-p .打包出来的文件可以放在任意路径下运行，如下示例： pyinstaller -w -F -p . your.py 参考资料 Freezing Your Code PyInstaller官方WIKI PyInstaller Github 到这里PyInstaller就简单介绍完毕，感兴趣的可以试一试，我以前使用的是py2exe，其实py2exe也蛮好只不过它需要创建一个py脚本来把需要打包的脚本包含进去，用起来没有PyInstaller方便，希望这个简单的入门可以帮助到需要的朋友。 Keep Real！","tags":[{"name":"python","slug":"python","permalink":"https://ningyu1.github.io/tags/python/"},{"name":"py2exe","slug":"py2exe","permalink":"https://ningyu1.github.io/tags/py2exe/"},{"name":"pyinstaller","slug":"pyinstaller","permalink":"https://ningyu1.github.io/tags/pyinstaller/"},{"name":"bbFreeze","slug":"bbFreeze","permalink":"https://ningyu1.github.io/tags/bbFreeze/"},{"name":"cx_Freeze","slug":"cx-Freeze","permalink":"https://ningyu1.github.io/tags/cx-Freeze/"},{"name":"py2app","slug":"py2app","permalink":"https://ningyu1.github.io/tags/py2app/"}]},{"title":"Git SSH Key settings and passphrase reset","date":"2018-01-30T08:10:20.000Z","path":"20180130/58-git-ssh.html","text":"在使用github仓库的时候我们经常会看到clone有两种方式:https、ssh，https的方式使用起来非常简单但是每次在pull、push的时候需要输入密码，一两次还可以忍受但是作为常态是有点崩溃的，这个时候我们可以使用ssh的方式，ssh的好处就是在pull、push的时候可以使用密码也可以不使用密码，但是前提是要设置好ssh key，如果你是Repository的管理员那很好设置，如果不是管理员那就老老实实的使用https的方式，下来我们就说一下使用ssh遇到的问题。 修改用户主目录（home）当出现下图问题时： 是说明你的.ssh目录设置的有问题，关于用户主目录（home）的问题，一般windows机器安装完git后home都会是C:\\Users\\用户名这种目录，但是打开Git bash时它无法识别home目录使用到了其他莫名其妙的目录（有的时候会是不存在的目录或是网络盘符），在这个时候就需要变更home目录，变更的方法如下： 环境：windows Git version 1.x系列如果是Git version 1.x系列，打开profile文件，文件位置：$\\Git\\etc\\profile（$替换成你的盘符）。在profile中找到：HOME=&quot;$(cd &quot;$HOME&quot; ; pwd)&quot;这个位置，在前面增加你想变成的home目录，例如： # normalize HOME to unix pathHOME=&quot;C:\\Users\\用户名&quot;HOME=&quot;$(cd &quot;$HOME&quot; ; pwd)&quot;export PATH=&quot;$HOME/bin:$PATH&quot;export GNUPGHOME=~/.gnupg 当修改好之后，重启Git bash即可，输入cd ~/.ssh，会进入你设置好的目录，在这个目录下生成相关的配置文件，如：.ssh、.gnupg、.bash_history、.gitconfig等，如果以前已经有这些文件可以copy到这个目录下直接使用。 Git version 2.x系列如果是Git version 2.x系列，请设置环境变量，增加HOME的环境变量，目录为：C:\\Users\\用户名（你想设置的目录），随后重启Git bash即可，输入cd ~/.ssh，会进入你设置好的目录。 按照上面步骤修改好之后，出现下图所示就证明修改完成了。如： ssh key设置输入cd ~/.ssh进入home目录使用如下如下方法生成ssh key 可以在Git bash中使用ssh-keygen生成ssh key 还可以使用eclipse的ssh2工具生成，操作如下：Window -&gt; Preferences -&gt; General -&gt; Network Connections -&gt; SSH -&gt; Key Management -&gt; Generate RSA Key 还可以使用TortoiseGit的PuTTY Key Generator工具生成。 方法有很多，生成好的private key用文本编辑器打开复制出来，粘贴到git hub的settings中即可，操作如下：github -&gt; Settings -&gt; SSH and GPG keys -&gt; New SSH key，起个名字粘贴key然后保存即可。 每次都输入passphrase问题当我们在第一次git clone的时候会提示Enter passphrase，这个时候如果输入了密码，那以后pull、push都需要输入这个密码，就像我下图这样： 我们使用ssh就是图个方便不想输入密码，出现这个问题怎么办呢？ 在第一次git clone的时候提示Enter passphrase的时候不要输入密码，直接回车即可，如果输入了密码那就需要重置密码才能解决这个问题。 重置passphrase打开Git bash使用如下命令重置密码 ssh-keygen -p 输入后根据下图提示操作： 这样就完成了重置密码为空的操作了，后面再pull、push的时候都不会再提示输入密码。","tags":[{"name":"git","slug":"git","permalink":"https://ningyu1.github.io/tags/git/"},{"name":"github","slug":"github","permalink":"https://ningyu1.github.io/tags/github/"},{"name":"ssh key","slug":"ssh-key","permalink":"https://ningyu1.github.io/tags/ssh-key/"},{"name":"passphrase","slug":"passphrase","permalink":"https://ningyu1.github.io/tags/passphrase/"}]},{"title":"CAS Server强制踢人功能实现方式","date":"2018-01-26T07:07:36.000Z","path":"20180126/57-cas-server1.html","text":"前面写过一篇关于CAS Server使用的经验总结，主要总结了CAS Server在使用的时候遇到的一些常见问题，比如说：证书、SLO、集群session处理、自定义用户认证、Ticket持久化等问题，传送门：CAS使用经验总结，纯干货，这次在基础上又增加了一个很常见很普通的问题，那就是踢人功能。 在管理系统这个领域里面踢人功能并不陌生，为了更好的管理用户串用账号，安全等方面考虑，接下来我们就细说一下CAS如何实现踢人的功能。 先说一下踢人功能的场景： 用户A在机器A上登录了APP1，用户A在机器B上登录APP1，在这种情况下后者登录需要踢掉前者的登录状态。 用户A在机器A上登录了APP1，用户B在机器B上登录了APP1，在这种情况下不存在踢人操作。 用户A在机器A上登录了APP1，用户A在机器B上登录了APP2，在这种情况下要分情况了，可以踢也可以不踢，这个就根据产品情况来选择，我们本次测试不能解决这个场景，如何解决我还在摸索中。 要做踢人功能之前先了解一下CAS的认证授权机制是如何完成的？ 我这里直接引用官网的架构图： CAS Server与应用的Session交互图： 其实CAS就是生成维护Ticket信息和应用session做绑定，当然它的Ticket实现还是比较复杂的，有树形关系以及和Service关联关系，从Ticket的源码能看的出来它有root的判断和Service的映射列表。 根据上面对CAS的理解，接下来我们说CAS怎么操作踢人功能？ 踢人功能实现思路在登录认证的时候记录一下，在下次登录获取到登录的人员列表，然后去匹配找出是否存在相同的用户，如果存在相同的用户，就注销掉这个用户的登录信息，这个是常规的思路和做法，但是在CAS里如何去找到切入点来进行判断操作呢？ 我们在上一篇中提到了自定义认证逻辑，那么我们就可以继续在认证的这个切入点去进一步分析。 这里要先搞清楚一个概念：Authentication和Authorization这两者是不同的。 Authentication：字面意思认证，怎么理解这个认证呢？举个例子：我们每个人都有身份证，比如你去买火车票，买火车票需要出示身份证，那这个身份证就是证明你是你自己的凭证，那这个证明的过程就是认证。 Authorization：字面意思授权，怎么理解这个授权呢？举个例子：继续拿买火车票来说，你刚才出示了身份证证明了你自己，然后给了钱买了一张火车票，铁道部给了你一张票，这个票授权了你可以乘坐X车次X座位的权限其他车次你无权乘坐，那么这张票就是证明你确实买了X车次X座位的凭证，这就是授权。 换回系统的角度来说，认证就是验证用户名密码，授权就是验证你能不能操作某个功能的权限。 理解完认证和授权的区别，我们就开始从认证这块的切入点去看如何操作，CAS提供了这个类TicketRegistry它是管理所有Ticket的接口，通过调用TicketRegistry.getTickets()方法可以获取到所有认证用户的凭证。 /** * Retrieve all tickets from the registry. * * @return collection of tickets currently stored in the registry. Tickets * might or might not be valid i.e. expired. */Collection&lt;Ticket&gt; getTickets(); 那有了凭证信息就好更进一步操作。 CAS提供了TicketGrantingTicket，这个类是Ticket接口的一个实现类，可以通过TicketGrantingTicket.getAuthentication().getPrincipal().getId()来获取用户的身份。 /** * @return the unique id for the Principal */String getId(); getId()返回的是登录的用户名，那拿到了用户名就要考虑如何注销的事情了。 刚才说到了它TicketGrantingTicket是Ticket接口的实现类，它的t.markTicketExpired()方法就是标记Ticket过期的动作。 /** * Mark a ticket as expired. */void markTicketExpired(); 光标记过期还不能完成注销操作，还需要通过ticketRegistry.deleteTicket(t.getId())来删除Ticket信息。 /** * Remove a specific ticket from the registry. * If ticket to delete is TGT then related service tickets are removed as well. * * @param ticketId The id of the ticket to delete. * @return the number of tickets deleted including children. */int deleteTicket(String ticketId); 上面的分析过程看上去是可行的，那我们就来测试一下是否可以达到踢人功能的目的。 踢人功能实现过程话不多说直接帖实现代码 /** * 登录成功，踢掉前一个相同登录的人 * * @param username */public void forceLogout(final String username) &#123; TicketRegistry ticketRegistry = (TicketRegistry) ApplicationContextProvider.getApplicationContext().getBean(&quot;ticketRegistry&quot;); final Collection&lt;Ticket&gt; ticketsInCache = ticketRegistry.getTickets(); for (final Ticket ticket : ticketsInCache) &#123; TicketGrantingTicket t = null; try &#123; log.info(&quot;cast TicketGrantingTicketImpl&quot;); t = (TicketGrantingTicketImpl) ticket; &#125; catch (Exception e) &#123; log.error(&quot;cast TicketGrantingTicketImpl is error:&quot;, e); t = ((ServiceTicketImpl) ticket).getGrantingTicket(); &#125; if (t.getAuthentication().getPrincipal().getId().equals(username) &amp;&amp; t.getId() != null) &#123; /*** * 注销方法一 涉及到cookie的删除，但是无法获取response 该方法有待考究 未测试 */ // centralAuthenticationService.destroyTicketGrantingTicket(t.getId()); /*** * 注销方法二 */ // t.expire(); t.markTicketExpired(); ticketRegistry.deleteTicket(t.getId()); &#125; &#125;&#125; 上面的代码放到认证的切入点上调用，切入的位置如下： 项目：cas-site 类：org.apereo.cas.adaptors.jdbc.QueryAndEncodeDatabaseAuthenticationHandler 方法：authenticateUsernamePasswordInternal()的createHandlerResult()之前调用。 代码如下： @Overrideprotected HandlerResult authenticateUsernamePasswordInternal(final UsernamePasswordCredential transformedCredential) throws GeneralSecurityException, PreventedException &#123; if (StringUtils.isBlank(this.sql) || StringUtils.isBlank(this.algorithmName) || getJdbcTemplate() == null) &#123; throw new GeneralSecurityException(&quot;Authentication handler is not configured correctly&quot;); &#125; final String username = transformedCredential.getUsername(); try &#123; // Get password and salt final Map&lt;String, Object&gt; rows = getJdbcTemplate().queryForMap(this.sql, username); final String encodedPassword = rows.get(&quot;password&quot;).toString(); final String dbSalt = rows.get(&quot;salt&quot;).toString(); SaltPasswordEncoder passwordEncoder = new SaltPasswordEncoder(); passwordEncoder.setSalt(dbSalt); if (!passwordEncoder.matches(transformedCredential.getPassword(), encodedPassword)) &#123; throw new FailedLoginException(&quot;Password does not match value on record.&quot;); &#125; // 登录成功，踢掉前一个相同登录的人 forceLogout(username); return createHandlerResult(transformedCredential, this.principalFactory.createPrincipal(username), null); &#125; catch (final IncorrectResultSizeDataAccessException e) &#123; if (e.getActualSize() == 0) &#123; throw new AccountNotFoundException(username + &quot; not found with SQL query&quot;); &#125; else &#123; throw new FailedLoginException(&quot;Multiple records found for &quot; + username); &#125; &#125; catch (final DataAccessException e) &#123; throw new PreventedException(&quot;SQL exception while executing query for &quot; + username, e); &#125;&#125; cas-site项目我已经放入到了github，在这篇《CAS使用经验总结，纯干货》博文中可以找到。 万事俱备只欠东风了，接下来就是启动程序来验证它。 理想很美好，现实很骨感，出现了如下错误： javax.persistence.TransactionRequiredException: No EntityManager with actual transaction available for current thread - cannot reliably process &apos;remove&apos; call at org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke(SharedEntityManagerCreator.java:282) ~[spring-orm-4.3.4.RELEASE.jar:4.3.4.RELEASE] at com.sun.proxy.$Proxy175.remove(Unknown Source) ~[?:?] at org.apereo.cas.ticket.registry.JpaTicketRegistry.removeTicket(JpaTicketRegistry.java:72) ~[cas-server-support-jpa-ticket-registry-5.0.4.jar:5.0.4] at org.apereo.cas.ticket.registry.JpaTicketRegistry.deleteTicketsFromResultList(JpaTicketRegistry.java:214) ~[cas-server-support-jpa-ticket-registry-5.0.4.jar:5.0.4] at org.apereo.cas.ticket.registry.JpaTicketRegistry.deleteTicketGrantingTickets(JpaTicketRegistry.java:244) ~[cas-server-support-jpa-ticket-registry-5.0.4.jar:5.0.4] at org.apereo.cas.ticket.registry.JpaTicketRegistry.deleteSingleTicket(JpaTicketRegistry.java:158) ~[cas-server-support-jpa-ticket-registry-5.0.4.jar:5.0.4] at org.apereo.cas.ticket.registry.AbstractTicketRegistry.deleteTicket(AbstractTicketRegistry.java:125) ~[cas-server-core-tickets-5.0.4.jar:5.0.4] at org.apereo.cas.ticket.registry.AbstractTicketRegistry$$FastClassBySpringCGLIB$$d3c67a11.invoke(&lt;generated&gt;) ~[cas-server-core-tickets-5.0.4.jar:5.0.4] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ~[spring-core-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:651) ~[spring-aop-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.apereo.cas.ticket.registry.JpaTicketRegistry$$EnhancerBySpringCGLIB$$b6d104b8.deleteTicket(&lt;generated&gt;) ~[cas-server-support-jpa-ticket-registry-5.0.4.jar:5.0.4] at org.apereo.cas.ticket.registry.AbstractTicketRegistry$$FastClassBySpringCGLIB$$d3c67a11.invoke(&lt;generated&gt;) ~[cas-server-core-tickets-5.0.4.jar:5.0.4] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ~[spring-core-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:651) ~[spring-aop-4.3.4.RELEASE.jar:4.3.4.RELEASE] at org.apereo.cas.ticket.registry.JpaTicketRegistry$$EnhancerBySpringCGLIB$$ef44b76a.deleteTicket(&lt;generated&gt;) ~[cas-server-support-jpa-ticket-registry-5.0.4.jar:5.0.4] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_31] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_31] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_31] at java.lang.reflect.Method.invoke(Method.java:483) ~[?:1.8.0_31] ps.异常堆栈很长我只截了一部分展示出来。 这个错误是个什么鬼？从异常字面理解：在当前的线程中没有找到可用的事务，无法处理“删除”调用。 这个错误是JPA的错误，因为我的Ticket Registry配置的是JPA的方式，我猜测换成其他方式也会有类似的错误，我去掉JPA采用InMemroy的方式处理Ticket Registry，再次进行测试。 果然出现了类似的错误，如下： javax.persistence.TransactionRequiredException: no transaction is in progress at org.hibernate.internal.SessionImpl.checkTransactionNeeded(SessionImpl.java:3428) ~[hibernate-core-5.2.2.Final.jar:5.2.2.Final] at org.hibernate.internal.SessionImpl.find(SessionImpl.java:3362) ~[hibernate-core-5.2.2.Final.jar:5.2.2.Final] at org.hibernate.internal.SessionImpl.find(SessionImpl.java:3342) ~[hibernate-core-5.2.2.Final.jar:5.2.2.Final] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_31] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_31] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_31] at java.lang.reflect.Method.invoke(Method.java:483) ~[?:1.8.0_31] at org.springframework.orm.jpa.ExtendedEntityManagerCreator$ExtendedEntityManagerInvocationHandler.invoke(ExtendedEntityManagerCreator.java:347) ~[spring-orm-4.3.4.RELEASE.jar:4.3.4.RELEASE] at com.sun.proxy.$Proxy175.find(Unknown Source) ~[?:?] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_31] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_31] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_31] at java.lang.reflect.Method.invoke(Method.java:483) ~[?:1.8.0_31] at org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke(SharedEntityManagerCreator.java:298) ~[spring-orm-4.3.4.RELEASE.jar:4.3.4.RELEASE] at com.sun.proxy.$Proxy175.find(Unknown Source) ~[?:?] 说白了就是没有开启事务被禁止操作了。 这个怎么解决？cas-site采用的是overlays的方式构建，要看具体功能就要翻CAS的源码来看它是如何控制事务的。 于是去翻CAS的源码，翻源码也要讲究技巧的，要不然翻一天都翻不到关键点。 我们这里需要找如何开启事务的代码，还好CAS使用的是Spring来管理事务的，Spring的事务开启无非就这两种：一种是AOP方式，一种是手动方式。 那么AOP的方式可以使用注解（Annotation）也可以使用XML的配置去做。 CAS v5.0.4使用的Spring Boot的方式构建，说白了就是使用编程（Java Config）的方式替换XML的配置方式。而且我们使用的Ticket Registry是JPA，JPA的操作肯定要处理事务的，因此我们就锁定到注解（Annotation）的方式和JPA的实现上去找。 最终目标定位到了cas-server-support-jpq-ticket-registry-5.0.4.jar这个包上。 查看这个包的org.apereo.cas.ticket.registry.JpaTicketRegistry类代码 /** * JPA implementation of a CAS &#123;@link TicketRegistry&#125;. This implementation of * ticket registry is suitable for HA environments. * * @author Scott Battaglia * @author Marvin S. Addison * @since 3.2.1 */@EnableTransactionManagement(proxyTargetClass = true)@Transactional(transactionManager = &quot;ticketTransactionManager&quot;, readOnly = false)public class JpaTicketRegistry extends AbstractTicketRegistry &#123;.....................其余的省略..............................&#125; 很明显就是我们说的注解（Annotation）的使用方式，我们再次修改代码。 踢人功能代码重构@EnableTransactionManagement(proxyTargetClass = true)开启代理的方式，那我们就要抽一个接口和一个实现类来做，这里的具体原因就不多说了做多了都明白。 @Transactional(transactionManager = &quot;ticketTransactionManager&quot;, readOnly = false)在实现类上直接使用这个注解方式。 直接贴重构后的代码： 新建接口ForceLogoutManager public interface ForceLogoutManager &#123; public void doLogout(final String username);&#125; 新建实现类ForceLogoutManagerImpl import java.util.Collection;import org.apereo.cas.ticket.ServiceTicketImpl;import org.apereo.cas.ticket.Ticket;import org.apereo.cas.ticket.TicketGrantingTicket;import org.apereo.cas.ticket.TicketGrantingTicketImpl;import org.apereo.cas.ticket.registry.TicketRegistry;import org.apereo.cas.util.ApplicationContextProvider;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Component;import org.springframework.transaction.annotation.EnableTransactionManagement;import org.springframework.transaction.annotation.Transactional;@EnableTransactionManagement(proxyTargetClass = true)@Transactional(transactionManager = &quot;ticketTransactionManager&quot;, readOnly = false)@Component(&quot;forceLogoutManager&quot;)public class ForceLogoutManagerImpl implements ForceLogoutManager &#123; private final Logger log = LoggerFactory.getLogger(this.getClass()); /** * 登录成功，踢掉前一个相同登录的人 * * @param username */ public void doLogout(final String username) &#123; TicketRegistry ticketRegistry = (TicketRegistry) ApplicationContextProvider.getApplicationContext() .getBean(&quot;ticketRegistry&quot;); final Collection&lt;Ticket&gt; ticketsInCache = ticketRegistry.getTickets(); for (final Ticket ticket : ticketsInCache) &#123; TicketGrantingTicket t = null; try &#123; log.info(&quot;cast TicketGrantingTicketImpl&quot;); t = (TicketGrantingTicketImpl) ticket; &#125; catch (Exception e) &#123; log.error(&quot;cast TicketGrantingTicketImpl is error:&quot;, e); t = ((ServiceTicketImpl) ticket).getGrantingTicket(); &#125; if (t.getAuthentication().getPrincipal().getId().equals(username) &amp;&amp; t.getId() != null) &#123; /*** * 注销方法一 涉及到cookie的删除，但是无法获取response 该方法有待考究 未测试 */ // centralAuthenticationService.destroyTicketGrantingTicket(t.getId()); /*** * 注销方法二 */ // t.expire(); t.markTicketExpired(); ticketRegistry.deleteTicket(t.getId()); &#125; &#125; &#125;&#125; 修改org.apereo.cas.adaptors.jdbc.QueryAndEncodeDatabaseAuthenticationHandler类authenticateUsernamePasswordInternal方法 public ForceLogoutManager getForceLogoutManager() &#123; return (ForceLogoutManager) ApplicationContextProvider.getApplicationContext().getBean(&quot;forceLogoutManager&quot;);&#125;@Overrideprotected HandlerResult authenticateUsernamePasswordInternal(final UsernamePasswordCredential transformedCredential) throws GeneralSecurityException, PreventedException &#123; if (StringUtils.isBlank(this.sql) || StringUtils.isBlank(this.algorithmName) || getJdbcTemplate() == null) &#123; throw new GeneralSecurityException(&quot;Authentication handler is not configured correctly&quot;); &#125; final String username = transformedCredential.getUsername(); try &#123; // Get password and salt final Map&lt;String, Object&gt; rows = getJdbcTemplate().queryForMap(this.sql, username); final String encodedPassword = rows.get(&quot;password&quot;).toString(); final String dbSalt = rows.get(&quot;salt&quot;).toString(); SaltPasswordEncoder passwordEncoder = new SaltPasswordEncoder(); passwordEncoder.setSalt(dbSalt); if (!passwordEncoder.matches(transformedCredential.getPassword(), encodedPassword)) &#123; throw new FailedLoginException(&quot;Password does not match value on record.&quot;); &#125; // 登录成功，踢掉前一个相同登录的人 getForceLogoutManager().doLogout(username); return createHandlerResult(transformedCredential, this.principalFactory.createPrincipal(username), null); &#125; catch (final IncorrectResultSizeDataAccessException e) &#123; if (e.getActualSize() == 0) &#123; throw new AccountNotFoundException(username + &quot; not found with SQL query&quot;); &#125; else &#123; throw new FailedLoginException(&quot;Multiple records found for &quot; + username); &#125; &#125; catch (final DataAccessException e) &#123; throw new PreventedException(&quot;SQL exception while executing query for &quot; + username, e); &#125;&#125; 再次启动测试。 很顺利调用没有任何问题，到这里基于CAS v5.0.4的踢人功能的处理过程就整理完毕了。 最后还有一句话，我的愿望是：世界和平，快乐编程每一天，keep real！","tags":[{"name":"CAS","slug":"CAS","permalink":"https://ningyu1.github.io/tags/CAS/"},{"name":"SLO","slug":"SLO","permalink":"https://ningyu1.github.io/tags/SLO/"},{"name":"Single Logout","slug":"Single-Logout","permalink":"https://ningyu1.github.io/tags/Single-Logout/"},{"name":"Ticket","slug":"Ticket","permalink":"https://ningyu1.github.io/tags/Ticket/"},{"name":"Ticket Registry","slug":"Ticket-Registry","permalink":"https://ningyu1.github.io/tags/Ticket-Registry/"},{"name":"Session Centralized Storage","slug":"Session-Centralized-Storage","permalink":"https://ningyu1.github.io/tags/Session-Centralized-Storage/"},{"name":"Cookie","slug":"Cookie","permalink":"https://ningyu1.github.io/tags/Cookie/"},{"name":"CAS Cluster","slug":"CAS-Cluster","permalink":"https://ningyu1.github.io/tags/CAS-Cluster/"},{"name":"CAS Server","slug":"CAS-Server","permalink":"https://ningyu1.github.io/tags/CAS-Server/"},{"name":"ForceLogout","slug":"ForceLogout","permalink":"https://ningyu1.github.io/tags/ForceLogout/"}]},{"title":"Trouble Shooting —— HTTPS(SSL)站点使用WebSocket(ws)出现SecurityError问题","date":"2018-01-25T09:04:36.000Z","path":"20180125/56-websocket-ssl.html","text":"最近发生了一个问题我觉得挺有意思的，所以针对这个问题总结一下。 最近公司服务上了https(SSL)，在https(SSL)的环境下呢本因为可以愉快的玩耍，但是后来发现程序有使用websocket（ws://domain.com），这里就有朋友想了使用ws跟ssl有什么关系？我可以很明确的告诉你当然有关系。 当你的站点使用的是http的时候，使用ws可以很愉快的玩耍。当换成了https(SSL)那么问题来了。 在chrome下是测试没有问题可以正常使用，但是在ie下就出现了问题，报SecurityError的错误，那这个错误是什么原因呢? WebSocket connection to &apos;ws://domain.com/websocket&apos; failed: Error in connection establishment: net::ERR_CONNECTION_REFUSED 应该是每个浏览器对websocket的支持不一样或者说每个浏览器的安全沙箱不太一样，禁止了一些用法，各大浏览器对websocket的支持情况请看：https://caniuse.com/#search=websocket 无意中看到了mozilla的websocket支持详细说明如下： Security considerationsWebSockets should not be used in a mixed content environment; that is, you shouldn’t open a non-secure WebSocket connection from a page loaded using HTTPS or vice-versa. In fact, some browsers explicitly forbid this, including Firefox 8 and later. 具体地址：https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API/Writing_WebSocket_client_applications 意思呢就是，ws与http对应，wss与https对应，如果站点使用的是https那就必须使用wss来做websocket请求不能使用ws来请求，不允许混合的方式使用。 看到这个就更加明确了问题所在：安全机制问题，最好不要混合使用避免奇怪的问题。 于是就开启了wss服务的使用路程。 如果你的wss服务是使用ip方式访问的，那么需要制作一个对应这个ip的证书，可以使用openssl生成自签名证书，但是不推荐使用ip的方式访问WebSocket。 如果你的wss服务是使用域名方式访问的，那么需要制作一个对应这个域名证书（最好是通配符域名证书），这样在构建wss服务的时候将证书配置进去。 构建wss服务有很多种方式，我这里提供一种比较简单的方式。 使用nginx提供ssl代理保留以前的ws服务提供方式不做任何变更，增加一个nginx开启ssl代理，配置跟常规的ssl配置有一些细微的变化，那就是header会有一些变化，websocket需要指定header：Upgrade和http version：1.1 ，因此我这里给出配置详情： server &#123; listen 443 ssl; server_name your.domain.com;#你的域名，如果没有域名就去掉 ssl on; #ssl_certificate 127.0.0.1.crt; #ssl_certificate_key 127.0.0.1.key; ssl_certificate your.domain.com.pem;#这里可以使用pem文件和crt文件 ssl_certificate_key your.domain.com.key; ssl_session_timeout 5m; ssl_session_cache shared:SSL:50m; ssl_protocols SSLv3 SSLv2 TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP; location / &#123; proxy_pass http://127.0.0.1:19808;# 这里换成你想转发的ws服务地址即可 proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;Upgrade&quot;; proxy_set_header X-Real-IP $remote_addr; &#125;&#125; 将证书文件放到conf同级目录即可，如果证书放在其他目录，需要修改ssl_certificate、ssl_certificate_key指定的位置。 这样就可以不用修改以前的ws服务来提供wss服务。 修改ws的请求方式为wsswss://your.domain.com ws服务这里也简单的说一下，有很多服务都可以构建ws服务，nginx、Workerman都可以，或者自己写程序开启ws服务。方式很多看个人喜好和公司的项目背景。 附录 nginx官方文档 Openssl生成自签名证书，简单步骤 mozilla的websocket支持说明 各大浏览器对websocket的支持情况 常见错误如果在ie下报如下错误： IE Network Error 12038, 证书中的主名称无效或不相符 那是因为证书与请求地址不匹配导致的错误，在chrome测试它的https验证不会这么严格，在ie下https验证很严格（坑爹的ie）。","tags":[{"name":"ssl","slug":"ssl","permalink":"https://ningyu1.github.io/tags/ssl/"},{"name":"WebSocket","slug":"WebSocket","permalink":"https://ningyu1.github.io/tags/WebSocket/"},{"name":"wss","slug":"wss","permalink":"https://ningyu1.github.io/tags/wss/"},{"name":"ws","slug":"ws","permalink":"https://ningyu1.github.io/tags/ws/"},{"name":"SecurityError","slug":"SecurityError","permalink":"https://ningyu1.github.io/tags/SecurityError/"}]},{"title":"生产环境如何快速跟踪、分析、定位问题-Java","date":"2018-01-23T06:36:36.000Z","path":"20180123/55-java-jvm-analysis.html","text":"我相信做技术的都会遇到过这样的问题，生产环境服务遇到宕机的情况下如何去分析问题？比如说JVM内存爆掉、CPU持续高位运行、线程被夯住或线程deadlocks，面对这样的问题，如何在生产环境第一时间跟踪分析与定位问题很关键。下来让我们看看通过如下步骤在第一时间分析问题。 CPU占用较高场景收集当前CPU占用较高的线程信息，执行如下命令： top -H -p PID -b -d 1 -n 1 &gt; top.log或top -H -p PID 结果如下： 上图显示的都是某一个进程内的线程信息，找到cpu消耗最高的线程id，再配合jstack来分析耗cpu的代码位置，那如何分析呢？ 先执行jstack获取线程信息 jstack -l PID &gt; jstackl.log 将PID（29978）转成16进制：0x751a，16进制转换工具很多可以在线随便搜索一个或者基本功好的自己计算。 打开jstackl.log，查找nid=0x751a的信息，这样就定位到了具体的代码位置，这里由于是安全原因我就不贴图了。 通过上面的步骤就可以轻松的定位那个线程导致cpu过高，当然也可以通过其他方式来定位，下面介绍一个快捷的方式 #线程cpu占用#!/bin/bash[ $# -ne 1 ] &amp;&amp; exit 1jstack $1 &gt;/tmp/jstack.logfor cpu_tid in `ps -mp $1 -o THREAD,tid,time|sort -k2nr| sed -n &apos;2,15p&apos; |awk &apos;&#123;print$2&quot;_&quot;$(NF-1)&#125;&apos;`;docpu=`echo $cpu_tid | cut -d_ -f1`tid=`echo $cpu_tid | cut -d_ -f2`xtid=`printf &quot;%x\\n&quot; $tid`echo -e &quot;\\033[31m========================$xtid $cpu%\\033[0m&quot;cat /tmp/jstack.log | sed -n -e &quot;/0x$xtid/,/^$/ p&quot;#cat /tmp/jstack.log | grep &quot;$xtid&quot; -A15donerm /tmp/jstack.log 上述命令会以百分比的方式来显示每个线程的cpu消耗百分比，这里我就不贴图了，谁用谁知道。 内存消耗过高场景收集当前活跃对象数据量信息，执行以下命令获取 jmap -histo:live pid &gt; jmaplive.log ps. jmap -histo:live 数据可以多进行几次，比如说间隔几分钟输出一次，然后对比两个文件的差异可以看出gc回收的对象，如果多次结果没有差异并且gc频繁执行，证明剩余对象在引用无法gc回收，这时就需要对服务进行限流给服务喘气的机会。 或者收集dump信息，通常这种获取方式需要较长时间执行，并产生大容量的dump文件，我们会考虑逐步废掉通过这个文件来分析。执行以下命令获取 jmap -dump:file=./dump.mdump pid dump文件通过MAT工具来进行内存泄漏分析。 线程、内存分析工具上面说过通过jstack生成的线程文件是可以通过工具来直接打开可视化分析的，这里我推荐使用：tda（Thread Dump Analyzer）这个工具可以自行搜索下载。 通过jmap -dump生成的dump文件也是可以通过工具来进行可视化分析的，这里我推荐使用MAT（Memory Analysis Tools）它可以通过eclipse plugin的方式使用或者独立的下载安装包使用。","tags":[{"name":"Java","slug":"Java","permalink":"https://ningyu1.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://ningyu1.github.io/tags/JVM/"},{"name":"CPU TOP","slug":"CPU-TOP","permalink":"https://ningyu1.github.io/tags/CPU-TOP/"},{"name":"Jstack","slug":"Jstack","permalink":"https://ningyu1.github.io/tags/Jstack/"},{"name":"Jmap","slug":"Jmap","permalink":"https://ningyu1.github.io/tags/Jmap/"},{"name":"JVM dump","slug":"JVM-dump","permalink":"https://ningyu1.github.io/tags/JVM-dump/"}]},{"title":"CAS使用经验总结，纯干货","date":"2018-01-19T08:25:36.000Z","path":"20180119/54-cas-server.html","text":"最近在处理公司项目对接到CAS server，在使用CAS发生了很多问题，下面整理一下遇到的问题与解决方式，希望可以帮助到需要的工程师们 CAS它是什么？它能做什么？这些我就不概述了，自行去搜索了解，https://baike.baidu.com/item/CAS/1329561 我们在使用CAS的时候基本都会遇到如下的几种问题： 证书问题 Client接入配置 SLO（Single Logout） CAS callback回调问题 Cookie问题 用户数据源以及认证问题 CAS Server Ticket持久化问题 Client Server集群模式下session问题 还有一些是公司内部项目框架集成问题这里就不多说了。 以下总结都是基于CAS v5.0.4版本测试 我用的CAS Server是通过overlays改造后的项目，为什么需要修改原有的CAS Server呢？ 我相信每个公司都有一些特殊的需求比如说： 对登录页面的修改 自有的密码加密验证方式 新老项目架构参差不齐 使用公司自有用户数据源 等等很多问题都需要对CAS Server进行改造 这里我将改造的CAS Server放到github上： 项目地址：cas-site &nbsp;&nbsp;&nbsp; 下面具体说一下上述的问题将如何来分析并解决 证书问题如果你的服务不打算使用SSL那请跳过这段说明。 一般公司项目会有很多域名大概都是子域名的方式，例如：account.xxxx.com,login.xxxx.com，那么最好使用通配符证书，为什么呢？这样你的cas server上配置一个通配符证书即可，如果没有使用通配符证书那cas server上要配置所有授信域名的证书，这样就很麻烦，除非一些历史问题没办法才会导入多个证书，一般使用通配符证书。 我使用的是自签名的通配符证书，具体自签名证书如何生成可以查看我之前写的文章： 《Openssl生成自签名证书，简单步骤》中讲述了如何生成自签名证书。 《使用自签名证书，简单步骤》中讲述了如何使用自签名证书。 《Java访问SSL地址，使用证书方式和免验证证书方式》中讲述了Java访问ssl使用证书方式和免验证证书方式。 ps.这里需要注意的是在制作单域名证书和通配符域名证书的区别是在：Common Name输入的时候，例如： 单域名证书：Common Name：account.xxxx.ccom通配符域名证书：Common Name：*.xxxx.com 将制作好的证书文件通过keytool导入到jdk下即可，或使用InstallCert来生成文件copy到jdk下，具体可以参考文章：《使用自签名证书，简单步骤》 证书放在：%JAVA_HOME%\\jre\\lib\\security 我们cas server使用的jdk1.8，client服务大多是jdk1.7，因此在证书处理上要注意这个细节，上面文章中有明确说明 如果需要使用Docker构建，可以参考我写好的Dockerfile，在cas-site项目下Dockerfile文件 Client接入配置接入cas的client端配置非常简单，可以使用spring framework对接cas方式，也可以使用spring security对接cas方式，或者其他支持cas的第三方框架，自己对接配置非常简单只需要配置SingleSignOutFilter和SingleSignOutHttpSessionListener org.jasig.cas.client.session.SingleSignOutFilter：解决Logout清空TGC和session信息 org.jasig.cas.client.session.SingleSignOutHttpSessionListener：session监听 这里在对接方面就不做过多的介绍了。 SLO（Single Logout）SLO是个什么？ 通俗点讲就是：浏览器多个tab页开启不同的APP（使用同一个用户登录），在某一个APP里进行登出操作，其余APP应该一起登出 CAS Server默认是开启SLO功能，如果想要关闭这个功能可以通过设置application.properties文件中的参数来关闭，具体如下： # 是否禁用SLO功能，true为禁用SLO功能cas.slo.disabled=true# 使用采用异步方式进行callbackcas.slo.asynchronous=true 这里需要注意Logout时服务重定向需要开启： # Logout时服务重定向cas.logout.followServiceRedirects=true CAS Server在进行异步回调时会忽略所有的错误来保证所有APP都能接收到Server发出的logout请求，因此在遇到错误时不开启trace级别日志是看不到错误信息的。 如果你的client端能看到接下来的章节（CAS callback回调问题） 说到的日志信息那就证明回调是没有问题的。 CAS callback回调问题CAS认证过程需要server端和client端来回调用，如果发现callback回调有问题多半是第一步证书问题导致，可以开启日志trace级别查看cas的日志来排除问题。 cas回调有三种情况: 一个是授权的时候进行回调信息如下 2018-01-19 11:44:28.419 [http-apr-8080-exec-9] TRACE org.jasig.cas.client.session.SingleSignOutHandler - Received a token request2018-01-19 11:44:28.419 [http-apr-8080-exec-9] DEBUG org.jasig.cas.client.session.SingleSignOutHandler - Recording session for token ST-250-AouhaxqAjvmh5sfaP3Yz-8ec54e2666082018-01-19 11:44:28.419 [http-apr-8080-exec-9] DEBUG c.j.f.c.s.storage.RedisBackedSessionMappingStorage - Attempting to remove Session=[8F24552DD446F669B7A522B1A8A0C86D]2018-01-19 11:44:28.419 [http-apr-8080-exec-9] DEBUG c.j.f.c.s.storage.RedisBackedSessionMappingStorage - No mapping for session found. Ignoring.2018-01-19 11:44:28.420 [http-apr-8080-exec-9] DEBUG o.j.c.c.validation.Cas20ServiceTicketValidator - Placing URL parameters in map.2018-01-19 11:44:28.420 [http-apr-8080-exec-9] DEBUG o.j.c.c.validation.Cas20ServiceTicketValidator - Calling template URL attribute map.2018-01-19 11:44:28.420 [http-apr-8080-exec-9] DEBUG o.j.c.c.validation.Cas20ServiceTicketValidator - Loading custom parameters from configuration.2018-01-19 11:44:28.420 [http-apr-8080-exec-9] DEBUG o.j.c.c.validation.Cas20ServiceTicketValidator - Constructing validation url: https://login.dev.xxx.com.cn/serviceValidate?ticket=ST-250-AouhaxqAjvmh5sfaP3Yz-8ec54e266608&amp;service=https%3A%2F%2Faccount.dev.xxx.com.cn%2Fcas_security_check_2018-01-19 11:44:28.420 [http-apr-8080-exec-9] DEBUG o.j.c.c.validation.Cas20ServiceTicketValidator - Retrieving response from server.2018-01-19 11:44:28.460 [http-apr-8080-exec-9] DEBUG o.j.c.c.validation.Cas20ServiceTicketValidator - Server response: &lt;cas:serviceResponse xmlns:cas=&apos;http://www.yale.edu/tp/cas&apos;&gt; &lt;cas:authenticationSuccess&gt; &lt;cas:user&gt;admin&lt;/cas:user&gt; &lt;/cas:authenticationSuccess&gt;&lt;/cas:serviceResponse&gt; 一个是SLO时清理session的回调信息如下 2018-01-19 11:44:45.484 [http-apr-8080-exec-5] TRACE org.jasig.cas.client.session.SingleSignOutHandler - Received a back channel logout request2018-01-19 11:44:45.484 [http-apr-8080-exec-5] DEBUG org.jasig.cas.client.util.CommonUtils - safeGetParameter called on a POST HttpServletRequest for Restricted Parameters. Cannot complete check safely. Reverting to standard behavior for this Parameter2018-01-19 11:44:45.485 [http-apr-8080-exec-5] TRACE org.jasig.cas.client.session.SingleSignOutHandler - Logout request:&lt;samlp:LogoutRequest xmlns:samlp=&quot;urn:oasis:names:tc:SAML:2.0:protocol&quot; ID=&quot;LR-79-M3OyvVsRH7Ft1gRVaBfeuBCAj4K1JEDnndt&quot; Version=&quot;2.0&quot; IssueInstant=&quot;2018-01-19T11:44:45Z&quot;&gt;&lt;saml:NameID xmlns:saml=&quot;urn:oasis:names:tc:SAML:2.0:assertion&quot;&gt;@NOT_USED@&lt;/saml:NameID&gt;&lt;samlp:SessionIndex&gt;ST-250-AouhaxqAjvmh5sfaP3Yz-8ec54e266608&lt;/samlp:SessionIndex&gt;&lt;/samlp:LogoutRequest&gt;2018-01-19 11:44:45.485 [http-apr-8080-exec-5] DEBUG c.j.f.c.s.storage.RedisBackedSessionMappingStorage - Attempting to remove Session=[8F24552DD446F669B7A522B1A8A0C86D]2018-01-19 11:44:45.485 [http-apr-8080-exec-5] DEBUG c.j.f.c.s.storage.RedisBackedSessionMappingStorage - Found mapping for session. Session Removed.2018-01-19 11:44:45.486 [http-apr-8080-exec-5] DEBUG org.jasig.cas.client.session.SingleSignOutHandler - Invalidating session [8F24552DD446F669B7A522B1A8A0C86D] for token [ST-250-AouhaxqAjvmh5sfaP3Yz-8ec54e266608] 还有一种也是SLO时清理session的回调和上面的有什么区别呢？ 上面的SLO是back channel logout方式，还有一种方式：front channel logout，后者是cas新版本提供的新方式，我这里没有使用，具体可以参考官方说明：https://apereo.github.io/cas/5.0.x/installation/Logout-Single-Signout.html#turning-off-single-logout 开启trace日志查看回调是否发生错误来解决回调不生效问题 Cookie问题当使用单个域名时会出现Cookie清理问题从而导致SLO失效，因为CAS Server生成TGC时如果不设置cookie domain它会写在对接的service所在的域名下，最好的方式是让Cookie写在根域名的根Path（/）下，在CAS server端配置TGC的domain以及其他cookie参数，具体参考： cas.tgc.path=/cas.tgc.maxAge=-1cas.tgc.domain=your.domain.com#cas.tgc.signingKey=cas.tgc.name=TGC#cas.tgc.encryptionKey=cas.tgc.secure=truecas.tgc.httpOnly=truecas.tgc.rememberMeMaxAge=1209600cas.tgc.cipherEnabled=true 具体说明查看官方文档：https://apereo.github.io/cas/5.0.x/installation/Configuration-Properties.html#ticket-granting-cookie 举个例子理解一下我有三个APP域名分别为：https://account.domain.comhttps://login.domain.comhttps://app.domain.com 我生成的通配符证书域名为：*.domain.com 我三个APP在部署时jdk下放通配符域名证书 这样修改tgc配置为： # cookie写的路径 / 为根域名下cas.tgc.path=/# cookie有效期，-1 为关闭浏览器自动清空cas.tgc.maxAge=-1# cookie写在那个域名下cas.tgc.domain=domain.com# cookie的名称cas.tgc.name=TGC# cookie开启器安全模式sslcas.tgc.secure=true# cookie禁止js调用cas.tgc.httpOnly=true# 这两个采用默认配置即可cas.tgc.rememberMeMaxAge=1209600cas.tgc.cipherEnabled=true 用户数据源以及认证问题CAS在这方面留了很多扩展的地方，而且很方便的配置就可以支持自定义 数据源支持的方式也有很多种（jdbc、mongodb、RestStorage、GIT、等）这里就不一一介绍了认证方式支持的方式也很多种（Basic、OAuth2.0|1.0、Google Authenticator、LDAP、REST、OpenID、SPNEGO、等）这里就不一一介绍了 具体可以查看官方说明对应的配置：https://apereo.github.io/cas/5.0.x/installation/Configuration-Properties.html 我使用的是jdbc方式 具体可以去github上查看cas-site源码：cas-site CAS Server Ticket持久化问题Ticket持久化方式也有很多中（JPA、Couchbase、Hazelcast、Infinispan、InMemory、Ehcache、Ignite、Memcached），默认方式（inMemory基于内存的），下面我给出JAP方式的配置参数： cas.ticket.registry.jpa.jpaLockingTimeout=3600cas.ticket.registry.jpa.healthQuery=SELECT 1cas.ticket.registry.jpa.isolateInternalQueries=falsecas.ticket.registry.jpa.url=jdbc:mysql://127.0.0.1:3306/cas?useUnicode=true&amp;characterEncoding=UTF-8&amp;noAccessToProcedureBodies=truecas.ticket.registry.jpa.failFast=truecas.ticket.registry.jpa.dialect=org.hibernate.dialect.MySQL5Dialectcas.ticket.registry.jpa.leakThreshold=10cas.ticket.registry.jpa.jpaLockingTgtEnabled=falsecas.ticket.registry.jpa.batchSize=1#cas.ticket.registry.jpa.defaultCatalog=cas.ticket.registry.jpa.defaultSchema=cascas.ticket.registry.jpa.user=rootcas.ticket.registry.jpa.ddlAuto=validatecas.ticket.registry.jpa.password=root@123456cas.ticket.registry.jpa.autocommit=truecas.ticket.registry.jpa.driverClass=com.mysql.jdbc.Drivercas.ticket.registry.jpa.idleTimeout=5000# 下面的参数根据实际情况选择使用# 连接池# cas.ticket.registry.jpa.pool.suspension=false# cas.ticket.registry.jpa.pool.minSize=6# cas.ticket.registry.jpa.pool.maxSize=18# cas.ticket.registry.jpa.pool.maxWait=2000# 签名与数据加解密密钥和算法# cas.ticket.registry.jpa.crypto.signing.key=# cas.ticket.registry.jpa.crypto.signing.keySize=512# cas.ticket.registry.jpa.crypto.encryption.key=# cas.ticket.registry.jpa.crypto.encryption.keySize=16# cas.ticket.registry.jpa.crypto.alg=AES 这里需要注意的是，以上给出的配置参数是建议值，ddlauto默认值是create-drop，可选值有（create、create-drop、validate、update），具体含义可以查看官方文档：https://apereo.github.io/cas/5.0.x/installation/JPA-Ticket-Registry.html，建议使用validate的方式，使用validate需要自己创建表，一共四张表下面贴出建表语句： CREATE TABLE `locks` (`application_id` varchar(255) NOT NULL,`expiration_date` datetime DEFAULT NULL,`unique_id` varchar(255) DEFAULT NULL,`lockVer` int(11) NOT NULL DEFAULT &apos;0&apos;,PRIMARY KEY (`application_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8CREATE TABLE `oauth_tokens` (`TYPE` varchar(31) NOT NULL,`ID` varchar(255) NOT NULL,`NUMBER_OF_TIMES_USED` int(11) DEFAULT NULL,`CREATION_TIME` datetime DEFAULT NULL,`EXPIRATION_POLICY` longblob NOT NULL,`LAST_TIME_USED` datetime DEFAULT NULL,`PREVIOUS_LAST_TIME_USED` datetime DEFAULT NULL,`AUTHENTICATION` longblob NOT NULL,`SERVICE` longblob NOT NULL,PRIMARY KEY (`ID`)) ENGINE=InnoDB DEFAULT CHARSET=utf8CREATE TABLE `serviceticket` (`TYPE` varchar(31) NOT NULL,`ID` varchar(255) NOT NULL,`NUMBER_OF_TIMES_USED` int(11) DEFAULT NULL,`CREATION_TIME` datetime DEFAULT NULL,`EXPIRATION_POLICY` longblob NOT NULL,`LAST_TIME_USED` datetime DEFAULT NULL,`PREVIOUS_LAST_TIME_USED` datetime DEFAULT NULL,`FROM_NEW_LOGIN` bit(1) NOT NULL,`TICKET_ALREADY_GRANTED` bit(1) NOT NULL,`SERVICE` longblob NOT NULL,`ticketGrantingTicket_ID` varchar(255) DEFAULT NULL,PRIMARY KEY (`ID`),KEY `FK60oigifivx01ts3n8vboyqs38` (`ticketGrantingTicket_ID`),CONSTRAINT `FK60oigifivx01ts3n8vboyqs38` FOREIGN KEY (`ticketGrantingTicket_ID`) REFERENCES `ticketgrantingticket` (`ID`)) ENGINE=InnoDB DEFAULT CHARSET=utf8CREATE TABLE `ticketgrantingticket` (`TYPE` varchar(31) NOT NULL,`ID` varchar(255) NOT NULL,`NUMBER_OF_TIMES_USED` int(11) DEFAULT NULL,`CREATION_TIME` datetime DEFAULT NULL,`EXPIRATION_POLICY` longblob NOT NULL,`LAST_TIME_USED` datetime DEFAULT NULL,`PREVIOUS_LAST_TIME_USED` datetime DEFAULT NULL,`AUTHENTICATION` longblob NOT NULL,`EXPIRED` bit(1) NOT NULL,`PROXIED_BY` longblob,`SERVICES_GRANTED_ACCESS_TO` longblob NOT NULL,`ticketGrantingTicket_ID` varchar(255) DEFAULT NULL,PRIMARY KEY (`ID`),KEY `FKiqyu3qw2fxf5qaqin02mox8r4` (`ticketGrantingTicket_ID`),CONSTRAINT `FKiqyu3qw2fxf5qaqin02mox8r4` FOREIGN KEY (`ticketGrantingTicket_ID`) REFERENCES `ticketgrantingticket` (`ID`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 其他参数含义可以查看官方配置说明：https://apereo.github.io/cas/5.0.x/installation/JPA-Ticket-Registry.html Client Server集群模式下session问题当我们CAS Server准备好后，就要处理Client接入的问题，如果我们的Client服务是单机模式那没有任何问题，一旦放到集群环境下就会发生如下有意思的事情。 我前面说了CAS在授权回调时会做几件事，第一TG保存到Cookie，第二个保存ticketid对应的session关系以及session对象。 那么如果我们的Client服务是集群的会发生什么？ 举个例子： 我的APP服务部署了2台服务（S1、S2）采用loadbalance映射一个域名出去访问，当CAS授权回调时被loadbalance路由到S1上，SingleSignOutFilter以及SingleSignOutHandler进行了TGC和SessionMappingStorage，默认的持久化方式是hash的方式，也就是说本地map方式，这样在下次访问到APP时被loadbalance路由到S2上就会发生什么有意思的事情呢？我相信做过分布式服务的应该都能猜出来什么问题。 APP：我没找到cas认证信息，跳转到cas login页面 CAS：我找到了你APP已经做过认证了，跳转到APP并且给你上次认证的ticlet APP：我真没找到你的认证信息，跳转到cas login页面 CAS：你真的已经做过认证了，跳转到APP并且给你上次认证的ticlet 这样就会发生无线跳转死循环问题。 那如何解决上面的问题呢？ 在分布式的环境下几乎服务都是集群的，甚至有很多公司会做异地多活等等。那么在集群环境下如何解决cas授权持久化的问题呢？很简单重新实现一个cas-client的SessionMappingStorage，这里可以使用很多方式，比如说：放到db、nosql的存储上（mongodb、redis）、memcache、分布式文件存储都可以。 我这里采用的是redis，而且我们dev和qa环境采用单机模式，stage和prod环境使用集群模式，因此我还做了集群和本地都兼容的方式，话不多说直接贴出实现代码 import java.util.HashMap;import java.util.Map;import javax.servlet.http.HttpSession;import org.jasig.cas.client.session.SessionMappingStorage;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import xxxxxxxx.framework.redis.client.IRedisClient;public class RedisBackedSessionMappingStorage implements SessionMappingStorage &#123; private final Logger logger = LoggerFactory.getLogger(getClass()); /** * Maps the ID from the CAS server to the Session. */ private final Map&lt;String, HttpSession&gt; MANAGED_SESSIONS = new HashMap&lt;String, HttpSession&gt;(); /** * Maps the Session ID to the key from the CAS Server. */ private final Map&lt;String, String&gt; ID_TO_SESSION_KEY_MAPPING = new HashMap&lt;String, String&gt;(); private final static String NAME_SPACE = &quot;CAS&quot;; private IRedisClient redisClient; /** * 在dev和qa环境使用单机模式：hash * 在stage和prod环境使用集群模式：redis */ private String storageMode = &quot;hash&quot;; /** * 获取 redisClient * @return the redisClient */ public IRedisClient getRedisClient() &#123; return redisClient; &#125; /** * 设置 redisClient * @param redisClient the redisClient to set */ public void setRedisClient(IRedisClient redisClient) &#123; this.redisClient = redisClient; &#125; /** * 获取 storageMode * @return the storageMode */ public String getStorageMode() &#123; return storageMode; &#125; /** * 设置 storageMode * @param storageMode the storageMode to set */ public void setStorageMode(String storageMode) &#123; this.storageMode = storageMode; &#125; @Override public HttpSession removeSessionByMappingId(String mappingId) &#123; HttpSession session = null; if (storageMode.equals(&quot;hash&quot;)) &#123; session = MANAGED_SESSIONS.get(mappingId); &#125; else &#123; session = redisClient.get(mappingId, NAME_SPACE, HttpSession.class, null); &#125; if (session != null) &#123; removeBySessionById(session.getId()); &#125; return session; &#125; @Override public void removeBySessionById(String sessionId) &#123; logger.debug(&quot;Attempting to remove Session=[&#123;&#125;]&quot;, sessionId); String key = null; if (storageMode.equals(&quot;hash&quot;)) &#123; key = ID_TO_SESSION_KEY_MAPPING.get(sessionId); &#125; else &#123; key = redisClient.get(sessionId, NAME_SPACE, null); &#125; if (logger.isDebugEnabled()) &#123; if (key != null) &#123; logger.debug(&quot;Found mapping for session. Session Removed.&quot;); &#125; else &#123; logger.debug(&quot;No mapping for session found. Ignoring.&quot;); &#125; &#125; if (storageMode.equals(&quot;hash&quot;)) &#123; MANAGED_SESSIONS.remove(key); ID_TO_SESSION_KEY_MAPPING.remove(sessionId); &#125; else &#123; redisClient.del(key, NAME_SPACE); redisClient.del(sessionId, NAME_SPACE); &#125; &#125; @Override public void addSessionById(String mappingId, HttpSession session) &#123; if (storageMode.equals(&quot;hash&quot;)) &#123; ID_TO_SESSION_KEY_MAPPING.put(session.getId(), mappingId); MANAGED_SESSIONS.put(mappingId, session); &#125; else &#123; redisClient.set(session.getId(), NAME_SPACE, mappingId, -1); redisClient.set(mappingId, NAME_SPACE, session, -1); &#125; &#125;&#125; 这里使用的redis-client是我自己封装，使用文档在：《RedisClient使用说明》，支持redis集群模式：《RedisClient升级支持Sentinel使用说明》，代码已经放到了github上： 项目地址：redis-client &nbsp;&nbsp;&nbsp; 把上面的RedisBackedSessionMappingStorage类注入到org.jasig.cas.client.session.SingleSignOutFilter中即可 &lt;bean id=&quot;singleLogoutFilter&quot; class=&quot;org.jasig.cas.client.session.SingleSignOutFilter&quot;&gt; &lt;property name=&quot;sessionMappingStorage&quot; ref=&quot;redisBackedSessionMappingStorage&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=&quot;redisBackedSessionMappingStorage&quot; class=&quot;xxxxxxx.cas.session.storage.RedisBackedSessionMappingStorage&quot;&gt; &lt;property name=&quot;redisClient&quot; ref=&quot;redisClient&quot;&gt;&lt;/property&gt; &lt;property name=&quot;storageMode&quot; value=&quot;$&#123;cas.session.storage.mode&#125;&quot;&gt;&lt;/property&gt;&lt;/bean&gt; ps.参数cas.session.storage.mode，值：hash（本地map）、redis（集中存储） WEB服务端session集中存储处理WEB服务端session集中存储处理方案也有很多种，使用tomcat可以使用TomcatRedisSessionManager来解决session集中存储问题，github地址：https://github.com/ran-jit/tomcat-cluster-redis-session-manager 如果要自己实现也很简单，我这里大致说一下思路，需要包装一个可序列话的session，说白了就是包装一下session实现序列化接口：java.io.Serializable接口生成一个version id，包装一个获取器，在生成session的时候序列化写入集中存储返回id，在用的使用通过id获取，id可以使用jsessionid或者自己生成一个uuid都行。这个id可以放入浏览器cookie，也可以放入url每次带入,在登录成功后将session序列化存储到redis或其他cache、nosql、db等，在登出时清空即可，就看自己喜好来实现了。 到这里基本上对cas的使用经验就总结完了，我相信大家在使用cas时都会遇到上面的问题，希望这篇总结可以帮助到需要的人，感谢看到最后。 最后我的愿望是：世界和平，快乐编程每一天，keep real","tags":[{"name":"CAS","slug":"CAS","permalink":"https://ningyu1.github.io/tags/CAS/"},{"name":"SLO","slug":"SLO","permalink":"https://ningyu1.github.io/tags/SLO/"},{"name":"Single Logout","slug":"Single-Logout","permalink":"https://ningyu1.github.io/tags/Single-Logout/"},{"name":"Ticket","slug":"Ticket","permalink":"https://ningyu1.github.io/tags/Ticket/"},{"name":"Ticket Registry","slug":"Ticket-Registry","permalink":"https://ningyu1.github.io/tags/Ticket-Registry/"},{"name":"Session Centralized Storage","slug":"Session-Centralized-Storage","permalink":"https://ningyu1.github.io/tags/Session-Centralized-Storage/"},{"name":"Cookie","slug":"Cookie","permalink":"https://ningyu1.github.io/tags/Cookie/"},{"name":"CAS Cluster","slug":"CAS-Cluster","permalink":"https://ningyu1.github.io/tags/CAS-Cluster/"},{"name":"CAS Server","slug":"CAS-Server","permalink":"https://ningyu1.github.io/tags/CAS-Server/"},{"name":"SSL","slug":"SSL","permalink":"https://ningyu1.github.io/tags/SSL/"},{"name":"Cert","slug":"Cert","permalink":"https://ningyu1.github.io/tags/Cert/"}]},{"title":"Java访问SSL地址，使用证书方式和免验证证书方式","date":"2018-01-15T06:08:36.000Z","path":"20180115/53-ssl-cert-3.html","text":"前文回顾《Openssl生成自签名证书，简单步骤》中讲述了如何生成自签名证书。 《使用自签名证书，简单步骤》中讲述了如何使用自签名证书。 下面讲述在Java中如何访问SSL地址，使用证书访问和免验证证书访问。 Java安装证书访问SSL地址使用InstallCert安装证书《使用自签名证书，简单步骤》这篇文章中介绍的InstallCert生成jssecacerts文件。将ssecacerts文件放入%JAVA_HOME%\\jre\\lib\\security 下即可。 使用keytool工具导入证书keytool -import -alias xstore -keystore &quot;cacerts_path&quot; -file a.cer cacerts_path: 你的cacerts文件路径，一般在%JAVA_HOME%jre\\lib\\security\\cacerts a.cer: 你需要导入的cer文件路径，可以是InstallCert生成的文件 密码使用jdk默认密码：changeit，或者在上面命令后增加-storepass changeit设置密码参数 通过上面两种方式可以将证书安装到jdk下，接下来就是java中如何访问ssl地址，不多说直接上代码。 自定义javax.net.ssl.X509TrustManager实现类import java.security.cert.CertificateException;import java.security.cert.X509Certificate;import javax.net.ssl.X509TrustManager;public class MyX509TrustManager implements X509TrustManager &#123; @Override public void checkClientTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; &#125; @Override public void checkServerTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; &#125; @Override public X509Certificate[] getAcceptedIssuers() &#123; return null; &#125;&#125; 包装HttpsDemo类HttpsDemo类中包装两个方法，sendHttps发起ssl地址请求，sendHttp发起普通地址请求 import java.io.BufferedReader;import java.io.ByteArrayOutputStream;import java.io.InputStream;import java.io.InputStreamReader;import java.io.OutputStream;import java.net.HttpURLConnection;import java.net.URL;import javax.net.ssl.HttpsURLConnection;import javax.net.ssl.SSLContext;import javax.net.ssl.SSLSocketFactory;import javax.net.ssl.TrustManager;import org.apache.commons.io.IOUtils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class HttpsDemo &#123; private static final Logger logger = LoggerFactory.getLogger(HttpsDemo.class.getName()); public static void sendHttps(String path, String outputStr) &#123; InputStream inputStream = null; OutputStream outputStream = null; HttpsURLConnection httpUrlConn = null; BufferedReader bufferedReader = null; InputStreamReader inputStreamReader = null; StringBuffer buffer = new StringBuffer(); try &#123; // 创建SSLContext对象，并使用我们指定的信任管理器初始化 TrustManager[] tm = &#123; new MyX509TrustManager() &#125;; SSLContext sslContext = SSLContext.getInstance(&quot;SSL&quot;, &quot;SunJSSE&quot;); sslContext.init(null, tm, new java.security.SecureRandom()); // 从上述SSLContext对象中得到SSLSocketFactory对象 SSLSocketFactory ssf = sslContext.getSocketFactory(); URL url = new URL(path); httpUrlConn = (HttpsURLConnection) url.openConnection(); httpUrlConn.setSSLSocketFactory(ssf); httpUrlConn.setDoOutput(true); httpUrlConn.setDoInput(true); httpUrlConn.setUseCaches(false); httpUrlConn.setRequestMethod(&quot;GET&quot;); httpUrlConn.connect(); // 当有数据需要提交时 if (null != outputStr) &#123; outputStream = httpUrlConn.getOutputStream(); // 注意编码格式，防止中文乱码 outputStream.write(outputStr.getBytes(&quot;UTF-8&quot;)); outputStream.close(); &#125; // 将返回的输入流转换成字符串 inputStream = httpUrlConn.getInputStream(); inputStreamReader = new InputStreamReader(inputStream, &quot;utf-8&quot;); bufferedReader = new BufferedReader(inputStreamReader); String str = null; while ((str = bufferedReader.readLine()) != null) &#123; buffer.append(str); &#125; logger.info(&quot;地址:&#123;&#125;, success, result:&#123;&#125;&quot;, path, buffer.toString()); &#125; catch (Exception e) &#123; logger.error(&quot;地址:&#123;&#125;, error, exception:&#123;&#125;&quot;, path, e); &#125; finally &#123; if (bufferedReader != null) &#123; IOUtils.closeQuietly(bufferedReader); &#125; if (inputStreamReader != null) &#123; IOUtils.closeQuietly(inputStreamReader); &#125; if (inputStream != null) &#123; IOUtils.closeQuietly(inputStream); &#125; if (httpUrlConn != null) &#123; httpUrlConn.disconnect(); &#125; &#125; &#125; public static void sendHttp(String path) &#123; InputStream inputStream = null; ByteArrayOutputStream outputStream = null; HttpURLConnection urlConnection = null; try &#123; URL url = new URL(path); urlConnection = (HttpURLConnection) url.openConnection(); urlConnection.setRequestMethod(&quot;GET&quot;); urlConnection.setUseCaches(false); inputStream = urlConnection.getInputStream(); outputStream = new ByteArrayOutputStream(); byte[] buffer = new byte[1024]; int n = 0; while (-1 != (n = inputStream.read(buffer))) &#123; outputStream.write(buffer, 0, n); &#125; logger.info(&quot;地址:&#123;&#125;, success, result:&#123;&#125;&quot;, path, outputStream.toString()); &#125; catch (Exception e) &#123; logger.error(&quot;地址:&#123;&#125;, error, exception:&#123;&#125;&quot;, path, e); &#125; finally &#123; if (outputStream != null) &#123; IOUtils.closeQuietly(inputStream); &#125; if (outputStream != null) &#123; IOUtils.closeQuietly(outputStream); &#125; if (urlConnection != null) &#123; urlConnection.disconnect(); &#125; &#125; &#125; public static void main(String[] args) &#123; sendHttps(&quot;https://xxx.com&quot;, null); &#125;&#125; 上面访问ssl地址如果报错java.security.cert.CertificateException: No name matching localhost found那就是证书没有安装好，检查前面证书安装过程。 Java访问ssl其实是可以绕过证书验证的，可以不需要证书直接发起ssl地址请求，下面介绍一下。 Java绕过证书验证访问SSL地址，达到免验证证书效果这种方式是采用重写HostnameVerifier的verify方法配合X509TrustManager来处理授信所有host，下面直接上代码 import java.net.HttpURLConnection;import java.net.URL;import java.security.cert.X509Certificate;import javax.net.ssl.HostnameVerifier;import javax.net.ssl.HttpsURLConnection;import javax.net.ssl.SSLContext;import javax.net.ssl.SSLSession;import javax.net.ssl.TrustManager;import javax.net.ssl.X509TrustManager;import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class HttpDemo &#123; private static final Logger logger = LoggerFactory.getLogger(HttpDemo.class.getName()); final static HostnameVerifier DO_NOT_VERIFY = new HostnameVerifier() &#123; public boolean verify(String hostname, SSLSession session) &#123; return true; &#125; &#125;; public static void httpGet(String path) &#123; StringBuffer tempStr = new StringBuffer(); String responseContent = &quot;&quot;; HttpURLConnection conn = null; try &#123; // Create a trust manager that does not validate certificate chains trustAllHosts(); URL url = new URL(path); HttpsURLConnection https = (HttpsURLConnection) url.openConnection(); if (url.getProtocol().toLowerCase().equals(&quot;https&quot;)) &#123; https.setHostnameVerifier(DO_NOT_VERIFY); conn = https; &#125; else &#123; conn = (HttpURLConnection) url.openConnection(); &#125; conn.connect(); logger.info(&quot;地址:&#123;&#125;, success, result:&#123;&#125;&quot;, path, conn.getResponseCode() + &quot; &quot; + conn.getResponseMessage()); // HttpURLConnection conn = (HttpURLConnection) // url.openConnection(); // conn.setConnectTimeout(5000); // conn.setReadTimeout(5000); // conn.setDoOutput(true); // // InputStream in = conn.getInputStream(); // conn.setReadTimeout(10*1000); // BufferedReader rd = new BufferedReader(new InputStreamReader(in, // &quot;UTF-8&quot;)); // String tempLine; // while ((tempLine = rd.readLine()) != null) &#123; // tempStr.append(tempLine); // &#125; // responseContent = tempStr.toString(); // System.out.println(responseContent); // rd.close(); // in.close(); &#125; catch (Exception e) &#123; logger.error(&quot;地址:&#123;&#125;, is error&quot;, e); &#125; finally &#123; if (conn != null) &#123; conn.disconnect(); &#125; &#125; &#125; /** * Trust every server - dont check for any certificate */ private static void trustAllHosts() &#123; // Create a trust manager that does not validate certificate chains TrustManager[] trustAllCerts = new TrustManager[] &#123; new X509TrustManager() &#123; public java.security.cert.X509Certificate[] getAcceptedIssuers() &#123; return new java.security.cert.X509Certificate[] &#123;&#125;; &#125; public void checkClientTrusted(X509Certificate[] chain, String authType) &#123; &#125; public void checkServerTrusted(X509Certificate[] chain, String authType) &#123; &#125; &#125; &#125;; // Install the all-trusting trust manager // 忽略HTTPS请求的SSL证书，必须在openConnection之前调用 try &#123; SSLContext sc = SSLContext.getInstance(&quot;TLS&quot;); sc.init(null, trustAllCerts, new java.security.SecureRandom()); HttpsURLConnection.setDefaultSSLSocketFactory(sc.getSocketFactory()); &#125; catch (Exception e) &#123; logger.error(&quot;trustAllHosts is error&quot;, e); &#125; &#125; public static void main(String[] args) &#123; httpGet(&quot;https://xxx.com&quot;); &#125;&#125; 以上代码需要注意一点：忽略HTTPS请求的SSL证书，必须在openConnection之前调用。 常见错误错误一如果发生如下错误，请添加vm参数：-Dhttps.protocols=TLSv1.1,TLSv1.2 -Djava.net.preferIPv4Stack=true，一般是jdk1.7会发生这个错误，具体原因在《使用自签名证书，简单步骤》这篇文章中已经解释。 javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:946) ~[na:1.7.0_45] at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1312) ~[na:1.7.0_45] at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1339) ~[na:1.7.0_45] at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1323) ~[na:1.7.0_45] at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:563) ~[na:1.7.0_45] at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185) ~[na:1.7.0_45] at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153) ~[na:1.7.0_45] at HttpDemo.httpGet(HttpDemo.java:59) [classes/:na] at HttpDemo.main(HttpDemo.java:122) [classes/:na]Caused by: java.io.EOFException: SSL peer shut down incorrectly at sun.security.ssl.InputRecord.read(InputRecord.java:482) ~[na:1.7.0_45] at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:927) ~[na:1.7.0_45] ... 8 common frames omitted 错误二如果发生如下错误，是因为没有找到匹配的证书。如果使用证书的方式访问，请检查证书安装是否错误。如果是免验证证书访问，请检查代码没有跳过证书验证。 javax.net.ssl.SSLHandshakeException: java.security.cert.CertificateException: No name matching xxxxxxx.com found at sun.security.ssl.Alerts.getSSLException(Alerts.java:192) ~[na:1.7.0_45] at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1884) ~[na:1.7.0_45] at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:276) ~[na:1.7.0_45] at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:270) ~[na:1.7.0_45] at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1341) ~[na:1.7.0_45] at sun.security.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:153) ~[na:1.7.0_45] at sun.security.ssl.Handshaker.processLoop(Handshaker.java:868) ~[na:1.7.0_45] at sun.security.ssl.Handshaker.process_record(Handshaker.java:804) ~[na:1.7.0_45] at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1016) ~[na:1.7.0_45] at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1312) ~[na:1.7.0_45] at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1339) ~[na:1.7.0_45] at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1323) ~[na:1.7.0_45] at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:563) ~[na:1.7.0_45] at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185) ~[na:1.7.0_45] at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153) ~[na:1.7.0_45] at HttpsDemo.sendHttps(HttpsDemo.java:62) [classes/:na] at HttpsDemo.main(HttpsDemo.java:133) [classes/:na]Caused by: java.security.cert.CertificateException: No name matching xxxxxxx.com found at sun.security.util.HostnameChecker.matchDNS(HostnameChecker.java:208) ~[na:1.7.0_45] at sun.security.util.HostnameChecker.match(HostnameChecker.java:93) ~[na:1.7.0_45] at sun.security.ssl.X509TrustManagerImpl.checkIdentity(X509TrustManagerImpl.java:347) ~[na:1.7.0_45] at sun.security.ssl.AbstractTrustManagerWrapper.checkAdditionalTrust(SSLContextImpl.java:847) ~[na:1.7.0_45] at sun.security.ssl.AbstractTrustManagerWrapper.checkServerTrusted(SSLContextImpl.java:814) ~[na:1.7.0_45] at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1323) ~[na:1.7.0_45] ... 12 common frames omitted","tags":[{"name":"ssl","slug":"ssl","permalink":"https://ningyu1.github.io/tags/ssl/"},{"name":"openssl","slug":"openssl","permalink":"https://ningyu1.github.io/tags/openssl/"}]},{"title":"使用自签名证书，简单步骤","date":"2018-01-12T11:13:36.000Z","path":"20180112/52-ssl-cert-2.html","text":"在前文《Openssl生成自签名证书，简单步骤》中讲述了如何生成自签名证书，接下来整理证书使用遇到的问题。 证书使用的方式也有很多中，可以使用keytool生成或导入导出证书，这里对keytool不做过多描述，可以通过–help查看使用方法。 证书文件可以放到应用服务器、负载均衡、jvm中使用，如：IIS、tomcat、nginx或者loadbalance、jdk等等。 这里介绍一个简单的工具：InstallCert安装证书文件到jdk下，这个在本地调试连接ssl服务器代码的时候很有用。 如果我们的服务端使用的是jdk1.8（比如说：cas服务），访问的客户端（业务系统）也是jdk1.8，那么直接使用InstallCert安装即可. 如果我们的服务端使用的是jdk1.8，但是客户端使用jdk1.7会遇到什么问题？ 我们都知道jdk1.7默认的TLS版本是1.0但是支持1.1和1.2，如何查看jdk支持的TLS版本呢？ 可以使用jdk自带的jcp（java control panel）工具 jcp（java control panel）路径：%JAVA_HOME%\\jre\\bin 点击高级，勾选TLS1.1 TSL1.2开启支持。 如果使用客户端程序（jdk1.7开发的）访问服务端程序（jdk1.8开发的），在使用InstallCert安装证书时会出现如下错误： javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:946) ~[na:1.7.0_45] at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1312) ~[na:1.7.0_45] 上面错误的意思就是服务器把你拒绝了！把你拒绝了！把你拒绝了！拒绝你的理由就是TLS版本不对。 下面我主要讲在客户端程序（jdk1.7开发的）访问服务端程序（jdk1.8开发的）的场景下安装证书如何解决上面的错误。 通过InstallCert源码安装证书/* * Copyright 2006 Sun Microsystems, Inc. All Rights Reserved. * * Redistribution and use in source and binary forms, with or without * modification, are permitted provided that the following conditions * are met: * * - Redistributions of source code must retain the above copyright * notice, this list of conditions and the following disclaimer. * * - Redistributions in binary form must reproduce the above copyright * notice, this list of conditions and the following disclaimer in the * documentation and/or other materials provided with the distribution. * * - Neither the name of Sun Microsystems nor the names of its * contributors may be used to endorse or promote products derived * from this software without specific prior written permission. * * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS * IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. */import java.io.*;import java.net.URL;import java.security.*;import java.security.cert.*;import javax.net.ssl.*;public class InstallCert &#123; public static void main(String[] args) throws Exception &#123; String host; int port; char[] passphrase; if ((args.length == 1) || (args.length == 2)) &#123; String[] c = args[0].split(&quot;:&quot;); host = c[0]; port = (c.length == 1) ? 443 : Integer.parseInt(c[1]); String p = (args.length == 1) ? &quot;changeit&quot; : args[1]; passphrase = p.toCharArray(); &#125; else &#123; System.out.println(&quot;Usage: java InstallCert &lt;host&gt;[:port] [passphrase]&quot;); return; &#125; File file = new File(&quot;jssecacerts&quot;); if (file.isFile() == false) &#123; char SEP = File.separatorChar; File dir = new File(System.getProperty(&quot;java.home&quot;) + SEP + &quot;lib&quot; + SEP + &quot;security&quot;); file = new File(dir, &quot;jssecacerts&quot;); if (file.isFile() == false) &#123; file = new File(dir, &quot;cacerts&quot;); &#125; &#125; System.out.println(&quot;Loading KeyStore &quot; + file + &quot;...&quot;); InputStream in = new FileInputStream(file); KeyStore ks = KeyStore.getInstance(KeyStore.getDefaultType()); ks.load(in, passphrase); in.close(); SSLContext context = SSLContext.getInstance(&quot;TLSv1.2&quot;); TrustManagerFactory tmf = TrustManagerFactory.getInstance(TrustManagerFactory.getDefaultAlgorithm()); tmf.init(ks); X509TrustManager defaultTrustManager = (X509TrustManager)tmf.getTrustManagers()[0]; SavingTrustManager tm = new SavingTrustManager(defaultTrustManager); context.init(null, new TrustManager[] &#123;tm&#125;, null); SSLSocketFactory factory = context.getSocketFactory(); System.out.println(&quot;Opening connection to &quot; + host + &quot;:&quot; + port + &quot;...&quot;); SSLSocket socket = (SSLSocket)factory.createSocket(host, port); socket.setSoTimeout(10000); try &#123; System.out.println(&quot;Starting SSL handshake...&quot;); socket.startHandshake(); socket.close(); System.out.println(); System.out.println(&quot;No errors, certificate is already trusted&quot;); &#125; catch (SSLException e) &#123; System.out.println(); e.printStackTrace(System.out); &#125; X509Certificate[] chain = tm.chain; if (chain == null) &#123; System.out.println(&quot;Could not obtain server certificate chain&quot;); return; &#125; BufferedReader reader = new BufferedReader(new InputStreamReader(System.in)); System.out.println(); System.out.println(&quot;Server sent &quot; + chain.length + &quot; certificate(s):&quot;); System.out.println(); MessageDigest sha1 = MessageDigest.getInstance(&quot;SHA1&quot;); MessageDigest md5 = MessageDigest.getInstance(&quot;MD5&quot;); for (int i = 0; i &lt; chain.length; i++) &#123; X509Certificate cert = chain[i]; System.out.println (&quot; &quot; + (i + 1) + &quot; Subject &quot; + cert.getSubjectDN()); System.out.println(&quot; Issuer &quot; + cert.getIssuerDN()); sha1.update(cert.getEncoded()); System.out.println(&quot; sha1 &quot; + toHexString(sha1.digest())); md5.update(cert.getEncoded()); System.out.println(&quot; md5 &quot; + toHexString(md5.digest())); System.out.println(); &#125; System.out.println(&quot;Enter certificate to add to trusted keystore or &apos;q&apos; to quit: [1]&quot;); String line = reader.readLine().trim(); int k; try &#123; k = (line.length() == 0) ? 0 : Integer.parseInt(line) - 1; &#125; catch (NumberFormatException e) &#123; System.out.println(&quot;KeyStore not changed&quot;); return; &#125; X509Certificate cert = chain[k]; String alias = host + &quot;-&quot; + (k + 1); ks.setCertificateEntry(alias, cert); OutputStream out = new FileOutputStream(&quot;jssecacerts&quot;); ks.store(out, passphrase); out.close(); System.out.println(); System.out.println(cert); System.out.println(); System.out.println (&quot;Added certificate to keystore &apos;jssecacerts&apos; using alias &apos;&quot; + alias + &quot;&apos;&quot;); &#125; private static final char[] HEXDIGITS = &quot;0123456789abcdef&quot;.toCharArray(); private static String toHexString(byte[] bytes) &#123; StringBuilder sb = new StringBuilder(bytes.length * 3); for (int b : bytes) &#123; b &amp;= 0xff; sb.append(HEXDIGITS[b &gt;&gt; 4]); sb.append(HEXDIGITS[b &amp; 15]); sb.append(&apos; &apos;); &#125; return sb.toString(); &#125; private static class SavingTrustManager implements X509TrustManager &#123; private final X509TrustManager tm; private X509Certificate[] chain; SavingTrustManager(X509TrustManager tm) &#123; this.tm = tm; &#125; public X509Certificate[] getAcceptedIssuers() &#123;// throw new UnsupportedOperationException(); return new X509Certificate[0]; &#125; public void checkClientTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; throw new UnsupportedOperationException(); &#125; public void checkServerTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; this.chain = chain; tm.checkServerTrusted(chain, authType); &#125; &#125;&#125; 上面源码我修改了SSLContext context = SSLContext.getInstance(&quot;TLSv1.2&quot;);，原本是TLS，这样在jdk1.7下会报错，尽管加了vm参数：-Dhttps.protocols=TLSv1.1,TLSv1.2 -Djava.net.preferIPv4Stack=true，依然会报错。 修改为TLSv1.2后，直接运行代码，参数为：你需要签名的域名 运行日志会出现如下错误（不用紧张，这个错误没有关系）： Opening connection to login.xxxxx.com.cn:443...Starting SSL handshake...javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at sun.security.ssl.Alerts.getSSLException(Alerts.java:192) at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1884) at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:276) at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:270) at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1341) at sun.security.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:153) at sun.security.ssl.Handshaker.processLoop(Handshaker.java:868) at sun.security.ssl.Handshaker.process_record(Handshaker.java:804) at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1016) at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1312) at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1339) at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1323) at InstallCert.main(InstallCert.java:99)Caused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:385) at sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:292) at sun.security.validator.Validator.validate(Validator.java:260) at sun.security.ssl.X509TrustManagerImpl.validate(X509TrustManagerImpl.java:326) at sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:231) at sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:107) at InstallCert$SavingTrustManager.checkServerTrusted(InstallCert.java:195) at sun.security.ssl.AbstractTrustManagerWrapper.checkServerTrusted(SSLContextImpl.java:813) at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1323) ... 8 moreCaused by: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at sun.security.provider.certpath.SunCertPathBuilder.engineBuild(SunCertPathBuilder.java:196) at java.security.cert.CertPathBuilder.build(CertPathBuilder.java:268) at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:380) ... 16 moreServer sent 1 certificate(s): 1 Subject EMAILADDRESS=ningyu@xxxxxx.com, CN=login.xxxxxxx.com, OU=JY, O=JY, L=Shanghai, ST=Shanghai, C=CN Issuer EMAILADDRESS=ningyu@xxxxxx.com, CN=login.xxxxxxx.com, OU=JY, O=JY, L=Shanghai, ST=Shanghai, C=CN sha1 18 fe a4 26 de 9f ef 9f d0 12 f9 1b da e8 f4 6e 46 a3 ca e2 md5 53 02 53 bc 1f 5d e3 0f c2 ce a5 fa 43 7b 53 83 Enter certificate to add to trusted keystore or &apos;q&apos; to quit: [1] 出现上面错误没关系，在命令行输入：1，生成文件，会在执行目录下生成：jssecacerts，并且会输出下面的日志： Enter certificate to add to trusted keystore or &apos;q&apos; to quit: [1]1[[ Version: V1 Subject: EMAILADDRESS=ningyu@xxxxx.com, CN=login.xxxxxxx.com, OU=JY, O=JY, L=Shanghai, ST=Shanghai, C=CN Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11 Key: Sun RSA public key, 1024 bits modulus: 150111273197244637724411949927732292545940427223472330318676441758610292860528090849280500452765059055376192276098938042951946335160244351904122898746077164287399465663417510841977938344538423662939325238497292924898237072606839002269269847753256718676717424760603548961942760492908854629736493402902120207483 public exponent: 65537 Validity: [From: Fri Jan 12 15:15:03 CST 2018, To: Mon Jan 10 15:15:03 CST 2028] Issuer: EMAILADDRESS=ningyu@xxxxxx.com, CN=login.xxxxxx.com, OU=JY, O=JY, L=Shanghai, ST=Shanghai, C=CN SerialNumber: [ b9c6224c 0cf5ee1a]] Algorithm: [SHA256withRSA] Signature:0000: B7 F8 1B FB 3C 7E 46 31 9C 56 31 47 F5 79 2C AA ....&lt;.F1.V1G.y,.0010: B0 E3 FB EA CF 6C 15 72 53 8B A9 36 1D 43 E0 AB .....l.rS..6.C..0020: 21 3C BD 65 51 11 B3 D6 5B 42 40 DB 07 9C 35 5C !&lt;.eQ...[B@...5\\0030: 84 9B B7 B8 02 5A E0 96 5D 5F 9E 5D B3 5F 85 A8 .....Z..]_.]._..0040: 50 64 63 E7 12 B0 DF CA 48 DD 28 B7 B2 8D 42 33 Pdc.....H.(...B30050: A5 C1 E8 E1 41 08 F8 39 21 DD 6C BE 6E F1 CD EE ....A..9!.l.n...0060: F9 C0 DC 2F 1E 99 D2 DC A3 2C C7 C2 64 ED 94 5E .../.....,..d..^0070: 32 6F CC B4 3D 93 B7 F8 09 8D F9 4E 39 CA 5E 53 2o..=......N9.^S]Added certificate to keystore &apos;jssecacerts&apos; using alias &apos;login.xxxxxx.com-1&apos; 这个时候再运行一遍InstallCert就不会报错，因为已经有jssecacerts文件，直接copy jssecacerts文件到%JAVA_HOME%\\jre\\lib\\security下，就可以愉快的玩耍了。 这个在我们本地调试连接ssl服务器的代码时很有用，如果不把证书放入jdk下你会被无限的拒绝。","tags":[{"name":"ssl","slug":"ssl","permalink":"https://ningyu1.github.io/tags/ssl/"},{"name":"openssl","slug":"openssl","permalink":"https://ningyu1.github.io/tags/openssl/"},{"name":"InstallCert","slug":"InstallCert","permalink":"https://ningyu1.github.io/tags/InstallCert/"}]},{"title":"Openssl生成自签名证书，简单步骤","date":"2018-01-12T09:06:36.000Z","path":"20180112/51-ssl-cert.html","text":"最近在调试服务时需要使用证书，因此对证书的生成和使用做了一些整理，网上关于这部分资料也很多，但是很杂乱，我整理出以下简单的步骤生成自签名证书，具体让我们来看一看吧。 第一种方式通过openssl生成私钥 openssl genrsa -out server.key 1024 使用私钥生成自签名的cert证书文件，以下是通过参数只定证书需要的信息 openssl req -new -x509 -days 3650 -key server.key -out server.crt -subj &quot;/C=CN/ST=mykey/L=mykey/O=mykey/OU=mykey/CN=domain1/CN=domain2/CN=domain3&quot; 如果对上面参数具体的说明不太了解的，可以使用不带参数的方式，通过命令行步骤生成，参考第二种方式。 第二种方式通过openssl生成私钥 openssl genrsa -out server.key 1024 根据私钥生成证书申请文件csr openssl req -new -key server.key -out server.csr 这里根据命令行向导来进行信息输入： ps.Common Name可以输入：*.yourdomain.com，这种方式生成通配符域名证书 使用私钥对证书申请进行签名从而生成证书 openssl x509 -req -in server.csr -out server.crt -signkey server.key -days 3650 这样就生成了有效期为：10年的证书文件，对于自己内网服务使用足够。 第三种方式直接生成证书文件 openssl req -new -x509 -keyout server.key -out server.crt -config openssl.cnf ps.以上生成得到的server.crt证书，格式都是pem的。 我个人比较推荐使用第二种方式，如果不在乎其他参数可以使用第三种直接一步生成。","tags":[{"name":"ssl","slug":"ssl","permalink":"https://ningyu1.github.io/tags/ssl/"},{"name":"openssl","slug":"openssl","permalink":"https://ningyu1.github.io/tags/openssl/"}]},{"title":"MySQL Gap Lock问题","date":"2018-01-11T09:10:36.000Z","path":"20180111/50-mysql-gap-lock.html","text":"文章来源：http://blog.chinaunix.net/uid-20726500-id-5749804.html作者：@小桥河西 初识MySQL的gap，觉得这个设计比较独特，和其他数据库的做法不太一样，所以整理一个简单的memo（虽然关于gap锁，相关资料已经很多了） 一、什么是gapA place in an InnoDB index data structure where new values could be inserted. 说白了gap就是索引树中插入新记录的空隙。相应的gap lock就是加在gap上的锁，还有一个next-key锁，是记录+记录前面的gap的组合的锁。 二、gap锁或next-key锁的作用http://dev.mysql.com/doc/refman/5.7/en/innodb-next-key-locking.html To prevent phantoms, InnoDB uses an algorithm called next-key locking that combines index-row locking with gap locking. InnoDB performs row-level locking in such a way that when it searches or scans a table index, it sets shared or exclusive locks on the index records it encounters. Thus, the row-level locks are actually index-record locks. In addition, a next-key lock on an index record also affects the “gap” before that index record. That is, a next-key lock is an index-record lock plus a gap lock on the gap preceding the index record. If one session has a shared or exclusive lock on record R in an index, another session cannot insert a new index record in the gap immediately before R in the index order. 简单讲就是防止幻读。通过锁阻止特定条件的新记录的插入，因为插入时也要获取gap锁(Insert Intention Locks)。 三、什么时候会取得gap lock或nextkey lock这和隔离级别有关,只在REPEATABLE READ或以上的隔离级别下的特定操作才会取得gap lock或nextkey lock。 http://dev.mysql.com/doc/refman/5.7/en/innodb-transaction-isolation-levels.html REPEATABLE READ... For consistent reads, there is an important difference from the READ COMMITTED isolation level: All consistent reads within the same transaction read the snapshot established by the first read. ...For locking reads (SELECT with FOR UPDATE or LOCK IN SHARE MODE), UPDATE, and DELETE statements, locking depends on whether the statement uses a unique index with a unique search condition, or a range-type search condition. For a unique index with a unique search condition, InnoDB locks only the index record found, not the gap before it. For other search conditions, InnoDB locks the index range scanned, using gap locks or next-key locks to block insertions by other sessions into the gaps covered by the range. locking reads，UPDATE和DELETE时，除了对唯一索引的唯一搜索外都会获取gap锁或next-key锁。即锁住其扫描的范围。 下面对非唯一索引做个测试。 表定义如下: mysql&gt; show create table tb2;+-------+------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+------------------------------------------------------------------------------------------------------------------------------------------------+| tb2 | CREATE TABLE `tb2` ( `id` int(11) DEFAULT NULL, `c1` int(11) DEFAULT NULL, KEY `tb2_idx1` (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 |+-------+------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 表中有3条记录： 10,20,30。 mysql&gt; select * from tb2;+------+------+| id | c1 |+------+------+| 10 | 0 || 20 | 0 || 30 | 0 |+------+------+3 rows in set (0.01 sec) 在REPEATABLE READ下，更新一条记录不提交，然后看看能阻塞另外的会话哪些操作。 SESSION 1:SESSION 1中更新id=20的记录 mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; update tb2 set c1=2 where id=20;Query OK, 1 row affected (0.04 sec)Rows matched: 1 Changed: 1 Warnings: 0 SESSION 2:SESSION 2中，执行插入操作，发现[10,30)范围不能插入数据。 mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into tb2 values(9,4);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into tb2 values(10,4);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionmysql&gt; insert into tb2 values(19,4);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionmysql&gt; insert into tb2 values(20,4);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionmysql&gt; insert into tb2 values(21,4);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionmysql&gt; insert into tb2 values(29,4);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionmysql&gt; insert into tb2 values(30,4);Query OK, 1 row affected (0.01 sec) 对于更新操作，仅20这条记录不能更新，因为更新操作不会去获取gap锁。 mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; update tb2 set c1=4 where id=10;Query OK, 0 rows affected (0.00 sec)Rows matched: 1 Changed: 0 Warnings: 0mysql&gt; update tb2 set c1=4 where id=20;ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionmysql&gt; update tb2 set c1=4 where id=30;Query OK, 0 rows affected (0.00 sec)Rows matched: 2 Changed: 0 Warnings: 0 如果SESSION 1的表扫描没有用到索引，那么gap或next-key锁住的范围是整个表，即任何值都不能插入。 READ COMMITTEDFor locking reads (SELECT with FOR UPDATE or LOCK IN SHARE MODE), UPDATE statements, and DELETE statements, InnoDB locks only index records, not the gaps before them, and thus permits the free insertion of new records next to locked records. 只会锁住已有记录，不会加gap锁。 SERIALIZABLEThis level is like REPEATABLE READ, but InnoDB implicitly converts all plain SELECT statements to SELECT ... LOCK IN SHARE MODE if autocommit is disabled. 和REPEATABLE READ的主要区别在于把普通的SELECT变成SELECT … LOCK IN SHARE MODE，即对普通的select都会获取gap锁或next-key锁。 REPEATABLE READ和幻读在“consistent-read”时，REPEATABLE READ下看到是事务开始时的快照，即使其它事务插入了新行通常也是看不到的，所以在常见的场合可以避免幻读。 但是，”locking read”或更新，删除时是会看到已提交的修改的，包括新插入的行。 http://dev.mysql.com/doc/refman/5.7/en/innodb-consistent-read.html If you want to see the “freshest” state of the database, use either the READ COMMITTED isolation level or a locking read: 下面看一个例子 SESSION 1:mysql&gt; START TRANSACTION;Query OK, 0 rows affected (0.00 sec)mysql&gt; select id,c1 from tb1 where id=1;+----+------+| id | c1 |+----+------+| 1 | 100 |+----+------+1 row in set (0.00 sec) SESSION 2:mysql&gt; update tb1 set c1=101 where id =1;Query OK, 1 row affected (0.03 sec)Rows matched: 1 Changed: 1 Warnings: 0 SESSION 1:mysql&gt; select id,c1 from tb1 where id=1 LOCK IN SHARE MODE;+----+------+| id | c1 |+----+------+| 1 | 101 |+----+------+1 row in set (0.00 sec)mysql&gt; select id,c1 from tb1 where id=1;+----+------+| id | c1 |+----+------+| 1 | 100 |+----+------+1 row in set (0.00 sec)mysql&gt; update tb1 set c1=c1+1000 where id=1;Query OK, 1 row affected (0.02 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; select id,c1 from tb1 where id=1;+----+------+| id | c1 |+----+------+| 1 | 1101 |+----+------+1 row in set (0.00 sec) 上面update的行为违反了REPEATABLE READ的承诺，看到了事务开始后其它事务的并发更新。这对应用开发需要特别注意，这种情况下其它数据库通常都是报错的。 其它RR和RC相比还有一个重要的区别，RC下，扫描过但不匹配的记录不会加锁，或者是先加锁再释放，即semi-consistent read。但RR下扫描过记录都要加锁。这个差别对有全表扫描的更新的场景影响极大。详细参考http://hedengcheng.com/?p=771，关于MySQL的加锁处理，这篇文章讲得很透彻！ 参考 http://hedengcheng.com/?p=771 http://dev.mysql.com/doc/refman/5.7/en/innodb-consistent-read.html http://dev.mysql.com/doc/refman/5.7/en/innodb-transaction-isolation-levels.html http://dev.mysql.com/doc/refman/5.7/en/innodb-next-key-locking.html http://blog.chinaunix.net/uid-20726500-id-3902528.html http://blog.itpub.net/22664653/viewspace-750824/ http://www.bitscn.com/pdb/mysql/201405/227973.html","tags":[{"name":"mysql gap lock","slug":"mysql-gap-lock","permalink":"https://ningyu1.github.io/tags/mysql-gap-lock/"}]},{"title":"推荐一个性能测试工具包（适用于单元测试）","date":"2018-01-11T08:52:36.000Z","path":"20180111/49-java-test.html","text":"给大家推荐一个做单元测试非常好用的性能测试工具包，contiperf，很方便的进行并发压力测试 pom引用 &lt;!-- 单元测试 --&gt;&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.7&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;!-- 性能测试 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.databene&lt;/groupId&gt; &lt;artifactId&gt;contiperf&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 使用示例 /** * &lt;功能描述&gt; * * @author ningyu * @date 2017年10月24日 下午2:40:58 */public class MyPerfTest &#123; private IRedisSequenceService sequenceService; @Rule public ContiPerfRule i = new ContiPerfRule(); @Before public void init() &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;test-spring-context.xml&quot;); sequenceService = (IRedisSequenceService) context.getBean(&quot;redisSequenceService&quot;); &#125; @Test @PerfTest(threads=10, invocations=10000)//threads并发线程数量，invocations总调用次数,还有其他参数可以设置查看文档或者源码 public void test() &#123; try &#123; long res = sequenceService.nextSeq(&quot;TEST_NINGYU&quot;); System.out.println(Thread.currentThread().getName()+&quot;:&quot;+res); &#125; catch(Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;","tags":[{"name":"test","slug":"test","permalink":"https://ningyu1.github.io/tags/test/"},{"name":"java","slug":"java","permalink":"https://ningyu1.github.io/tags/java/"}]},{"title":"如何直接操作Docker容器？","date":"2018-01-11T08:11:36.000Z","path":"20180111/48-docker.html","text":"如果你想对Docker的容器进行操作，比如直接查看日志（Rancher无法看的时候），可以通过以下方式实现： 执行命令docker ps，找到该容器 第一种方式： 执行命令docker exec -it [容器号前几位即可] /bin/bash，进入容器内部（类似Linux环境），如： 如果/bin/bash不能执行，那就用/bin/sh。换一种shell。 进入容器后我们就可以做任何事情，建议只在容器内做只读操作，必要进行修改操作。如果不想进入容器内部操作也可以： 执行命令docker exec -it [容器号前几位即可] tailf -n 100 /xxxx/xxxxx.log，进入容器内部（类似Linux环境），如： 第二种方式： 执行命令docker logs [容器号前几位即可]，查看日志 docker logs --tail=200 -f 容器id ps:–tail=200 显示最近200行 ,all显示所有 这个可以用于不知道日志存放在哪里，如： 或者直接去宿主机器上查看容器日志文件，docker会在主机上面的/var/lib/docker/containers/[容器id]/生成每个容器的日志文件，以[容器id]-json.log命名，但是不推荐这种方式查看，如： 在/var/lib/docker/containers能看到很多关于容器的信息比如说hostname等。 docker还支持Log Driver可以将日志接入到日志分析工具，比如说：ELKB套件","tags":[{"name":"docker","slug":"docker","permalink":"https://ningyu1.github.io/tags/docker/"},{"name":"rancher","slug":"rancher","permalink":"https://ningyu1.github.io/tags/rancher/"}]},{"title":"Jenkins、SVN、MAVEN打包时区问题解决方案","date":"2018-01-09T10:30:36.000Z","path":"20180109/47-jenkins-svn-maven-timezone.html","text":"目录 Jenkins时区设置问题 SVN更新代码时区问题 MAVEN打包时区问题 一、Jenkins时区设置问题docker@jenkins:~$ cat /etc/default/jenkins|grep 2048JAVA_ARGS=&quot;-Xmx2048m -Xms2048m -XX:PermSize=512m -XX:MaxPermSize=512m -Dorg.apache.commons.jelly.tags.fmt.timeZone=Asia/Shanghai -Djava.awt.headless=true&quot; # Allow graphs etc. to work even when an X server is present 增加时区参数：-Dorg.apache.commons.jelly.tags.fmt.timeZone=Asia/Shanghai 修改启动后查看jenkins系统参数： 二、SVN更新代码时区问题svn时区依赖jenkins的时区设置 没有修改时区之前： 能看的出来revision时间是有问题的跟我们机器时间不一致少了8小时 修复这个问题有两个方法 可以通过设置svn路径后增加@HEAD忽略掉revision来修复这个问题，具体设置如下 修改jenkins时区，参考第一个问题 jenkins时区设置完之后svn拉取代码会自动修改：revision，如图 三、MAVEN打包时区问题我项目中使用的是maven自己的timestamp &lt;timestamp&gt;$&#123;maven.build.timestamp&#125;&lt;/timestamp&gt; 它的问题是：时区是UTC而且无法修改，如果要使用GMT+8，就需要插件提供支持 使用maven utc的timestamp构建出来的包名如下： 我使用插件：build-helper-maven-plugin 在pom中增加plugin build-helper-maven-plugin来覆盖maven的timestamp变量： &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;build-helper-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;timestamp-property&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;timestamp-property&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;name&gt;timestamp&lt;/name&gt; &lt;pattern&gt;yyyyMMddHHmm&lt;/pattern&gt; &lt;timeZone&gt;GMT+8&lt;/timeZone&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 然后打包测试： 测试通过，plugin配置建议配置在parent pom中这样所有子集项目都可以继承","tags":[{"name":"jenkins","slug":"jenkins","permalink":"https://ningyu1.github.io/tags/jenkins/"},{"name":"svn","slug":"svn","permalink":"https://ningyu1.github.io/tags/svn/"},{"name":"maven","slug":"maven","permalink":"https://ningyu1.github.io/tags/maven/"}]},{"title":"Docker Registry镜像清理问题","date":"2017-12-29T06:45:36.000Z","path":"20171229/46-docker-registry.html","text":"目录 修改Docker Registry配置 使用Registry V2 RestfulAPI 删除镜像 Docker Registry GC回收空间 使用UI管理Docker Registry 修改Docker Registry配置配置开启删除功能:config.yml version: 0.1log: fields: service: registrystorage: delete: enabled: true cache: blobdescriptor: inmemory filesystem: rootdirectory: /var/lib/registryhttp: addr: :5000 headers: X-Content-Type-Options: [nosniff]health: storagedriver: enabled: true interval: 10s threshold: 3 主要在storage下增加delete开启状态 enabled:true 具体配置参考官方配置详情：https://github.com/docker/distribution/blob/master/docs/configuration.md 使用Registry V2 RestfulAPI 删除镜像镜像删除之前需要获取镜像的digest值 获取镜像digest值 curl --cacert /etc/docker/certs.d/192.168.0.34\\:5000/ca.crt -H &quot;Accept:application/vnd.docker.distribution.manifest.v2+json&quot; https://192.168.0.34:5000/v2/messer/manifests/1.0 注意： 我们配置了证书，所以必须要添加证书 –cacert使用crt证书 在获取镜像digest值时必须要指定Header “Accept:application/vnd.docker.distribution.manifest.v2+json” 否则无法获取 RESTful API格式： /v2/&lt;镜像名称&gt;/manifests/&lt;tag&gt; 具体Docker registry V2 RESTful API查看：https://docs.docker.com/registry/spec/api/ 通过上面获取到的具体返回信息 &#123; &quot;schemaVersion&quot;: 2, &quot;mediaType&quot;: &quot;application/vnd.docker.distribution.manifest.v2+json&quot;, &quot;config&quot;: &#123; &quot;mediaType&quot;: &quot;application/octet-stream&quot;, &quot;size&quot;: 4191, &quot;digest&quot;: &quot;sha256:c8043677c5d750e0904298c29825d1da8389a1ea2e2564e076ed54a023ece056&quot; &#125;, &quot;layers&quot;: [ &#123; &quot;mediaType&quot;: &quot;application/vnd.docker.image.rootfs.diff.tar.gzip&quot;, &quot;size&quot;: 51363125, &quot;digest&quot;: &quot;sha256:75a822cd7888e394c49828b951061402d31745f596b1f502758570f2d0ee79e2&quot; &#125;, &#123; &quot;mediaType&quot;: &quot;application/vnd.docker.image.rootfs.diff.tar.gzip&quot;, &quot;size&quot;: 20179224, &quot;digest&quot;: &quot;sha256:0aefb9dc4a57d3de6a9cfa2e87e4502dfa8ce3876264bb20783b1610f8e44806&quot; &#125;, &#123; &quot;mediaType&quot;: &quot;application/vnd.docker.image.rootfs.diff.tar.gzip&quot;, &quot;size&quot;: 193, &quot;digest&quot;: &quot;sha256:046e44ee6057f1264d00b0c54adcff2f2c44d30a29b50dfef928776f7aa45cc8&quot; &#125;, &#123; &quot;mediaType&quot;: &quot;application/vnd.docker.image.rootfs.diff.tar.gzip&quot;, &quot;size&quot;: 596, &quot;digest&quot;: &quot;sha256:614a7b3525a1442775b9d1b52413024dc750b6a9169fcae8d4ef9cf98bda7f0f&quot; &#125;, &#123; &quot;mediaType&quot;: &quot;application/vnd.docker.image.rootfs.diff.tar.gzip&quot;, &quot;size&quot;: 1083978, &quot;digest&quot;: &quot;sha256:5fe57df972ae5e10f02783cb372841e6feab67a296e2abc16f9a868e4322c33d&quot; &#125; ]&#125; 我们要的就是&quot;digest&quot;: &quot;sha256:c8043677c5d750e0904298c29825d1da8389a1ea2e2564e076ed54a023ece056&quot;这个值 通过delete接口删除镜像 curl --cacert /etc/docker/certs.d/192.168.0.34\\:5000/ca.crt -X DELETE https://192.168.0.34:5000/v2/messer/manifests/sha256:c8043677c5d750e0904298c29825d1da8389a1ea2e2564e076ed54a023ece056 返回不是404 就是删除了 具体Docker registry V2 RESTful API查看：https://docs.docker.com/registry/spec/api/ Docker Registry GC回收空间但是实际上并没有删除，只是删除了 Registry 的索引。实际文件并没有删除。 最后还需要执行镜像的垃圾回收： registry garbage-collect /etc/docker/registry/config.yml 上面需要进入到registry容器里面去执行，/etc/docker/registry/config.yml为配置文件路径 gc完后会看到被gc的信息例如： root@83d6f5acc9f5:/# /bin/registry garbage-collect /etc/docker/registry/config.ymlINFO[0013] Deleting blob: /docker/registry/v2/blobs/sha256/c0/c0c9ad6136b5e7b142c48c7167eede3d15af54c538f7f3177c50693006cca242 go.version=go1.6.2 instance.id=73c88c92-c196-413e-9cdf-413760de2a62INFO[0013] Deleting blob: /docker/registry/v2/blobs/sha256/0c/0c1f3512513001c7e37c0dff11064a5c76ad9098507ee74189d6a810742173d7 go.version=go1.6.2 instance.id=73c88c92-c196-413e-9cdf-413760de2a62 如果没有任何输出证明没有回收到任何东西。 使用UI管理Docker Registry上面是通过Docker registry V2 RESTful API的方式删除，也可以通过UI工具删除，目前Docker registry UI工具也比较多这里介绍两个， docker-registry-frontend和hyper/docker-registry-web。 docker-registry-frontend我们使用的是 docker-registry-frontend但是他的功能比较弱没有删除的操作，只能浏览，虽然他的说明里面有说明添加了删除功能但是发布的版本中并没有合并删除功能的代码： 官方hub信息：https://hub.docker.com/r/konradkleine/docker-registry-frontend/ 这个MODE_BROWSE_ONLY=false这个配置是完全没有效果的，今天可以查看docker-registry-frontend的github issue：https://github.com/kwk/docker-registry-frontend/issues/106 hyper/docker-registry-web这个UI虽然不是很好看，但是有删除功能 官方hub信息：https://hub.docker.com/r/hyper/docker-registry-web/ 创建步骤根据官方hub上面的说明信息一步一步做就ok了，但是这个东西做的不太好速度有点慢。 界面预览： 不管是通过RESTful API还是UI删除镜像，都需要去再registry里去gc一下才能真正释放空间，如下时候gc后的效果图","tags":[{"name":"docker","slug":"docker","permalink":"https://ningyu1.github.io/tags/docker/"},{"name":"docker registry","slug":"docker-registry","permalink":"https://ningyu1.github.io/tags/docker-registry/"},{"name":"docker registry web","slug":"docker-registry-web","permalink":"https://ningyu1.github.io/tags/docker-registry-web/"},{"name":"docker registry frontend","slug":"docker-registry-frontend","permalink":"https://ningyu1.github.io/tags/docker-registry-frontend/"}]},{"title":"Spring Cloud Netflix架构浅析","date":"2017-12-25T05:58:36.000Z","path":"20171225/45-spring-cloud-netflix.html","text":"点评这篇文章比较适合入门，对于spring cloud生态的成员有一个大致的了解，其实spring cloud生态将netflix的产品进行了很好的整合，netflix早几年就在服务治理这块有很深入的研究，出品了很多服务治理的工具hystrix就是很有名的一个，具体可以查看：https://github.com/netflix，刚好在微服务盛行的年代服务治理是必不可少的一环，现在在微服务开发套件这块常用也就是下面这两种选择： spring cloud套件，成熟上手快 自建微服务架构 UCM，统一配置管理（百度的disconf、阿里的diamond、点评的lion，等很多开源的）。 RPC，阿里的Dubbo、点评的Pigeon，当当改的DubboX，grpc，等等很多开源的，还有很多公司自研的。 服务治理，netflix的hystrix老牌的功能强大的服务治理工具，有熔断、降级等功能，很多公司会结合监控套件开发自己的服务治理工具。 开发框架（rpc、restful这个一般公司都有自研的开发框架） 注册中心（zookeeper、redis、Consul、SmartStack、Eureka，其中一些已经是spring cloud生态的一员了）。 网关，restful的使用nginx+lua，这也是openAPI网关常用的手段 负载均衡，这个结合选用的rpc框架来选择。一般rpc框架都有负载均衡的功能。 服务治理熔断，使用hystrix（也已经是spring cloud生态的一员了） 监控，使用pinpoint、点评的cat、等其他开源的APM工具 DevOPS，持续交付一般也是自己构架的，采用jenkins打包docker镜像，使用docker生态的工具构建容器化发布平台。 下面文章转自：https://my.oschina.net/u/3747963/blog/1592777作者：@海岸线的曙光 微服务框架Spring Boot+Spring CloudSpring Cloud是基于Spring Boot的一整套实现微服务的框架，可以说，Spring Boot作为框架，Spring Cloud作为微服务，一起构成了一种不可忽视的、新生的框架体系。它提供了微服务开发所需的配置管理、服务发现、断路器、智能路由、微代理、控制总线、全局锁、决策竞选、分布式会话和集群状态管理等组件，方便易用。Spring Cloud包含了非常多的子框架，其中，Spring Cloud Netflix是其中一套框架，它主要提供的模块包括：服务发现、断路器和监控、智能路由、客户端负载均衡等。 Spring Cloud Netflix组件以及部署 Eureka，服务注册和发现，它提供了一个服务注册中心、服务发现的客户端，还有一个方便的查看所有注册的服务的界面。 所有的服务使用Eureka的服务发现客户端来将自己注册到Eureka的服务器上。 Zuul，网关，所有的客户端请求通过这个网关访问后台的服务。他可以使用一定的路由配置来判断某一个URL由哪个服务来处理。并从Eureka获取注册的服务来转发请求。 Ribbon，即负载均衡，Zuul网关将一个请求发送给某一个服务的应用的时候，如果一个服务启动了多个实例，就会通过Ribbon来通过一定的负载均衡策略来发送给某一个服务实例。 Feign，服务客户端，服务之间如果需要相互访问，可以使用RestTemplate，也可以使用Feign客户端访问。它默认会使用Ribbon来实现负载均衡。 Hystrix，监控和断路器。我们只需要在服务接口上添加Hystrix标签，就可以实现对这个接口的监控和断路器功能。 Hystrix Dashboard，监控面板，他提供了一个界面，可以监控各个服务上的服务调用所消耗的时间等。 Turbine，监控聚合，使用Hystrix监控，我们需要打开每一个服务实例的监控信息来查看。而Turbine可以帮助我们把所有的服务实例的监控信息聚合到一个地方统一查看。 Spring Cloud Netflix组件开发可以参考其中文文档：https://springcloud.cc/spring-cloud-netflix.html 服务注册与监控中心： @SpringBootApplication@EnableEurekaServer@EnableHystrixDashboardpublic class ApplicationRegistry &#123; public static void main(String[] args) &#123; new SpringApplicationBuilder(Application.class).web(true).run(args); &#125;&#125; 这里使用spring boot标签的 @SpringBootApplication 说明当前的应用是一个spring boot应用。这样我就可以直接用main函数在IDE里面启动这个应用，也可以打包后用命令行启动。当然也可以把打包的war包用tomcat之类的服务器启动。 使用标签 @EnableEurekaServer ，就能在启动过程中启动Eureka服务注册中心的组件。它会监听一个端口，默认是8761，来接收服务注册。并提供一个web页面，打开以后，可以看到注册的服务。 添加 @EnableHystrixDashboard 就会提供一个监控的页面，我们可以在上面输入要监控的服务的地址，就可以查看启用了Hystrix监控的接口的调用情况。 当然，为了使用上面的组件，我们需要在maven的POM文件里添加相应的依赖，比如使用 spring-boot-starter-parent ，依赖 spring-cloud-starter-eureka-server 和 spring-cloud-starter-hystrix-dashboard 等。 服务间调用： 两种方式可以进行服务调用，RestTemplate和FeignClient。不管是什么方式，他都是通过REST接口调用服务的http接口，参数和结果默认都是通过jackson序列化和反序列化。因为Spring MVC的RestController定义的接口，返回的数据都是通过jackson序列化成json数据。 第一种：RestTemplate，只需要定义一个RestTemplate的Bean，设置成 LoadBalanced 即可： @Configurationpublic class SomeCloudConfiguration &#123; @LoadBalanced @Bean RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; 这样我们就可以在需要用的地方注入这个bean使用： public class SomeServiceClass &#123; @Autowired private RestTemplate restTemplate; public String getUserById(Long userId) &#123; UserDTO results = restTemplate.getForObject(&quot;http://users/getUserDetail/&quot; + userId, UserDTO.class); return results; &#125;&#125; 其中， users 是服务ID，Ribbon会从服务实例列表获得这个服务的一个实例，发送请求，并获得结果。对象 UserDTO 需要序列号，它的反序列号会自动完成。 第二种：FeignClient @FeignClient(value = &quot;users&quot;, path = &quot;/users&quot;)public interface UserCompositeService &#123; @RequestMapping(value = &quot;/getUserDetail/&#123;id&#125;&quot;, method = RequestMethod.GET, produces = MediaType.APPLICATION_JSON_VALUE) UserDTO getUserById(@PathVariable Long id);&#125; 我们只需要使用 @FeignClient 定义一个借口，Spring Cloud Feign会帮我们生成一个它的实现，从相应的users服务获取数据。 其中， @FeignClient(value = “users”, path = “/users/getUserDetail”) 里面的value是服务ID，path是这一组接口的path前缀。 在下面的方法定义里，就好像设置Spring MVC的接口一样，对于这个方法，它对应的URL是 /users/getUserDetail/{id} 。 然后，在使用它的时候，就像注入一个一般的服务一样注入后使用即可： public class SomeOtherServiceClass &#123; @Autowired private UserCompositeService userService; public void doSomething() &#123; // ..... UserDTO results = userService.getUserById(userId); // other operation... &#125;&#125; 断路器： //断路器：为了解决当某个方法调用失败的时候，调用后备方法来替代失败的方法，已达到容错／阻止级联错误的功能//fallbackMethod指定后备方法@HystrixCommand(fallbackMethod = &quot;doStudentFallback&quot;)@RequestMapping(value = &quot;dostudent&quot;,method = RequestMethod.GET)public String doStudent()&#123; return &quot;your name:secret,your age:secret!&quot;;&#125;public String doStudentFallback()&#123; return &quot;your name:FEIFEI,your age:26!&quot;;&#125; 其中，使用@EnableCircuitBreaker来启用断路器支持，Spring Cloud提供了一个控制台来监控断路器的运行情况，通过@EnableHystrixDashboard注解开启。 以上是简单的一些对Spring Cloud Netflix组件的介绍。","tags":[{"name":"rpc","slug":"rpc","permalink":"https://ningyu1.github.io/tags/rpc/"},{"name":"ucm","slug":"ucm","permalink":"https://ningyu1.github.io/tags/ucm/"},{"name":"spring cloud","slug":"spring-cloud","permalink":"https://ningyu1.github.io/tags/spring-cloud/"},{"name":"netflix","slug":"netflix","permalink":"https://ningyu1.github.io/tags/netflix/"},{"name":"hystrix","slug":"hystrix","permalink":"https://ningyu1.github.io/tags/hystrix/"},{"name":"Eureka","slug":"Eureka","permalink":"https://ningyu1.github.io/tags/Eureka/"},{"name":"zuul","slug":"zuul","permalink":"https://ningyu1.github.io/tags/zuul/"},{"name":"ribbon","slug":"ribbon","permalink":"https://ningyu1.github.io/tags/ribbon/"},{"name":"devops","slug":"devops","permalink":"https://ningyu1.github.io/tags/devops/"},{"name":"monitor","slug":"monitor","permalink":"https://ningyu1.github.io/tags/monitor/"}]},{"title":"JDK1.8新特性详解","date":"2017-12-15T10:15:36.000Z","path":"20171215/44-jdk1.8-feature.html","text":"将Java8的新特新逐一列出，并将使用简单的代码示例来指导你如何使用默认接口方法，lambda表达式，方法引用以及多重Annotation，之后你将会学到最新的API上的改进，比如流，函数式接口，Map以及全新的日期API 一、接口的默认方法Java 8允许我们给接口添加一个非抽象的方法实现，只需要使用 default关键字即可，这个特征又叫做扩展方法，示例如下： interface Formula &#123; double calculate(int a); default double sqrt(int a) &#123; return Math.sqrt(a); &#125;&#125; Formula接口在拥有calculate方法之外同时还定义了sqrt方法，实现了Formula接口的子类只需要实现一个calculate方法，默认方法sqrt将在子类上可以直接使用。 Formula formula = new Formula() &#123; @Override public double calculate(int a) &#123; return sqrt(a * 100); &#125;&#125;;formula.calculate(100); // 100.0formula.sqrt(16); // 4.0 文中的formula被实现为一个匿名类的实例，该代码非常容易理解，6行代码实现了计算 sqrt(a * 100)。在下一节中，我们将会看到实现单方法接口的更简单的做法。 二、Lambda 表达式首先看看在老版本的Java中是如何排列字符串的： List&lt;String&gt; names = Arrays.asList(&quot;peter&quot;, &quot;anna&quot;, &quot;mike&quot;, &quot;xenia&quot;);Collections.sort(names, new Comparator&lt;String&gt;() &#123; @Override public int compare(String a, String b) &#123; return b.compareTo(a); &#125;&#125;); 只需要给静态方法 Collections.sort 传入一个List对象以及一个比较器来按指定顺序排列。通常做法都是创建一个匿名的比较器对象然后将其传递给sort方法。 在Java 8 中你就没必要使用这种传统的匿名对象的方式了，Java 8提供了更简洁的语法，lambda表达式： Collections.sort(names, (String a, String b) -&gt; &#123; return b.compareTo(a);&#125;); 看到了吧，代码变得更段且更具有可读性，但是实际上还可以写得更短： Collections.sort(names, (String a, String b) -&gt; b.compareTo(a)); 对于函数体只有一行代码的，你可以去掉大括号{}以及return关键字，但是你还可以写得更短点： Collections.sort(names, (a, b) -&gt; b.compareTo(a)); Java编译器可以自动推导出参数类型，所以你可以不用再写一次类型。接下来我们看看lambda表达式还能作出什么更方便的东西来： 三、函数式接口Lambda表达式是如何在java的类型系统中表示的呢？每一个lambda表达式都对应一个类型，通常是接口类型。而“函数式接口”是指仅仅只包含一个抽象方法的接口，每一个该类型的lambda表达式都会被匹配到这个抽象方法。因为 默认方法 不算抽象方法，所以你也可以给你的函数式接口添加默认方法。 我们可以将lambda表达式当作任意只包含一个抽象方法的接口类型，确保你的接口一定达到这个要求，你只需要给你的接口添加 @FunctionalInterface 注解，编译器如果发现你标注了这个注解的接口有多于一个抽象方法的时候会报错的。 @FunctionalInterfaceinterface Converter&lt;F, T&gt; &#123; T convert(F from);&#125;Converter&lt;String, Integer&gt; converter = (from) -&gt; Integer.valueOf(from);Integer converted = converter.convert(&quot;123&quot;);System.out.println(converted); // 123 需要注意如果@FunctionalInterface如果没有指定，上面的代码也是对的。 将lambda表达式映射到一个单方法的接口上，这种做法在Java 8之前就有别的语言实现，比如Rhino JavaScript解释器，如果一个函数参数接收一个单方法的接口而你传递的是一个function，Rhino 解释器会自动做一个单接口的实例到function的适配器，典型的应用场景有 org.w3c.dom.events.EventTarget 的addEventListener 第二个参数 EventListener。 四、方法与构造函数引用前一节中的代码还可以通过静态方法引用来表示： Converter&lt;String, Integer&gt; converter = Integer::valueOf;Integer converted = converter.convert(&quot;123&quot;);System.out.println(converted); // 123 Java 8 允许你使用 :: 关键字来传递方法或者构造函数引用，上面的代码展示了如何引用一个静态方法，我们也可以引用一个对象的方法： converter = something::startsWith;String converted = converter.convert(&quot;Java&quot;);System.out.println(converted); // &quot;J&quot; 接下来看看构造函数是如何使用::关键字来引用的，首先我们定义一个包含多个构造函数的简单类： class Person &#123; String firstName; String lastName; Person() &#123;&#125; Person(String firstName, String lastName) &#123; this.firstName = firstName; this.lastName = lastName; &#125;&#125; 接下来我们指定一个用来创建Person对象的对象工厂接口： interface PersonFactory&lt;P extends Person&gt; &#123; P create(String firstName, String lastName);&#125; 这里我们使用构造函数引用来将他们关联起来，而不是实现一个完整的工厂： PersonFactory&lt;Person&gt; personFactory = Person::new;Person person = personFactory.create(&quot;Peter&quot;, &quot;Parker&quot;); 我们只需要使用 Person::new 来获取Person类构造函数的引用，Java编译器会自动根据PersonFactory.create方法的签名来选择合适的构造函数。 五、Lambda 作用域在lambda表达式中访问外层作用域和老版本的匿名对象中的方式很相似。你可以直接访问标记了final的外层局部变量，或者实例的字段以及静态变量。 六、访问局部变量我们可以直接在lambda表达式中访问外层的局部变量： final int num = 1;Converter&lt;Integer, String&gt; stringConverter = (from) -&gt; String.valueOf(from + num);stringConverter.convert(2); // 3 但是和匿名对象不同的是，这里的变量num可以不用声明为final，该代码同样正确： int num = 1;Converter&lt;Integer, String&gt; stringConverter = (from) -&gt; String.valueOf(from + num);stringConverter.convert(2); // 3 不过这里的num必须不可被后面的代码修改（即隐性的具有final的语义），例如下面的就无法编译： int num = 1;Converter&lt;Integer, String&gt; stringConverter = (from) -&gt; String.valueOf(from + num);num = 3; 在lambda表达式中试图修改num同样是不允许的。 七、访问对象字段与静态变量和本地变量不同的是，lambda内部对于实例的字段以及静态变量是即可读又可写。该行为和匿名对象是一致的： class Lambda4 &#123; static int outerStaticNum; int outerNum; void testScopes() &#123; Converter&lt;Integer, String&gt; stringConverter1 = (from) -&gt; &#123; outerNum = 23; return String.valueOf(from); &#125;; Converter&lt;Integer, String&gt; stringConverter2 = (from) -&gt; &#123; outerStaticNum = 72; return String.valueOf(from); &#125;; &#125;&#125; 八、访问接口的默认方法还记得第一节中的formula例子么，接口Formula定义了一个默认方法sqrt可以直接被formula的实例包括匿名对象访问到，但是在lambda表达式中这个是不行的。Lambda表达式中是无法访问到默认方法的，以下代码将无法编译： Formula formula = (a) -&gt; sqrt( a * 100);Built-in Functional Interfaces JDK 1.8 API包含了很多内建的函数式接口，在老Java中常用到的比如Comparator或者Runnable接口，这些接口都增加了@FunctionalInterface注解以便能用在lambda上。Java 8 API同样还提供了很多全新的函数式接口来让工作更加方便，有一些接口是来自Google Guava库里的，即便你对这些很熟悉了，还是有必要看看这些是如何扩展到lambda上使用的。 Predicate接口Predicate 接口只有一个参数，返回boolean类型。该接口包含多种默认方法来将Predicate组合成其他复杂的逻辑（比如：与，或，非）： Predicate&lt;String&gt; predicate = (s) -&gt; s.length() &gt; 0;predicate.test(&quot;foo&quot;); // truepredicate.negate().test(&quot;foo&quot;); // falsePredicate&lt;Boolean&gt; nonNull = Objects::nonNull;Predicate&lt;Boolean&gt; isNull = Objects::isNull;Predicate&lt;String&gt; isEmpty = String::isEmpty;Predicate&lt;String&gt; isNotEmpty = isEmpty.negate(); Function 接口Function 接口有一个参数并且返回一个结果，并附带了一些可以和其他函数组合的默认方法（compose, andThen）： Function&lt;String, Integer&gt; toInteger = Integer::valueOf;Function&lt;String, String&gt; backToString = toInteger.andThen(String::valueOf);backToString.apply(&quot;123&quot;); // &quot;123&quot; Supplier 接口Supplier 接口返回一个任意范型的值，和Function接口不同的是该接口没有任何参数 Supplier&lt;Person&gt; personSupplier = Person::new;personSupplier.get(); // new Person Consumer 接口Consumer 接口表示执行在单个参数上的操作。 Consumer greeter = (p) -&gt; System.out.println(“Hello, “ + p.firstName);greeter.accept(new Person(“Luke”, “Skywalker”)); Comparator 接口Comparator 是老Java中的经典接口， Java 8在此之上添加了多种默认方法： Comparator&lt;Person&gt; comparator = (p1, p2) -&gt; p1.firstName.compareTo(p2.firstName);Person p1 = new Person(&quot;John&quot;, &quot;Doe&quot;);Person p2 = new Person(&quot;Alice&quot;, &quot;Wonderland&quot;);comparator.compare(p1, p2); // &gt; 0comparator.reversed().compare(p1, p2); // &lt; 0 Optional 接口Optional 不是函数是接口，这是个用来防止NullPointerException异常的辅助类型，这是下一届中将要用到的重要概念，现在先简单的看看这个接口能干什么： Optional 被定义为一个简单的容器，其值可能是null或者不是null。在Java 8之前一般某个函数应该返回非空对象但是偶尔却可能返回了null，而在Java 8中，不推荐你返回null而是返回Optional。 Optional&lt;String&gt; optional = Optional.of(&quot;bam&quot;);optional.isPresent(); // trueoptional.get(); // &quot;bam&quot;optional.orElse(&quot;fallback&quot;); // &quot;bam&quot;optional.ifPresent((s) -&gt; System.out.println(s.charAt(0))); // &quot;b&quot; Stream 接口java.util.Stream 表示能应用在一组元素上一次执行的操作序列。Stream 操作分为中间操作或者最终操作两种，最终操作返回一特定类型的计算结果，而中间操作返回Stream本身，这样你就可以将多个操作依次串起来。Stream 的创建需要指定一个数据源，比如 java.util.Collection的子类，List或者Set， Map不支持。Stream的操作可以串行执行或者并行执行。 首先看看Stream是怎么用，首先创建实例代码的用到的数据List： List&lt;String&gt; stringCollection = new ArrayList&lt;&gt;();stringCollection.add(&quot;ddd2&quot;);stringCollection.add(&quot;aaa2&quot;);stringCollection.add(&quot;bbb1&quot;);stringCollection.add(&quot;aaa1&quot;);stringCollection.add(&quot;bbb3&quot;);stringCollection.add(&quot;ccc&quot;);stringCollection.add(&quot;bbb2&quot;);stringCollection.add(&quot;ddd1&quot;); Java 8扩展了集合类，可以通过 Collection.stream() 或者 Collection.parallelStream() 来创建一个Stream。下面几节将详细解释常用的Stream操作： Filter 过滤过滤通过一个predicate接口来过滤并只保留符合条件的元素，该操作属于中间操作，所以我们可以在过滤后的结果来应用其他Stream操作（比如forEach）。forEach需要一个函数来对过滤后的元素依次执行。forEach是一个最终操作，所以我们不能在forEach之后来执行其他Stream操作。 stringCollection .stream() .filter((s) -&gt; s.startsWith(&quot;a&quot;)) .forEach(System.out::println);// &quot;aaa2&quot;, &quot;aaa1&quot; Sort 排序排序是一个中间操作，返回的是排序好后的Stream。如果你不指定一个自定义的Comparator则会使用默认排序。 stringCollection .stream() .sorted() .filter((s) -&gt; s.startsWith(&quot;a&quot;)) .forEach(System.out::println);// &quot;aaa1&quot;, &quot;aaa2&quot; 需要注意的是，排序只创建了一个排列好后的Stream，而不会影响原有的数据源，排序之后原数据stringCollection是不会被修改的： System.out.println(stringCollection);// ddd2, aaa2, bbb1, aaa1, bbb3, ccc, bbb2, ddd1 Map 映射中间操作map会将元素根据指定的Function接口来依次将元素转成另外的对象，下面的示例展示了将字符串转换为大写字符串。你也可以通过map来讲对象转换成其他类型，map返回的Stream类型是根据你map传递进去的函数的返回值决定的。 stringCollection .stream() .map(String::toUpperCase) .sorted((a, b) -&gt; b.compareTo(a)) .forEach(System.out::println);// &quot;DDD2&quot;, &quot;DDD1&quot;, &quot;CCC&quot;, &quot;BBB3&quot;, &quot;BBB2&quot;, &quot;AAA2&quot;, &quot;AAA1&quot; Match 匹配Stream提供了多种匹配操作，允许检测指定的Predicate是否匹配整个Stream。所有的匹配操作都是最终操作，并返回一个boolean类型的值。 boolean anyStartsWithA = stringCollection .stream() .anyMatch((s) -&gt; s.startsWith(&quot;a&quot;));System.out.println(anyStartsWithA); // trueboolean allStartsWithA = stringCollection .stream() .allMatch((s) -&gt; s.startsWith(&quot;a&quot;));System.out.println(allStartsWithA); // falseboolean noneStartsWithZ = stringCollection .stream() .noneMatch((s) -&gt; s.startsWith(&quot;z&quot;));System.out.println(noneStartsWithZ); // true Count 计数计数是一个最终操作，返回Stream中元素的个数，返回值类型是long。 long startsWithB = stringCollection .stream() .filter((s) -&gt; s.startsWith(&quot;b&quot;)) .count();System.out.println(startsWithB); // 3 Reduce 规约这是一个最终操作，允许通过指定的函数来讲stream中的多个元素规约为一个元素，规越后的结果是通过Optional接口表示的： Optional&lt;String&gt; reduced = stringCollection .stream() .sorted() .reduce((s1, s2) -&gt; s1 + &quot;#&quot; + s2);reduced.ifPresent(System.out::println);// &quot;aaa1#aaa2#bbb1#bbb2#bbb3#ccc#ddd1#ddd2&quot; 并行Streams前面提到过Stream有串行和并行两种，串行Stream上的操作是在一个线程中依次完成，而并行Stream则是在多个线程上同时执行。 下面的例子展示了是如何通过并行Stream来提升性能： 首先我们创建一个没有重复元素的大表： int max = 1000000;List&lt;String&gt; values = new ArrayList&lt;&gt;(max);for (int i = 0; i &lt; max; i++) &#123; UUID uuid = UUID.randomUUID(); values.add(uuid.toString());&#125; 然后我们计算一下排序这个Stream要耗时多久，串行排序： long t0 = System.nanoTime();long count = values.stream().sorted().count();System.out.println(count);long t1 = System.nanoTime();long millis = TimeUnit.NANOSECONDS.toMillis(t1 - t0);System.out.println(String.format(&quot;sequential sort took: %d ms&quot;, millis)); // 串行耗时: 899 ms并行排序： long t0 = System.nanoTime();long count = values.parallelStream().sorted().count();System.out.println(count);long t1 = System.nanoTime();long millis = TimeUnit.NANOSECONDS.toMillis(t1 - t0);System.out.println(String.format(&quot;parallel sort took: %d ms&quot;, millis)); // 并行排序耗时: 472 ms上面两个代码几乎是一样的，但是并行版的快了50%之多，唯一需要做的改动就是将stream()改为parallelStream()。 Map前面提到过，Map类型不支持stream，不过Map提供了一些新的有用的方法来处理一些日常任务。 Map&lt;Integer, String&gt; map = new HashMap&lt;&gt;();for (int i = 0; i &lt; 10; i++) &#123; map.putIfAbsent(i, &quot;val&quot; + i);&#125; map.forEach((id, val) -&gt; System.out.println(val));以上代码很容易理解， putIfAbsent 不需要我们做额外的存在性检查，而forEach则接收一个Consumer接口来对map里的每一个键值对进行操作。 下面的例子展示了map上的其他有用的函数： map.computeIfPresent(3, (num, val) -&gt; val + num);map.get(3); // val33map.computeIfPresent(9, (num, val) -&gt; null);map.containsKey(9); // falsemap.computeIfAbsent(23, num -&gt; &quot;val&quot; + num);map.containsKey(23); // truemap.computeIfAbsent(3, num -&gt; &quot;bam&quot;);map.get(3); // val33 接下来展示如何在Map里删除一个键值全都匹配的项： map.remove(3, &quot;val3&quot;);map.get(3); // val33map.remove(3, &quot;val33&quot;);map.get(3); // null 另外一个有用的方法： map.getOrDefault(42, &quot;not found&quot;); // not found 对Map的元素做合并也变得很容易了： map.merge(9, &quot;val9&quot;, (value, newValue) -&gt; value.concat(newValue));map.get(9); // val9map.merge(9, &quot;concat&quot;, (value, newValue) -&gt; value.concat(newValue));map.get(9); // val9concat Merge做的事情是如果键名不存在则插入，否则则对原键对应的值做合并操作并重新插入到map中。 九、Date APIJava 8 在包java.time下包含了一组全新的时间日期API。新的日期API和开源的Joda-Time库差不多，但又不完全一样，下面的例子展示了这组新API里最重要的一些部分： Clock 时钟Clock类提供了访问当前日期和时间的方法，Clock是时区敏感的，可以用来取代 System.currentTimeMillis() 来获取当前的微秒数。某一个特定的时间点也可以使用Instant类来表示，Instant类也可以用来创建老的java.util.Date对象。 Clock clock = Clock.systemDefaultZone();long millis = clock.millis();Instant instant = clock.instant();Date legacyDate = Date.from(instant); // legacy java.util.Date Timezones 时区在新API中时区使用ZoneId来表示。时区可以很方便的使用静态方法of来获取到。 时区定义了到UTS时间的时间差，在Instant时间点对象到本地日期对象之间转换的时候是极其重要的。 System.out.println(ZoneId.getAvailableZoneIds());// prints all available timezone idsZoneId zone1 = ZoneId.of(&quot;Europe/Berlin&quot;);ZoneId zone2 = ZoneId.of(&quot;Brazil/East&quot;);System.out.println(zone1.getRules());System.out.println(zone2.getRules());// ZoneRules[currentStandardOffset=+01:00]// ZoneRules[currentStandardOffset=-03:00] LocalTime 本地时间LocalTime 定义了一个没有时区信息的时间，例如 晚上10点，或者 17:30:15。下面的例子使用前面代码创建的时区创建了两个本地时间。之后比较时间并以小时和分钟为单位计算两个时间的时间差： LocalTime now1 = LocalTime.now(zone1);LocalTime now2 = LocalTime.now(zone2);System.out.println(now1.isBefore(now2)); // falselong hoursBetween = ChronoUnit.HOURS.between(now1, now2);long minutesBetween = ChronoUnit.MINUTES.between(now1, now2);System.out.println(hoursBetween); // -3System.out.println(minutesBetween); // -239 LocalTime 提供了多种工厂方法来简化对象的创建，包括解析时间字符串。 LocalTime late = LocalTime.of(23, 59, 59);System.out.println(late); // 23:59:59DateTimeFormatter germanFormatter = DateTimeFormatter .ofLocalizedTime(FormatStyle.SHORT) .withLocale(Locale.GERMAN);LocalTime leetTime = LocalTime.parse(&quot;13:37&quot;, germanFormatter);System.out.println(leetTime); // 13:37 LocalDate 本地日期LocalDate 表示了一个确切的日期，比如 2014-03-11。该对象值是不可变的，用起来和LocalTime基本一致。下面的例子展示了如何给Date对象加减天/月/年。另外要注意的是这些对象是不可变的，操作返回的总是一个新实例。 LocalDate today = LocalDate.now();LocalDate tomorrow = today.plus(1, ChronoUnit.DAYS);LocalDate yesterday = tomorrow.minusDays(2);LocalDate independenceDay = LocalDate.of(2014, Month.JULY, 4);DayOfWeek dayOfWeek = independenceDay.getDayOfWeek(); System.out.println(dayOfWeek); // FRIDAY从字符串解析一个LocalDate类型和解析LocalTime一样简单： DateTimeFormatter germanFormatter = DateTimeFormatter .ofLocalizedDate(FormatStyle.MEDIUM) .withLocale(Locale.GERMAN);LocalDate xmas = LocalDate.parse(&quot;24.12.2014&quot;, germanFormatter);System.out.println(xmas); // 2014-12-24 LocalDateTime 本地日期时间LocalDateTime 同时表示了时间和日期，相当于前两节内容合并到一个对象上了。LocalDateTime和LocalTime还有LocalDate一样，都是不可变的。LocalDateTime提供了一些能访问具体字段的方法。 LocalDateTime sylvester = LocalDateTime.of(2014, Month.DECEMBER, 31, 23, 59, 59);DayOfWeek dayOfWeek = sylvester.getDayOfWeek();System.out.println(dayOfWeek); // WEDNESDAYMonth month = sylvester.getMonth();System.out.println(month); // DECEMBERlong minuteOfDay = sylvester.getLong(ChronoField.MINUTE_OF_DAY);System.out.println(minuteOfDay); // 1439 只要附加上时区信息，就可以将其转换为一个时间点Instant对象，Instant时间点对象可以很容易的转换为老式的java.util.Date。 Instant instant = sylvester .atZone(ZoneId.systemDefault()) .toInstant();Date legacyDate = Date.from(instant);System.out.println(legacyDate); // Wed Dec 31 23:59:59 CET 2014 格式化LocalDateTime和格式化时间和日期一样的，除了使用预定义好的格式外，我们也可以自己定义格式： DateTimeFormatter formatter = DateTimeFormatter .ofPattern(&quot;MMM dd, yyyy - HH:mm&quot;);LocalDateTime parsed = LocalDateTime.parse(&quot;Nov 03, 2014 - 07:13&quot;, formatter);String string = formatter.format(parsed);System.out.println(string); // Nov 03, 2014 - 07:13 和java.text.NumberFormat不一样的是新版的DateTimeFormatter是不可变的，所以它是线程安全的。关于时间日期格式的详细信息：http://download.java.net/jdk8/docs/api/java/time/format/DateTimeFormatter.html 十、Annotation 注解在Java 8中支持多重注解了，先看个例子来理解一下是什么意思。首先定义一个包装类Hints注解用来放置一组具体的Hint注解： @interface Hints &#123; Hint[] value();&#125;@Repeatable(Hints.class)@interface Hint &#123; String value();&#125; Java 8允许我们把同一个类型的注解使用多次，只需要给该注解标注一下@Repeatable即可。例 1: 使用包装类当容器来存多个注解（老方法） @Hints(&#123;@Hint(&quot;hint1&quot;), @Hint(&quot;hint2&quot;)&#125;)class Person &#123;&#125; 例 2：使用多重注解（新方法） @Hint(&quot;hint1&quot;)@Hint(&quot;hint2&quot;)class Person &#123;&#125; 第二个例子里java编译器会隐性的帮你定义好@Hints注解，了解这一点有助于你用反射来获取这些信息： Hint hint = Person.class.getAnnotation(Hint.class);System.out.println(hint); // nullHints hints1 = Person.class.getAnnotation(Hints.class);System.out.println(hints1.value().length); // 2Hint[] hints2 = Person.class.getAnnotationsByType(Hint.class);System.out.println(hints2.length); // 2 即便我们没有在Person类上定义@Hints注解，我们还是可以通过 getAnnotation(Hints.class) 来获取 @Hints注解，更加方便的方法是使用 getAnnotationsByType 可以直接获取到所有的@Hint注解。另外Java 8的注解还增加到两种新的target上了： @Target(&#123;ElementType.TYPE_PARAMETER, ElementType.TYPE_USE&#125;)@interface MyAnnotation &#123;&#125; 关于Java 8的新特性就写到这了，肯定还有更多的特性等待发掘。JDK 1.8里还有很多很有用的东西，比如Arrays.parallelSort, StampedLock和CompletableFuture等等。","tags":[{"name":"jdk","slug":"jdk","permalink":"https://ningyu1.github.io/tags/jdk/"}]},{"title":"JDK1.7新特性详解","date":"2017-12-15T10:00:36.000Z","path":"20171215/43-jdk1.7-feature.html","text":"JDK7对Java语法有少量更新，重点是在易用性和便捷性的改进。 1.二进制字面量JDK7开始，终于可以用二进制来表示整数（byte,short,int和long）。使用二进制字面量的好处是，可以是代码更容易被理解。语法非常简单，只要在二进制数值前面加 0b或者0B byte nByte = (byte)0b0001; short nShort = (short)0B0010; int nInt = 0b0011; long nLong = 0b0100L; 2.数字字面量可以出现下划线对于一些比较大的数字，我们定义起来总是不方面，经常缺少或者增加位数。JDK7为我们提供了一种解决方案，下划线可以出现在数字字面量。 int a = 10_0000_0000; long b = 0xffff_ffff_ffff_ffffl; byte c = 0b0001_1000; 注意：你只能将下划线置于数字之间，以下使用方法是错误的， 数字的开头或者结尾 小数点的前后 ‘F’或者‘f’的后缀 只能用数字的位置 nt err1 = _11,err2=11_; float err3=3._4,err4=3_.4; long err5=0x888_f; 3.switch 语句可以用字符串了这个功能千呼万唤，终于出来了 private static void switchString(String str)&#123; switch(str)&#123; case &quot;one&quot;: System.err.println(&quot;1&quot;); break; case &quot;two&quot;: System.out.println(&quot;2&quot;); break; default : System.out.println(&quot;err&quot;); &#125; &#125; 4.泛型实例的创建可以通过类型推断来简化以后你创建一个泛型实例，不需要再详细说明类型，只需用&lt;&gt;,编译器会自动帮你匹配 //例如 Map&lt;String, List&lt;String&gt;&gt; myMap = new HashMap&lt;String, List&lt;String&gt;&gt;(); //可以简化为 Map&lt;String, List&lt;String&gt;&gt; myMap = new HashMap&lt;&gt;(); 5.在可变参数方法中传递非具体化参数（Non-Reifiable Formal Parameters）,改进编译警告和错误有些参数类型，例如ArrayList 和 List,是非具体化的（non-reifiable）.在编译阶段，编译器会擦除该类型信息。 Heappollution 指一个变量被指向另外一个不是相同类型的变量。例如 List l = new ArrayList&lt;Number&gt;(); List&lt;String&gt; ls = l; // unchecked warning l.add(0, new Integer(42)); // another unchecked warning String s = ls.get(0); // ClassCastException is thrown 回到我们的主题，在jdk7中，当你定义下面的函数时 public static &lt;T&gt; void addToList (List&lt;T&gt; listArg, T... elements) &#123; for (T x : elements) &#123; listArg.add(x); &#125; &#125; 你会得到一个warning warning: [varargs] Possible heap pollution from parameterized vararg type 在jdk7之前，当你调用一个含有非具体化参数的可变参数方法，你必须自行保证不会发生heappollution。这有一个问题，如果调用者对方法不熟悉，他根本无法判断。JDK7对此做了改进，在该方法被定义时久发出警告 要消除警告，可以有三种方式 加 annotation @SafeVarargs 加 annotation @SuppressWarnings({“unchecked”, “varargs”}) 使用编译器参数 –Xlint:varargs; 6.try-with-resources 语句jdk7提供了try-with-resources,可以自动关闭相关的资源（只要该资源实现了AutoCloseable接口，jdk7为绝大部分资源对象都实现了这个接口） static String readFirstLineFromFile(String path) throws IOException &#123; try (BufferedReader br = new BufferedReader(new FileReader(path))) &#123; return br.readLine(); &#125; &#125; try 语句块中还可以同时处理多个资源,可以跟普通的try语句一样catch异常，有finally语句块 try ( java.util.zip.ZipFile zf = new java.util.zip.ZipFile(zipFileName); java.io.BufferedWriter writer = java.nio.file.Files.newBufferedWriter(outputFilePath, charset) ) &#123; &#125;catch(…)&#123; &#125;finally&#123; &#125; 7.Catch多个Exception，rethrow exception 改进了类型检测很多时候，我们捕获了多个异常，却做了相同的事情，比如记日志，包装成新的异常，然后rethrow。这时，代码就不那么优雅了，例如 catch (IOException ex) &#123; logger.log(ex); throw ex; catch (SQLException ex) &#123; logger.log(ex); throw ex; &#125; Jdk7允许捕获多个异常 catch (IOException|SQLException ex) &#123; logger.log(ex); throw ex; &#125; 注意，catch后面的异常参数是final的，不能重新再复制 RethrowException更具包容性的类型检测 当你重新抛出多个异常时，不再需要详细定义异常类型了，编译器已经知道你具体抛出的是哪个异常了。你只需在方法定义的时候声明需要抛出的异常即可 public void call() throws ReflectiveOperationException, IOException &#123; try &#123; callWithReflection(arg); &#125; catch (final Exception e) &#123; logger.trace(&quot;Exception in reflection&quot;, e); throw e; &#125; &#125; 参考资料 Jdk7官网 http://openjdk.java.net/projects/jdk7/","tags":[{"name":"jdk","slug":"jdk","permalink":"https://ningyu1.github.io/tags/jdk/"}]},{"title":"Fastjson反序列化java.lang.VerifyError错误","date":"2017-12-15T07:42:36.000Z","path":"20171215/42-fastjson.html","text":"现象当反序列化目标对象属性超过32个时会报如下错误： Exception in thread &quot;main&quot; java.lang.VerifyError: (class: com/alibaba/fastjson/parser/deserializer/FastjsonASMDeserializer_1_OmsMaterialStorageReconciliationEntity, method: deserialze signature: (Lcom/alibaba/fastjson/parser/DefaultJSONParser;Ljava/lang/reflect/Type;Ljava/lang/Object;I)Ljava/lang/Object;) Accessing value from uninitialized register 48 at java.lang.Class.getDeclaredConstructors0(Native Method) at java.lang.Class.privateGetDeclaredConstructors(Class.java:2493) at java.lang.Class.getConstructor0(Class.java:2803) at java.lang.Class.getConstructor(Class.java:1718) at com.alibaba.fastjson.parser.deserializer.ASMDeserializerFactory.createJavaBeanDeserializer(ASMDeserializerFactory.java:82) at com.alibaba.fastjson.parser.ParserConfig.createJavaBeanDeserializer(ParserConfig.java:639) at com.alibaba.fastjson.parser.ParserConfig.getDeserializer(ParserConfig.java:491) at com.alibaba.fastjson.parser.ParserConfig.getDeserializer(ParserConfig.java:348) at com.alibaba.fastjson.parser.DefaultJSONParser.parseObject(DefaultJSONParser.java:639) at com.alibaba.fastjson.JSON.parseObject(JSON.java:350) at com.alibaba.fastjson.JSON.parseObject(JSON.java:254) at com.alibaba.fastjson.JSON.parseObject(JSON.java:467) at com.jiuyescm.uam.main.Main.main(Main.java:29) 查看我们使用的fastjson包版本： &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.28&lt;/version&gt;&lt;/dependency&gt; 查看官方issues是否有同样的问题 找到问题：https://github.com/alibaba/fastjson/issues/1071 是一个反序列化的bug，在1.2.29版本修复 升级我们使用的fastjson版本验证是否修复问题 &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.29&lt;/version&gt;&lt;/dependency&gt; 测试代码： public static void main(String[] args) throws IOException &#123; String a = &quot;&#123;\\&quot;region\\&quot;:\\&quot;aaa\\&quot;,\\&quot;weight\\&quot;:null,\\&quot;outqty\\&quot;:null,\\&quot;inVolume\\&quot;:null,\\&quot;qtyMax\\&quot;:null,\\&quot;creTime\\&quot;:null,\\&quot;lastStock\\&quot;:null,\\&quot;inHeight\\&quot;:null,\\&quot;wallThickness\\&quot;:null,\\&quot;id\\&quot;:null,\\&quot;height\\&quot;:null,\\&quot;length\\&quot;:null,\\&quot;materialType\\&quot;:null,\\&quot;inqty\\&quot;:null,\\&quot;materialTypeName\\&quot;:null,\\&quot;materialName\\&quot;:null,\\&quot;supplierId\\&quot;:null,\\&quot;status\\&quot;:null,\\&quot;width\\&quot;:null,\\&quot;barcode\\&quot;:null,\\&quot;qtyMin\\&quot;:null,\\&quot;crePersonId\\&quot;:null,\\&quot;unit\\&quot;:null,\\&quot;changeDate\\&quot;:null,\\&quot;initStock\\&quot;:null,\\&quot;materialNo\\&quot;:null,\\&quot;crePerson\\&quot;:null,\\&quot;inLength\\&quot;:null,\\&quot;materialPrice\\&quot;:null,\\&quot;volume\\&quot;:null,\\&quot;inWidth\\&quot;:null,\\&quot;warehouseNo\\&quot;:null&#125;&quot;; OmsMaterialStorageReconciliationEntity t2 = JSON.parseObject(a, OmsMaterialStorageReconciliationEntity.class); System.out.println(t2.getRegion());&#125; OmsMaterialStorageReconciliationEntity 这个entity对象属性超过32个，运行测试结果： aaa 运行结果符合预期，验证完毕 结论 升级fastjson包版本 -&gt; 1.2.29","tags":[{"name":"Fastjson","slug":"Fastjson","permalink":"https://ningyu1.github.io/tags/Fastjson/"}]},{"title":"Java开源APM概要","date":"2017-12-11T02:00:36.000Z","path":"20171211/41-apm.html","text":"候选APM naver/pinpoint(github上2148个star) 韩国的一个公司开源的，有待评估使用情况，就是整体还不是JDK8，有些还是有点费劲，技术上采用agent的方式，对java友好 大众点评cat(github上1725个star) 看接入的公司还是挺多的，个人感觉是点评名气还可以，但是搭建起来有点费劲，很多东西都写死配置了，不灵活。整体设计的话，由于没有采用agent的方式，采用的是api手工埋点的方式，跟SNG的很像，好处的是跨语言，不好的地方就是对java来说用起来还需要包装一下 sky-walking(github上374个star) 开发团队加入了OneAPM,目前看使用的公司不多，整体技术采用agent方式，对java友好。提供了对dubbo等的支持，属于soa时代的产品 技术架构pinpoint CAT skywalking 简要评价从技术架构上看，对于log的存储都使用了hbase，也都是自己实现了日志/监控数据的上报。pinpoint支持udp的方式，这个好一点。这类还是有点SOA时代的痕迹，更为符合大数据时代的做法是，监控数据丢给kafka，然后监控server来消费数据即可，这一点在cat中使用了consumer有点这个味道，但是没有彻底转型过来。 展望APM整体的功能结构，主要是 1.日志追踪，2.监控报警 3.性能统计。对于日志追踪，已经有spirng cloud zipkin了，这个对spring cloud体系结合的很好，确的就是监控报警和性能统计，可以采用agent的方式进行无侵入的监控，或者采用log appender的方式到kafka，之后再进行error的监控报警，以及把performance的数据log到日志，发送到kafka来进行统计。 docs pinpoint 大众点评Cat–架构分析 透过CAT，来看分布式实时监控系统的设计与实现 sky-walking 转自原文地址：https://segmentfault.com/a/1190000006817114","tags":[{"name":"APM","slug":"APM","permalink":"https://ningyu1.github.io/tags/APM/"},{"name":"pinpoint","slug":"pinpoint","permalink":"https://ningyu1.github.io/tags/pinpoint/"},{"name":"cat","slug":"cat","permalink":"https://ningyu1.github.io/tags/cat/"},{"name":"sky walking","slug":"sky-walking","permalink":"https://ningyu1.github.io/tags/sky-walking/"}]},{"title":"跨库分页-架构技术实践","date":"2017-11-24T10:00:36.000Z","path":"20171124/40-distributed-db-paging.html","text":"文章来源：http://gitbook.cn/books/58a98f512bd83c246b6b8866/index.html作者：@58沈剑说明：文章转自沈老板的文章，分析的很不错 一、需求缘起分页需求互联网很多业务都有分页拉取数据的需求，例如： 微信消息过多时，拉取第N页消息。 京东下单过多时，拉取第N页订单。 浏览58同城，查看第N页帖子。这些业务场景对应的消息表，订单表，帖子表分页拉取需求有这样一些特点： 有一个业务主键id，例如msg_id，order_id，tiezi_id 分页排序是按照非业务主键id来排序的，业务中经常按照时间time来排序order by 在数据量不大时，可以通过在排序字段time上建立索引，利用SQL提供的offset/limit功能就能满足分页查询需求： select * from t_msg order by time offset 200 limit 100 select * from t_order order by time offset 200 limit 100 select * from t_tiezi order by time offset 200 limit 100 此处假设一页数据为100条，均拉取第3页数据。 分库需求高并发大流量的互联网架构，一般通过服务层来访问数据库，随着数据量的增大，数据库需要进行水平切分，分库后将数据分布到不同的数据库实例（甚至物理机器）上，以达到降低数据量，增加实例数的扩容目的。 一旦涉及分库，逃不开“分库依据”patition key的概念，使用哪一个字段来水平切分数据库呢：大部分的业务场景，会使用业务主键id。 确定了分库依据patition key后，接下来要确定的是分库算法：大部分的业务场景，会使用业务主键id取模的算法来分库，这样即能够保证每个库的数据分布是均匀的，又能够保证每个库的请求分布是均匀的，实在是简单实现负载均衡的好方法，此法在互联网架构中应用颇多。 举一个更具体的例子： 用户库user，水平切分后变为两个库，分库依据patition key是uid，分库算法是uid取模：uid%2余0的数据会落到db0，uid%2余1的数据会落到db1。 问题的提出仍然是上述用户库的例子，如果业务要查询“最近注册的第3页用户”，该如何实现呢？单库上，可以select * from t_user order by time offset 200 limit 100，变成两个库后，分库依据是uid，排序依据是time，数据库层失去了time排序的全局视野，数据分布在两个库上，此时该怎么办呢？ 如何满足“跨越多个水平切分数据库，且分库依据与排序依据为不同属性，并需要进行分页”的查询需求，实现select*from T order by time offset X limit Y的跨库分页SQL，是本文将要讨论的技术问题。 二、全局视野法 如上图所述，服务层通过uid取模将数据分布到两个库上去之后，每个数据库都失去了全局视野，数据按照time局部排序之后，不管哪个分库的第3页数据，都不一定是全局排序的第3页数据。 那到底哪些数据才是全局排序的第3页数据呢，暂且分三种情况讨论。 （1）极端情况，两个库的数据完全一样 如果两个库的数据完全相同，只需要每个库offset一半，再取半页，就是最终想要的数据（如上图中粉色部分数据）。 （2）极端情况，结果数据来自一个库 也可能两个库的数据分布及其不均衡，例如db0的所有数据的time都大于db1的所有数据的time，则可能出现：一个库的第3页数据，就是全局排序后的第3页数据（如上图中粉色部分数据）。 （3）一般情况，每个库数据各包含一部分 正常情况下，全局排序的第3页数据，每个库都会包含一部分（如上图中粉色部分数据）。 由于不清楚到底是哪种情况，所以必须每个库都返回3页数据，所得到的6页数据在服务层进行内存排序，得到数据全局视野，再取第3页数据，便能够得到想要的全局分页数据。 再总结一下这个方案的步骤： 将order by time offset X limit Y，改写成order by time offset 0 limit X+Y。 服务层将改写后的SQL语句发往各个分库：即例子中的各取3页数据。 假设共分为N个库，服务层将得到N*(X+Y)条数据：即例子中的6页数据。 服务层对得到的N*(X+Y)条数据进行内存排序，内存排序后再取偏移量X后的Y条记录，就是全局视野所需的一页数据。 方案优点：通过服务层修改SQL语句，扩大数据召回量，能够得到全局视野，业务无损，精准返回所需数据。 方案缺点（显而易见）： 每个分库需要返回更多的数据，增大了网络传输量（耗网络）； 除了数据库按照time进行排序，服务层还需要进行二次排序，增大了服务层的计算量（耗CPU）； 最致命的，这个算法随着页码的增大，性能会急剧下降，这是因为SQL改写后每个分库要返回X+Y行数据：返回第3页，offset中的X=200；假如要返回第100页，offset中的X=9900，即每个分库要返回100页数据，数据量和排序量都将大增，性能平方级下降。 三、业务折衷法“全局视野法”虽然性能较差， 但其业务无损，数据精准，不失为一种方案，有没有性能更优的方案呢？ “任何脱离业务的架构设计都是耍流氓”，技术方案需要折衷，在技术难度较大的情况下，业务需求的折衷能够极大的简化技术方案。 业务折衷一：禁止跳页查询在数据量很大，翻页数很多的时候，很多产品并不提供“直接跳到指定页面”的功能，而只提供“下一页”的功能，这一个小小的业务折衷，就能极大的降低技术方案的复杂度。 如上图，不能够跳页，那么第一次只能够查询第一页： 将查询order by time offset 0 limit 100，改写成order by time where time&gt;0 limit 100。 上述改写和offset 0 limit 100的效果相同，都是每个分库返回了一页数据（上图中粉色部分）。 服务层得到2页数据，内存排序，取出前100条数据，作为最终的第一页数据，这个全局的第一页数据，一般来说每个分库都包含一部分数据（如上图粉色部分）。 咦，这个方案也需要服务器内存排序，岂不是和“全局视野法”一样么？第一页数据的拉取确实一样，但每一次“下一页”拉取的方案就不一样了。 点击“下一页”时，需要拉取第二页数据，在第一页数据的基础之上，能够找到第一页数据time的最大值： 这个上一页记录的time_max，会作为第二页数据拉取的查询条件： 将查询order by time offset 100 limit 100，改写成order by time where time&gt;$time_max limit 100。 这下不是返回2页数据了（“全局视野法，会改写成offset 0 limit 200”），每个分库还是返回一页数据（如上图中粉色部分）。 服务层得到2页数据，内存排序，取出前100条数据，作为最终的第2页数据，这个全局的第2页数据，一般来说也是每个分库都包含一部分数据（如上图粉色部分）。 如此往复，查询全局视野第100页数据时，不是将查询条件改写为offset 0 limit 9900+100（返回100页数据），而是改写为time&gt;$time_max99 limit 100（仍返回一页数据），以保证数据的传输量和排序的数据量不会随着不断翻页而导致性能下降。 业务折衷二：允许数据精度损失“全局视野法”能够返回业务无损的精确数据，在查询页数较大，例如第100页时，会有性能问题，此时业务上是否能够接受，返回的100页不是精准的数据，而允许有一些数据偏差呢？ 数据库分库-数据均衡原理 使用patition key进行分库，在数据量较大，数据分布足够随机的情况下，各分库所有非patition key属性，在各个分库上的数据分布，统计概率情况应该是一致的。 例如，在uid随机的情况下，使用uid取模分两库，db0和db1： 性别属性，如果db0库上的男性用户占比70%，则db1上男性用户占比也应为70%； 年龄属性，如果db0库上18-28岁少女用户比例占比15%，则db1上少女用户比例也应为15%； 时间属性，如果db0库上每天10:00之前登录的用户占比为20%，则db1上应该是相同的统计规律； … 利用这一原理，要查询全局100页数据，offset 9900 limit 100改写为offset 4950 limit 50，每个分库偏移4950（一半），获取50条数据（半页），得到的数据集的并集，基本能够认为，是全局数据的offset 9900 limit 100的数据，当然，这一页数据的精度，并不是精准的。 根据实际业务经验，用户都要查询第100页网页、帖子、邮件的数据了，这一页数据的精准性损失，业务上往往是可以接受的，但此时技术方案的复杂度便大大降低列，既不需要返回更多的数据，也不需要进行服务内存排序了。 四、终极武器：二次查询法有没有一种技术方案，即能够满足业务的精确需要，无需业务折衷，又高性能的方法呢？这就是接下来要介绍的终极武器：“二次查询法”。 为了方便举例，假设一页只有5条数据，查询第200页的SQL语句为select*from T order by time offset 1000 limit 5。 步骤一：查询改写将select*from T order by time offset 1000 limit 5改写为select*from T order by time offset 500 limit 5并投递给所有的分库，注意，这个offset的500，来自于全局offset的总偏移量1000，除以水平切分数据库个数2。 如果是3个分库，则可以改写为select*from T order by time offset 333 limit 5，假设这三个分库返回的数据(time, uid)如下： 可以看到，每个分库都是返回的按照time排序的一页数据。 步骤二：找到所返回3页全部数据的最小值 第一个库，5条数据的time最小值是1487501123 第二个库，5条数据的time最小值是1487501133 第三个库，5条数据的time最小值是1487501143 故，三页数据中，time最小值来自第一个库，time_min=1487501123，这个过程只需要比较各个分库第一条数据，时间复杂度很低。 步骤三：查询二次改写第一次改写的SQL语句是select*from T order by time offset 333 limit 5。第二次要改写成一个between语句，between的起点是time_min，between的终点是原来每个分库各自返回数据的最大值： 第一个分库，第一次返回数据的最大值是1487501523；所以查询改写为select*from T order by time where time between time_min and 1487501523。 第二个分库，第一次返回数据的最大值是1487501323；所以查询改写为select*from T order by time where time between time_min and 1487501323。 第三个分库，第一次返回数据的最大值是1487501553；所以查询改写为select*from T order by time where time between time_min and 1487501553。 相对第一次查询，第二次查询条件放宽了，故第二次查询会返回比第一次查询结果集更多的数据，假设这三个分库返回的数据(time, uid)如下： 可以看到： 由于time_min来自原来的分库一，所以分库一的返回结果集和第一次查询相同（所以其实这次查询是可以省略的）； 分库二的结果集，比第一次多返回了1条数据，头部的1条记录（time最小的记录）是新的（上图中粉色记录）； 分库三的结果集，比第一次多返回了2条数据，头部的2条记录（time最小的2条记录）是新的（上图中粉色记录）。 步骤四：在每个结果集中虚拟一个time_min记录，找到time_min在全局的offset 在第一个库中，time_min在第一个库的offset是333； 在第二个库中，(1487501133, uid_aa)的offset是333（根据第一次查询条件得出的），故虚拟time_min在第二个库的offset是331； 在第三个库中，(1487501143, uid_aaa)的offset是333（根据第一次查询条件得出的），故虚拟time_min在第三个库的offset是330。 综上，time_min在全局的offset是333+331+330=994。 步骤五：既然得到了time_min在全局的offset，就相当于有了全局视野，根据第二次的结果集，就能够得到全局offset 1000 limit 5的记录 第二次查询在各个分库返回的结果集是有序的，又知道了time_min在全局的offset是994，一路排下来，容易知道全局offset 1000 limit 5的一页记录（上图中黄色记录）。 是不是非常巧妙？这种方法的优点是：可以精确的返回业务所需数据，每次返回的数据量都非常小，不会随着翻页增加数据的返回量。 不足是：需要进行两次数据库查询。 五、总结今天分享了解决“夸N库分页”这一技术难题的四种方法，稍作总结： 方法一：全局视野法 将order by time offset X limit Y，改写成order by time offset 0 limit X+Y。 服务层对得到的N*(X+Y)条数据进行内存排序，内存排序后再取偏移量X后的Y条记录。 方法二：业务折衷法-禁止跳页查询 用正常的方法取得第一页数据，并得到第一页记录的time_max。 每次翻页，将order by time offset X limit Y，改写成order by time where time&gt;$time_max limit Y以保证每次只返回一页数据，性能为常量。 方法三：业务折衷法-允许模糊数据 将order by time offset X limit Y，改写成order by time offset X/N limit Y/N。 方法四：二次查询法 将order by time offset X limit Y，改写成order by time offset X/N limit Y； 找到最小值time_min； between二次查询，order by time between $$time_min and $time_i_max； 设置虚拟time_min，找到time_min在各个分库的offset，从而得到time_min在全局的offset； 得到了time_min在全局的offset，自然得到了全局的offset X limit Y。","tags":[{"name":"rdb-paging","slug":"rdb-paging","permalink":"https://ningyu1.github.io/tags/rdb-paging/"}]},{"title":"BTrace使用笔记","date":"2017-11-15T03:00:36.000Z","path":"20171115/39-btrace.html","text":"BTrace是什么？Btrace是由sundararajan在2009年6月开发的一个开源项目，是一种动态跟踪分析一个运行中的Java应用程序的工具。BTrace是一个为Java平台开发的安全、动态的追踪工具。BTrace动态地向目标应用程序的字节码注入追踪代码（字节码追踪），这些追踪字节码追踪代码使用Java语言表达，也就是BTrace的脚本。 BTrace能做什么？BTrace可以用来帮我们做运行时的JAVA程序分析，监控等等操作，BTrace也有一些使用上的限制，如：不能在脚本中新建类等。Btrace是通过Attach API中提供的VirtualMachine.attach(PID)方法来获得要监控的JVM，然后使用VirtualMachine.loadAgent(“*.jar”)方法来加载jar文件。 特别注意BTrace植入过的代码，会一直在，直到应用重启为止。所以即使Btrace退出了，业务函数每次执行时都会执行Btrace植入的代码 Btrace术语Probe Point(探测点)追踪语句（或者一组追踪语句）被触发执行的“位置”或“事件”。也就是我们想要执行一些追踪语句的“位置”或“事件”。Trace Actions or Actions（追踪动作）probe被触发时，执行的追踪语句。Action Methods（动作方法）我的理解是定义追踪动作的方法，当然根据官方的说明这个方法应该是静态的。在静态方法中定义probe触发所调用的trace语句，那么这种定义了trace脚本的静态方法就是”动作方法” BTrace程序结构一个BTrace程序是其实就是一个普通的java类，特别之处就是由一个或者多个被(public static void)组合修饰的方法并且这些方法被BTrace对应的annotations注解。注解用来指出被追踪程序的位置（probe point）。追踪动作须书写在静态方法体中，也就是action方法（可以有多个action方法）。 BTrace约束为了保证追踪动作是“只读”的（也就是这些动作不可以修改被追踪程序的状态）和有限度的（比如在固定时间里结束）。一个BTrace程序只允许完成一些指定的动作。下面是BTrace一些不可以完成的事情： 不能创建新的对象 不能创建新的数组 不能抛出异常 不能捕获异常 不能进行任何的实例函数或者静态函数 – 只有com.sun.btrace.BTraceUtils类中的静态函数或者BTrace程序自己声明的函数才可以被BTrace调用 不可以在目标程序的类，或者对象的静态或者实例级别的field进行赋值。但是，BTrace自身的类是可以给它的静态field进行赋值的 不能有outer，inner,嵌套的或者本地类。 不能有同步代码块或者同步的函数 不能有循环语句（for,while, do..while） 不能继承其它类（父类只能是java.lang.Object） 不能实现接口 不能包含断言(assert)语句 不能使用类字面值 这上面的种种限制可以通过一个配置改变：unsafe=true，在使用BTrace注解时修改该属性的默认值（false）为true，即@BTrace（unsafe=true）；也可以启动选项中显式声明-Dcom.sun.btrace.unsafe=true（响应也有-u参数）；现在你可以为所欲为了。BUT，这样做之前最好考虑好风险并再三检查脚本，请斟酌使用！ BTrace安装btrace git下载地址下载下来直接解压就可以使用 基本语法btrace &lt;pid&gt; &lt;btrace-script&gt;脚本 btrace命令行工具运行命令如下： btrace &lt;options&gt; &lt;pid&gt; &lt;btrace source or .class file&gt; &lt;btrace arguments&gt;常用选项：[-I &lt;include-path&gt;] [-p &lt;port&gt;] [-cp &lt;classpath&gt;] 参数说明： where possible options include: --version Show the version -v Run in verbose mode -o &lt;file&gt; The path to store the probe output (will disable showing the output in console) -u Run in trusted mode -d &lt;path&gt; Dump the instrumented classes to the specified path -pd &lt;path&gt; The search path for the probe XML descriptors -classpath &lt;path&gt; Specify where to find user class files and annotation processors -cp &lt;path&gt; Specify where to find user class files and annotation processors -I &lt;path&gt; Specify where to find include files -p &lt;port&gt; Specify port to which the btrace agent listens for clients -statsd &lt;host[:port]&gt; Specify the statsd server, if any include-path : 是一些用来查找头文件的目录。BTrace包含一个简单的预处理,支持# define,# + include和条件编译。它不像一个完整的C / c++预处理器–而是一个有用的子集。详见demo代码“ThreadBean.java”，如果没有显式的声明选项-I，Btrace跳过预处理程序调用步骤。 port： BTrace代理程序所侦听的端口，这是可选的选项。默认是2020 classpath: 是一些用来查找jar文件的目录。默认是当前目录”.” pid：是要追踪目标程序id btrace-script: 就是追踪程序本身。如果这是个java文件，那么提交前会进行编译。否则,它被认为已预编译(即它必须是一个类)并提交 arguments: 这是传递给BTrace程序的参数。BTrace程序可以通过内置的符号来引用这些参数，length是这些参数的个数。 在samples目录下有很多示例，并且有的跟踪很有用可直接使用，下来让我们编写一个脚本来看一下具体是怎么使用的 BTrace的注解方法注解 **@com.sun.btrace.annotations.OnMethod** 该注解可用来指定目标类，目标方法，以及目标方法里的“位置”。加了该注解后的操作方法会在对应的方法运行到指定的“位置”时被执行。这该注解中，目标类用“clazz”属性来指定，而目标方法用“method”属性来指定。”clazz”可以是类的全路径(比如java.awt.Component或者用两个反斜杠中间的正则表达式，参考例子NewComponent.java和Classload.java来看它们的用法，正则表达式可以匹配0个或多个目标类，这个时候多个类都会被进行动态指令更换。如/java.awt.+/匹配java.awt包下的所有类)。方法名也可以用这样的正则表达式 来匹配零个或者多个多个方法。参考例子MultiClass.java来查看用法。 还有一种方法来指定追踪类和函数。被追踪的类和函数可以用注解来指定。比如，如果”clazz”属性是@javax.jws.Webservice.那么BTrace会会把所有注解是这个的函数都进行动态指令更换。类似地，方法级别的注解也可以用来执行方法。参看例子WebServiceTracker.java来了解如何使用。可以把正则表达式和注解放在一起用，比如@/com.acme..+/可以匹配任何类，只要这个类的注解能跟那段正则表达式匹配即可。可以通过指定父类来匹配多个类名，比如+java.lang.Runnable就可以匹配所有实现了java.lang.Runnable这个接口的类。参考例子SubtypeTracer.java来看它的用法。 **@com.sun.btrace.annotations.OnTimer** 该注解可以用来执行那些需要周期性（间隔是毫秒）的追踪操作。参考Histogram.java来看它的用法。 **@com.sun.btrace.annotations.OnError** 该注解可以用来指定当任何异常抛出时需要执行的操作。被该注解修饰后的BTrace函数会在同一个BTrace类的其他操作方法抛出异常时执行。 **@com.sun.btrace.annotations.OnExit** 该注解用来执行党BTrace代码调用了exit(int)结束追踪会话后需要执行的操作。参考例子ProbeExit.java来了解如何使用。 **@com.sun.btrace.annotations.OnEvent** 该注解用来追踪函数与”外部”的事件关联起来。当BTrace客户端发送了一个“事件”后，该注解里的操作就会被执行。客户端发送的事件可能是由用户触发的（比如按下Ctrl-C）。事件的名字是个字符串，这样追踪操作就只会在对应的事件触发后被执行。到目标为止，BTrace命令行客户端会在用户按下Ctrl-C后发送事件，参考例子HistoOnEvent.java来了解用法。 **@com.sun.btrace.annotations.OnLowMemory** 该注解可以用来追踪特定内存阈值被用光的事件。参看例子MemAlerter.java了解用法。 **@com.sun.btrace.annotations.OnProbe** 该注解可以用来避免使用BTrace脚本的内部类。@OnProbe探测点被映射到一个或多个@OnMethod上。目前这个映射是通过一个XML探测描述文件类指定的（这个文件会被BTrace代理所使用）。参考例子SocketTracker1.java和对应的描述文件java.net.socket.xml.当运行这个例子时，xml文件需要放在目标JVM所有运行的目录下(或者修改btracer.bat中的probeDescPath选项来指向任意的xml文件)。 **@com.sun.btrace.annotations.Location**：该注解在一个traced/probed方法中指定一个特定的“位置” **@com.sun.btrace.annotations.Simpled**：标记@OnMethod注解处理器采样。采样处理程序时并不是所有的事件将被追踪,只有一个统计样品与给定的意思。在默认情况下使用一种自适应采样。BTrace将增加或减少样品之间的调用数量保持平均时间窗口,因此减少整体的开销。 参数相关的注解 **@com.sun.btrace.annotations.Self**：该注解把一个参数标识为保留了目标函数所指向的this的值。参考例子AWTEventTracer.java和AllCalls1.java. **@com.sun.btrace.annotations.Return**：该注解说明这个参数保存目标函数的返回值。参考例子Classload.java **@com.sun.btrace.annotations.ProbeClassName**：所修饰的参数保留了探测类的类名 。参看AllMethods.java（有多个探测类） **@com.sun.btrace.annotations.ProbeMethodName**：所修饰的参数保留了探测函数的函数名。参考WebServiceTracker.java（多个探测函数） **@com.sun.btrace.annotations.TargetInstance**：修饰的参数保留了被调用的实例。参考例子AllCall2.java. **@com.sun.btrace.annotations.TargetMethodOrField**：该注解修饰的参数保存了调用的函数名。参考AllCalls1.java 和AllCall2.java **@com.sun.btrace.annotations.Duration**：探测方法参数标记为持续时间值的接收者，即目标方法执行的时间，单位纳秒。只是用带Location属性的@OnMethod，并且需要配合Kind.ERROR或者Kind.RETURN使用 无注解的参数没有注解的BTrace探测函数参数是用来作签名匹配的，因为他们必须必须在固定的位置上出现。然而，它们可以和其他的注解的参数进行交换。如果一个参数的类型是AnyType[]，它就会“吃”掉所所有剩下的参数。没有注解的参数的具体含义与他们所在的位置有关： 名称 作用 Kind.ARRAY_GET 数组元素加载 Kind.ARRAY_SET 数组元素存储 Kind.CALL 方法调用 Kind.CATCH 异常捕获 Kind.CHECKCAST checkcast Kind.ENTRY 方法进入。意指进入匹配probe点，跟你@Location设置的clazz和method没有任何关系 Kind.ERROR 错误，异常没有捕获，返回 Kind.FIELD_GET field获取 Kind.FIELD_SET field设置 Kind.INSTANCEOF 实例检测 Kind.LINE 源代码行号 Kind.NEW 创建新实例 Kind.NEWARRAY 新的数组对象被创建 Kind.RETURN 意指从某个匹配probe的方法中调用了匹配A class method的点，一定要和clazz,method配合使用。clazz和method的默认值为”“，所以不能被匹配 Kind.SYNC_ENTRY 进入一个同步方法锁 Kind.SYNC_EXIT 离开一个同步方法锁 Kind.THROW 抛出异常 字段相关的注解 **@com.sun.btrace.annotations.Export** BTrace字段使用该注解来说明它已经被映射到一个jvmstat计数器上。使用该注解，BTrace程序可以把追踪计数器暴露给外部的jvmstat客户端（比如jstat）。参考例子ThreadCounter.java **@com.sun.btrace.annotations.Property**该注解可以把一个字段标识为一个MBean属性。如果一个BTrace类至少有一个静态的字段使用了该注解。那么一个MBean就会被创建并且注册到平台MBean服务器上。JMX客户端比如VisualVM，jconsole可以访问这个字段来查看BTrace的MBean。在把BTrace附加到目标程序上后，你可以把VisualVM或者jconsole也附加到同一个目标程序上来查看刚创建好的MBean属性。通过VisualVM或者jconsole,你可以通过MBeans tab页来查看BTrace相关的域，然后查看它们的值。参考例子ThreadCounterBean.java 和HistogramBean.java来了解用法 **@com.sun.btrace.annotations.TLS** BTrace字段使用该注解来说明它自己是一个线程本地字段（thread local field）.注意你只能在@OnMethod注解后的函数里访问这样的字段。每个Java线程都有一个这个字段的拷贝。为了让这样的方式能够工作，这个字段的类型只能是immutable（比如原始类型） 或者是cloneable （实现了Cloneable接口并且覆盖了clone()函数）的。这些线程本地字段可以被BTrace程序用来识别它是否在同一个线程里执行了多个探测操作。参考例子OnThrow.java和WebServiceTracker.java 类相关的注解 **@com.sun.btrace.annotations.DTrace**该注解用来把一小段D脚本（嵌在BTrace 的java类中）和BTrace程序关联起来。参考例子DTraceInline.java **@com.sun.btrace.annotations.DTraceRef** 和上个注解一样，不同的是D脚本是在独立的文件中，不是嵌在java类中。 **@com.sun.btrace.annotations.BTrace**必须使用该注解来指定一个Java类是BTrace程序。BTrace编译器会强制查找该注解，BTrace代理也会检查这个是否有该注解。如果没有，则提示错误，并且不会执行。 脚本编写package btrace;import com.sun.btrace.BTraceUtils;import com.sun.btrace.annotations.*;@BTracepublic class UniqueIdMgrBtrace &#123; @OnMethod(clazz = &quot;com.atomikos.util.UniqueIdMgr&quot;, method = &quot;get&quot;, location = @Location(Kind.RETURN)) public static void onGet(@Return String result) &#123; long millis = BTraceUtils.timeMillis(); String threadName = BTraceUtils.Threads.name(BTraceUtils.currentThread()); String str = BTraceUtils.strcat(BTraceUtils.str(millis), &quot; - [&quot;); str = BTraceUtils.strcat(str, BTraceUtils.str(threadName)); str = BTraceUtils.strcat(str, &quot;] - com.atomikos.util.UniqueIdMgr.get()--&gt;&quot;); str = BTraceUtils.strcat(str, BTraceUtils.str(result)); BTraceUtils.println(BTraceUtils.str(str)); &#125; @OnMethod(clazz = &quot;com.atomikos.icatch.imp.TransactionServiceImp&quot;, method = &quot;setTidToTx&quot;) public static void onSetTidToTx(String tid) &#123; long millis = BTraceUtils.timeMillis(); String threadName = BTraceUtils.Threads.name(BTraceUtils.currentThread()); String str = BTraceUtils.strcat(BTraceUtils.str(millis), &quot; - [&quot;); str = BTraceUtils.strcat(str, BTraceUtils.str(threadName)); str = BTraceUtils.strcat(str, &quot;] - com.atomikos.icatch.imp.TransactionServiceImp.setTidToTx(&quot;); str = BTraceUtils.strcat(str, BTraceUtils.str(tid)); str = BTraceUtils.strcat(str, &quot;)&quot;); BTraceUtils.println(BTraceUtils.str(str)); &#125;&#125; 上面代码意思是在com.atomikos.util.UniqueIdMgr.get()方法上面进行跟踪返回值，要跟踪赶回值必须要加@Location(Kind.RETURN)),才能使用参数的@Return 如果要使用方法参数，可以在脚本方法上直接写跟踪的原始方法参数并且类型保持一样，例如： package com.btrace;//需要跟踪的类public class RemoteClass &#123; public String f1(String a, int b) &#123; System.out.println(a + &quot; &quot; + b); return a; &#125;&#125;//btrace脚本@BTrace public class HelloBtrace &#123; @OnMethod( clazz=&quot;com.btrace.RemoteClass&quot;, method=&quot;f1&quot; ) public static void onF1() &#123; println(&quot;Hello BTrace&quot;); &#125; @OnMethod( clazz=&quot;com.btrace.RemoteClass&quot;, method=&quot;f1&quot; ) public static void onF2(String a,int b) &#123; println(str(a)); println(str(b)); println(&quot;&quot;); &#125;&#125; 注意事项 脚本中方法参数需要跟原方法参数类型保持一致 脚本中不允许使用除btrace之外的类，拼接字符串使用BTraceUtils.strcat(),打印使用BTraceUtils.println(),获取线程使用BTraceUtils.Threads BTrace植入过的代码，会一直在，直到应用重启为止。所以即使Btrace退出了，业务函数每次执行时都会执行Btrace植入的代码","tags":[{"name":"btrace","slug":"btrace","permalink":"https://ningyu1.github.io/tags/btrace/"}]},{"title":"ActiveMQ发送速度慢问题排查","date":"2017-11-09T09:00:36.000Z","path":"20171109/38-activemq-slow-speed.html","text":"目录： 关于使用发送消息给activemq的同步/异步发送问题需要注意 同步/异步发送使用场景 maxConnections配置问题注意事项 idleTimeout配置问题注意事项 关于Failover的问题 关于使用发送消息给activemq的同步/异步发送问题需要注意activemq发送异步参数：useAsyncSend与发送超时参数：sendTimeout是存在冲突的， 当useAsyncSend=true，没有sendTimeout参数时（sendTimeout默认值0秒），走异步发送 当useAsyncSend=false，没有sendTimeout参数时（sendTimeout默认值0秒），走同步发送 当useAsyncSend=true，sendTimeout=1000，优先根据sendTimeout参数走同步发送 同步/异步发送使用场景场景一：业务可以容忍消息丢失（日志记录）这样的场景使用：使用：异步发送配置：useAsyncSend=true，sendTimeout不配置（sendTimeout默认值0秒）注意：可以不需要补偿机制 场景二：业务不能容忍消息丢失，这样的场景使用：使用1：异步发送配置1：useAsyncSend=true，sendTimeout不配置（sendTimeout默认值0秒）注意1：当异步发送消息失败或异常导致消息丢失时有补偿的做法（如：定时任务、重发消息、等）使用2：同步发送配置2：useAsyncSend=false（useAsyncSend默认值false），sendTimeout=2000（超时时间一定要配置）注意2：可以不需要补偿机制 场景三：业务必须将消息发送和jdbc事务放在一个事务内，保证数据的强一致性，这样的场景使用：使用：同步发送配置：useAsyncSend=false（useAsyncSend默认值false），sendTimeout=2000（超时时间一定要配置）注意：消息发送的超时时间（sendTimeout）&lt; jdbc事务超时时间 禁止使用的配置：配置：useAsyncSend=false（useAsyncSend默认值false），sendTimeout不配置（sendTimeout默认值0秒）注意：上面不配置超时时间的同步发送会造成请求阻塞在这里。 maxConnections配置问题注意事项根据activemq的连接池实现代码，发现maxconnections不适合设置很大，除非并发非常高的情况下，因为现在activemq创建一个连接平均在1-2秒钟左右，根据activemq的连接实现发现 if (getConnectionsPool().getNumIdle(key) &lt; getMaxConnections()) &#123; try &#123; connectionsPool.addObject(key); connection = mostRecentlyCreated.getAndSet(null); connection.incrementReferenceCount(); &#125; catch (Exception e) &#123; throw createJmsException(&quot;Error while attempting to add new Connection to the pool&quot;, e); &#125; &#125; else &#123; try &#123; // We can race against other threads returning the connection when there is an // expiration or idle timeout. We keep pulling out ConnectionPool instances until // we win and get a non-closed instance and then increment the reference count // under lock to prevent another thread from triggering an expiration check and // pulling the rug out from under us. while (connection == null) &#123; connection = connectionsPool.borrowObject(key); synchronized (connection) &#123; if (connection.getConnection() != null) &#123; connection.incrementReferenceCount(); break; &#125; // Return the bad one to the pool and let if get destroyed as normal. connectionsPool.returnObject(key, connection); connection = null; &#125; &#125; &#125; catch (Exception e) &#123; throw createJmsException(&quot;Error while attempting to retrieve a connection from the pool&quot;, e); &#125; try &#123; connectionsPool.returnObject(key, connection); &#125; catch (Exception e) &#123; throw createJmsException(&quot;Error when returning connection to the pool&quot;, e); &#125; &#125; 当MaxConnections设置的很大的时候，会在发消息的时候一直判断池子中数量是否达到最大值，如果小于最大值再创建一个新的连接放入池子，这样就会前面发送消息的动作都会创建连接从而发送时间会增长。比如：MaxConnections=20，发送消息50次，前20次都会去创建连接并且发送，后面30次会去复用连接池内的连接 idleTimeout配置问题注意事项空闲时间配置问题，activemq默认idleTimeout=30秒，activemq开启failover的话它的连接创建时间相对较长，因此建议这个时间设置大一些，尽量不要让超时清空掉，提高复用率 关于Failover的问题activemq开启failover策略会根据配置的连接串中的tpc ip按顺序迭代去检测可用来创建连接，当可用的连接排在第一个的时候他的创建连接时间相比可用连接排在后面的时间短一些。但是我们现在单个连接的时间耗时确实很高，这个问题不太清楚具体是什么问题，如下是创建连接耗时日志：不开启failover的日志 耗时0：945ms耗时1：1040ms耗时2：595ms耗时3：853ms耗时4：716ms耗时5：0ms耗时6：0ms耗时7：0ms 开启failover，可用连接排在第一位置，的日志 耗时0：2689ms2017-11-03 18:47:20.599 [ActiveMQ Task-1] INFO o.a.activemq.transport.failover.FailoverTransport - Successfully connected to tcp://10.51.232.238:61616耗时1：1944ms2017-11-03 18:47:22.615 [ActiveMQ Task-1] INFO o.a.activemq.transport.failover.FailoverTransport - Successfully connected to tcp://10.51.232.238:61616耗时2：1968ms2017-11-03 18:47:24.724 [ActiveMQ Task-1] INFO o.a.activemq.transport.failover.FailoverTransport - Successfully connected to tcp://10.51.232.238:61616耗时3：2079ms2017-11-03 18:47:25.318 [ActiveMQ Task-1] INFO o.a.activemq.transport.failover.FailoverTransport - Successfully connected to tcp://10.51.232.238:61616耗时4：608ms耗时5：0ms耗时6：0ms耗时7：0ms 开启failover，可用连接排在最后的位置，的日志 耗时0：1960ms2017-11-03 18:49:14.991 [ActiveMQ Task-1] INFO o.a.activemq.transport.failover.FailoverTransport - Successfully connected to tcp://10.51.232.238:61616耗时1：2084ms2017-11-03 18:49:16.661 [ActiveMQ Task-1] INFO o.a.activemq.transport.failover.FailoverTransport - Successfully connected to tcp://10.51.232.238:61616耗时2：1775ms2017-11-03 18:49:17.397 [ActiveMQ Task-1] INFO o.a.activemq.transport.failover.FailoverTransport - Successfully connected to tcp://10.51.232.238:61616耗时3：708ms2017-11-03 18:49:18.066 [ActiveMQ Task-1] INFO o.a.activemq.transport.failover.FailoverTransport - Successfully connected to tcp://10.51.232.238:61616耗时4：864ms耗时5：3ms耗时6：0ms耗时7：0ms 以上创建连接包括vpn加密的过程，可能会影响时间。ps.前五个是创建连接，因为我配置的5个连接数，后面都是连接复用，异步发送","tags":[{"name":"activemq","slug":"activemq","permalink":"https://ningyu1.github.io/tags/activemq/"},{"name":"activemq slow speed","slug":"activemq-slow-speed","permalink":"https://ningyu1.github.io/tags/activemq-slow-speed/"}]},{"title":"并发与幂等性","date":"2017-11-06T09:40:36.000Z","path":"20171106/37-concurrency-idempotent.html","text":"文章来源：https://my.oschina.net/wangen2009/blog/1560975作者：@码代码的小司机","tags":[{"name":"concurrency","slug":"concurrency","permalink":"https://ningyu1.github.io/tags/concurrency/"},{"name":"idempotent","slug":"idempotent","permalink":"https://ningyu1.github.io/tags/idempotent/"}]},{"title":"atomikos jta(xa) transaction问题：Already mapped: xxxx","date":"2017-11-02T07:52:36.000Z","path":"20171102/36-atomikos-transactions-trouble.html","text":"目录： 问题现象 问题分析 修改验证 解决方案 总结 问题现象库存中心在压测过程中会时不时的报错，错误如下： 2017-11-02 11:38:37.620 [DubboServerHandler-10.27.69.168:20888-thread-156] ERROR xx.xx.inv.service.impl.OptionApiImpl - java.lang.IllegalStateException: Already mapped: 10.27.69.168.tm150959391756909559xx.xx.exception.BizException: java.lang.IllegalStateException: Already mapped: 10.27.69.168.tm150959391756909559 at xx.xx.inv.service.impl.OptionApiImpl.invWmsOption(OptionApiImpl.java:290) ~[inv-api-impl-1.0.1-SNAPSHOT.jar:na] at com.alibaba.dubbo.common.bytecode.Wrapper1.invokeMethod(Wrapper1.java) [na:2.5.3] at com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory$1.doInvoke(JavassistProxyFactory.java:46) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker.invoke(AbstractProxyInvoker.java:72) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke(InvokerWrapper.java:53) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.rpc.filter.AccessLogFilter.invoke(AccessLogFilter.java:199) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.rpc.filter.ExceptionFilter.invoke(ExceptionFilter.java:64) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.rpc.filter.TimeoutFilter.invoke(TimeoutFilter.java:42) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.monitor.support.MonitorFilter.invoke(MonitorFilter.java:75) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.rpc.protocol.dubbo.filter.TraceFilter.invoke(TraceFilter.java:78) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.rpc.filter.ContextFilter.invoke(ContextFilter.java:60) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.rpc.filter.GenericFilter.invoke(GenericFilter.java:112) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.rpc.filter.ClassLoaderFilter.invoke(ClassLoaderFilter.java:38) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.rpc.filter.EchoFilter.invoke(EchoFilter.java:38) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol$1.reply(DubboProtocol.java:108) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.handleRequest(HeaderExchangeHandler.java:84) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.received(HeaderExchangeHandler.java:170) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.remoting.transport.DecodeHandler.received(DecodeHandler.java:52) [dubbo-2.5.3.jar:2.5.3] at com.alibaba.dubbo.remoting.transport.dispatcher.ChannelEventRunnable.run(ChannelEventRunnable.java:82) [dubbo-2.5.3.jar:2.5.3] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_79] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_79] at java.lang.Thread.run(Thread.java:745) [na:1.7.0_79]Caused by: java.lang.IllegalStateException: Already mapped: 10.27.69.168.tm150959391756909559 at com.atomikos.icatch.imp.TransactionServiceImp.setTidToTx(TransactionServiceImp.java:191) ~[transactions-4.0.0.jar:na] at com.atomikos.icatch.imp.TransactionServiceImp.createCT(TransactionServiceImp.java:277) ~[transactions-4.0.0.jar:na] at com.atomikos.icatch.imp.TransactionServiceImp.createCompositeTransaction(TransactionServiceImp.java:783) ~[transactions-4.0.0.jar:na] at com.atomikos.icatch.imp.CompositeTransactionManagerImp.createCompositeTransaction(CompositeTransactionManagerImp.java:393) ~[transactions-4.0.0.jar:na] at com.atomikos.icatch.jta.TransactionManagerImp.begin(TransactionManagerImp.java:271) ~[transactions-jta-4.0.0.jar:na] at com.atomikos.icatch.jta.TransactionManagerImp.begin(TransactionManagerImp.java:249) ~[transactions-jta-4.0.0.jar:na] at com.atomikos.icatch.jta.UserTransactionImp.begin(UserTransactionImp.java:72) ~[transactions-jta-4.0.0.jar:na] at org.springframework.transaction.jta.JtaTransactionManager.doJtaBegin(JtaTransactionManager.java:874) ~[spring-tx-4.3.6.RELEASE.jar:4.3.6.RELEASE] at org.springframework.transaction.jta.JtaTransactionManager.doBegin(JtaTransactionManager.java:831) ~[spring-tx-4.3.6.RELEASE.jar:4.3.6.RELEASE] at org.springframework.transaction.support.AbstractPlatformTransactionManager.getTransaction(AbstractPlatformTransactionManager.java:373) ~[spring-tx-4.3.6.RELEASE.jar:4.3.6.RELEASE] at org.springframework.transaction.interceptor.TransactionAspectSupport.createTransactionIfNecessary(TransactionAspectSupport.java:447) ~[spring-tx-4.3.6.RELEASE.jar:4.3.6.RELEASE] at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:277) ~[spring-tx-4.3.6.RELEASE.jar:4.3.6.RELEASE] at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) ~[spring-tx-4.3.6.RELEASE.jar:4.3.6.RELEASE] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-4.3.6.RELEASE.jar:4.3.6.RELEASE] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:656) ~[spring-aop-4.3.6.RELEASE.jar:4.3.6.RELEASE] at xx.xx.inv.service.impl.VoucherExecutor$$EnhancerBySpringCGLIB$$a5e2dd9c.doWms(&lt;generated&gt;) ~[inv-api-impl-1.0.1-SNAPSHOT.jar:na] at xx.xx.inv.service.impl.OptionApiImpl.invWmsOption(OptionApiImpl.java:286) ~[inv-api-impl-1.0.1-SNAPSHOT.jar:na] ... 30 common frames omitted 问题分析跟踪源码：com.atomikos.icatch.imp.TransactionServiceImp.setTidToTx() private void setTidToTx ( String tid , CompositeTransaction ct ) throws IllegalStateException&#123; synchronized ( tidToTransactionMap_ ) &#123; if ( tidToTransactionMap_.containsKey ( tid.intern () ) ) throw new IllegalStateException ( &quot;Already mapped: &quot; + tid ); tidToTransactionMap_.put ( tid.intern (), ct ); ct.addSubTxAwareParticipant(this); // for GC purposes &#125;&#125; 发现在tidToTransactionMap_中存在tid重复的情况，这个方法判断如果出现重复报：Already mapped: ${tid}，继续跟踪找到tid生成的地方 public CompositeTransaction createCompositeTransaction ( long timeout ) throws SysException&#123; if ( !initialized_ ) throw new IllegalStateException ( &quot;Not initialized&quot; ); if ( maxNumberOfActiveTransactions_ &gt;= 0 &amp;&amp; tidToTransactionMap_.size () &gt;= maxNumberOfActiveTransactions_ ) &#123; throw new IllegalStateException ( &quot;Max number of active transactions reached:&quot; + maxNumberOfActiveTransactions_ ); &#125; String tid = tidmgr_.get (); Stack&lt;CompositeTransaction&gt; lineage = new Stack&lt;CompositeTransaction&gt;(); // create a CC with heuristic preference set to false, // since it does not really matter anyway (since we are // creating a root) CoordinatorImp cc = createCC ( null, tid, true, false, timeout ); CompositeTransaction ct = createCT ( tid, cc, lineage, false ); return ct;&#125; tid是通过tidmgr_.get ();这个东西生成的，那我们进去看一下生成的代码具体是什么？ private final static int MAX_LENGTH_OF_NUMERIC_SUFFIX = 8 + 5;private final static int MAX_COUNTER_WITHIN_SAME_MILLIS = 32000; private final String commonPartOfId; //name of serverprivate int lastcounter; public String get()&#123; incrementAndGet(); StringBuffer buffer = new StringBuffer(); return buffer.append(commonPartOfId). append(System.currentTimeMillis()). append(getCountWithLeadingZeroes ( lastcounter )). toString() ;&#125; private synchronized void incrementAndGet() &#123; lastcounter++; if (lastcounter == MAX_COUNTER_WITHIN_SAME_MILLIS) lastcounter = 0;&#125; 那极其有可能get的时候在极端的情况下生成的id是相同的，incrementAndGet方法是synchronized 理论上不会有并发问题，但是lastcounter这个属性不是支持并发的对象，在get方法中先调用同步方法incrementAndGet对属性lastcounter++，后面buffer在append的时候直接使用的是属性lastcounter属性的值，很有可能问题就出在这里，那让我们使用btrace验证一下。 通过btrace对get方法拦截验证发现确实在极端的情况下会有多个线程生成同一个tid，如下： [DubboServerHandler-10.27.69.168:20888-thread-177] - com.atomikos.util.UniqueIdMgr.get()--&gt;10.27.69.168.tm150959391749109556[DubboServerHandler-10.27.69.168:20888-thread-156] - com.atomikos.util.UniqueIdMgr.get()--&gt;10.27.69.168.tm150959391749509557[DubboServerHandler-10.27.69.168:20888-thread-156] - com.atomikos.util.UniqueIdMgr.get()--&gt;10.27.69.168.tm150959391756909559[DubboServerHandler-10.27.69.168:20888-thread-177] - com.atomikos.util.UniqueIdMgr.get()--&gt;10.27.69.168.tm150959391756909559[DubboServerHandler-10.27.69.168:20888-thread-155] - com.atomikos.util.UniqueIdMgr.get()--&gt;10.27.69.168.tm150959391780109560[DubboServerHandler-10.27.69.168:20888-thread-155] - com.atomikos.util.UniqueIdMgr.get()--&gt;10.27.69.168.tm150959391786909561[DubboServerHandler-10.27.69.168:20888-thread-112] - com.atomikos.util.UniqueIdMgr.get()--&gt;10.27.69.168.tm150959391791609562[DubboServerHandler-10.27.69.168:20888-thread-197] - com.atomikos.util.UniqueIdMgr.get()--&gt;10.27.69.168.tm150959391794109563 出现了两个tm150959391756909559，那就能断定肯定是这块出问题，那如何解决呢? 首先查看我们使用的atomikos transaction的版本号 – &gt; 4.0.0 去maven官服上搜索transaction的版本信息:http://mvnrepository.com/artifact/com.atomikos/atomikos-util 1.png 看来有更高的版本，那我们下载一个版本看一下get的代码是否发生了变化，我们从4.0.1版本开始查看。 public String get()&#123; StringBuffer buffer = new StringBuffer(); String id = this.commonPartOfId + System.currentTimeMillis() + getCountWithLeadingZeroes(incrementAndGet()); return id;&#125; private synchronized int incrementAndGet()&#123; this.lastcounter += 1; if (this.lastcounter == 32000) &#123; this.lastcounter = 0; &#125; return this.lastcounter;&#125; 从上面代码可以发现跟4.0.0的代码是有变化的 一、4.0.0版本在incrementAndGet方法同步的对lastcounter++之后，在拼接id的时候是直接使用属性lastcounter进行拼接二、4.0.1版本在incrementAndGet方法同步的对lastcounter++之后直接将lastcounter值返回，在拼接的时候使用返回的lastcounter值来进行拼接 从代码上看好像是为了解决这个问题，那我们还需要进一步验证 首先先找到官方的chang log看是否有明确的版本升级描述中fixed并发tid的bug，翻atomikos的官网站点 2.png 功夫不负有心人找到了fixed记录，接下来就需要升级程序然后再进行实际压测过程去校验是否真的解决了这个问题 修改验证升级atomikos transactions版本–&gt;4.0.1,打包程序发布进行压力测试压测场景：4个仓，一个仓10个线程，一个线程2000单，一单2个商品，一个商品6个sku压测后再没有Already mapped: xxxx的错误爆出，库存扣除也是正确的。 解决方案升级atomikos transactions版本–&gt;4.0.1 总结在使用任何第三方框架都是存在风险，就看如何进行权衡，出现问题能否hold的住，当出现由于使用第三方框架带来的问题时。 首先要彻底的分析出问题的原因 其次就去社区或者官网或者问作者是否bug已经fixed。 上面的都尝试之后如果还不能解决，要么寻找替换方案，要么修改源码。能使用官网升级的版本解决问题尽量升级版本解决，第三步的方法虽然不推荐，但是在特定的环境也是一个兜底的方案。","tags":[{"name":"transaction","slug":"transaction","permalink":"https://ningyu1.github.io/tags/transaction/"},{"name":"atomikos","slug":"atomikos","permalink":"https://ningyu1.github.io/tags/atomikos/"},{"name":"jta xa","slug":"jta-xa","permalink":"https://ningyu1.github.io/tags/jta-xa/"},{"name":"Already mapped","slug":"Already-mapped","permalink":"https://ningyu1.github.io/tags/Already-mapped/"}]},{"title":"数据源连接泄漏问题分析","date":"2017-10-26T05:29:36.000Z","path":"20171026/35-datasource-connection-leak.html","text":"目录： 问题现象 问题分析 修改验证 解决方案 总结 问题现象开启druid数据源的连接泄漏开关（removeAbandoned=true），设置强制回收非法连接的超时时间为120（removeAbandonedTimeout=120,2分钟，目的是调试方便，让非法连接快速close掉）。启动程序，等待2分钟会有连接泄漏的异常爆出，具体日志如下： 2017-10-25 17:19:52.858 [qtp365976330-72] WARN org.jasig.cas.client.session.SingleSignOutHandler - Front Channel single sign out redirects are disabled when the &apos;casServerUrlPrefix&apos; value is not set.2017-10-25 17:21:56.531 [Druid-ConnectionPool-Destroy-678372234] ERROR com.alibaba.druid.pool.DruidDataSource - abandon connection, open stackTrace at java.lang.Thread.getStackTrace(Thread.java:1588) at com.alibaba.druid.pool.DruidDataSource.getConnectionDirect(DruidDataSource.java:995) at com.alibaba.druid.filter.FilterChainImpl.dataSource_connect(FilterChainImpl.java:4544) at com.alibaba.druid.filter.FilterAdapter.dataSource_getConnection(FilterAdapter.java:2723) at com.alibaba.druid.filter.FilterChainImpl.dataSource_connect(FilterChainImpl.java:4540) at com.alibaba.druid.filter.stat.StatFilter.dataSource_getConnection(StatFilter.java:661) at com.alibaba.druid.filter.FilterChainImpl.dataSource_connect(FilterChainImpl.java:4540) at com.alibaba.druid.pool.DruidDataSource.getConnection(DruidDataSource.java:919) at com.alibaba.druid.pool.DruidDataSource.getConnection(DruidDataSource.java:911) at com.alibaba.druid.pool.DruidDataSource.getConnection(DruidDataSource.java:98) at com.github.pagehelper.PageHelper.initSqlUtil(PageHelper.java:165) at com.github.pagehelper.PageHelper.intercept(PageHelper.java:148) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:60) at com.sun.proxy.$Proxy64.query(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:108) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:102) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:358) at com.sun.proxy.$Proxy57.selectList(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:198) at com.xx.xx.xx.mybatis.MyBatisDao.selectList(MyBatisDao.java:391) at com.xx.xx.xx.xx.xx.xx.XXDaoImpl.queryByDeliverCode(XXDaoImpl.java:158) at com.xx.xx.xx.xx.xx.xx.XXServiceImpl.queryByDeliverCode(XXServiceImpl.java:159) at com.xx.xx.xx.xx.xx.xx.XXServiceImpl$$FastClassByCGLIB$$41eff1cc.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:642) at com.xx.xx.xx.xx.xx.xx.XXServiceImpl$$EnhancerByCGLIB$$708c18f3.queryByDeliverCode(&lt;generated&gt;) at com.xx.xx.xx.xx.xx.XXController.initId(XXController.java:168) at com.xx.xx.xx.xx.xx.XXController.afterPropertiesSet(XXController.java:2080) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1612) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1549) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:700) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482) at org.springframework.web.context.ContextLoader.configureAndRefreshWebApplicationContext(ContextLoader.java:381) at org.springframework.web.context.ContextLoader.initWebApplicationContext(ContextLoader.java:293) at org.springframework.web.context.ContextLoaderListener.contextInitialized(ContextLoaderListener.java:106) at com.bstek.dorado.web.servlet.SpringContextLoaderListener.contextInitialized(SpringContextLoaderListener.java:73) at org.eclipse.jetty.server.handler.ContextHandler.callContextInitialized(ContextHandler.java:782) at org.eclipse.jetty.servlet.ServletContextHandler.callContextInitialized(ServletContextHandler.java:424) at org.eclipse.jetty.server.handler.ContextHandler.startContext(ContextHandler.java:774) at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:249) at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1242) at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:717) at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:494) at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64) at org.eclipse.jetty.server.handler.HandlerWrapper.doStart(HandlerWrapper.java:95) at org.eclipse.jetty.server.Server.doStart(Server.java:282) at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64) at net.sourceforge.eclipsejetty.starter.embedded.JettyEmbeddedAdapter.start(JettyEmbeddedAdapter.java:67) at net.sourceforge.eclipsejetty.starter.common.AbstractJettyLauncherMain.launch(AbstractJettyLauncherMain.java:84) at net.sourceforge.eclipsejetty.starter.embedded.JettyEmbeddedLauncherMain.main(JettyEmbeddedLauncherMain.java:42) 问题分析断点调试com.alibaba.druid.pool.DruidDataSource与com.alibaba.druid.pool.DruidPooledConnection中的close方法均有调用，如果都有关闭的话那怎么还会有连接泄漏呢？肯定有地方不对劲，因此进一步查询，开启druid的管理页面查看连接数，如下 1.png 逻辑连接打开次数132，逻辑连接关闭次数131，发现问题有一个连接是没有放回连接池的，当到2分钟报了连接泄漏异常后再刷新查看，如下： 2.png 逻辑连接打开次数和关闭次数一致了。 于是从上面的错误日志跟踪代码，第一感觉就是自己的业务代码出现了问题，找到业务代码的地方 at com.xx.xx.xx.xx.xx.xx.XXDaoImpl.queryByDeliverCode(XXDaoImpl.java:158)at com.xx.xx.xx.xx.xx.xx.XXServiceImpl.queryByDeliverCode(XXServiceImpl.java:159)at com.xx.xx.xx.xx.xx.xx.XXServiceImpl$$FastClassByCGLIB$$41eff1cc.invoke(&lt;generated&gt;) 打开：XXServiceImpl.queryByDeliverCode代码第159行，代码如下： @Overridepublic DeliverEntity queryByDeliverCode(String code) &#123; return deliverDao.queryByDeliverCode(code);&#125; 代码非常简单调用dao的方法，代开dao的queryByDeliverCode方法，代码如下： @Overridepublic DeliverEntity queryByDeliverCode(String deliverCode) &#123; Map&lt;String,Object&gt; map=new HashMap&lt;String,Object&gt;(); map.put(&quot;deliverCode&quot;, deliverCode); List&lt;DeliverEntity&gt; list = selectList(&quot;com.xx.xx.xx.xx.xx.XXMapper.queryByDeliverCode&quot;, map); return list.size() &gt; 0 ? list.get(0) : null;&#125; 代码也非常简单调用的是基类：MybatisDao的selectList方法，代码如下： public List&lt;E&gt; selectList(final String aStatement, final Map&lt;String, Object&gt; aCondition) &#123; SqlSession session = getSqlSessionTemplate(); return session.selectList(aStatement, aCondition);&#125; 就是调用sqlsession的selectList方法，这个没有问题，连接是可以正常回收的，如果不能回收那上面的数字不可能是只有1个连接泄漏，应该是逻辑打开的132个都没有关闭才对。因此排除了这个地方，那还有什么地方会有问题呢？肯定是有地方getConnection之后没有close导致!继续分析连接泄漏打出来的日志！日志中的代码逐个分析，最终找到PageHelper.initSqlUtil方法 at com.github.pagehelper.PageHelper.initSqlUtil(PageHelper.java:165)at com.github.pagehelper.PageHelper.intercept(PageHelper.java:148) 打开PageHelper.initSqlUtil代码，如下： public synchronized void initSqlUtil(Invocation invocation) &#123; if (sqlUtil == null) &#123; String url = null; try &#123; MappedStatement ms = (MappedStatement) invocation.getArgs()[0]; MetaObject msObject = SystemMetaObject.forObject(ms); DataSource dataSource = (DataSource) msObject.getValue(&quot;configuration.environment.dataSource&quot;); url = dataSource.getConnection().getMetaData().getURL(); &#125; catch (SQLException e) &#123; throw new RuntimeException(&quot;分页插件初始化异常:&quot; + e.getMessage()); &#125; if (url == null || url.length() == 0) &#123; throw new RuntimeException(&quot;无法自动获取jdbcUrl，请在分页插件中配置dialect参数!&quot;); &#125; String dialect = Dialect.fromJdbcUrl(url); if (dialect == null) &#123; throw new RuntimeException(&quot;无法自动获取数据库类型，请通过dialect参数指定!&quot;); &#125; sqlUtil = new SqlUtil(dialect); sqlUtil.setProperties(properties); properties = null; autoDialect = false; &#125;&#125; 貌似问题找到了，第8行代码：dataSource.getConnection()，但是没有在finally中对connection进行回收，罪魁祸首竟然是PageHelper public Object intercept(Invocation invocation) throws Throwable &#123; if (autoDialect) &#123; initSqlUtil(invocation); &#125; return sqlUtil.processPage(invocation);&#125; 根据代码逻辑发现当autoDialect=true时会调用initSqlUtil(invocation);，因此核对了我们的配置mybatis-config.xml &lt;plugins&gt; &lt;!-- com.github.pagehelper为PageHelper类所在包名 --&gt; &lt;plugin interceptor=&quot;com.github.pagehelper.PageHelper&quot;&gt;&lt;!-- &lt;property name=&quot;dialect&quot; value=&quot;mysql&quot; /&gt; --&gt; &lt;property name=&quot;autoDialect&quot; value=&quot;true&quot; /&gt; &lt;!-- 该参数默认为false --&gt; &lt;!-- 设置为true时，会将RowBounds第一个参数offset当成pageNum页码使用 --&gt; &lt;!-- 和startPage中的pageNum效果一样 --&gt; &lt;property name=&quot;offsetAsPageNum&quot; value=&quot;true&quot; /&gt; &lt;!-- 该参数默认为false --&gt; &lt;!-- 设置为true时，使用RowBounds分页会进行count查询 --&gt; &lt;property name=&quot;rowBoundsWithCount&quot; value=&quot;true&quot; /&gt; &lt;!-- 设置为true时，如果pageSize=0或者RowBounds.limit = 0就会查询出全部的结果 --&gt; &lt;!-- （相当于没有执行分页查询，但是返回结果仍然是Page类型） --&gt; &lt;property name=&quot;pageSizeZero&quot; value=&quot;true&quot; /&gt; &lt;!-- 3.3.0版本可用 - 分页参数合理化，默认false禁用 --&gt; &lt;!-- 启用合理化时，如果pageNum&lt;1会查询第一页，如果pageNum&gt;pages会查询最后一页 --&gt; &lt;!-- 禁用合理化时，如果pageNum&lt;1或pageNum&gt;pages会返回空数据 --&gt; &lt;property name=&quot;reasonable&quot; value=&quot;false&quot; /&gt; &lt;!-- 3.5.0版本可用 - 为了支持startPage(Object params)方法 --&gt; &lt;!-- 增加了一个`params`参数来配置参数映射，用于从Map或ServletRequest中取值 --&gt; &lt;!-- 可以配置pageNum,pageSize,count,pageSizeZero,reasonable,不配置映射的用默认值 --&gt; &lt;!-- 不理解该含义的前提下，不要随便复制该配置 --&gt; &lt;property name=&quot;params&quot; value=&quot;pageNum=start;pageSize=limit;&quot; /&gt; &lt;/plugin&gt; &lt;/plugins&gt; 我们果然配置的是：autoDialect=true，PageHelper在没有设置数据库方言的时候，他会主动的获取jdbc url来判断时那种数据库，因此会发生有一个连接是泄漏的，那这个问题如何解决呢？我们打开PageHelper.setProperties方法，如下： public void setProperties(Properties p) &#123; //MyBatis3.2.0版本校验 try &#123; Class.forName(&quot;org.apache.ibatis.scripting.xmltags.SqlNode&quot;);//SqlNode是3.2.0之后新增的类 &#125; catch (ClassNotFoundException e) &#123; throw new RuntimeException(&quot;您使用的MyBatis版本太低，MyBatis分页插件PageHelper支持MyBatis3.2.0及以上版本!&quot;); &#125; //数据库方言 String dialect = p.getProperty(&quot;dialect&quot;); if (dialect == null || dialect.length() == 0) &#123; autoDialect = true; this.properties = p; &#125; else &#123; autoDialect = false; sqlUtil = new SqlUtil(dialect); sqlUtil.setProperties(p); &#125;&#125; 只要我们在plugin配置的时候设置具体的方言就可以避免这个问题：dialect=mysql，如果有明确的dialect设置，autoDialect就会等于false，因此在intercept方法中就不会走initSqlUtil(invocation);方法，这就间接的避免了PageHelper的这个bug。但是如果我们的数据源有不同的dialect怎么办呢？有两个办法解决 构造SessionFactory的时候加载不同的mybatis-config.xml配置，如果有两种数据库类型就写两个mybatis-config.xml分别配置不同的dialect 查看PageHelper高版本是否修复了这个bug，升级PageHelper版本 修改PageHelper源码，在dataSource.getConnection()之后增加close调用 ps. 我们现在用的PageHelper版本–&gt;4.0.0，根据官方的chang log可以看出4.X的版本修复了这个问题，可以升级到4.x的final released version –&gt; 4.2.1解决这个问题，5.x版本变更比较大。 修改验证修改mybatis-config.xml的plugin中PageHelper的dialect的配置 &lt;plugin interceptor=&quot;com.github.pagehelper.PageHelper&quot;&gt; &lt;property name=&quot;dialect&quot; value=&quot;mysql&quot; /&gt;&lt;!-- &lt;property name=&quot;autoDialect&quot; value=&quot;true&quot; /&gt; --&gt; &lt;/plugin&gt; 修改后启动程序，打开druid的管理页面和等待2分钟超时看是否还有泄漏的异常爆出，如下： 3.png 超过2分钟并没有泄漏异常爆出 解决方案升级pagehelper版本–&gt;4.2.1,升级jsqlparser版本–&gt;0.9.5,其余配置无需变更 如果升级了4.2.1，如果出现SqlUtil.java(120)行报NullPointerException，具体异常如下： 4.png 遇到上面问题，请修改pagehelper的配置参数，参数修改有两种方式，如下： 直接配置dialect=目标数据源类型（适合使用场景：项目中只有一个固定的数据库类型，例如：mysql，无需开启自动发现dialect） 配置autoRuntimeDialect=true走自动获取，这个属性是替换老属性（autoDialect），老的属性为了向下兼容在并发获取dialect时会有bug存在。（适合使用场景：项目中有多个数据库类型，需要运行中自动发现时使用） 总结这个问题告诉我们使用第三方的组件的风险很大。","tags":[{"name":"abandon connection","slug":"abandon-connection","permalink":"https://ningyu1.github.io/tags/abandon-connection/"},{"name":"connection leak","slug":"connection-leak","permalink":"https://ningyu1.github.io/tags/connection-leak/"},{"name":"datasource","slug":"datasource","permalink":"https://ningyu1.github.io/tags/datasource/"}]},{"title":"Redis RDB文件格式全解析","date":"2017-10-09T06:30:36.000Z","path":"20171009/34-redis-rdb.html","text":"点评这篇文章作为对RDB理解的教程文章，对RDB文件的原理理解有助于进行Redis高阶应用的设计与开发。 文章转自：http://blog.nosqlfan.com/html/3734.html作者：@nosqlfan RDB文件是Redis持久化的一种方式，Redis通过制定好的策略，按期将内存中的数据以镜像的形式转存到RDB文件中。那么RDB文件内部格式是什么样的呢，Redis又做了哪些工作让RDB能够更快的dump和加载呢，下面我们深入RDB文件，来看一看其内部结构。首先我们来看一个RDB文件的概况图： ----------------------------# RDB文件是二进制的，所以并不存在回车换行来分隔一行一行.52 45 44 49 53 # 以字符串 &quot;REDIS&quot; 开头30 30 30 33 # RDB 的版本号，大端存储，比如左边这个表示版本号为0003----------------------------FE 00 # FE = FE表示数据库编号，Redis支持多个库，以数字编号，这里00表示第0个数据库----------------------------# Key-Value 对存储开始了FD $length-encoding # FD 表示过期时间，过期时间是用 length encoding 编码存储的，后面会讲到$value-type # 1 个字节用于表示value的类型，比如set,hash,list,zset等$string-encoded-key # Key 值，通过string encoding 编码，同样后面会讲到$encoded-value # Value值，根据不同的Value类型采用不同的编码方式----------------------------FC $length-encoding # FC 表示毫秒级的过期时间，后面的具体时间用length encoding编码存储$value-type # 同上，也是一个字节的value类型$string-encoded-key # 同样是以 string encoding 编码的 Key值$encoded-value # 同样是以对应的数据类型编码的 Value 值----------------------------$value-type # 下面是没有过期时间设置的 Key-Value对，为防止冲突，数据类型不会以 FD, FC, FE, FF 开头$string-encoded-key$encoded-value----------------------------FE $length-encoding # 下一个库开始，库的编号用 length encoding 编码----------------------------... # 继续存储这个数据库的 Key-Value 对FF ## FF：RDB文件结束的标志 下面我们对上面的内容进行详细讲解 Magic Number第一行就不用讲了，REDIS字符串用于标识是Redis的RDB文件 版本号用了4个字节存储版本号，以大端（big endian）方式存储和读取 数据库编号以一个字节的0xFE开头，后面存储数据库的具体编号，数据库的编号是一个数字，通过 “Length Encoding” 方式编码存储，“Length Encoding” 我们后面会讲到。 Key-Value值对值对包括下面四个部分 Key 过期时间，这一项是可有可无的 一个字节表示value的类型 Key的值，Key都是字符串，通过 “Redis String Encoding” 来保存 Value的值，通过 “Redis Value Encoding” 来根据不同的数据类型做不同的存储 Key过期时间过期时间由 0xFD 或 0xFC开头用于标识，分别表示秒级的过期时间和毫秒级的过期时间，后面的具体时间是一个UNIX时间戳，秒级或毫秒级的。具体时间戳的值通过“Redis Length Encoding” 编码存储。在导入RDB文件的过程中，会通过过期时间判断是否已过期并需要忽略。 Value类型Value类型用一个字节进行存储，目前包括以下一些值： 0 = “String Encoding” 1 = “List Encoding” 2 = “Set Encoding” 3 = “Sorted Set Encoding” 4 = “Hash Encoding” 9 = “Zipmap Encoding” 10 = “Ziplist Encoding” 11 = “Intset Encoding” 12 = “Sorted Set in Ziplist Encoding” KeyKey值就是简单的 “String Encoding” 编码，具体可以看后面的描述 Value上面列举了Value的9种类型，实际上可以分为三大类 type = 0, 简单字符串 type 为 9, 10, 11 或 12, value字符串在读取出来后需要先解压 type 为 1, 2, 3 或 4, value是字符串序列，这一系列的字符串用于构建list，set，hash 和 zset 结构 Length Encoding上面说了很多 Length Encoding ，现在就为大家讲解。可能你会说，长度用一个int存储不就行了吗？但是，通常我们使用到的长度可能都并不大，一个int 4个字节是否有点浪费呢。所以Redis采用了变长编码的方法，将不同大小的数字编码成不同的长度。 首先在读取长度时，会读一个字节的数据，其中前两位用于进行变长编码的判断 如果前两位是 0 0，那么下面剩下的 6位就表示具体长度 如果前两位是 0 1，那么会再读取一个字节的数据，加上前面剩下的6位，共14位用于表示具体长度 如果前两位是 1 0，那么剩下的 6位就被废弃了，取而代之的是再读取后面的4 个字节用于表示具体长度 如果前两位是 1 1，那么下面的应该是一个特殊编码，剩下的 6位用于标识特殊编码的种类。特殊编码主要用于将数字存成字符串，或者编码后的字符串。具体见 “String Encoding” 这样做有什么好处呢，实际就是节约空间： 0 – 63的数字只需要一个字节进行存储 而64 – 16383 的数字只需要两个字节进行存储 16383 - 2^32 -1 的数字只需要用5个字节（1个字节的标识加4个字节的值）进行存储 String EncodingRedis的 String Encoding 是二进制安全的，也就是说他没有任何特殊分隔符用于分隔各个值，你可以在里面存储任何东西。它就是一串字节码。下面是 String Encoding 的三种类型 长度编码的字符串 数字替代字符串：8位，16位或者32位的数字 LZF 压缩的字符串 长度编码字符串长度编码字符串是最简单的一种类型，它由两部分组成，一部分是用 “Length Encoding” 编码的字符串长度，第二部分是具体的字节码。 数字替代字符串上面说到过 Length Encoding 的特殊编码，就在这里用上了。所以数字替代字符串是以 1 1 开头的，然后读取这个字节剩下的6 位，根据不同的值标识不同的数字类型： 0 表示下面是一个8 位的数字 1 表示下面是一个16 位的数字 2 表示下面是一个32 位的数字 LZF压缩字符串和数据替代字符串一样，它也是以1 1 开头的，然后剩下的6 位如果值为4，那么就表示它是一个压缩字符串。压缩字符串解析规则如下： 首先按 Length Encoding 规则读取压缩长度 clen 然后按 Length Encoding 规则读取非压缩长度 再读取第二个 clen 获取到上面的三个信息后，再通过LZF算法解码后面clen长度的字节码 List EncodingRedis List 结构在RDB文件中的存储，是依次存储List中的各个元素的。其结构如下： 首先按 Length Encoding 读取这个List 的长度 size 然后读取 size个 String Encoding的值 然后再用这些读到的 size 个值重新构建 List就完成了 Set EncodingSet结构和List结构一样，也是依次存储各个元素的 Sorted Set Encodingtodo Hash Encoding 首先按 Length Encoding 读出hash 结构的大小 size 然后读取2×size 个 String Encoding的字符串（因为一个hash项包括key和value两项） 将上面读取到的2×size 个字符串解析为hash 和key 和 value 然后将上面的key value对存储到hash结构中 Zipmap Encoding参见本站之前的文章：Redis zipmap内存布局分析","tags":[{"name":"Redis","slug":"Redis","permalink":"https://ningyu1.github.io/tags/Redis/"},{"name":"RDB","slug":"RDB","permalink":"https://ningyu1.github.io/tags/RDB/"}]},{"title":"Redis数据结构使用以及注意事项，运维问题总结","date":"2017-10-09T04:00:36.000Z","path":"20171009/33-redis-considerations.html","text":"文章转自：http://www.cnblogs.com/cnmenglang/p/6225987.html作者：@江南白衣 优缺点非常非常的快，有测评说比Memcached还快(当大家都是单CPU的时候)，而且是无短板的快，读写都一般的快，所有API都差不多快，也没有MySQL Cluster、MongoDB那样更新同一条记录如Counter时慢下去的毛病。 丰富的数据结构，超越了一般的Key-Value数据库而被认为是一个数据结构服务器。组合各种结构，限制Redis用途的是你自己的想象力，作者自己捉刀写的用途入门。 因为是个人作品，Redis目前只有2.3万行代码，Keep it simple的死硬做法，使得普通公司而不需淘宝那个级别的文艺公司也可以吃透它。 Redis宣言就是作者的自白，我最喜欢其中的”代码像首诗”，”设计是一场与复杂性的战斗”，”Coding是一件艰苦的事情，唯一的办法是享受它。如果它已不能带来快乐就停止它。为了防止这一天的出现，我们要尽量避免把Redis往乏味的路上带。 让人又爱又恨的单线程架构，使得代码不用处理平时最让人头痛的并发而大幅简化，也不用老是担心作者的并发有没有写对，但也带来CPU的瓶颈，而且单线程被慢操作所阻塞时，其他请求的延时变得不确定。 那Redis不是什么？ Redis 不是Big Data，数据都在内存中，无法以T为单位。 在Redis-Cluster发布并被稳定使用之前，Redis没有真正的平滑水平扩展能力。 Redis 不支持Ad-Hoc Query，提供的只是数据结构的API，没有SQL一样的查询能力。 Feature速览所有数据都在内存中。 五种数据结构：String / Hash / List / Set / Ordered Set。 数据过期时间支持。 不完全的事务支持。 服务端脚本：使用Lua Script编写，类似存储过程的作用。 PubSub：捞过界的消息一对多发布订阅功能，起码Redis-Sentinel使用了它。 持久化：支持定期导出内存的Snapshot 与 记录写操作日志的Append Only File两种模式。 Replication：Master-Slave模式，Master可连接多个只读Slave，暂无专门的Geographic Replication支持。 Fail-Over：Redis-Sentinel节点负责监控Master节点，在master失效时提升slave，独立的仲裁节点模式有效防止脑裂。 Sharding：开发中的Redis-Cluser。 动态配置：所有参数可用命令行动态配置不需重启，并重新写回配置文件中，对云上的大规模部署非常合适。 八卦作者是意大利的Salvatore Sanfilippo(antirez)，又是VMWare大善人聘请了他专心写Redis。 EMC与VMWare将旗下的开源产品如Redis和Spring都整合到了孙公司Pivotal公司。 Pivotal做的antirez访谈录，内含一切八卦，比如他的爱好是举重、跑步和品红酒。 默认端口6379，是手机按键上MERZ对应的号码，意大利歌女Alessia Merz是antirez和朋友们认为愚蠢的代名词。 数据结构KeyKey 不能太长，比如1024字节，但antirez也不喜欢太短如”u:1000:pwd”，要表达清楚意思才好。他私人建议用”:”分隔域，用”.”作为单词间的连接，如”comment:1234:reply.to”。 Keys，返回匹配的key，支持通配符如 “keys a*” 、 “keys a?c”，但不建议在生产环境大数据量下使用。 Sort，对集合按数字或字母顺序排序后返回或另存为list，还可以关联到外部key等。因为复杂度是最高的O(N+M*log(M))(N是集合大小，M 为返回元素的数量)，有时会安排到slave上执行。 Expire/ExpireAt/Persist/TTL，关于Key超时的操作。默认以秒为单位，也有p字头的以毫秒为单位的版本， Redis的内部实现见2.9 过期数据清除。 String最普通的key-value类型，说是String，其实是任意的byte[]，比如图片，最大512M。 所有常用命令的复杂度都是O(1)，普通的Get/Set方法，可以用来做Cache，存Session，为了简化架构甚至可以替换掉Memcached。 Incr/IncrBy/IncrByFloat/Decr/DecrBy，可以用来做计数器，做自增序列。key不存在时会创建并贴心的设原值为0。IncrByFloat专门针对float，没有对应的decrByFloat版本？用负数啊。 SetNx， 仅当key不存在时才Set。可以用来选举Master或做分布式锁：所有Client不断尝试使用SetNx master myName抢注Master，成功的那位不断使用Expire刷新它的过期时间。 如果Master倒掉了key就会失效，剩下的节点又会发生新一轮抢夺。 其他Set指令： SetEx， Set + Expire 的简便写法，p字头版本以毫秒为单位。 GetSet， 设置新值，返回旧值。比如一个按小时计算的计数器，可以用GetSet获取计数并重置为0。这种指令在服务端做起来是举手之劳，客户端便方便很多。 MGet/MSet/MSetNx， 一次get/set多个key。 2.6.12版开始，Set命令已融合了Set/SetNx/SetEx三者，SetNx与SetEx可能会被废弃，这对Master抢注非常有用，不用担心setNx成功后，来不及执行Expire就倒掉了。可惜有些懒惰的Client并没有快速支持这个新指令。 GetBit/SetBit/BitOp,与或非/BitCount/BitMap的玩法，比如统计今天的独立访问用户数时，每个注册用户都有一个offset，他今天进来的话就把他那个位设为1，用BitCount就可以得出今天的总人树。 Append/SetRange/GetRange/StrLen，对文本进行扩展、替换、截取和求长度，只对特定数据格式如字段定长的有用，json就没什么用。 HashKey-HashMap结构，相比String类型将这整个对象持久化成JSON格式，Hash将对象的各个属性存入Map里，可以只读取/更新对象的某些属性。 这样有些属性超长就让它一边呆着不动，另外不同的模块可以只更新自己关心的属性而不会互相并发覆盖冲突。 另一个用法是土法建索引。比如User对象，除了id有时还要按name来查询。 可以有如下的数据记录: (String) user:101 -&gt; &#123;&quot;id&quot;:101,&quot;name&quot;:&quot;calvin&quot;...&#125;(String) user:102 -&gt; &#123;&quot;id&quot;:102,&quot;name&quot;:&quot;kevin&quot;...&#125;(Hash) user:index-&gt; &quot;calvin&quot;-&gt;101, &quot;kevin&quot; -&gt; 102 底层实现是hash table，一般操作复杂度是O(1)，要同时操作多个field时就是O(N)，N是field的数量。 ListList是一个双向链表，支持双向的Pop/Push，江湖规矩一般从左端Push，右端Pop——LPush/RPop，而且还有Blocking的版本BLPop/BRPop，客户端可以阻塞在那直到有消息到来，所有操作都是O(1)的好孩子，可以当Message Queue来用。 当多个Client并发阻塞等待，有消息入列时谁先被阻塞谁先被服务。任务队列系统Resque是其典型应用。 还有RPopLPush/ BRPopLPush，弹出来返回给client的同时，把自己又推入另一个list，LLen获取列表的长度。 还有按值进行的操作：LRem(按值删除元素)、LInsert(插在某个值的元素的前后)，复杂度是O(N)，N是List长度，因为List的值不唯一，所以要遍历全部元素，而Set只要O(log(N))。 按下标进行的操作：下标从0开始，队列从左到右算，下标为负数时则从右到左。 LSet ，按下标设置元素值。 LIndex，按下标返回元素。 LRange，不同于POP直接弹走元素，只是返回列表内一段下标的元素，是分页的最爱。 LTrim，限制List的大小，比如只保留最新的20条消息。 复杂度也是O(N)，其中LSet的N是List长度，LIndex的N是下标的值，LRange的N是start的值+列出元素的个数，因为是链表而不是数组，所以按下标访问其实要遍历链表，除非下标正好是队头和队尾。LTrim的N是移除元素的个数。 在消息队列中，并没有JMS的ack机制，如果消费者把job给Pop走了又没处理完就死机了怎么办？ 解决方法之一是加多一个sorted set，分发的时候同时发到list与sorted set，以分发时间为score，用户把job做完了之后要用ZREM消掉sorted set里的job，并且定时从sorted set中取出超时没有完成的任务，重新放回list。 另一个做法是为每个worker多加一个的list，弹出任务时改用RPopLPush，将job同时放到worker自己的list中，完成时用LREM消掉。 如果集群管理(如zookeeper)发现worker已经挂掉，就将worker的list内容重新放回主list。 SetSet就是Set，可以将重复的元素随便放入而Set会自动去重，底层实现也是hash table。 SAdd/SRem/SISMember/SCard/SMove/SMembers，各种标准操作。除了SMembers都是O(1)。 SInter/SInterStore/SUnion/SUnionStore/SDiff/SDiffStore，各种集合操作。交集运算可以用来显示在线好友(在线用户 交集 好友列表)，共同关注(两个用户的关注列表的交集)。 O(N)，并集和差集的N是集合大小之和，交集的N是小的那个集合的大小*2。 Sorted Set有序集，元素放入集合时还要提供该元素的分数。 ZRange/ZRevRange，按排名的上下限返回元素，正数与倒数。 ZRangeByScore/ZRevRangeByScore，按分数的上下限返回元素，正数与倒数。 ZRemRangeByRank/ZRemRangeByScore，按排名/按分数的上下限删除元素。 ZCount，统计分数上下限之间的元素个数。 ZRank/ZRevRank ，显示某个元素的正倒序的排名。 ZScore/ZIncrby，显示元素的分数/增加元素的分数。 ZAdd(Add)/ZRem(Remove)/ZCard(Count)，ZInsertStore(交集)/ZUnionStore(并集)，Set操作，与正牌Set相比，少了IsMember和差集运算。 Sorted Set的实现是hash table(element-&gt;score, 用于实现ZScore及判断element是否在集合内)，和skip list(score-&gt;element,按score排序)的混合体。 skip list有点像平衡二叉树那样，不同范围的score被分成一层一层，每层是一个按score排序的链表。 ZAdd/ZRem是O(log(N))，ZRangeByScore/ZRemRangeByScore是O(log(N)+M)，N是Set大小，M是结果/操作元素的个数。 可见，原本可能很大的N被很关键的Log了一下，1000万大小的Set，复杂度也只是几十不到。 当然，如果一次命中很多元素M很大那谁也没办法了。 事务用Multi(Start Transaction)、Exec(Commit)、Discard(Rollback)实现。 在事务提交前，不会执行任何指令，只会把它们存到一个队列里，不影响其他客户端的操作。在事务提交时，批量执行所有指令。《Redis设计与实现》中的详述。 注意，Redis里的事务，与我们平时的事务概念很不一样： 它仅仅是保证事务里的操作会被连续独占的执行。因为是单线程架构，在执行完事务内所有指令前是不可能再去同时执行其他客户端的请求的。 它没有隔离级别的概念，因为事务提交前任何指令都不会被实际执行，也就不存在”事务内的查询要看到事务里的更新，在事务外查询不能看到”这个让人万分头痛的问题。 它不保证原子性——所有指令同时成功或同时失败，只有决定是否开始执行全部指令的能力，没有执行到一半进行回滚的能力。 在redis里失败分两种，一种是明显的指令错误，比如指令名拼错，指令参数个数不对，在2.6版中全部指令都不会执行。 另一种是隐含的，比如在事务里，第一句是SET foo bar， 第二句是LLEN foo，对第一句产生的String类型的key执行LLEN会失败，但这种错误只有在指令运行后才能发现，这时候第一句成功，第二句失败。 还有，如果事务执行到一半redis被KILL，已经执行的指令同样也不会被回滚。 Watch指令，类似乐观锁，事务提交时，如果Key的值已被别的客户端改变，比如某个list已被别的客户端push/pop过了，整个事务队列都不会被执行。 Lua ScriptRedis2.6内置的Lua Script支持，可以在Redis的Server端一次过运行大量逻辑，就像存储过程一样，避免了海量中间数据在网路上的传输。 Lua自称是在Script语言里关于快的标准，Redis选择了它而不是流行的JavaScript。 因为Redis的单线程架构，整个Script默认是在一个事务里的。 Script里涉及的所有Key尽量用变量，从外面传入，使Redis一开始就知道你要改变哪些key，为了日后做水平分区做准备。如果涉及的key在不同服务器…… Eval每次传输一整段Script比较费带宽，可以先用Script Load载入script，返回哈希值。然后用EvalHash执行。因为就是SHA-1，所以任何时候执行返回的哈希值都是一样的。 内置的Lua库里还很贴心的带了CJSON，可以处理json字符串。 Script一旦执行则不容易中断，中断了也会有不可知后果，因此最好在开发环境充分测试了再上线。 一段用Redis做Timer的示例代码，下面的script被定期调用，从以触发时间为score的sorted set中取出已到期的Job，放到list中给Client们blocking popup。 -- KEYS: [1]job:sleeping, [2]job:ready-- ARGS: [1]currentTime-- Comments: result is the job idlocal jobs=redis.call(&apos;zrangebyscore&apos;, KEYS[1], &apos;-inf&apos;, ARGV[1])local count = table.maxn(jobs)if count&gt;0 then -- Comments: remove from Sleeping Job sorted set redis.call(&apos;zremrangebyscore&apos;, KEYS[1], &apos;-inf&apos;, ARGV[1]) -- Comments: add to the Ready Job list -- Comments: can optimize to use lpush id1,id2,... for better performance for i=1,count do redis.call(&apos;lpush&apos;, KEYS[2], jobs[i]) endend 过期数据清除官方文档 与 《Redis设计与实现》中的详述，过期数据的清除从来不容易，为每一条key设置一个timer，到点立刻删除的消耗太大，每秒遍历所有数据消耗也大，Redis使用了一种相对务实的做法： 当client主动访问key会先对key进行超时判断，过时的key会立刻删除。 如果clien永远都不再get那条key呢？ 它会在Master的后台，每秒10次的执行如下操作： 随机选取100个key校验是否过期，如果有25个以上的key过期了，立刻额外随机选取下100个key(不计算在10次之内)。 可见，如果过期的key不多，它最多每秒回收200条左右，如果有超过25%的key过期了，它就会做得更多，但只要key不被主动get，它占用的内存什么时候最终被清理掉只有天知道。 性能测试结果测试环境： RHEL 6.3 / HP Gen8 Server/ 2 * Intel Xeon 2.00GHz(6 core) / 64G DDR3 memory / 300G RAID-1 SATA / 1 master(writ AOF), 1 slave(write AOF &amp; RDB) 数据准备： 预加载两千万条数据，占用10G内存。 测试工具：自带的redis-benchmark，默认只是基于一个很小的数据集进行测试，调整命令行参数如下，就可以开100条线程(默认50)，SET 1千万次(key在0-1千万间随机)，key长21字节，value长256字节的数据。 redis-benchmark -t SET -c 100 -n 10000000 -r 10000000 -d 256 测试结果(TPS)： 1.SET：4.5万， 2.GET：6万 ，3.INCR：6万，4.真实混合场景: 2.5万SET &amp; 3万GET 单条客户端线程时6千TPS，50与100条客户端线程差别不大，200条时会略多。 Get/Set操作，经过了LAN，延时也只有1毫秒左右，可以反复放心调用，不用像调用REST接口和访问数据库那样，每多一次外部访问都心痛。 资源监控: CPU: 占了一个处理器的100%，总CPU是4%(因为总共有2CPU6核超线程 = 24个处理器)，可见单线程下单处理器的能力是瓶颈。 AOF rewrite时另一个处理器占用50-70%。 网卡：15-20 MB/s receive, 3Mb/s send(no slave) or 15-20 MB/s send (with slave) 。当把value长度加到4K时，receive 99MB/s，已经到达千兆网卡的瓶颈，TPS降到2万。 硬盘：15MB/s(AOF append), 100MB/s(AOF rewrite/AOF load，普通硬盘的瓶颈) 为什么快纯ANSI C编写。 不依赖第三方类库，没有像memcached那样使用libevent，因为libevent迎合通用性而造成代码庞大，所以作者用libevent中两个文件修改实现了自己的epoll event loop。微软的兼容Windows补丁也因为同样原因被拒了。 快，原因之一是Redis多样的数据结构，每种结构只做自己爱做的事，当然比数据库只有Table，MongogoDB只有JSON一种结构快了。 可惜单线程架构，虽然作者认为CPU不是瓶颈，内存与网络带宽才是。但实际测试时并非如此，见上。 性能调优官方文档关于各种产生Latency的原因的详细分析, 中文版 正视网络往返时间： 1.MSet/LPush/ZAdd等都支持一次输入多个Key。 2.PipeLining模式 可以一次输入多个指令。 3.更快的是Lua Script模式，还可以包含逻辑，直接在服务端又get又set的，见2.8 Lua Script。 发现执行缓慢的命令，可配置执行超过多少时间的指令算是缓慢指令(默认10毫秒，不含IO时间)，可以用slowlog get 指令查看(默认只保留最后的128条)。 单线程的模型下，一个请求占掉10毫秒是件大事情，注意设置和显示的单位为微秒。 CPU永远是瓶颈，但top看到单个CPU 100%时，就是垂直扩展的时候了。 持久化对性能的影响很大，见5.1持久化。 要熟悉各指令的复杂度，不过只要不是O(N)一个超大集合，都不用太担心。 容量最大内存所有的数据都必须在内存中，原来2.0版的VM策略(将Value放到磁盘，Key仍然放在内存)，2.4版后嫌麻烦又不支持了。 一定要设置最大内存，否则物理内存用爆了就会大量使用Swap，写RDB文件时的速度慢得你想死。 多留一倍内存是最安全的。重写AOF文件和RDB文件的进程(即使不做持久化，复制到Slave的时候也要写RDB)会fork出一条新进程来，采用了操作系统的Copy-On-Write策略(子进程与父进程共享Page。 如果父进程的Page-每页4K有修改，父进程自己创建那个Page的副本，不会影响到子进程，父爱如山)。留意Console打出来的报告，如”RDB: 1215 MB of memory used by copy-on-write”。 在系统极度繁忙时，如果父进程的所有Page在子进程写RDB过程中都被修改过了，就需要两倍内存。 按照Redis启动时的提醒，设置 vm.overcommit_memory = 1 ，使得fork()一条10G的进程时，因为COW策略而不一定需要有10G的free memory。 其他需要考虑的内存包括： 1.AOF rewrite过程中对新写入命令的缓存(rewrite结束后会merge到新的aof文件)，留意”Background AOF buffer size: 80 MB”的字样。 2.负责与Slave同步的Client的缓存，默认设置master需要为每个slave预留不高于256M的缓存(见5.1持久化)。 当最大内存到达时，按照配置的Policy进行处理， 默认策略为volatile-lru，对设置了expire time的key进行LRU清除(不是按实际expire time)。 如果沒有数据设置了expire time或者policy为noeviction，则直接报错，但此时系统仍支持get之类的读操作。 另外还有几种policy，比如volatile-ttl按最接近expire time的，allkeys-lru对所有key都做LRU。 内存占用测试表明，string类型需要90字节的额外代价，就是说key 1个字节，value 1个字节时，还是需要占用92字节的长度，而上面的benchmark的记录就占用了367个字节。 其他类型可根据文档自行计算或实际测试一下。 使用jemalloc分配内存，删除数据后，内存并不会乖乖还给操作系统而是被Redis截留下来重用到新的数据上，直到Redis重启。 因此进程实际占用内存是看INFO里返回的used_memory_peak_human。 Redis内部用了ziplist/intset这样的压缩结构来减少hash/list/set/zset的存储，默认当集合的元素少于512个且最长那个值不超过64字节时使用，可配置。 用make 32bit可以编译出32位的版本，每个指针占用的内存更小，但只支持最大4GB内存。 水平分区，Sharding其实，大内存加上垂直分区也够了，不一定非要沙丁一把。 Jedis支持在客户端做分区，局限是不能动态re-sharding， 有分区的master倒了，不能减少分区必须用slave顶上。要增加分区的话，呃….. antire在博客里提到了Twemproxy，一个Twitter写的Proxy，但它在发现节点倒掉后，只会重新计算一致性哈希环，把数据存到别的master去，而不是集成Sentinel指向新由slave升级的master，像Memcached一样的做法也只适合做Cache的场景。 Redis-Cluster是今年工作重点，支持automatic re-sharding， 采用和Hazelcast类似的算法，总共有N个分区(eg.N=1024)，每台Server负责若干个分区。 在客户端先hash出key 属于哪个分区，随便发给一台server，server会告诉它真正哪个Server负责这个分区，缓存下来，下次还有该分区的请求就直接发到地儿了。 Re-sharding时，会将某些分区的数据移到新的Server上，完成后各Server周知分区Server映射的变化，因为分区数量有限，所以通讯量不大。 在迁移过程中，客户端缓存的依然是旧的分区映射信息，原server对于已经迁移走的数据的get请求，会返回一个临时转向的应答，客户端先不会更新Cache。 等迁移完成了，就会像前面那样返回一条永久转向信息，客户端更新Cache，以后就都去新server了。 高可用性高可用性关乎系统出错时到底会丢失多少数据，多久不能服务。要综合考虑持久化，Master-Slave复制及Fail-Over配置，以及具体Crash情形，比如Master死了，但Slave没死。或者只是Redis死了，操作系统没死等等。 持久化综述： 解密Redis持久化(中文概括版), 英文原版，《Redis设计与实现》： RDB 与 AOF。 很多人开始会想象两者是互相结合的，即dump出一个snapshot到RDB文件，然后在此基础上记录变化日志到AOF文件。 实际上两者毫无关系，完全独立运行，因为作者认为简单才不会出错。如果使用了AOF，重启时只会从AOF文件载入数据，不会再管RDB文件。 正确关闭服务器：redis-cli shutdown 或者 kill，都会graceful shutdown，保证写RDB文件以及将AOF文件fsync到磁盘，不会丢失数据。 如果是粗暴的Ctrl+C，或者kill -9 就可能丢失。 RDB文件RDB是整个内存的压缩过的Snapshot，RDB的数据结构，可以配置复合的快照触发条件，默认是1分钟内改了1万次，或5分钟内改了10次，或15分钟内改了1次。 RDB写入时，会连内存一起Fork出一个新进程，遍历新进程内存中的数据写文件，这样就解决了些Snapshot过程中又有新的写入请求进来的问题。 Fork的细节见4.1最大内存。 RDB会先写到临时文件，完了再Rename成，这样外部程序对RDB文件的备份和传输过程是安全的。而且即使写新快照的过程中Server被强制关掉了，旧的RDB文件还在。 可配置是否进行压缩，压缩方法是字符串的LZF算法，以及将string形式的数字变回int形式存储。 动态所有停止RDB保存规则的方法：redis-cli config set save “” AOF文件操作日志，记录所有有效的写操作，等于mysql的binlog，格式就是明文的Redis协议的纯文本文件。 一般配置成每秒调用一次fdatasync将kernel的文件缓存刷到磁盘。当操作系统非正常关机时，文件可能会丢失不超过2秒的数据(更严谨的定义见后)。 如果设为fsync always，性能只剩几百TPS，不用考虑。 如果设为no，靠操作系统自己的sync，Linux系统一般30秒一次。 AOF文件持续增长而过大时，会fork出一条新进程来将文件重写(也是先写临时文件，最后再rename，)， 遍历新进程的内存中数据，每条记录有一条的Set语句。 默认配置是当AOF文件大小是上次rewrite后大小的一倍，且文件大于64M时触发。 Redis协议，如set mykey hello，将持久化成*3 $3 set $5 mykey $5 hello， 第一个数字代表这条语句有多少元，其他的数字代表后面字符串的长度。 这样的设计，使得即使在写文件过程中突然关机导致文件不完整，也能自我修复，执行redis-check-aof即可。 综上所述，RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件。 那要不要只使用AOF呢？作者建议不要，因为RDB更适合用于备份数据库(AOF在不断变化不好备份)，快速重启，而且不会有AOF可能潜在的bug，留着作为一个万一的手段。 读写性能AOF重写和RDB写入都是在fork出新进程后，遍历新进程的内存顺序写的，既不阻塞主进程继续处理客户端请求，顺序写的速度也比随机写快。 测试把刚才benchmark的11G数据写成一个1.3的RDB文件，或者等大的AOF文件rewrite，需要80秒，在redis-cli info中可查看。启动时载入一个AOF或RDB文件的速度与上面写入时相同，在log中可查看。 Fork一个使用了大量内存的进程也要时间，大约10ms per GB的样子，但Xen在EC2上是让人郁闷的239ms (KVM和VMWare貌似没有这个毛病)，各种系统的对比，Info指令里的latest_fork_usec显示上次花费的时间。 在bgrewriteaof过程中，所有新来的写入请求依然会被写入旧的AOF文件，同时放到buffer中，当rewrite完成后，会在主线程把这部分内容合并到临时文件中之后才rename成新的AOF文件。 所以rewrite过程中会不断打印”Background AOF buffer size: 80 MB， Background AOF buffer size: 180 MB”，计算系统容量时要留意这部分的内存消耗。 注意，这个合并的过程是阻塞的，如果你产生了280MB的buffer，在100MB/s的传统硬盘上，Redis就要阻塞2.8秒！！！ NFS或者Amazon上的EBS都不推荐，因为它们也要消耗带宽。 bgsave和bgaofrewrite不会被同时执行，如果bgsave正在执行，bgaofrewrite会自动延后。 2.4版以后，写入AOF时的fdatasync由另一条线程来执行，不会再阻塞主线程。 2.4版以后，lpush/zadd可以输入一次多个值了，使得AOF重写时可以将旧版本中的多个lpush/zadd指令合成一个，每64个key串一串。 性能调整因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留save 900 1这条规则。 如果Enalbe AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自己的AOF文件就可以了。 代价一是带来了持续的IO，二是AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。 只要硬盘许可，应该尽量减少AOF rewrite的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上。 默认超过原大小100%大小时重写可以改到适当的数值，比如之前的benchmark每个小时会产生40G大小的AOF文件，如果硬盘能撑到半夜系统闲时才用cron调度bgaofrewrite就好了。 如果不Enable AOF，仅靠Master-Slave Replication 实现高可用性也可以。能省掉一大笔IO也减少了rewrite时带来的系统波动。 代价是如果Master/Slave同时倒掉，会丢失十几分钟的数据，启动脚本也要比较两个Master/Slave中的RDB文件，载入较新的那个。新浪微博就选用了这种架构，见Tim的博客 Trouble Shooting —— Enable AOF可能导致整个Redis被Block住，在2.6.12版之前现象描述：当AOF rewrite 15G大小的内存时，Redis整个死掉的样子，所有指令甚至包括slave发到master的ping，redis-cli info都不能被执行。 原因分析：官方文档，由IO产生的Latency详细分析, 已经预言了悲剧的发生，但一开始没留意。 Redis为求简单，采用了单请求处理线程结构。 打开AOF持久化功能后， Redis处理完每个事件后会调用write(2)将变化写入kernel的buffer，如果此时write(2)被阻塞，Redis就不能处理下一个事件。 Linux规定执行write(2)时，如果对同一个文件正在执行fdatasync(2)将kernel buffer写入物理磁盘，或者有system wide sync在执行，write(2)会被block住，整个Redis被block住。 如果系统IO繁忙，比如有别的应用在写盘，或者Redis自己在AOF rewrite或RDB snapshot(虽然此时写入的是另一个临时文件，虽然各自都在连续写，但两个文件间的切换使得磁盘磁头的寻道时间加长），就可能导致fdatasync(2)迟迟未能完成从而block住write(2)，block住整个Redis。 为了更清晰的看到fdatasync(2)的执行时长，可以使用”strace -p (pid of redis server) -T -e -f trace=fdatasync”，但会影响系统性能。 Redis提供了一个自救的方式，当发现文件有在执行fdatasync(2)时，就先不调用write(2)，只存在cache里，免得被block。但如果已经超过两秒都还是这个样子，则会硬着头皮执行write(2)，即使redis会被block住。 此时那句要命的log会打印：“Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.” 之后用redis-cli INFO可以看到aof_delayed_fsync的值被加1。 因此，对于fsync设为everysec时丢失数据的可能性的最严谨说法是：如果有fdatasync在长时间的执行，此时redis意外关闭会造成文件里不多于两秒的数据丢失。 如果fdatasync运行正常，redis意外关闭没有影响，只有当操作系统crash时才会造成少于1秒的数据丢失。 解决方法：最后发现，原来是AOF rewrite时一直埋头的调用write(2)，由系统自己去触发sync。在RedHat Enterprise 6里，默认配置vm.dirty_background_ratio=10，也就是占用了10%的可用内存才会开始后台flush，而我的服务器有64G内存。 很明显一次flush太多数据会造成阻塞，所以最后果断设置了sysctl vm.dirty_bytes=33554432(32M)，问题解决。 然后提了个issue，AOF rewrite时定时也执行一下fdatasync嘛， antirez三分钟后就回复了，新版中，AOF rewrite时32M就会重写主动调用fdatasync。 Master-Slave复制概述slave可以在配置文件、启动命令行参数、以及redis-cli执行SlaveOf指令来设置自己是奴隶。 测试表明同步延时非常小，指令一旦执行完毕就会立刻写AOF文件和向Slave转发，除非Slave自己被阻塞住了。 比较蠢的是，即使在配置文件里设了slavof，slave启动时依然会先从数据文件载入一堆没用的数据，再去执行slaveof。 “Slaveof no one”，立马变身master。 2.8版本将支持PSYNC部分同步，master会拨出一小段内存来存放要发给slave的指令，如果slave短暂的断开了，重连时会从内存中读取需要补读的指令，这样就不需要断开两秒也搞一次全同步了。 但如果断开时间较长，已经超过了内存中保存的数据，就还是要全同步。 Slave也可以接收Read-Only的请求。 slaveof执行过程，完全重用已有功能，非常经济先执行一次全同步 – 请求master BgSave出自己的一个RDB Snapshot文件发给slave，slave接收完毕后，清除掉自己的旧数据，然后将RDB载入内存。 再进行增量同步 – master作为一个普通的client连入slave，将所有写操作转发给slave，没有特殊的同步协议。 Trouble Shooting again有时候明明master/slave都活得好好的，突然间就说要重新进行全同步了： 1）Slave显示： # MASTER time out: no data nor PING received... slave会每隔repl-ping-slave-period(默认10秒)ping一次master，如果超过repl-timeout(默认60秒)都没有收到响应，就会认为Master挂了。 如果Master明明没挂但被阻塞住了也会报这个错。可以适当调大repl-timeout。 2）Master显示： # Client addr=10.175.162.123:44670 flags=S oll=104654 omem=2147487792 events=rw cmd=sync scheduled to be closed ASAP for overcoming of output buffer limits. 当slave没挂但被阻塞住了，比如正在loading Master发过来的RDB， Master的指令不能立刻发送给slave，就会放在output buffer中(见oll是命令数量，omem是大小)， 在配置文件中有如下配置：client-output-buffer-limit slave 256mb 64mb 60， 这是说负责发数据给slave的client，如果buffer超过256m或者连续60秒超过64m，就会被立刻强行关闭！！！ Traffic大的话一定要设大一点。 否则就会出现一个很悲剧的循环，Master传输一个大的RDB给Slave，Slave努力的装载，但还没装载完，Master对client的缓存满了，再来一次。 平时可以在master执行 redis-cli client list 找那个cmd=sync，flag=S的client，注意OMem的变化。 Fail-OverRedis-sentinel是2.6版开始加入的另一组独立运行的节点，提供自动Fail Over的支持。 官方文档 与 Redis核心解读–集群管理工具(Redis-sentinel) antirez 对 Sentinel的反驳，与下篇 主要执行过程Sentinel每秒钟对所有master，slave和其他sentinel执行Ping，redis-server节点要应答+PONG或-LOADING或-MASTERDOWN. 如果某一台Sentinel没有在30秒内(可配置得短一些哦)收到上述正确应答，它就会认为master处于sdown状态(主观Down) 它向其他sentinel询问是否也认为该master倒了（SENTINEL is-master-down-by-addr ）， 如果quonum台(默认是2)sentinel在5秒钟内都这样认为，就会认为master真是odown了(客观Down)。 此时会选出一台sentinel作为Leader执行fail-over, Leader会从slave中选出一个提升为master(执行slaveof no one)，然后让其他slave指向它(执行slaveof new master)。 master/slave 及 其他sentinel的发现master地址在sentinel.conf里, sentinel会每10秒一次向master发送INFO，知道master的slave有哪些。 如果master已经变为slave，sentinel会分析INFO的应答指向新的master。 以前，sentinel重启时，如果master已经切换过了，但sentinel.conf里master的地址并没有变，很可能有悲剧发生。 另外master重启后如果没有切换成slave，也可能有悲剧发生。新版好像修复了一点这个问题，待研究。 另外，sentinel会在master上建一个pub/sub channel，名为”sentinel:hello”，通告各种信息，sentinel们也是通过接收pub/sub channel上的+sentinel的信息发现彼此，因为每台sentinel每5秒会发送一次自己的host信息，宣告自己的存在。 自定义reconfig脚本sentinel在failover时还会执行配置文件里指定的用户自定义reconfig脚本，做用户自己想做的事情，比如让master变为slave并指向新的master。 脚本的将会在命令行按顺序传入如下参数： &lt;role(leader/observer)&gt; &lt;state(上述三种情况)&gt; 脚本返回0是正常，如果返回1会被重新执行，如果返回2或以上不会。 如果超过60秒没返回会被强制终止。 觉得Sentinel至少有两个可提升的地方: 一是如果master 主动shutdown，比如系统升级，有办法主动通知sentinel提升新的master，减少服务中断时间。 二是比起redis-server太原始了，要自己丑陋的以nohup sentinel &gt; logfile 2&gt;&amp;1 &amp; 启动，也不支持shutdown命令，要自己kill pid。 Client的高可用性基于Sentinel的方案，client需要执行语句SENTINEL get-master-addr-by-name mymaster 可获得当前master的地址。 Jedis正在集成sentinel，已经支持了sentinel的一些指令，但还没发布，但sentinel版的连接池则暂时完全没有，在公司的项目里我参考网友的项目自己写了一个。 淘宝的Tedis driver，使用了完全不同的思路，不基于Sentinel，而是多写随机读， 一开始就同步写入到所有节点，读的话随便读一个还活着的节点就行了。 但有些节点成功有些节点失败如何处理? 节点死掉重新起来后怎么重新同步?什么时候可以重新Ready? 所以不是很敢用。 另外如Ruby写的redis_failover，也是抛开了Redis Sentinel，基于ZooKeeper的临时方案。 Redis作者也在博客里抱怨怎么没有人做Dynamo-style 的client。 Geographic Replication没有特别支持，依然用Master Slave复制，3Scale想出了诸如用压缩的SSH隧道降低传输量等方法。 运维安装安装包制作：没有现成，需要自己编译，自己写rpm包的脚本，可参考utils中的install_server.sh与redis_init_script。 但RHEL下设定script runlevel的方式不一样，redis_init_script中要增加一句 “# chkconfig: 345 90 10” ，而install_server.sh可以删掉后面的那句chkconfig --level 345 reis 云服务：Redis Cloud，在Amazon、Heroku、Windows Azure、App Frog上提供云服务，供同样部署在这些云上的应用使用。 其他的云服务有GarantiaData，已被redis-cloud收购。另外还有Redis To Go, OpenRedis, RedisGreen。 CopperEgg统计自己的用户在AWS上的数据库部署：mysqld占了50%半壁江山, redis占了18%排第二, mongodb也有11%, cassandra是3%，Oracle只有可怜的2%。 Chef Recipes：brianbianco/redisio，活跃，同步更新版本。 部署模型Redis只能使用单线程，为了提高CPU利用率，有提议在同一台服务器上启动多个Redis实例，但这会带来严重的IO争用，除非Redis不需要持久化，或者有某种方式保证多个实例不会在同一个时间重写AOF。 一组sentinel能同时监控多个Master。 有提议说环形的slave结构，即master只连一个slave，然后slave再连slave，此部署有两个前提，一是有大量的只读需求需要在slave完成，二是对slave传递时的数据不一致性不敏感。 配置约30个配置项，全都有默认配置，对redif.conf默认配置的修改见附录1。 三条路可以配置文件中编写。 可以在启动时的命令行配置，redis-server –port 7777 –slaveof 127.0.0.1 8888。 云时代大规模部署，把配置文件满街传显然不是好的做法， 可以用redis-cli执行Config Set指令， 修改所有的参数，达到维护人员最爱的不重启服务而修改参数的效果，而且在新版本里还可以执行 Config Rewrite 将改动写回到文件中，不过全部默认值都会打印出来，可能会破坏掉原来的文件的排版，注释。 安全保护在配置文件里设置密码：requirepass foobar。 禁止某些危险命令，比如残暴的FlushDB，将它rename成””：rename-command FLUSHDB “”。 监控与维护综述： Redis监控技巧 监控指令Info指令将返回非常丰富的信息。 着重监控检查内存使用，是否已接近上限，used_memory是Redis申请的内存，used_memory_rss是操作系统分配给Redis的物理内存，两者之间隔着碎片，隔着Swap。 还有重点监控 AOF与RDB文件的保存情况，以及master-slave的关系。Statistic 信息还包括key命中率，所有命令的执行次数，所有client连接数量等， CONFIG RESETSTAT 可重置为0。 Monitor指令可以显示Server收到的所有指令，主要用于debug，影响性能，生产环境慎用。 SlowLog 检查慢操作(见2.性能)。 Trouble Shooting支持日志可以动态的设置成verbose/debug模式，但不见得有更多有用的log可看,verbose还会很烦的每5秒打印当前的key情况和client情况。指令为config set loglevel verbose。 最爱Redis的地方是代码只有2.3万行，而且编码优美，而且huangz同学还在原来的注释上再加上了中文注释——Redis 2.6源码中文注释版 ，所以虽然是C写的代码，虽然有十年没看过C代码，但这几天trouble shooting毫无难度，一看就懂。 Trobule shotting的经历证明antirez处理issue的速度非常快(如果你的issue言之有物的话)，比Weblogic之类的商业支持还好。 持久化文件维护如果AOF文件在写入过程中crash，可以用redis-check-aof修复，见5.1.2 如果AOF rewrite和 RDB snapshot的过程中crash，会留下无用的临时文件，需要定期扫描删除。 三方工具官网列出了如下工具，但暂时没发现会直接拿来用的： Redis Live，基于Python的web应用，使用Info和Monitor获得系统情况和指令统计分析。 因为Monitor指令影响性能，所以建议用cron定期运行，每次偷偷采样两分钟的样子。 phpRedisAdmin，基于php的Web应用，目标是MysqlAdmin那样的管理工具，可以管理每一条Key的情况，但它的界面应该只适用于Key的数量不太多的情况，Demo。 Redis Faina，基于Python的命令行，Instagram出品，用户自行获得Monitor的输出后发给它进行统计分析。由于Monitor输出的格式在Redis版本间不一样，要去github下最新版。 Redis-rdb-tools 基于Python的命令行，可以分析RDB文件每条Key对应value所占的大小，还可以将RDB dump成普通文本文件然后比较两个库是否一致，还可以将RDB输出成JSON格式，可能是最有用的一个了。 Redis Sampler，基于Ruby的命令行，antirez自己写的，统计数据分布情况。 Java DriverDriver选择各个Driver好像只有Jedis比较活跃，但也5个月没提交了，也是Java里唯一的Redis官方推荐。 Spring Data Redis的封装并不太必要，因为Jedis已足够简单，没有像Spring Data MongoDB对MongoDB java driver的封装那样大幅简化代码，顶多就是加强了一点点点pipeline和transaction状态下的coding，禁止了一些此状态下不能用的命令。 而所谓屏蔽各种底层driver的差异并不太吸引人，因为我就没打算选其他几种driver。有兴趣的可以翻翻它的JedisConnection代码。 所以，SpringSide直接在Jedis的基础上，按Spring的风格封装了一个JedisTemplate，负责从池中获取与归还Jedis实例，处理异常。 Jedis的细节Jedis基于Apache Commons Pool做的连接池，默认MaxActive最大连接数只有8，必须重新设置。而且MaxIdle也要相应增大，否则所有新建的连接用完即弃，然后会不停的重新连接。 另外Jedis设定了每30秒对所有连接执行一次ping，以发现失效的连接，这样每30秒会有一个拿不到连接的高峰。 但效果如何需要独立分析。比如系统高峰之后可能有一长段时间很闲，而且Redis Server那边做了Timeout控制会把连接断掉，这时候做idle checking是有意义的，但30秒一次也太过频繁了。否则关掉它更好。 Jedis的blocking pop函数，应用执行ExecutorService.shutdownNow()中断线程时并不能把它中断，见讨论组。 两个解决方法： 不要用不限时的blocking popup，传多一个超时时间参数，如5秒。 找地方将调用blocking popup的jedis保存起来，shutdown时主动调用它的close。 Redis对Client端连接的处理Redis默认最大连接数是一万。 Redis默认不对Client做Timeout处理，可以用timeout 项配置，但即使配了也不会非常精确。 Windows的版本Windows版本方便对应用的本地开发调试，但Redis并没有提供，好在微软提供了一个依赖LibUV实现兼容的补丁，https://github.com/MSOpenTech/redis，但redis作者拒绝合并到master中，微软只好苦憋的时时人工同步。 目前的稳定版是2.6版本，支持Lua脚本。 因为github现在已经没有Download服务了，所以编译好的可执行文件藏在这里： https://github.com/MSOpenTech/redis/tree/2.6/bin/release 成功案例注：下文中的链接都是网站的架构描述文档。 Twitter和新浪微博， 都属于将Redis各种数据结构用得出神入化的那种，如何发布大V如奥巴马的消息是它们最头痛的问题。 Tumblr： 11亿美刀卖给Yahoo的图片日志网站，22 台Redis server，每台运行8 - 32个实例，总共100多个Redis实例在跑。 有着Redis has been completely problem free and the community is great的崇高评价。Redis在里面扮演了八爪鱼多面手的角色： Dashboard的海量通知的存储。 Dashboard的二级索引。 存储海量短链接的HBase前面的缓存。 Gearman Job Queue的存储。 正在替换另外30台memcached。 Instagram ，曾经，Redis powers their main feed, activity feed, sessions system, and other services。 但可惜目前已迁往Cassandra，说新架构只需1/4的硬件费用，是的，就是那个导致Digg CTO辞职的Canssandra。 Flickr , 依然是asynchronous task system and rudimentary queueing system。之前Task system放在mysql innodb，根本，撑不住。 The Others： Pinterest，混合使用MySQL、Membase与Redis作为存储。 Youporn.com，100%的Redis，MySQL只用于创建新需求用到的sorted set，300K QPS的大压力。 日本微信 ，Redis在前负责异步Job Queue和O(n)的数据，且作为O(nt)数据的cache，HBase在后，负责O(nt)数据， n是用户，t是时间。 StackOverflow ，2 Redis servers for distribute caching，好穷好轻量。 Github，任务系统Resque的存储。 Discourge，号称是为下一个十年打造的论坛系统， We use Redis for our job queue, rate limiting, as a cache and for transient data，刚好和我司的用法一样。 情色网站 YouPorn，使用 Redis 进行数据存储，Redis 服务器每秒处理30万个页面请求，每小时会记录8-15GB数据。 In SpringSideextension modules项目封装了常用的函数与场景，showcase example的src/demo/redis目录里有各场景的benchmark测试。 Jedis Template典型的Spring Template风格，和JdbcTemplate，HibernateTemplate一样，封装从JedisPool获取与归还Connecton的代码，有带返回值与无返回值两种返回接口。 同时，对最常用的Jedis调用，直接封装了一系列方法。 Scheduler与Master ElectorScheduler实现了基于Redis的高并发单次定时任务分发。具体选型见Scheduler章节。 Master Elector基于redis setNx()与expire()两个api实现，与基于Zookeeper，Hazelcast实现的效果类似。 Showcase中的Demo计有Session，Counter，Scheduler 与 Master Elector四款。 附录附录1： 对redis.conf默认配置的修改Master主机daemonize no -&gt; yes ，启动daemonize模式，注意如果用daemon工具启动redis-server时设回false。logfile stdout -&gt; /var/log/redis/redis.log ，指定日志文件注释掉RDB的所有触发规则，在Master不保存RDB文件。dir ./ -&gt; /var/data/redis，指定持久化文件及临时文件目录.maxmemory，设置为可用内存/2.(可选)appendonly no-&gt;yes，打开AOF文件.auto-aof-rewrite-percentage 100, 综合考虑硬盘大小，可接受重启加载延时等尽量的大，减少AOF rewrite频率.auto-aof-rewrite-min-size 64mb，同上，起码设为5G.client-output-buffer-limit slave 256mb 64mb 60. 考虑Traffic及Slave同步是RDB加载所需时间，正确设置避免buffer撑爆client被关掉后又要重新进行全同步。Master上的安全配置，可选。 Slave主机设置RDB保存频率，因为RDB只作为Backup工具，只保留15分钟的规则，设置为15分钟保存一次就够了save 900 1。 (可选)slaveof 设置master地址，也可动态设定。 repl-timeout 60, 适当加大比如120，避免master实际还没倒掉就认为master倒了。 附录2：版本变更历史3.0.1版-3.0.3版 2013-8-1，在微博发布后反应良好，持续修改。 3.0版 2013-6-29，在公司Workshop后修订，提高wiki的可读性而不只是简单的记录知识点。 附录3：其他参考资料Redis的几个认识误区 by Tim yang。","tags":[{"name":"Redis","slug":"Redis","permalink":"https://ningyu1.github.io/tags/Redis/"},{"name":"AOF Block","slug":"AOF-Block","permalink":"https://ningyu1.github.io/tags/AOF-Block/"},{"name":"AOF","slug":"AOF","permalink":"https://ningyu1.github.io/tags/AOF/"},{"name":"Asynchronous AOF fsync is taking too long (disk is busy?)Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis","slug":"Asynchronous-AOF-fsync-is-taking-too-long-disk-is-busy-Writing-the-AOF-buffer-without-waiting-for-fsync-to-complete-this-may-slow-down-Redis","permalink":"https://ningyu1.github.io/tags/Asynchronous-AOF-fsync-is-taking-too-long-disk-is-busy-Writing-the-AOF-buffer-without-waiting-for-fsync-to-complete-this-may-slow-down-Redis/"}]},{"title":"Trouble Shooting —— Enable AOF可能导致整个Redis被Block住，在3.0.6版本仍然存在","date":"2017-10-09T01:53:36.000Z","path":"20171009/32-redis-aof.html","text":"Redis会有短暂的几秒Block，应用报：Jedis connection failed, retrying…这个问题现象是这样的，应用周期性的报：Jedis connection failed, retrying…，Redis开启AOF会被Block住导致无法连接，查看redis的日志 1486:M 09 Oct 09:33:18.072 * 10 changes in 300 seconds. Saving...1486:M 09 Oct 09:33:18.075 * Background saving started by pid 207061486:M 09 Oct 09:33:34.011 * Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.20706:C 09 Oct 09:33:42.629 * DB saved on disk20706:C 09 Oct 09:33:42.630 * RDB: 178 MB of memory used by copy-on-write1486:M 09 Oct 09:33:42.723 * Background saving terminated with success 重点：Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis. 为什么每次写入磁盘会有disk is busy？这个问题？ 网上有人写到：当AOF rewrite 15G大小的内存时，Redis整个死掉的样子，所有指令甚至包括slave发到master的ping，redis-cli info都不能被执行。 原因分析官方文档，由IO产生的Latency详细分析, 已经预言了悲剧的发生，但一开始没留意。 Redis为求简单，采用了单请求处理线程结构。 打开AOF持久化功能后， Redis处理完每个事件后会调用write(2)将变化写入kernel的buffer，如果此时write(2)被阻塞，Redis就不能处理下一个事件。 Linux规定执行write(2)时，如果对同一个文件正在执行fdatasync(2)将kernel buffer写入物理磁盘，或者有system wide sync在执行，write(2)会被Block住，整个Redis被Block住。 如果系统IO繁忙，比如有别的应用在写盘，或者Redis自己在AOF rewrite或RDB snapshot(虽然此时写入的是另一个临时文件，虽然各自都在连续写，但两个文件间的切换使得磁盘磁头的寻道时间加长），就可能导致fdatasync(2)迟迟未能完成从而Block住write(2)，Block住整个Redis。 为了更清晰的看到fdatasync(2)的执行时长，可以使用”strace -p (pid of redis server) -T -e -f trace=fdatasync”，但会影响系统性能。 Redis提供了一个自救的方式，当发现文件有在执行fdatasync(2)时，就先不调用write(2)，只存在cache里，免得被Block。但如果已经超过两秒都还是这个样子，则会硬着头皮执行write(2)，即使redis会被Block住。 此时那句要命的log会打印：“Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.” 之后用redis-cli INFO可以看到aof_delayed_fsync的值被加1。 因此，对于fsync设为everysec时丢失数据的可能性的最严谨说法是：如果有fdatasync在长时间的执行，此时redis意外关闭会造成文件里不多于两秒的数据丢失。 如果fdatasync运行正常，redis意外关闭没有影响，只有当操作系统crash时才会造成少于1秒的数据丢失。 影响版本网上有说是在2.6.12版之前，但是我们使用的版本：redis_version:3.0.6 任然存在这个问题 解决方法最后发现，原来是AOF rewrite时一直埋头的调用write(2)，由系统自己去触发sync。在RedHat Enterprise 6里，默认配置vm.dirty_background_ratio=10，也就是占用了10%的可用内存才会开始后台flush，而我的服务器有8G内存。 很明显一次flush太多数据会造成阻塞，所以最后果断设置了sysctl vm.dirty_bytes=33554432(32M)，问题解决。 然后提了个issue，AOF rewrite时定时也执行一下fdatasync嘛， antirez回复新版中，AOF rewrite时32M就会重写主动调用fdatasync。 查看一下系统内核参数 &gt;sysctl -a | grep dirty_background_ratiovm.dirty_background_ratio = 10&gt;sysctl -a | grep vm.dirty_bytesvm.dirty_bytes = 0 ps.尝试修改一下 编辑/etc/sysctl.conf &gt;vi /etc/sysctl.conf## 在最后面增加# 32Mvm.dirty_bytes=33554432 ps.保存后下次启动会生效，下面是立即生效的修改方法： 立即生效的修改方法 &gt;sysctl vm.dirty_bytes=33554432&gt;sysctl -p 验证修改是否成功 &gt;sysctl -a | grep vm.dirty_bytesvm.dirty_bytes = 33554432 修改后redis下次RDB和AOF时的日志 1486:M 09 Oct 10:05:02.043 * 10 changes in 300 seconds. Saving...1486:M 09 Oct 10:05:02.046 * Background saving started by pid 2098720987:C 09 Oct 10:05:17.188 * DB saved on disk20987:C 09 Oct 10:05:17.188 * RDB: 944 MB of memory used by copy-on-write1486:M 09 Oct 10:05:17.274 * Background saving terminated with success 从redis的日志中发现已经没有了这句：Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis. 应用日志中也看不到：Jedis connection failed, retrying...异常 这个问题解决","tags":[{"name":"调优","slug":"调优","permalink":"https://ningyu1.github.io/tags/调优/"},{"name":"Redis","slug":"Redis","permalink":"https://ningyu1.github.io/tags/Redis/"},{"name":"AOF Block","slug":"AOF-Block","permalink":"https://ningyu1.github.io/tags/AOF-Block/"},{"name":"AOF","slug":"AOF","permalink":"https://ningyu1.github.io/tags/AOF/"},{"name":"Asynchronous AOF fsync is taking too long (disk is busy?)Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis","slug":"Asynchronous-AOF-fsync-is-taking-too-long-disk-is-busy-Writing-the-AOF-buffer-without-waiting-for-fsync-to-complete-this-may-slow-down-Redis","permalink":"https://ningyu1.github.io/tags/Asynchronous-AOF-fsync-is-taking-too-long-disk-is-busy-Writing-the-AOF-buffer-without-waiting-for-fsync-to-complete-this-may-slow-down-Redis/"}]},{"title":"条形码处理类库 ZXing","date":"2017-09-30T08:56:36.000Z","path":"20170930/31-zxing.html","text":"ZXing 详细介绍ZXing是一个开源Java类库用于解析多种格式的1D/2D条形码。目标是能够对QR编码、Data Matrix、UPC的1D条形码进行解码。 其提供了多种平台下的客户端包括：J2ME、J2SE和Android。 示例代码import com.google.zxing.BarcodeFormat;import com.google.zxing.EncodeHintType;import com.google.zxing.MultiFormatWriter;import com.google.zxing.WriterException;import com.google.zxing.client.j2se.MatrixToImageWriter;import com.google.zxing.common.BitMatrix;import com.google.zxing.qrcode.decoder.ErrorCorrectionLevel;import java.io.File;import java.io.IOException;import java.io.OutputStream;import java.util.HashMap;import java.util.Map;/*** 二维码工具类*/public class QRCodeUtil &#123; private static final int width = 300;// 默认二维码宽度 private static final int height = 300;// 默认二维码高度 private static final String format = &quot;png&quot;;// 默认二维码文件格式 private static final Map&lt;EncodeHintType, Object&gt; hints = new HashMap();// 二维码参数 static &#123; hints.put(EncodeHintType.CHARACTER_SET, &quot;utf-8&quot;);// 字符编码 hints.put(EncodeHintType.ERROR_CORRECTION, ErrorCorrectionLevel.H);// 容错等级 L、M、Q、H 其中 L 为最低, H 为最高 hints.put(EncodeHintType.MARGIN, 2);// 二维码与图片边距 &#125; /** * 返回一个 BufferedImage 对象 * @param content 二维码内容 * @param width 宽 * @param height 高 */ public static BufferedImage toBufferedImage(String content, int width, int height) throws WriterException, IOException &#123; BitMatrix bitMatrix = new MultiFormatWriter().encode(content, BarcodeFormat.QR_CODE, width, height, hints); return MatrixToImageWriter.toBufferedImage(bitMatrix); &#125; /** * 将二维码图片输出到一个流中 * @param content 二维码内容 * @param stream 输出流 * @param width 宽 * @param height 高 */ public static void writeToStream(String content, OutputStream stream, int width, int height) throws WriterException, IOException &#123; BitMatrix bitMatrix = new MultiFormatWriter().encode(content, BarcodeFormat.QR_CODE, width, height, hints); MatrixToImageWriter.writeToStream(bitMatrix, format, stream); &#125; /** * 生成二维码图片文件 * @param content 二维码内容 * @param path 文件保存路径 * @param width 宽 * @param height 高 */ public static void createQRCode(String content, String path, int width, int height) throws WriterException, IOException &#123; BitMatrix bitMatrix = new MultiFormatWriter().encode(content, BarcodeFormat.QR_CODE, width, height, hints); //toPath() 方法由 jdk1.7 及以上提供 MatrixToImageWriter.writeToPath(bitMatrix, format, new File(path).toPath()); &#125;&#125;","tags":[{"name":"google","slug":"google","permalink":"https://ningyu1.github.io/tags/google/"},{"name":"zxing","slug":"zxing","permalink":"https://ningyu1.github.io/tags/zxing/"}]},{"title":"npm registry太慢？怎么办？使用nrm","date":"2017-09-29T06:16:36.000Z","path":"20170929/30-npm-nrm.html","text":"转载自：http://cnodejs.org/topic/5326e78c434e04172c006826 开发的npm registry 管理工具 nrm, 能够查看和切换当前使用的registry, 最近NPM经常 down 掉, 这个还是很有用的哈哈 Install$ npm install -g nrm Example$ nrm ls* npm ---- https://registry.npmjs.org/ cnpm --- http://r.cnpmjs.org/ eu ----- http://registry.npmjs.eu/ au ----- http://registry.npmjs.org.au/ sl ----- http://npm.strongloop.com/ nj ----- https://registry.nodejitsu.com/ $ nrm use cnpm //switch registry to cnpm Registry has been set to: http://r.cnpmjs.org/ cmdnrm help // show helpnrm list // show all registriesnrm use cnpm // switch to cnpmnrm home // go to a registry home page Registries npm cnpm strongloop european australia nodejitsu","tags":[{"name":"npm","slug":"npm","permalink":"https://ningyu1.github.io/tags/npm/"},{"name":"nrm","slug":"nrm","permalink":"https://ningyu1.github.io/tags/nrm/"}]},{"title":"分布式锁（Redis实现）使用说明","date":"2017-09-27T08:43:36.000Z","path":"20170927/29-distributed-lock.html","text":"概述[ GitHub release](https://img.shields.io/github/release/ningyu1/distributed-lock.svg?style=social&label=Release)](https://github.com/ningyu1/distributed-lock/releases)&nbsp;[![GitHub stars](https://img.shields.io/github/stars/ningyu1/distributed-lock.svg?style=social&label=Star)](https://github.com/ningyu1/distributed-lock/stargazers)&nbsp;[![GitHub forks](https://img.shields.io/github/forks/ningyu1/distributed-lock.svg?style=social&label=Fork)](https://github.com/ningyu1/distributed-lock/fork)&nbsp;[![GitHub watchers](https://img.shields.io/github/watchers/ningyu1/distributed-lock.svg?style=social&label=Watch) 项目地址distributed-lock [ License](https://img.shields.io/badge/license-GPLv3-blue.svg) 分布式锁，默认是redis实现，可扩展接口增加zk、等其他实现,这个分布式锁采用redis实现，根据CAP理论保证了可用性、分区容错性、和最终一致性。 实现的分布式锁特性 这把锁是非阻塞锁，可以根据超时时间和重试频率来定义重试次数 这把锁支持失效时间，极端情况下解锁失败，到达时间之后锁会自动删除 这把锁是非重入锁，一个线程获得锁之后，在释放锁之前，其他线程无法再次获得锁，只能根据获取锁超时时间和重试策略进行多次尝试获取锁。 因为这把锁是非阻塞的，所以性能很好，支持高并发 使用方无需手动获取锁和释放锁，锁的控制完全由框架控制操作，避免使用方由于没有释放锁或释放锁失败导致死锁的问题 实现的分布式锁缺点 通过超时时间来控制锁的失效时间其实并不完美，但是根据性能和CAP理论有做取舍 这把锁不支持阻塞，因为要达到高的性能阻塞的特性是要牺牲 使用步骤Maven中引入&lt;dependency&gt; &lt;groupId&gt;cn.tsoft.framework&lt;/groupId&gt; &lt;artifactId&gt;distributed-lock&lt;/artifactId&gt; &lt;version&gt;1.1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; spring中引入配置&lt;import resource=&quot;classpath:spring-lock.xml&quot; /&gt; 使用到了RedisClient具体可以查看《RedisCliet使用说明》 &lt;aop:aspectj-autoproxy /&gt;&lt;context:component-scan base-package=&quot;cn.tsoft.framework&quot; /&gt;&lt;context:property-placeholder location=&quot;classpath:redis.properties&quot;/&gt;&lt;import resource=&quot;classpath:spring-redis.xml&quot; /&gt; 代码中使用import cn.tsoft.framework.lock.Lock;import cn.tsoft.framework.lock.LockCallBack;import cn.tsoft.framework.lock.DefaultLockCallBack; @AutowiredLock lock;//方法一T t = lock.lock(&quot;Test_key_2&quot;,20,60,new LockCallBack&lt;T&gt;()&#123; public T handleObtainLock()&#123; dosomething(); &#125; public T handleNotObtainLock() throws LockCantObtainException&#123; return T;//throw new LockCantObtainException(); &#125; public T handleException(LockInsideExecutedException e) throws LockInsideExecutedException&#123; return T;//throw new e; &#125;&#125;);//方法二T t = lock.lock(&quot;Test_key_2&quot;,LockRetryFrequncy.VERY_QUICK,20,60,new DefaultLockCallBack&lt;T&gt;(T,T)&#123; public T handleObtainLock()&#123; dosomething(); &#125;&#125;); 锁重试策略说明/** * 锁重试获取频率策略 * * @author ningyu * */LockRetryFrequncy.VERY_QUICK; //非常快LockRetryFrequncy.QUICK; //快LockRetryFrequncy.NORMAL; //中LockRetryFrequncy.SLOW; //慢LockRetryFrequncy.VERYSLOW; //很慢//例如：//以获取锁的超时时间为：1秒来计算//VERY_QUICK的重试次数为：100次//QUICK的重试次数为：20次//NORMAL的重试次数为：10次//SLOW的重试次数为：2次//QUICK的重试次数为：1次//这个重试策略根据自身业务来选择合适的重试策略 Example第一种用法//锁名称：Test_key_2//获取锁超时时间：20秒//锁最大过期时间：60秒//内部执行回调，包含（1.获取到锁回调，2.没有获取到锁回调，3.获取到锁内部执行业务代码报错）//默认策略：NORMALlock.lock(&quot;Test_key_2&quot;,20,60,new LockCallBack&lt;String&gt;() &#123; @Override public String handleException(LockInsideExecutedException e) throws LockInsideExecutedException &#123; logger.error(&quot;获取到锁，内部执行报错&quot;); return &quot;Exception&quot;; &#125; @Override public String handleNotObtainLock() throws LockCantObtainException &#123; logger.error(&quot;没有获取到锁&quot;); return &quot;NotObtainLock&quot;; &#125; @Override public String handleObtainLock() &#123; logger.info(&quot;获取到锁&quot;); dosomething(); return &quot;ok&quot;; &#125;); 第二种用法//锁名称：Test_key_2//获取锁超时时间：20秒//锁最大过期时间：60秒//内部执行回调，使用默认回调实现，只需要实现获取到锁后需要执行的方法，当遇到没有获取锁和获取锁内部执行错误时会返回构造函数中设置的值（支持泛型）//默认策略：NORMALlock.lock(&quot;Test_key_2&quot;,20,60,new DefaultLockCallBack&lt;String&gt;(&quot;NotObtainLock&quot;, &quot;Exception&quot;) &#123; @Override public String handleObtainLock() &#123; logger.info(&quot;获取到锁&quot;); dosomething(); return &quot;ok&quot;; &#125;); 第三种用法//锁名称：Test_key_2//锁重试获取频率：VERY_QUICK 非常快//获取锁超时时间：20秒//锁最大过期时间：60秒//内部执行回调，包含（1.获取到锁回调，2.没有获取到锁回调，3.获取到锁内部执行业务代码报错）lock.lock(&quot;Test_key_2&quot;,LockRetryFrequncy.VERY_QUICK,20,60,new LockCallBack&lt;String&gt;() &#123; @Override public String handleException(LockInsideExecutedException e) throws LockInsideExecutedException &#123; logger.error(&quot;获取到锁，内部执行报错&quot;); return &quot;Exception&quot;; &#125; @Override public String handleNotObtainLock() throws LockCantObtainException &#123; logger.error(&quot;没有获取到锁&quot;); return &quot;NotObtainLock&quot;; &#125; @Override public String handleObtainLock() &#123; logger.info(&quot;获取到锁&quot;); dosomething(); return &quot;ok&quot;; &#125;); 第四种用法//锁名称：Test_key_2//锁重试获取频率：VERY_QUICK 非常快//获取锁超时时间：20秒//锁最大过期时间：60秒//内部执行回调，使用默认回调实现，只需要实现获取到锁后需要执行的方法，当遇到没有获取锁和获取锁内部执行错误时会返回构造函数中设置的值（支持泛型）lock.lock(&quot;Test_key_2&quot;,LockRetryFrequncy.VERY_QUICK,20,60,new DefaultLockCallBack&lt;String&gt;(&quot;NotObtainLock&quot;, &quot;Exception&quot;) &#123; @Override public String handleObtainLock() &#123; logger.info(&quot;获取到锁&quot;); dosomething(); return &quot;ok&quot;; &#125;); 注意事项 获取锁的超时时间和重试策略直接影响获取锁重试的次数，根据业务场景来定义适合的重试获取锁的频次，避免线程阻塞。 场景： 快速响应给客户端的场景，超时时间尽量短，超时时间 &lt; 锁后执行时间，例如：秒杀、抢购 可以容忍响应速度的场景，锁后执行时间*2 &gt; 超时时间 &gt;=锁后执行时间 根据业务场景来定义锁的最大过期时间，理论上业务执行越慢过期时间越大，因为是并发锁，为了杜绝因为获得锁而没有释放造成的问题 建议 锁后执行时间*1.5 &gt; 锁超时时间 &gt; 锁后执行时间，避免并发问题 获取锁后执行的代码块一定是小而快的，就像事务块使用原则一样，禁止重而长的逻辑包在里面造成其他线程获取锁失败率过高，如果逻辑很复杂需要分析那一块需要支持并发就把需要并发的代码包在里面。","tags":[{"name":"Redis","slug":"Redis","permalink":"https://ningyu1.github.io/tags/Redis/"},{"name":"Lock","slug":"Lock","permalink":"https://ningyu1.github.io/tags/Lock/"},{"name":"Distributed","slug":"Distributed","permalink":"https://ningyu1.github.io/tags/Distributed/"}]},{"title":"RedisClient升级支持Sentinel使用说明","date":"2017-09-25T05:29:36.000Z","path":"20170925/28-redis-client-sentinel.html","text":"项目地址redis-client &nbsp;&nbsp;&nbsp; RedisClient操作单点Redis使用文档：《RedisClient使用》以下是支持Sentinel（哨兵）+Redis集群的RedisClient（架构封装的Java访问Redis的客户端程序）高级使用方式 Redis集群方式：Master-Slave（1 - n 为一套集群可以多套）Sentinel集群方式：Sentinel（n台，n&gt;=3），投票人数：n-1（参与Master是否宕机以及下一任Master选举的投票人数） 1. Maven中引用（目前预览版）&lt;dependency&gt; &lt;groupId&gt;cn.tsoft.framework&lt;/groupId&gt; &lt;artifactId&gt;redis-client&lt;/artifactId&gt; &lt;version&gt;1.2.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 2. 配置说明原始（基础）配置： redis.pool.maxTotal=1000redis.pool.maxIdle=50redis.pool.minIdle=10redis.pool.testOnBorrow=trueredis.pool.testOnReturn=trueredis.ip=192.168.0.65redis.port=6379redis.timeout=2000redis.password=123456 sentinel新增配置 # sentinelredis.mastername=mymasterredis.sentinels=127.0.0.1:26379,127.0.0.1:26380,127.0.0.1:26381 redis.mastername指的是monitor master的名称redis.sentinels指的是哨兵的ip：port集合（ip和port需要替换） 删除配置 #redis.ip=192.168.0.65#redis.port=6379 ps.由于使用了sentinel自动发现redis服务因此不需要此配置，注释或删除即可 3. spring配置说明xml配置跟以前pool的配置方式有所不同，单节点redis的pool配置使用的是：redis.clients.jedis.JedisPoolConfig和redis.clients.jedis.JedisPoolsentinel的配置替换为：redis.clients.jedis.JedisPoolConfig和cn.tsoft.framework.redis.pool.JedisSentinelPoolFactory &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd&quot;&gt; &lt;aop:aspectj-autoproxy /&gt; &lt;context:component-scan base-package=&quot;cn.tsoft.framework.redis&quot; /&gt; &lt;bean id=&quot;redisClient&quot; class=&quot;cn.tsoft.framework.redis.client.impl.RedisClientImpl&quot;&gt; &lt;property name=&quot;jedisSentinelPoolFactory&quot; ref=&quot;jedisSentinelPoolFactory&quot; /&gt; &lt;/bean&gt; &lt;bean id=&quot;jedisPoolConfig&quot; class=&quot;redis.clients.jedis.JedisPoolConfig&quot;&gt; &lt;property name=&quot;maxTotal&quot; value=&quot;$&#123;redis.pool.maxTotal&#125;&quot; /&gt; &lt;property name=&quot;maxIdle&quot; value=&quot;$&#123;redis.pool.maxIdle&#125;&quot; /&gt; &lt;property name=&quot;minIdle&quot; value=&quot;$&#123;redis.pool.minIdle&#125;&quot; /&gt; &lt;property name=&quot;testOnBorrow&quot; value=&quot;$&#123;redis.pool.testOnBorrow&#125;&quot; /&gt; &lt;property name=&quot;testOnReturn&quot; value=&quot;$&#123;redis.pool.testOnReturn&#125;&quot; /&gt; &lt;/bean&gt; &lt;bean id=&quot;jedisSentinelPoolFactory&quot; class=&quot;cn.tsoft.framework.redis.pool.JedisSentinelPoolFactory&quot;&gt; &lt;property name=&quot;poolConfig&quot; ref=&quot;jedisPoolConfig&quot; /&gt; &lt;property name=&quot;masterName&quot; value=&quot;$&#123;redis.mastername&#125;&quot; /&gt; &lt;property name=&quot;sentinels&quot; value=&quot;$&#123;redis.sentinels&#125;&quot; /&gt; &lt;property name=&quot;timeout&quot; value=&quot;$&#123;redis.timeout&#125;&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;redis.password&#125;&quot; /&gt; &lt;/bean&gt;&lt;/beans&gt; ps.以上配置在redis-client-1.2.0-SNAPSHOT.jar包的spring-redis-sentinel.xml文件中 4. 项目中引用&lt;!-- redis.properties加载方式采用UCM的统一配置加载，具体可以查看global中的配置，如需要替换global的配置只需要在项目自定义配置中配置相同的key来进行属性覆盖 --&gt;&lt;context:component-scan base-package=&quot;cn.tsoft.framework.redis&quot; /&gt;&lt;import resource=&quot;classpath:spring-redis-sentinel.xml&quot; /&gt; ps.替换掉以前的：&lt;import resource=&quot;classpath:spring-redis.xml&quot; /&gt; 5. 注意事项5.1. pool使用只允许使用一种，要么使用jedis pool要么使用jedis sentinel pool，两者不允许共存，redisclient启动会检测pool的设置是否合法，不合法会throw出异常，可能遇见的异常如下： 异常 描述 解决办法 RedisClientException(“There can only be one pool! Will not work.”) 只能存在一个pool的设置 检查xml配置，确定使用的pool，只允许保留一个pool设置，直接引用redis-client.jar中的（spring-redis.xml、spring-redis-sentinel.xml）可以解决这个问题 RedisClientException(“No connection pool found! Will not work.”) 没有找到pool的设置 检查xml配置，是否有pool的设置，直接引用redis-client.jar中的（spring-redis.xml、spring-redis-sentinel.xml）可以解决这个问题 5.2. API使用起来跟以前没有任何变化，只是配置发生了变化","tags":[{"name":"Redis","slug":"Redis","permalink":"https://ningyu1.github.io/tags/Redis/"}]},{"title":"Webpack 打包优化之速度篇","date":"2017-09-20T03:57:36.000Z","path":"20170920/27-webpack2.html","text":"文章来源：https://jeffjade.com/2017/08/12/125-webpack-package-optimization-for-speed/作者：@晚晴幽草轩轩主 在前文 Webpack 打包优化之体积篇中，对如何减小 Webpack 打包体积，做了些探讨；当然，那些法子对于打包速度的提升，也是大有裨益。然而，打包速度之于开发体验和及时构建，相当重要；所以有必要对其做更为深入的研究，以便完善工作流，这就是本文存在的缘由。 Webpack Package optimization Webpack Package optimization 减小文件搜索范围在使用实际项目开发中，为了提升开发效率，很明显你会使用很多成熟第三方库；即便自己写的代码，模块间相互引用，为了方便也会使用相对路劲，或者别名(alias)；这中间如果能使得 Webpack 更快寻找到目标，将对打包速度产生很是积极的影响。于此，我们需要做的即：减小文件搜索范围，从而提升速度；实现这一点，可以有如下两法： 配置 resolve.modulesWebpack的resolve.modules配置模块库（即 node_modules）所在的位置，在 js 里出现 import &#39;vue&#39; 这样不是相对、也不是绝对路径的写法时，会去 node_modules 目录下找。但是默认的配置，会采用向上递归搜索的方式去寻找，但通常项目目录里只有一个 node_modules，且是在项目根目录，为了减少搜索范围，可以直接写明 node_modules 的全路径；同样，对于别名(alias)的配置，亦当如此： function resolve (dir) &#123; return path.join(__dirname, &apos;..&apos;, dir)&#125;module.exports = &#123; resolve: &#123; extensions: [&apos;.js&apos;, &apos;.vue&apos;, &apos;.json&apos;], modules: [ resolve(&apos;src&apos;), resolve(&apos;node_modules&apos;) ], alias: &#123; &apos;vue$&apos;: &apos;vue/dist/vue.common.js&apos;, &apos;src&apos;: resolve(&apos;src&apos;), &apos;assets&apos;: resolve(&apos;src/assets&apos;), &apos;components&apos;: resolve(&apos;src/components&apos;), // ... &apos;store&apos;: resolve(&apos;src/store&apos;) &#125; &#125;, ...&#125; 需要额外补充一点的是，这是 Webpack2. 以上的写法。在 1. 版本中，使用的是 resolve.root，如今已经被弃用为 resolve.modules；同时被弃用的还有resolve.fallback、resolve.modulesDirectories。 设置 test &amp; include &amp; excludeWebpack 的装载机(loaders)，允许每个子项都可以有以下属性： test：必须满足的条件（正则表达式，不要加引号，匹配要处理的文件）exclude：不能满足的条件（排除不处理的目录）include：导入的文件将由加载程序转换的路径或文件数组（把要处理的目录包括进来）loader：一串“！”分隔的装载机（2.0版本以上，”-loader”不可以省略）loaders：作为字符串的装载器阵列 对于include，更精确指定要处理的目录，这可以减少不必要的遍历，从而减少性能损失。同样，对于已经明确知道的，不需要处理的目录，则应该予以排除，从而进一步提升性能。假设你有一个第三方组件的引用，它肯定位于node_modules，通常它将有一个 src 和一个 dist 目录。如果配置 Webpack 来排除 node_modules，那么它将从 dist 已经编译的目录中获取文件。否则会再次编译它们。故而，合理的设置 include &amp; exclude，将会极大地提升 Webpack 打包优化速度，比如像这样： module: &#123; preLoaders: [ &#123; test: /\\.js$/, loader: &apos;eslint&apos;, include: [resolve(&apos;src&apos;)], exclude: /node_modules/ &#125;, &#123; test: /\\.svg$/, loader: &apos;svgo?&apos; + JSON.stringify(svgoConfig)， include: [resolve(&apos;src/assets/icons&apos;)], exclude: /node_modules/ &#125; ], loaders: [ &#123; test: /\\.vue$/, loader: &apos;vue-loader&apos;, include: [resolve(&apos;src&apos;)], exclude: /node_modules\\/(?!(autotrack|dom-utils))|vendor\\.dll\\.js/ &#125;, &#123; test: /\\.(png|jpe?g|gif|svg)(\\?.*)?$/, loader: &apos;url&apos;, exclude: /assets\\/icons/, query: &#123; limit: 10000, name: utils.assetsPath(&apos;img/[name].[hash:7].[ext]&apos;) &#125; &#125; ]&#125; 增强代码代码压缩工具Webpack 默认提供的 UglifyJS 插件，由于采用单线程压缩，速度颇慢 ；推荐采用 webpack-parallel-uglify-plugin 插件，她可以并行运行 UglifyJS 插件，更加充分而合理的使用 CPU 资源，这可以大大减少的构建时间；当然，该插件应用于生产环境而非开发环境，其做法如下， new webpack.optimize.UglifyJsPlugin(&#123; compress: &#123; warnings: false &#125;, sourceMap: true&#125;) 替换如上自带的 UglifyJsPlugin 写法为如下配置即可： var ParallelUglifyPlugin = require(&apos;webpack-parallel-uglify-plugin&apos;);new ParallelUglifyPlugin(&#123; cacheDir: &apos;.cache/&apos;, uglifyJS:&#123; output: &#123; comments: false &#125;, compress: &#123; warnings: false &#125; &#125;&#125;) 当然也有其他同类型的插件，比如：webpack-uglify-parallel，但根据自己实践效果来看，并没有 webpack-parallel-uglify-plugin 表现的那么卓越，有兴趣的朋友，可以更全面的做下对比，择优选用。需要额外说明的是，webpack-parallel-uglify-plugin 插件的运用，会相对 UglifyJsPlugin 打出的包，看起来略大那么一丢丢(其实可以忽略不计)；如果在你使用时也是如此，那么在打包速度跟包体积之间，你应该有自己的抉择。 用 Happypack 来加速代码构建你知道，Webpack 中为了方便各种资源和类型的加载，设计了以 loader 加载器的形式读取资源，但是受限于 nodejs 的编程模型影响，所有的 loader 虽然以 async 的形式来并发调用，但是还是运行在单个 node 的进程，以及在同一个事件循环中，这就直接导致了些问题：当同时读取多个loader文件资源时，比如babel-loader需要 transform 各种jsx，es6的资源文件。在这种同步计算同时需要大量耗费 cpu 运算的过程中，node的单进程模型就无优势了，而 Happypack 就是针对解决此类问题而生的存在。 Webpack-Happypack Webpack-Happypack Happypack 的处理思路是：将原有的 webpack 对 loader 的执行过程，从单一进程的形式扩展多进程模式，从而加速代码构建；原本的流程保持不变，这样可以在不修改原有配置的基础上，来完成对编译过程的优化，具体配置如下： var HappyPack = require(&apos;happypack&apos;);var happyThreadPool = HappyPack.ThreadPool(&#123; size: os.cpus().length &#125;);module: &#123; loaders: [ &#123; test: /\\.js[x]?$/, include: [resolve(&apos;src&apos;)], exclude: /node_modules/, loader: &apos;happypack/loader?id=happybabel&apos; &#125; ]&#125;,plugins: [ new HappyPack(&#123; id: &apos;happybabel&apos;, loaders: [&apos;babel-loader&apos;], threadPool: happyThreadPool, cache: true, verbose: true &#125;)] 可以研究看到，通过在 loader 中配置直接指向 happypack 提供的 loader，对于文件实际匹配的处理 loader，则是通过配置在 plugin 属性来传递说明，这里 happypack 提供的 loader 与 plugin 的衔接匹配，则是通过id=happybabel来完成。配置完成后，laoder的工作模式就转变成了如下所示： Webpack-Happypack Webpack-Happypack Happypack 在编译过程中，除了利用多进程的模式加速编译，还同时开启了 cache 计算，能充分利用缓存读取构建文件，对构建的速度提升也是非常明显的；更多关于 happyoack 个中原理，可参见 @淘宝前端团队(FED) 的这篇：happypack 原理解析。如果你使用的 Vue.js 框架来开发，也可参考 vue-webpack-happypack 相关配置。 设置 babel 的 cacheDirectory 为truebabel-loader is slow! 所以不仅要使用exclude、include，尽可能准确的指定要转化内容的范畴，而且要充分利用缓存，进一步提升性能。babel-loader 提供了 cacheDirectory特定选项（默认 false）：设置时，给定的目录将用于缓存加载器的结果。未来的 Webpack 构建将尝试从缓存中读取，以避免在每次运行时运行潜在昂贵的 Babel 重新编译过程。如果值为空（loader: ‘babel-loader?cacheDirectory’）或true（loader: babel-loader?cacheDirectory=true），node_modules/.cache/babel-loader 则 node_modules 在任何根目录中找不到任何文件夹时，加载程序将使用默认缓存目录或回退到默认的OS临时文件目录。实际使用中，效果显著；配置示例如下： rules: [ &#123; test: /\\.js$/, loader: &apos;babel-loader?cacheDirectory=true&apos;, exclude: /node_modules/, include: [resolve(&apos;src&apos;), resolve(&apos;test&apos;)] &#125;, ... ...] 设置 noParse如果你确定一个模块中，没有其它新的依赖，就可以配置这项， Webpack 将不再扫描这个文件中的依赖，这对于比较大型类库，将能促进性能表现，具体可以参见以下配置： module: &#123; noParse: /node_modules\\/(element-ui\\.js)/, rules: [ &#123; ... &#125;&#125; 拷贝静态文件在前文 Webpack 打包优化之体积篇中提到，引入 DllPlugin 和 DllReferencePlugin 来提前构建一些第三方库，来优化 Webpack 打包。而在生产环境时，就需要将提前构建好的包，同步到 dist 中；这里拷贝静态文件，你可以使用 copy-webpack-plugin 插件：把指定文件夹下的文件复制到指定的目录；其配置如下： var CopyWebpackPlugin = require(&apos;copy-webpack-plugin&apos;)plugins: [ ... // copy custom static assets new CopyWebpackPlugin([ &#123; from: path.resolve(__dirname, &apos;../static&apos;), to: config.build.assetsSubDirectory, ignore: [&apos;.*&apos;] &#125; ])] 当然，这种工作，实现的法子很多，比如可以借助 shelljs，可以参见这里的实现 vue-boilerplate-template。","tags":[{"name":"Webpack","slug":"Webpack","permalink":"https://ningyu1.github.io/tags/Webpack/"},{"name":"Vue","slug":"Vue","permalink":"https://ningyu1.github.io/tags/Vue/"},{"name":"React","slug":"React","permalink":"https://ningyu1.github.io/tags/React/"},{"name":"Angular","slug":"Angular","permalink":"https://ningyu1.github.io/tags/Angular/"}]},{"title":"Webpack 打包优化之体积篇","date":"2017-09-20T02:36:36.000Z","path":"20170920/26-webpack1.html","text":"文章来源：https://jeffjade.com/2017/08/06/124-webpack-packge-optimization-for-volume/作者：@晚晴幽草轩轩主 谈及如今欣欣向荣的前端圈，不仅有各类框架百花齐放，如Vue， React， Angular等等，就打包工具而言，发展也是如火如荼，百家争鸣；从早期的王者Browserify, Grunt，到后来赢得宝座的 Gulp， 以及独树一帜的 fis3, 以及下一代打包神器 Rollup ；在 browserify,grunt,gulp,rollup,webpack 可以一窥其中部分对比。在本文要探究的是，当前打包工具绝对霸者 Webpack。 Webpack Package optimization Webpack Package optimization Webpack，当前各大主流框架默认配备的打包方案，对其如何使用，已有较完备中英文文档；并且，各主流框架也有对应 CLI 予以基础配置，故不作为探讨范畴。从产品层来讲，如何使得构建的包体积小、运行快，这有必要不断摸索实践，提炼升级，使之臻于最佳。本文将从以下些许方面，对 Webpack 打包体积方面，做下优化探讨(备注： Webpack实践版本： 3.3.0)： 定位 webpack 大的原因这里推荐使用 webpack-bundle-analyzer —— Webpack 插件和 CLI 实用程序，她可以将内容束展示为方便交互的直观树状图，让你明白你所构建包中真正引入的内容；我们可以借助她，发现它大体有哪些模块组成，找到不合时宜的存在，然后优化它。我们可以在 项目的 package.json 文件中注入如下命令，以方便运行她(npm run analyz)，默认会打开 http://127.0.0.1:8888 作为展示。 “analyz”: “NODE_ENV=production npm_config_report=true npm run build” webpack-bundle-analyzer webpack-bundle-analyzer 当然，同类型的还有 webpack-chart 以及 webpack-analyse，这两个站点也是以可视方式呈现构造的组件，可以让你清楚的看到模块的组成部分；不过稍显麻烦的是，你需要运行以下命令，生成工具分析所需要的 json 文件： webpack --profile --json &gt; stats.json// 如果，运行指定的 weboack 文件，可用此命令webpack --config build/webpack.prod.conf.js --profile --json &gt; stats.json 引入 DllPlugin 和 DllReferencePluginDllPlugin 和 DllReferencePlugin 提供了以大幅度提高构建时间性能的方式拆分软件包的方法。其中原理是，将特定的第三方NPM包模块提前构建👌，然后通过页面引入。这不仅能够使得 vendor 文件可以大幅度减小，同时，也极大的提高了构件速度。鉴于篇幅，具体用法可参见：webpack.dll.conf.js。 外部引入模块(CDN)如今前端开发，自然是使用ES6甚至更高版本，撸将起来才更嗨。但由于浏览器兼容问题，仍得使用 babel 转换。而这 babel-polyfill 也得引入以确保兼容；还比如项目开发中常用到的 moment, lodash等，都是挺大的存在，如果必须引入的话，即考虑外部引入之，再借助 externals 予以指定， webpack可以处理使之不参与打包，而依旧可以在代码中通过CMD、AMD或者window/global全局的方式访问。 // webpack 中予以指定externals: &#123; // &apos;vue&apos;: &apos;Vue&apos;, // &apos;lodash&apos;: &apos;_&apos;, &apos;babel-polyfill&apos;: &apos;window&apos;&#125;//&lt;script src=&quot;//cdn.bootcss.com/autotrack/2.4.1/autotrack.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;//cdn.bootcss.com/babel-polyfill/7.0.0-alpha.15/polyfill.min.js&quot;&gt;&lt;/script&gt; 需要补充的是 externals 中：key 是 require 的包名，value 是全局的变量。 让每个第三包“引有所值”确定引入的必要性前端发展到如今时期，倘若项目采用了 MVVM模式框架，数据双向绑定，那么像 jQuery 这般类库，不能说没有丝毫引入的必要，至少可以说确实没有引入的必要。对此，如果还有些顾虑，完全可以参考下 YOU MIGHT NOT NEED JQUERY；用原生写几行代码就可以解决的事儿，实在不易引入这么个庞然大物，平添烦恼。 避免类库引而不用倘若这类情况发生，对整个打包体积，不仅大而且亏。项目一旦大了，很难人为保证每个引入的类库，都被有用到，尤其是二次开发。所以工具的利用十分必要，强烈推荐类如 Eslint 这般工具，并且注入对应规则，对声明却未使用的代码，给予强制提醒；这不仅可以有效的规避类似情形发生(也适用于普通变量的检测)，而且还能使得团队代码风格，尽可能地保持相似；要知道代码足够遵守规则，也可让压缩工具更有效压缩代码，一举多得，何乐不为？ 尽量使用模块化引入如果说 jQuery 确实没有引入必要，很多人会同意；但对于 lodash 这类依赖的工具，并不是所有人都会去造一发轮子的。然而全包引入 400kb 的体量，可否有让你心肝一颤？幸好的是，lodash 提供了模块化的引入方式；可按需引入，快哉快哉： import &#123; debounce &#125; from &apos;lodash&apos;import &#123; throttle &#125; from &apos;lodash&apos;// 改成如下写法import debounce from &apos;lodash/debounce&apos;import throttle from &apos;lodash/throttle&apos; 擅懒如你的优秀程序员，是否也发现这样写颇为麻烦？那么恭喜你，这个问题已经被解决；lodash-webpack-plugin 和 babel-plugin-lodash 的存在（组合使用），即是解决这问题的。它可将全路径引用的 lodash， 自动转变为模块化按使用引入（如下例示）；并且所需配置也十分简单，就不在此赘述(温馨提示：当涉及些特殊方法时，尚需些留意)。 // 引入组件，自动转换import _ from &apos;lodash&apos;_.debounce()_.throttle() 额外补充的是，即便采用如上写法，还是不够快捷，每个用到的文件，都写一遍 import，实在多有不便。更可取的是，将项目所需的方法，统一引入，按需添加，组建出本地 lodash 类库，然后 export 给框架层（比如 Vue.prototype），以便全局使用；详情可参见：vue-modular-import-lodash。 // helper 文件夹下 lodash，统一引入你需要的方法import _ from &apos;lodash&apos;export default &#123; cloneDeep: _.cloneDeep, debounce: _.debounce, throttle: _.throttle, size: _.size, pick: _.pick, isEmpty: _.isEmpty&#125;// 注入到全局import _ from &apos;@helper/lodash.js&apos;Vue.prototype.$_ = _// vue 组件内运用this.$_.debounce() 尽可能引入更合适的包作为前端开发的你，想必知道有 momentjs 的存在（Parse, validate, manipulate, and display dates in javascript.）；更多的是，你想必知道它很好用，然而它的体态却十分丰满(丰盈)，没念及此，是否有重新造轮子的冲动？SpaceTime: A lightweight way to manipulate, traverse, compare, and format dates and times across planet Earth。 具有与 monent 相似 api 的新类库，其体积又相对小很多（当然，据观察其灵活度略逊一筹）；date-fns：现代JavaScript日期实用程序库（ Modern JavaScript date utility library ），如 lodash 一样，可支持模块化；知道这些或者更多的你，会如何选择？ 按需异步加载模块关于前端开发优化，重要的一条是，尽可能合并请求及资源，如常用的请求数据合并，压缩合并 js，构造雪碧图诸此等等（当然得适当，注意体积，过大不宜）；但，同时也当因需制宜，根据需要去异步加载，避免无端就引入早成的浪费。webpack 也是内置对这方面的支持； 假如，你使用的是 Vue，将一个组件（以及其所有依赖）改为异步加载，所需要的只是把： import Foo from &apos;./Foo.vue&apos; 改为如下写法: const Foo = () =&gt; import(&apos;./Foo.vue&apos;) 如此分割之时，该组件所依赖的其他组件或其他模块，都会自动被分割进对应的 chunk 里，实现异步加载，当然也支持把组件按组分块，将同组中组件，打包在同个异步 chunk 中。如此能够非常有效的抑制 Javascript 包过大，同时也使得资源的利用更加合理化。 生产环境，压缩混淆并移除console现代化中等规模以上的开发中，区分开发环境、测试环境和生产环境，并根据需要予以区别对待，已然成为行业共识；可能的话，还会有预发布环境。对待生产环境，压缩混淆可以很有效的减小包的体积；同时，如果能够移除使用比较频繁的 console，而不是简单的替换为空方法，也是精彩的一笔小优化。如果使用 UglifyJsPlugin 插件来压缩代码，加入如下配置，即可移除掉代码中的 console： new webpack.optimize.UglifyJsPlugin(&#123; compress: &#123; warnings: false, drop_console: true, pure_funcs: [&apos;console.log&apos;] &#125;, sourceMap: false&#125;) Webpack3 新功能: Scope Hoisting截止目前(17-08-06), Webpack 最新版本是 3.4.1；Webpack在 3.0 版本，提供了一个新的功能：Scope Hoisting，又译作“作用域提升”。只需在配置文件中添加一个新的插件，就可以让 Webpack 打包出来的代码文件更小、运行的更快： module.exports = &#123; plugins: [ new webpack.optimize.ModuleConcatenationPlugin() ]&#125; 据悉这个 Scope Hoisting 与 Tree Shaking，最初都是由 Rollup 实现的。在个人中实践中，这个功能的注入，对打包体积虽有影响，却不甚明显，有兴趣的盆友可以试下；更对关于此功能讯息，可参见 Webpack 3 的新功能：Scope Hoisting。 下一篇 《Webpack 打包优化之速度篇》","tags":[{"name":"Webpack","slug":"Webpack","permalink":"https://ningyu1.github.io/tags/Webpack/"},{"name":"Vue","slug":"Vue","permalink":"https://ningyu1.github.io/tags/Vue/"},{"name":"React","slug":"React","permalink":"https://ningyu1.github.io/tags/React/"},{"name":"Angular","slug":"Angular","permalink":"https://ningyu1.github.io/tags/Angular/"}]},{"title":"五种开源协议(GPL,LGPL,BSD,MIT,Apache)","date":"2017-09-19T05:36:36.000Z","path":"20170919/25-licence.html","text":"什么是许可协议？什么是许可，当你为你的产品签发许可，你是在出让自己的权利，不过，你仍然拥有版权和专利（如果申请了的话），许可的目的是，向使用你产品的人提供 一定的权限。 不管产品是免费向公众分发，还是出售，制定一份许可协议非常有用，否则，对于前者，你相当于放弃了自己所有的权利，任何人都没有义务表明你的原始作 者身份，对于后者，你将不得不花费比开发更多的精力用来逐个处理用户的授权问题。 而开源许可协议使这些事情变得简单，开发者很容易向一个项目贡献自己的代码，它还可以保护你原始作者的身份，使你 至少获得认可，开源许可协议还可以阻止其它人将某个产品据为己有。以下是开源界的 5 大许可协议。 GNU GPLGNU General Public Licence (GPL) 有可能是开源界最常用的许可模式。GPL 保证了所有开发者的权利，同时为使用者提供了足够的复制，分发，修改的权利： 可自由复制你可以将软件复制到你的电脑，你客户的电脑，或者任何地方。复制份数没有任何限制。 可自由分发在你的网站提供下载，拷贝到U盘送人，或者将源代码打印出来从窗户扔出去（环保起见，请别这样做）。 可以用来盈利你可以在分发软件的时候收费，但你必须在收费前向你的客户提供该软件的 GNU GPL 许可协议，以便让他们知道，他们可以从别的渠道免费得到这份软件，以及你收费的理由。 可自由修改如果你想添加或删除某个功能，没问题，如果你想在别的项目中使用部分代码，也没问题，唯一的要求是，使用了这段代码的项目也必须使用 GPL 协议。 需要注意的是，分发的时候，需要明确提供源代码和二进制文件，另外，用于某些程序的某些协议有一些问题和限制，你可以看一下 @PierreJoye 写的 Practical Guide to GPL Compliance 一文。使用 GPL 协议，你必须在源代码代码中包含相应信息，以及协议本身。 GNU LGPLGNU 还有另外一种协议，叫做 LGPL （Lesser General Public Licence），它对产品所保留的权利比 GPL 少，总的来说，LGPL 适合那些用于非 GPL 或非开源产品的开源类库或框架。因为 GPL 要求，使用了 GPL 代码的产品必须也使用 GPL 协议，开发者不允许将 GPL 代码用于商业产品。LGPL 绕过了这一限制。 BSDBSD 在软件分发方面的限制比别的开源协议（如 GNU GPL）要少。该协议有多种版本，最主要的版本有两个，新 BSD 协议与简单 BSD 协议，这两种协议经过修正，都和 GPL 兼容，并为开源组织所认可。 新 BSD 协议（3条款协议）在软件分发方面，除需要包含一份版权提示和免责声明之外，没有任何限制。另外，该协议还禁止拿开发者的名义为衍生产品背书，但简单 BSD 协议删除了这一条款。 MITMIT 协议可能是几大开源协议中最宽松的一个，核心条款是： 该软件及其相关文档对所有人免费，可以任意处置，包括使用，复制，修改，合并，发表，分发，再授权，或者销售。唯一的限制是，软件中必须包含上述版 权和许可提示。 这意味着： 你可以自由使用，复制，修改，可以用于自己的项目。 可以免费分发或用来盈利。 唯一的限制是必须包含许可声明。 MIT 协议是所有开源许可中最宽松的一个，除了必须包含许可声明外，再无任何限制。 ApacheApache 协议 2.0 和别的开源协议相比，除了为用户提供版权许可之外，还有专利许可，对于那些涉及专利内容的开发者而言，该协议最适合（这里有 一篇文章阐述这个问题）。 Apache 协议还有以下需要说明的地方: 永久权利一旦被授权，永久拥有。 全球范围的权利在一个国家获得授权，适用于所有国家。假如你在美国，许可是从印度授权的，也没有问题。 授权免费，且无版税前期，后期均无任何费用。 授权无排他性任何人都可以获得授权 授权不可撤消一旦获得授权，没有任何人可以取消。比如，你基于该产品代码开发了衍生产品，你不用担心会在某一天被禁止使用该代码。 分发代码方面包含一些要求，主要是，要在声明中对参与开发的人给予认可并包含一份许可协议原文。 Creative CommonsCreative Commons (CC) 并非严格意义上的开源许可，它主要用于设计。Creative Commons 有多种协议，每种都提供了相应授权模式，CC 协议主要包含 4 种基本形式： 署名权必须为原始作者署名，然后才可以修改，分发，复制。 保持一致作品同样可以在 CC 协议基础上修改，分发，复制。 非商业作品可以被修改，分发，复制，但不能用于商业用途。但商业的定义有些模糊，比如，有的人认为非商业用途指的是不能销售，有的认为是甚至不能放在有广告的网 站，也有人认为非商业的意思是非盈利。 不能衍生新作品你可以复制，分发，但不能修改，也不能以此为基础创作自己的作品。 这些许可形式可以结合起来用，其中最严厉的组合是“署名，非商用，不能衍生新作品”，意味着，你可以分享作品，但不能改动或以此盈利，而且必须为原 作者署名。在这种许可模式下，原始作者对作品还拥有完全的控制权，而最宽松的组合是“署名”，意味着，只要为原始作者署名了，就可以自由处置。 ## 因为在此之前，我用了国内的一些开源程序，但是呢这些程序都是需要商业授权的，不知道能不能免费的自己搭建起来给企业用。比如说 shopex，康盛的产品， PHPCMS等等。。。。如果真用了，他们会找上门来问你要版权么？","tags":[{"name":"Licence","slug":"Licence","permalink":"https://ningyu1.github.io/tags/Licence/"},{"name":"GPL","slug":"GPL","permalink":"https://ningyu1.github.io/tags/GPL/"},{"name":"LGPL","slug":"LGPL","permalink":"https://ningyu1.github.io/tags/LGPL/"},{"name":"BSD","slug":"BSD","permalink":"https://ningyu1.github.io/tags/BSD/"},{"name":"MIT","slug":"MIT","permalink":"https://ningyu1.github.io/tags/MIT/"},{"name":"Apache","slug":"Apache","permalink":"https://ningyu1.github.io/tags/Apache/"}]},{"title":"利用Zipkin对Spring Cloud应用进行服务追踪分析","date":"2017-09-08T05:36:36.000Z","path":"20170908/24-zipkin.html","text":"文章转自：https://yq.aliyun.com/articles/60165作者：@libinjingshan 摘要： 本文简单介绍了如何利用Zipkin对SpringCloud应用进行服务分析。在实际的应用场景中，Zipkin可以结合压力测试工具一起使用，分析系统在大压力下的可用性和性能。设想这么一种情况，如果你的微服务数量逐渐增大，服务间的依赖关系越来越复杂，怎么分析它们之间的调用关系及相互的影响？ 服务追踪分析一个由微服务构成的应用系统通过服务来划分问题域，通过REST请求服务API来连接服务来完成完整业务。对于入口的一个调用可能需要有多个后台服务协同完成，链路上任何一个调用超时或出错都可能造成前端请求的失败。服务的调用链也会越来越长，并形成一个树形的调用链。 1.png 随着服务的增多，对调用链的分析也会越来越负责。设想你在负责下面这个系统，其中每个小点都是一个微服务，他们之间的调用关系形成了复杂的网络。 2.png 有密集恐惧症的同学就忽略吧。 针对服务化应用全链路追踪的问题，Google发表了Dapper论文，介绍了他们如何进行服务追踪分析。其基本思路是在服务调用的请求和响应中加入ID，标明上下游请求的关系。利用这些信息，可以可视化地分析服务调用链路和服务间的依赖关系。 Spring Cloud Sleuth和Zipkin对应Dpper的开源实现是Zipkin，支持多种语言包括JavaScript，Python，Java, Scala, Ruby, C#, Go等。其中Java由多种不同的库来支持。 在这个示例中，我们准备开发两个基于Spring Cloud的应用，利用Spring Cloud Sleuth来和Zipkin进行集成。Spring Cloud Sleuth是对Zipkin的一个封装，对于Span、Trace等信息的生成、接入HTTP Request，以及向Zipkin Server发送采集信息等全部自动完成。 这是Spring Cloud Sleuth的概念图。 3.png 服务REST调用本次演示的服务有两个：tracedemo做为前端服务接收用户的请求，tracebackend为后端服务，tracedemo通过http协议调用后端服务。 利用RestTemplate进行HTTP请求调用tracedemo应用通过restTemplate调用后端tracedemo服务，注意，URL中指明tracedemo的地址为backend。 @RequestMapping(\"/\")public String callHome()&#123; LOG.log(Level.INFO, \"calling trace demo backend\"); return restTemplate.getForObject(\"http://backend:8090\", String.class);&#125; 后端服务响应HTTP请求，输出一行日志后返回经典的“hello world”。 @RequestMapping(\"/\")public String home()&#123; LOG.log(Level.INFO, \"trace demo backend is being called\"); return \"Hello World.\";&#125; 引入Sleuth和Zipkin依赖包可以看到，这是典型的两个spring应用通过RestTemplate进行访问的方式，哪在HTTP请求中注入追踪信息并把相关信息发送到Zipkin Server呢？答案在两个应用所加载的JAR包里。 本示例采用gradle来构建应用，在build.gradle中加载了sleuth和zipkin相关的JAR包： dependencies &#123; compile('org.springframework.cloud:spring-cloud-starter-sleuth') compile('org.springframework.cloud:spring-cloud-sleuth-zipkin') testCompile('org.springframework.boot:spring-boot-starter-test')&#125; Spring应用在监测到Java依赖包中有sleuth和zipkin后，会自动在RestTemplate的调用过程中向HTTP请求注入追踪信息，并向Zipkin Server发送这些信息。 哪么Zipkin Server的地址又是在哪里指定的呢？答案是在application.properties中： spring.zipkin.base-url=http://zipkin-server:9411 注意Zipkin Server的地址为zipkin-server。 构建Docker镜像为这两个服务创建相同的Dockerfile，用于生成Docker镜像： FROM java:8-jre-alpineRUN sed -i &apos;s/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/&apos; /etc/apk/repositoriesVOLUME /tmpADD build/libs/*.jar app.jarRUN sh -c &apos;touch /app.jar&apos;ENTRYPOINT [&quot;java&quot;,&quot;-Djava.security.egd=file:/dev/./urandom&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;] 构建容器镜像的步骤如下： cd tracedemo./gradlew builddocker build -t zipkin-demo-frontend .cd ../tracebackend./gradlew builddocker build -t zipkin-demo-backend . 构建镜像完成后用docker push命令上传到你的镜像仓库。 Zipkin Server利用Annotation声明方式创建Zipkin在build.gradle中引入Zipkin依赖包。 dependencies &#123; compile(&apos;org.springframework.boot:spring-boot-starter&apos;) compile(&apos;io.zipkin.java:zipkin-server&apos;) runtime(&apos;io.zipkin.java:zipkin-autoconfigure-ui&apos;) testCompile(&apos;org.springframework.boot:spring-boot-starter-test&apos;)&#125; 在主程序Class增加一个注解@EnableZipkinServer @SpringBootApplication@EnableZipkinServerpublic class ZipkinApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZipkinApplication.class, args); &#125;&#125; 在application.properties将端口指定为9411。 server.port=9411 构建Docker镜像Dockerfile和前面的两个服务一样，这里就不重复了。 在阿里云容器服务上部署创建docker-compose.yml文件，内容如下： version: &quot;2&quot;services: zipkin-server: image: registry.cn-hangzhou.aliyuncs.com/jingshanlb/zipkin-demo-server labels: aliyun.routing.port_9411: http://zipkin restart: always frontend: image: registry.cn-hangzhou.aliyuncs.com/jingshanlb/zipkin-demo-frontend labels: aliyun.routing.port_8080: http://frontend links: - zipkin-server - backend restart: always backend: image: registry.cn-hangzhou.aliyuncs.com/jingshanlb/zipkin-demo-backend links: - zipkin-server restart: always 在阿里云容器服务上使用编排模版创建应用，访问zipkin端点，可以看到服务分析的效果。 访问前端应用3次，页面显示3次服务调用。 4.png 点击其中任意一个trace，可以看到请求链路上不同span所花费的时间。 5.png 进入Dependencies页面，还可以看到服务之间的依赖关系。 6.png 从这个过程可以看出，Zipkin和Spring Cloud的集成做得很好。而且对服务追踪分析的可视化也很直观。 注意的是，在生产环境中还需要为Zipkin配置数据库，这里就不详细介绍了。 本文的示例代码在此：https://github.com/binblee/zipkin-demo 小节本文简单介绍了如何利用Zipkin对SpringCloud应用进行服务分析。在实际的应用场景中，Zipkin可以结合压力测试工具一起使用，分析系统在大压力下的可用性和性能。这部分内容未来会在DevOps系列中继续介绍。","tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://ningyu1.github.io/tags/Spring-Cloud/"},{"name":"Zipkin","slug":"Zipkin","permalink":"https://ningyu1.github.io/tags/Zipkin/"}]},{"title":"Spring Cloud学习-Eureka、Ribbon和Feign","date":"2017-09-08T01:09:36.000Z","path":"20170908/23-spring-cloud.html","text":"前沿这篇文章比较适合入门，对于spring cloud生态的成员有一个大致的了解，其实spring cloud生态将netflix的产品进行了很好的整合，netflix早几年就在服务治理这块有很深入的研究，出品了很多服务治理的工具hystrix就是很有名的一个，具体可以查看：https://github.com/netflix，刚好在微服务盛行的年代服务治理是必不可少的一环，现在在微服务开发套件这块常用也就是下面这两种选择： spring cloud套件，成熟上手快 自建微服务架构 UCM，统一配置管理（百度的disconf、阿里的diamond、点评的lion，等很多开源的）。 RPC，阿里的Dubbo、点评的Pigeon，当当改的DubboX，grpc，等等很多开源的，还有很多公司自研的。 服务治理，netflix的hystrix老牌的功能强大的服务治理工具，有熔断、降级等功能，很多公司会结合监控套件开发自己的服务治理工具。 开发框架（rpc、restful这个一般公司都有自研的开发框架） 注册中心（zookeeper、redis、Consul、SmartStack、Eureka，其中一些已经是spring cloud生态的一员了）。 网关，restful的使用nginx+lua，这也是openAPI网关常用的手段 负载均衡，这个结合选用的rpc框架来选择。一般rpc框架都有负载均衡的功能。 服务治理熔断，使用hystrix（也已经是spring cloud生态的一员了） 监控，使用pinpoint、点评的cat、等其他开源的APM工具 DevOPS，持续交付一般也是自己构架的，采用jenkins打包docker镜像，使用docker生态的工具构建容器化发布平台。 下面文章转自：https://www.jianshu.com/p/0aef3724e6bc作者：@杜琪 Talk is cheap，show me the code ， 书上得来终觉浅，绝知此事要躬行。在自己真正实现的过程中，会遇到很多莫名其妙的问题，而正是在解决这些问题的过程中，你会发现自己之前思维的盲点。引子看完《微服务设计》后，算是补上了自己在服务化这块的理论知识，在业界，一般有两种微服务的实践方法：基于dubbo的微服务架构、基于Spring Cloud的微服务架构。从概念上来讲，Dubbo和Spring Cloud并不能放在一起对比，因为Dubbo仅仅是一个RPC框架，实现Java程序的远程调用，实施服务化的中间件则需要自己开发；而Spring Cloud则是实施微服务的一系列套件，包括：服务注册与发现、断路器、服务状态监控、配置管理、智能路由、一次性令牌、全局锁、分布式会话管理、集群状态管理等。 在有赞，我们基于Dubbo实施服务化，刚开始是基于ZooKeeper进行服务注册与发现，现在已经转成使用Etcd。我这次学习Spring Cloud，则是想成体系得学习下微服务架构的实现，也许能够对基于Dubbo实施微服务架构有所借鉴。 Spring Cloud下有很多工程： Spring Cloud Config：依靠git仓库实现的中心化配置管理。配置资源可以映射到Spring的不同开发环境中，但是也可以使用在非Spring应用中。 Spring Cloud Netflix：不同的Netflix OSS组件的集合：Eureka、Hystrix、Zuul、Archaius等。 Spring Cloud Bus：事件总线，利用分布式消息将多个服务连接起来。非常适合在集群中传播状态的改变事件（例如：配置变更事件） Spring Cloud Consul：服务发现和配置管理，由Hashicorp团队开发。 我决定先从Spring Cloud Netflix看起，它提供了如下的功能特性： 服务发现：Eureka-server实例作为服务提供者，可以注册到服务注册中心，Eureka客户端可以通过Spring管理的bean发现实例； 服务发现：嵌套式的Eureka服务可以通过声明式的Java配置文件创建； 断路器：利用注解，可以创建一个简单的Hystrix客户端； 断路器：通过Java配置文件可以创建内嵌的Hystrix控制面板； 声明式REST客户端：使用Feign可以创建声明式、模板化的HTTP客户端； 客户端负载均衡器：Ribbon 路由器和过滤器：Zuul可以在微服务架构中提供路由功能、身份验证、服务迁移、金丝雀发布等功能。 本文计划利用Eureka实现一个简答的服务注册于发现的例子，需要创建三个角色：服务注册中心、服务提供者、服务消费者。 实践1. 服务注册中心在IDEA中创建一个Spring Cloud工程，引入Eureka-Server包，pom文件整体如下： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.example.springcloud&lt;/groupId&gt; &lt;artifactId&gt;service-register&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!-- spring boot的parent 配置文件，有大部分spring boot需要用的Jar包 --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.1.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;!-- spring boot的maven打包插件 --&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;dependencies&gt; &lt;!-- eureka-server --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- spring boot test--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Camden.SR5&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt; 在src/main/java包下创建一个名为hello的包，然后创建EurekaServiceRegisterApplication类，并用@EnableEurekaServer和@SpringBootApplication两个注解修饰，后者是Spring Boot应用都需要用的，这里不作过多解释；@EnableEurekaServer注解的作用是触发Spring Boot的自动配置机制，由于我们之前在pom文件中导入了eureka-server，spring boot会在容器中创建对应的bean。EurekaServiceRegisterApplication的代码如下： package hello;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;/** * Created by IntelliJ IDEA. * User: duqi * Date: 2017/3/2 * Time: 20:02 */@EnableEurekaServer //通过@EnableEurekaServer启动一个服务注册中心给其他应用使用@SpringBootApplicationpublic class EurekaServiceRegisterApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServiceRegisterApplication.class, args); &#125;&#125; 在application.properties中还需要增加如下配置，才能创建一个真正可以使用的服务注册中心。 #注册服务的端口号server.port=8761#是否需要注册到注册中心，因为该项目本身作为服务注册中心，所以为falseeureka.client.register-with-eureka=false#是否需要从注册中心获取服务列表，原因同上，为falseeureka.client.fetch-registry=false#注册服务器的地址：服务提供者和服务消费者都要依赖这个地址eureka.client.service-url.defaultZone=http://localhost:$&#123;server.port&#125;/eurekalogging.level.com.netflix.eureka=OFFlogging.level.com.netflix.discovery=OFF 启动注册服务，并访问：http://localhost:8761，就可以看到如下界面。 eureka 服务注册中心后台 2. 服务提供者创建一个Spring Boot工程，代表服务提供者，该服务提供者会暴露一个加法服务，接受客户端传来的加数和被加数，并返回两者的和。 工程的pom文件内容如下： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.example.springcloud&lt;/groupId&gt; &lt;artifactId&gt;service-client&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Camden.SR5&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt; 其中的关键在于spring-cloud-starter-eureka这个Jar包，其中包含了eureka的客户端实现。 在src/main/java/hello下创建工程的主类EurekaServerProducerApplication，使用@EnableDiscoveryClient注解修饰，该注解在服务启动的时候，可以触发服务注册的过程，向配置文件中指定的服务注册中心（Eureka-Server）的地址注册自己提供的服务。EurekaServerProducerApplication的源码如下： package hello;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;/** * Created by IntelliJ IDEA. * User: duqi * Date: 2017/3/2 * Time: 20:34 */@EnableDiscoveryClient@SpringBootApplicationpublic class EurekaServerProducerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServerProducerApplication.class, args); &#125;&#125; 配置文件的内容如下： #服务提供者的名字spring.application.name=compute-service#服务提供者的端口号server.port=8888#服务注册中心的地址eureka.client.serviceUrl.defaultZone=http://localhost:8761/eureka/ 服务提供者的基本框架搭好后，需要实现服务的具体内容，在ServiceInstanceRestController类中实现，它的具体代码如下： package hello;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.cloud.client.ServiceInstance;import org.springframework.cloud.client.discovery.DiscoveryClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;/** * Created by IntelliJ IDEA. * User: duqi * Date: 2017/3/2 * Time: 20:36 */@RestControllerpublic class ServiceInstanceRestController &#123; private static final Logger logger = LoggerFactory.getLogger(ServiceInstanceRestController.class); @Autowired private DiscoveryClient discoveryClient; //服务发现客户端 @GetMapping(value = \"/add\") public Integer add(@RequestParam Integer a, @RequestParam Integer b) &#123; ServiceInstance instance = discoveryClient.getLocalServiceInstance(); Integer r = a + b; logger.info(\"/add, host:\" + instance.getHost() + \", service_id:\" + instance.getServiceId() + \", result:\" + r); return r; &#125;&#125; 先启动服务注册中心的工程，然后再启动服务提供者，在访问：localhost:8761，如下图所示，服务提供者已经注册到服务注册中心啦。 eureka2 服务提供者注册到服务注册中心 在Spring Cloud Netflix中，使用Ribbon实现客户端负载均衡，使用Feign实现声明式HTTP客户端调用——即写得像本地函数调用一样。 3. 服务消费者-Ribbon创建一个Spring boot工程，引入ribbon和eureka，pom文件内容如下： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.example.springcloud&lt;/groupId&gt; &lt;artifactId&gt;serviceconsumer&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.1.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;dependencies&gt; &lt;!-- 客户端负载均衡 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- eureka客户端 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- spring boot实现Java Web服务--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Camden.SR5&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt; 创建EurekaConsumerApplication类，定义REST客户端实例，代码如下： package hello;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;/** * Created by IntelliJ IDEA. * User: duqi * Date: 2017/3/2 * Time: 22:55 */@EnableDiscoveryClient //开启服务发现的能力@SpringBootApplicationpublic class EurekaConsumerApplication &#123; @Bean //定义REST客户端，RestTemplate实例 @LoadBalanced //开启负债均衡的能力 RestTemplate restTemplate() &#123; return new RestTemplate(); &#125; public static void main(String[] args) &#123; SpringApplication.run(EurekaConsumerApplication.class, args); &#125;&#125; application.properties中定义了服务注册中心的地址、消费者服务的端口号、消费者服务的名称这些内容： #应用名称spring.application.name=ribbon-consumer#端口号server.port=9000#注册中心的地址eureka.client.serviceUrl.defaultZone=http://localhost:8761/eureka/ 消费者服务的入口为：ConsumerController，我们通过这个实例进行测试。消费者服务启动过程中，会从服务注册中心中拉最新的服务列表，当浏览器触发对应的请求，就会根据COMPUTE-SERVICE查找服务提供者的IP和端口号，然后发起调用。 package hello;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;/** * Created by IntelliJ IDEA. * User: duqi * Date: 2017/3/2 * Time: 22:58 */@RestControllerpublic class ConsumerController &#123; @Autowired private RestTemplate restTemplate; @GetMapping(value = \"/add\") public String add() &#123; return restTemplate.getForEntity(\"http://COMPUTE-SERVICE/add?a=10&amp;b=20\", String.class).getBody(); &#125;&#125; 首先启动服务注册中心，第二分别启动两个服务提供者（IP相同、端口不同即可），然后启动服务消费者。 eureka3 两个服务提供者 在浏览器里访问localhost:9000/add两次，可以看到请求有时候会在8888端口的服务，有时候会到8889的服务。具体背后选择的原理，还有待后续研究。 4. 服务消费者-Feign使用类似restTemplate.getForEntity(&quot;http://COMPUTE-SERVICE/add?a=10&amp;b=20&quot;,String.class).getBody()这样的语句进行服务间调用并非不可以，只是我们在服务化的过程中，希望跨服务调用能够看起来像本地调用，这也是我理解的Feign的使用场景。 创建一个spring boot工程，该工程的pom文件与上一节的类似，只是把ribbon的依赖换为feign的即可，代码如下： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.example.springcloud&lt;/groupId&gt; &lt;artifactId&gt;serviceconsumer&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.1.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;dependencies&gt; &lt;!-- Feign实现声明式HTTP客户端 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- eureka客户端 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- spring boot实现Java Web服务--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Camden.SR5&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt; 首先创建应用程序启动类：EurekaConsumerApplication，代码如下： package hello;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.netflix.feign.EnableFeignClients;/** * Created by IntelliJ IDEA. * User: duqi * Date: 2017/3/19 * Time: 16:59 */@EnableDiscoveryClient //用于启动服务发现功能@EnableFeignClients //用于启动Fegin功能@SpringBootApplicationpublic class EurekaConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaConsumerApplication.class); &#125;&#125; 然后定义远程调用的接口，在hello包下创建depend包，然后创建ComputeClient接口，使用@FeignClient(“COMPUTE-SERVICE”)注解修饰，COMPUTE-SERVICE就是服务提供者的名称，然后定义要使用的服务，代码如下： package hello.depend;import org.springframework.cloud.netflix.feign.FeignClient;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RequestParam;/** * Created by IntelliJ IDEA. * User: duqi * Date: 2017/3/19 * Time: 17:02 */@FeignClient(\"COMPUTE-SERVICE\")public interface ComputeClient &#123; @RequestMapping(method = RequestMethod.GET, value = \"/add\") Integer add(@RequestParam(value = \"a\") Integer a, @RequestParam(value = \"b\") Integer b);&#125; 在ConsumerController中，像引入普通的spring bean一样引入ComputeClient对象，其他的和Ribbon的类似。 package hello;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RestController;import hello.depend.ComputeClient;/** * Created by IntelliJ IDEA. * User: duqi * Date: 2017/3/19 * Time: 17:06 */@RestControllerpublic class ConsumerController &#123; @Autowired private ComputeClient computeClient; @RequestMapping(value = \"/add\", method = RequestMethod.GET) public Integer add() &#123; return computeClient.add(10, 20); &#125;&#125; application.properties的内容如下： #应用名称spring.application.name=fegin-consumer#端口号server.port=9000#注册中心的地址eureka.client.serviceUrl.defaultZone=http://localhost:8761/eureka/ 启动fegin消费者，访问localhost:9000/add，也可以看到服务提供者已经收到了消费者发来的请求。 log1 请求到达服务提供者1 log2 请求到达服务提供者2 源码下载 服务注册中心(Eureka服务端) 服务提供者(Eureka客户端) 服务消费者-Ribbon(Eureka客户端) 服务消费者-Feign(Eureka客户端) 参考资料 Spring Cloud构建微服务架构（一）服务注册与发现 Spring Cloud实现服务注册于发现 spring-cloud-netflix官网 spring cloud 官网 使用Spring Cloud Feign作为HTTP客户端调用远程HTTP服务 作者：杜琪链接：http://www.jianshu.com/p/0aef3724e6bc來源：简书著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://ningyu1.github.io/tags/Spring-Cloud/"},{"name":"Eureka","slug":"Eureka","permalink":"https://ningyu1.github.io/tags/Eureka/"},{"name":"Ribbon","slug":"Ribbon","permalink":"https://ningyu1.github.io/tags/Ribbon/"},{"name":"Feign","slug":"Feign","permalink":"https://ningyu1.github.io/tags/Feign/"}]},{"title":"RedisClient使用说明","date":"2017-09-06T03:17:36.000Z","path":"20170906/22-redis-client.html","text":"项目地址redis-client &nbsp;&nbsp;&nbsp; Maven引入&lt;dependency&gt; &lt;groupId&gt;cn.tsoft.framework&lt;/groupId&gt; &lt;artifactId&gt;redis-client&lt;/artifactId&gt; &lt;version&gt;1.1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; Spring引入&lt;import resource=\"classpath:spring-redis.xml\" /&gt; Api使用说明ps.本次版本增加了namespace、泛型的支持（存、取直接使用java对象），namespace可以有效的避免key名称冲突和对以后做sharding提供了基础，泛型则是提升使用友好度，本次版本包装了驱动（jedis）的95%的方法，有一些性能不好的方法没有开放，新增了一些使用上更加友好的方法。 常规操作的command实现：RedisClientImpl 二进制操作的command实现：BinaryRedisClientImpl 两者都支持直接存、取java对象，区别在于前者序列化为json以string的方式发送到redis服务器，后者序列化为byte[]以字节方式发送到redis服务，通过redis-cli工具前者可以很明确的看到存的值，后者看到的是二进制编码。 接口方法 1.png 回调接口cn.tsoft.framework.redis.callback.GetDataCallBack 接口提供两个方法 /** * ttl时间,不是所有命令都支持ttl设置 * */int getExpiredTime(); /** * 执行回调方法 */R invoke(); ps.int getExpiredTime();这个方法并不是所有命令都支持（hget系列不支持，因为hash的attr是不支持ttl设置的，ttl必须设置在hash的key上并不是hash的attr上），因此不支持ttl的命令就采用默认的空实现。在使用get和hget方法时，如果key返回为null，则通过该接口的R invoke();方法获取数据并放到redis中。hgetAllObjects方法上的GetDataCallBack gbs参数是无效的传入null即可。如果在get方法获取不到值时不想走数据回调时传入null即可。 示例：//不设置回调Metadata resule = redisClient.get(bizkey, nameSpace, Metadata.class, null); List&lt;Metadata &gt; resule = redisClient.get(bizkey, nameSpace, new TypeReference&lt;List&lt;Metadata&gt;&gt;() &#123;&#125;, null); //设置回调List&lt;Long&gt; resule = redisClient.get(bizkey, nameSpace, new TypeReference&lt;List&lt;Long&gt;&gt;() &#123;&#125;, new GetDataCallBack&lt;List&lt;Long&gt;&gt;() &#123; @Override public int getExpiredTime() &#123; return 3600; &#125; @Override public List&lt;Long&gt; invoke() &#123; return getMetadataSourceProvider().getUserRoles(uid); &#125; &#125;); List&lt;Long&gt; resule = redisClient.hgetObject(bizkey, nameSpace, String.valueOf(uid), new TypeReference&lt;List&lt;Long&gt;&gt;() &#123;&#125;, new GetDataCallBack&lt;List&lt;Long&gt;&gt;() &#123; @Override public int getExpiredTime() &#123; return 0; &#125; @Override public List&lt;Long&gt; invoke() &#123; return getMetadataSourceProvider().getUserRoles(uid); &#125; &#125;); 参数说明get*方法的参数Class value和TypeReference type的区别，前者不支持嵌套泛型，后者支持嵌套泛型，举一个例子说明 Metadata value = redisClient.get(bizkey, nameSpace, Metadata.class, null); List&lt;Metadata&gt; list = redisClient.get(bizkey, nameSpace, new TypeReference&lt;List&lt;Metadata&gt;&gt;()&#123;&#125;, null); 综合使用示例redisClient.set(bizkey, namespace, new Metadata(), 60);//set并设置ttl60秒redisClient.set(bizkey, namespace, new Metadata(), -1);//set不设置ttlredisClient.setnx(bizkey, namespace, \"aaaa\");//key不存在时才设置值redisClient.setex(bizkey, namespace, 60, new Metadata());//set一个key并设置ttl60秒，等价于第一行的用法//setbit和setrange用法不多做说明，参考redis.io上面的command说明 redisClient.get(bizkey, namespace, new GetDataCallBack&lt;String&gt;()&#123; @Override public int getExpiredTime() &#123; return 60; &#125; @Override public String invoke() &#123; return \"aaaa\"; &#125;&#125;);//获取，找不到取数据并set进去 redisClient.get(bizkey, namespace, Metadata.class, new GetDataCallBack&lt;Metadata&gt;()&#123; @Override public int getExpiredTime() &#123; return 60; &#125; @Override public Metadata invoke() &#123; return new Metadata(); &#125;&#125;);//获取值，类型：Metadata redisClient.get(bizkey, namespace, new TypeReference&lt;List&lt;Metadata.class&gt;&gt;()&#123;&#125;, new GetDataCallBack&lt;List&lt;Metadata&gt;&gt;()&#123; @Override public int getExpiredTime() &#123; return 60; &#125; @Override public List&lt;Metadata&gt; invoke() &#123; return new ArrayList&lt;Metadata&gt;; &#125;&#125;);//获取值，类型：List&lt;Metadata&gt; redisClient.get(bizkey, namespace, new TypeReference&lt;List&lt;Metadata.class&gt;&gt;()&#123;&#125;, null);//获取值，类型：List&lt;Metadata&gt; //getbit、getrange、getSet、hget、hgetAll、hgetObject、hgetAllObjects，用法不多做说明，参考redis.io上面的command说明 //管道，批量发送多条命令，但是不支持namespace需要手动添加namespacePipeline pipelined = redisClient.pipelined();pipelined.set(key, value);pipelined.get(key);pipelined.syncAndReturnAll(); //发送命令并接受返回值pipelined.sync();//发送命令不接受返回值 //其他z*、incr、decr、h*、s*命令不做说明，参考redis.io上面的command说明","tags":[{"name":"Redis","slug":"Redis","permalink":"https://ningyu1.github.io/tags/Redis/"}]},{"title":"FastDFS-Client使用说明","date":"2017-09-06T02:17:36.000Z","path":"20170906/21-fastfds-client.html","text":"项目地址fastdfs-client &nbsp;&nbsp;&nbsp; fastdfs-client是什么fastdfs-client是一个访问fastdfs的Java客户端框架，帮助开发人员快速使用分布式文件系统的工具，封装了TrackerClient操作来管理存储节点，封装了StorageClient操作来执行文件上传下载功能。 change logV1.1.0 修改download文件receive时带入的inputStream对象，inputStream对象修改为克隆socket的inputstream，避免污染连接池中的socket对象，当业务回调不读取留时会影响下一次连接池中获取的socket对象。 在使用1.0.0版本进行download文件时，建议使用DownloadCallback的实现类：DownloadByteArray和DownloadFileWriter不要自己去实现，不要关闭receive方法传入的inputStream对象。 在使用1.1.0版本进行download文件时，receive传入的inputStream是克隆的，因此使用完后必须进行关闭操作。 V1.0.0 包装Request和Response报文解析 包装Storage和Tracker操作命令 增加连接池提升使用性能 接口方法StorageClient 1.png TrackerClient 2.png Maven引入&lt;dependency&gt; &lt;groupId&gt;cn.tsoft.framework&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; Spring引入&lt;import resource=\"classpath:spring-fastdfs.xml\"/&gt; Client使用@Autowiredprivate StorageClient storageClient; //上传String path = ClassLoader.getSystemResource(\"123456.txt\").getPath();File file = new File(path);FileInputStream fileInputStream = FileUtils.openInputStream(file);//方式1StorePath storePath = storageClient.uploadFile(\"group1\", fileInputStream, file.length(), \"txt\");//方式2StorePath storePath = storageClient.uploadFile(fileInputStream, file.length(), \"txt\");//方式3StorePath storePath = storageClient.uploadFile(path);//方式4StorePath storePath = storageClient.uploadFile(path, \"txt\");//方式5StorePath storePath = storageClient.uploadFile(\"group1\", path, \"txt\");//方式6StorePath storePath = storageClient.uploadFile(fileInputStream, file.length(), \"txt\", metaDataSet);//上传文件并增加元数据Set&lt;MateData&gt; metaDataSet = new HashSet&lt;MateData&gt;();MateData mateData = new MateData(\"mateDataName\",\"mateDataValue\");metaDataSet.add(mateData);StorePath storePath = storageClient.uploadFile(\"group1\", fileInputStream, file.length(), \"txt\", metaDataSet); //上传从文件，一个主文件可以挂多个从文件//方式1String masterFileId = storePath.getFullPath();String[] parts = new String[2];splitFileId(masterFileId, parts);storePath = storageClient.uploadSlaveFile(parts[0], parts[1], fileInputStream, file.length(), \"-1\", \"txt\");//方式2storePath = storageClient.uploadSlaveFile(masterFileId, fileInputStream, file.length(), \"-1\", \"xlsx\"); fileInputStream.close(); //下载//方式1String path = ClassLoader.getSystemResource(\"123456.txt\").getPath();StorePath storePath = storageClient.uploadFile(\"group1\", path, \"txt\");addResultFileId(storePath.getFullPath());DownloadFileWriter downloadFileWriter = new DownloadFileWriter(path.replaceAll(\"123456.txt\", \"123456downlaod1.txt\"));String filePath = storageClient.downloadFile(storePath.getGroup(), storePath.getPath(), downloadFileWriter);//方式2DownloadFileWriter downloadFileWriter = new DownloadFileWriter(path.replaceAll(\"123456.txt\", \"123456downlaod2.txt\"));String filePath = storageClient.downloadFile(storePath.getFullPath(), downloadFileWriter);//方式3DownloadFileWriter downloadFileWriter = new DownloadFileWriter(path.replaceAll(\"123456.txt\", \"123456downlaod3.txt\"));String filePath = storageClient.downloadFile(storePath.getGroup(), storePath.getPath(), 10, 0, downloadFileWriter); //方式4DownloadFileWriter downloadFileWriter = new DownloadFileWriter(path.replaceAll(\"123456.txt\", \"123456downlaod4.txt\"));String filePath = storageClient.downloadFile(storePath.getFullPath(), 5, 0, downloadFileWriter); //删除//方式1String path = ClassLoader.getSystemResource(\"123456.txt\").getPath();StorePath storePath = storageClient.uploadFile(\"group1\", path, \"txt\");boolean flag = storageClient.deleteFile(storePath.getGroup(), storePath.getPath());//方式2boolean flag = storageClient.deleteFile(storePath.getFullPath()); //获取文件信息//方式1String path = ClassLoader.getSystemResource(\"123456.txt\").getPath();StorePath storePath = storageClient.uploadFile(\"group1\", path, \"txt\");addResultFileId(storePath.getFullPath());String fileId = storePath.getFullPath();FileInfo fileInfo = storageClient.getFileInfo(storePath.getGroup(), storePath.getPath());//方式2FileInfo fileInfo = storageClient.getFileInfo(fileId); //获取文件元数据//方式1String masterFileId = storePath.getFullPath();String[] parts = new String[2];splitFileId(masterFileId, parts);Set&lt;MateData&gt; mateDataSet = storageClient.getMetadata(parts[0], parts[1]);//方式2Set&lt;MateData&gt; mateDataSet = storageClient.getMetadata(masterFileId); //覆盖文件元数据//方式1String[] parts = new String[2];splitFileId(masterFileId, parts);mateDataSet = new HashSet&lt;MateData&gt;();mateDataSet.add(new MateData(\"key5\", \"value5\"));mateDataSet.add(new MateData(\"key6\", \"value6\"));mateDataSet.add(new MateData(\"key7\", \"value7\"));boolean flag = storageClient.overwriteMetadata(parts[0], parts[1], mateDataSet);//方式2boolean flag = storageClient.overwriteMetadata(masterFileId, mateDataSet); //合并文件元数据//方式1String[] parts = new String[2];splitFileId(masterFileId, parts);mateDataSet = new HashSet&lt;MateData&gt;();mateDataSet.add(new MateData(\"key5\", \"value5\"));mateDataSet.add(new MateData(\"key6\", \"value6\"));mateDataSet.add(new MateData(\"key7\", \"value7\"));boolean flag = storageClient.mergeMetadata(parts[0], parts[1], mateDataSet);//方式2boolean flag = storageClient.mergeMetadata(masterFileId, mateDataSet); //一下方法就不具体介绍//续传文件appendFile//修改续传文件modifyFile//清除续传文件truncateFile ps.TrackerClient的操作是配合StorageClient使用，我们在正常业务使用中一般不会用到它。 FastDFS-nginx-module使用上传的文件可以通过nginx直接访问 例如：我们上传的文件获取的文件id：group1/M00/02/92/wKgAMFkekciAC8fhAAJjfD2dq-w10.xlsx nginx访问路径：http://192.168.0.48:8079/group1/M00/02/92/wKgAMFkekciAC8fhAAJjfD2dq-w10.xlsx 目前nginx模块跟storage存储节点匹配，nginx会通过fastdfs-plugin跟tracker通信将文件的信息路由到不同的storage上去 注意事项 上传文件后记录fileId，fastdfs不会自动删除文件，所以业务需要进行定期删除无用的文件，避免硬盘消耗过大 rpc之间调用时 以前是rpc client端通过文件byte方式传入rpc server端，这样rpc的请求包过大会导致rpc调用性能急速下降 应修改为通过fastdfs做桥接，rpc client端upload文件到fastdfs，将返回的fileId做参数传入rpc server端 ，rpc server端通过fileid去fastdfs服务器上download文件文件 FastDFS-client-api说明/** * 存储服务(Storage)客户端接口 * * @author ningyu * @date 2017年5月18日 上午11:25:03 * */public interface StorageClient &#123; /** * 上传文件 * * @param groupName 组名称 * @param inputStream 文件输入流 * @param fileSize 文件大小 * @param fileExtName 文件扩展名 * @return 文件存储路径 */ StorePath uploadFile(String groupName, InputStream inputStream, long fileSize, String fileExtName); /** * 文件上传 * * @param inputStream 文件输入流 * @param fileSize 文件大小 * @param fileExtName 文件扩展名 * @return */ StorePath uploadFile(InputStream inputStream, long fileSize, String fileExtName); /** * 文件上传 * * @param localFilePath 文件完全路径 * @return */ StorePath uploadFile(String localFilePath); /** * 文件上传 * * @param localFilePath 文件完全路径 * @param fileExtName 文件后缀名 * @return */ StorePath uploadFile(String localFilePath, String fileExtName); /** * 文件上传 * * @param groupName 组名称 * @param localFilePath 文件完全路径 * @param fileExtName 文件后缀名 * @return */ StorePath uploadFile(String groupName, String localFilePath, String fileExtName); /** * 上传从文件 * * @param groupName 组名称 * @param masterFilename 主文件路径(fastdfs返回的file_id 去掉前面的group) * @param inputStream 从文件输入流 * @param fileSize 从文件大小 * @param prefixName 从文件前缀 * @param fileExtName 主文件扩展名 * @return 文件存储路径 */ StorePath uploadSlaveFile(String groupName, String masterFilename, InputStream inputStream, long fileSize, String prefixName, String fileExtName); /** * 上传从文件 * * @param masterFileId 主文件路径（fastdfs返回的file_id，包含前面的group） * @param inputStream 从文件输入流 * @param fileSize 从文件大小 * @param prefixName 从文件前缀 * @param fileExtName 主文件扩展名 * @return */ StorePath uploadSlaveFile(String masterFileId, InputStream inputStream, long fileSize, String prefixName, String fileExtName); /** * 获取文件元信息 * * @param groupName 组名称 * @param path 主文件路径 * @return 获取文件元信息集合，不存在返回空集合 */ Set&lt;MateData&gt; getMetadata(String groupName, String path); /** * 获取文件元信息 * * @param fileId 文件路径（fastdfs返回的file_id，包含前面的group） * @return */ Set&lt;MateData&gt; getMetadata(String fileId); /** * 修改文件元信息（覆盖） * * @param groupName 组名称 * @param path 主文件路径 * @param metaDataSet 元信息集合 */ boolean overwriteMetadata(String groupName, String path, Set&lt;MateData&gt; metaDataSet); /** * 修改文件元信息（覆盖） * * @param fileId 文件路径（fastdfs返回的file_id，包含前面的group） * @param metaDataSet 元信息集合 * @return */ boolean overwriteMetadata(String fileId, Set&lt;MateData&gt; metaDataSet); /** * 修改文件元信息（合并） * * @param groupName 组名称 * @param path 主文件路径 * @param metaDataSet 元信息集合 */ boolean mergeMetadata(String groupName, String path, Set&lt;MateData&gt; metaDataSet); /** * 修改文件元信息（合并） * * @param fileId 文件路径（fastdfs返回的file_id，包含前面的group） * @param metaDataSet 元信息集合 * @return */ boolean mergeMetadata(String fileId, Set&lt;MateData&gt; metaDataSet); /** * 获取文件的信息 * * @param groupName 组名称 * @param path 主文件路径 * @return 文件信息(不存在返回null) */ FileInfo getFileInfo(String groupName, String path); /** * 获取文件信息 * * @param fileId 文件路径（fastdfs返回的file_id，包含前面的group） * @return */ FileInfo getFileInfo(String fileId); /** * 删除文件 * * @param groupName 组名称 * @param path 主文件路径 */ boolean deleteFile(String groupName, String path); /** * 删除文件 * * @param fileId 文件路径（fastdfs返回的file_id，包含前面的group） * @return */ boolean deleteFile(String fileId); /** * 下载整个文件 * * @param groupName 组名称 * @param path 主文件路径 * @param callback 下载回调接口 * @return 下载回调接口返回结果 */ &lt;T&gt; T downloadFile(String groupName, String path, DownloadCallback&lt;T&gt; callback); /** * 下载整个文件 * * @param fileId 文件路径（fastdfs返回的file_id，包含前面的group） * @param callback 下载回调接口 * @return */ &lt;T&gt; T downloadFile(String fileId, DownloadCallback&lt;T&gt; callback); /** * 下载文件片段 * * @param groupName 组名称 * @param path 主文件路径 * @param fileOffset 开始位置 * @param fileSize 文件大小(经过测试好像这个参数值只能是“0”) * @param callback 下载回调接口 * @return 下载回调接口返回结果 */ &lt;T&gt; T downloadFile(String groupName, String path, long fileOffset, long fileSize, DownloadCallback&lt;T&gt; callback); /** * 下载文件片段 * * @param fileId 文件路径（fastdfs返回的file_id，包含前面的group） * @param fileOffset 开始位置 * @param fileSize 文件大小(经过测试好像这个参数值只能是“0”) * @param callback 下载回调接口 * @return */ &lt;T&gt; T downloadFile(String fileId, long fileOffset, long fileSize, DownloadCallback&lt;T&gt; callback); // ---------------------------------------------------------------------------------------------------------------------------------------------------- /** * 上传文件， 并设置文件元数据 * * @param inputStream 文件输入流 * @param fileSize 文件大小 * @param fileExtName 文件扩展名 * @param metaDataSet 元信息集合 * @return 文件存储路径 */ StorePath uploadFile(InputStream inputStream, long fileSize, String fileExtName, Set&lt;MateData&gt; metaDataSet); /** * 上传文件， 并设置文件元数据 * * @param groupName 组名 * @param inputStream 文件输入流 * @param fileSize 文件大小 * @param fileExtName 文件扩展名 * @param metaDataSet 元信息集合 * @return */ StorePath uploadFile(String groupName, InputStream inputStream, long fileSize, String fileExtName, Set&lt;MateData&gt; metaDataSet); /** * 文件上传(支持续传追加内容) * * @param groupName 组名称 * @param inputStream 文件输入流(文件部分) * @param fileSize 文件大小 * @param fileExtName 文件扩展名 * @return 文件存储路径 */ StorePath uploadAppenderFile(String groupName, InputStream inputStream, long fileSize, String fileExtName); /** * 续传文件(追加内容)&lt;/br&gt; * 从末尾追加内容&lt;/br&gt; * * @param groupName 组名称 * @param path 文件路径 * @param inputStream 文件输入流(文件部分) * @param fileSize 文件大小 * */ void appendFile(String groupName, String path, InputStream inputStream, long fileSize); /** * 续传文件(追加内容)&lt;/br&gt; * 从末尾追加内容&lt;/br&gt; * * @param fileId 文件路径（fastdfs返回的file_id，包含前面的group） * @param inputStream 文件输入流(文件部分) * @param fileSize 文件大小 * */ void appendFile(String fileId, InputStream inputStream, long fileSize); /** * 修改文件内容的内容&lt;/br&gt; * 从offset开始覆盖fileSize长度&lt;/br&gt; * 报22参数错误，请检查offset是否超过文件长度&lt;/br&gt; * * @param groupName 组名称 * @param path 文件路径 * @param inputStream 文件输入流 * @param fileSize 文件大小 * @param fileOffset 开始位置 * */ void modifyFile(String groupName, String path, InputStream inputStream, long fileSize, long fileOffset); /** * 修改文件内容的内容&lt;/br&gt; * 从offset开始覆盖fileSize长度&lt;/br&gt; * 报22参数错误，请检查offset是否超过文件长度&lt;/br&gt; * * @param fileId 文件路径（fastdfs返回的file_id，包含前面的group） * @param inputStream 文件输入流 * @param fileSize 文件大小 * @param fileOffset 开始位置 * */ void modifyFile(String fileId, InputStream inputStream, long fileSize, long fileOffset); /** * 清除文件的内容 * * @param groupName 组名称 * @param path 文件路径 * @param truncatedFileSize 截断文件大小 * */ void truncateFile(String groupName, String path, long truncatedFileSize); /** * 清除文件的内容 * * @param fileId 文件路径（fastdfs返回的file_id，包含前面的group） * @param truncatedFileSize 截断文件大小 * */ void truncateFile(String fileId, long truncatedFileSize); /** * 清除文件的内容 * * @param groupName 组名称 * @param path 文件路径 * */ void truncateFile(String groupName, String path); /** * 清除文件的内容 * * @param fileId 文件路径（fastdfs返回的file_id，包含前面的group） * */ void truncateFile(String fileId);&#125; ps.api我只放出了StorageClient的说明，TrackerClient的使用常规开发时用不到的，架构在进行调优的时候可能会使用到，所以这里就不做过多的解释","tags":[{"name":"Fastdfs","slug":"Fastdfs","permalink":"https://ningyu1.github.io/tags/Fastdfs/"}]},{"title":"MybatisSql获取工具类SqlHelper使用说明","date":"2017-09-05T09:50:36.000Z","path":"20170905/20-mybatis-sqlhelper.html","text":"项目地址tsoft-common [ License](https://img.shields.io/badge/license-GPLv3-blue.svg) 前言有的时候我们想在代码中获取Mybatis方法的sql但是又不想去实际执行Mybatis的查询方法，可以使用该工具直接得到sql。 Maven引入&lt;dependency&gt; &lt;groupId&gt;cn.tsoft.framework&lt;/groupId&gt; &lt;artifactId&gt;tsoft-common&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 目标SqlHelper是获取Mybatis方法的sql工具包，支持mybatis mapper方式和sqlmap方式，支持参数：entity，map，array，list，这个工具不需要你实际去执行Mybatis的查询方法就能得到sql，方法主要分两大类，使用命名空间namespace调用或者使用Mapper接口方式调用。 测试方法String sql = null;UserEntity entity = new UserEntity();entity.setUserId(1L);entity.setPassword(\"sdflkjsldjf\");entity.setPasswordExpire(new Date());entity.setVersion(2L);List&lt;Long&gt; list = new ArrayList&lt;Long&gt;();list.add(1L);list.add(2L);Long[] ids = new Long[]&#123;1L,2L&#125;;//方式一sql = SqlHelper.getMapperSql(userMapper, \"mobileIsExists\", 1L, \"13800138000\");System.out.println(\"方式一：参数为：@Param：\"+sql);sql = SqlHelper.getMapperSql(userMapper, \"mobileIsExists\");System.out.println(\"方式一：参数为：无参：\"+sql);sql = SqlHelper.getMapperSql(userMapper, \"modifyPassword\", entity);System.out.println(\"方式一：参数为：entity\"+sql);sql = SqlHelper.getMapperSql(userMapper, \"blockedArrays\", ids);System.out.println(\"方式一：参数为：arrays\"+sql);sql = SqlHelper.getMapperSql(userMapper, \"blockedList\", list);System.out.println(\"方式一：参数为：list\"+sql); SqlSession sqlSession = mybatisSessionFactory.getObject().openSession();//方式二sql = SqlHelper.getMapperSql(sqlSession, \"cn.tsoft.account.mapper.UserMapper.mobileIsExists\", 1L, \"13800138000\");System.out.println(\"方式二：参数为：@Param：\"+sql);sql = SqlHelper.getMapperSql(sqlSession, \"cn.tsoft.account.mapper.UserMapper.mobileIsExists\");System.out.println(\"方式二：参数为：无参：\"+sql);sql = SqlHelper.getMapperSql(sqlSession, \"cn.tsoft.account.mapper.UserMapper.modifyPassword\", entity);System.out.println(\"方式二：参数为：entity\"+sql);sql = SqlHelper.getMapperSql(sqlSession, \"cn.tsoft.account.mapper.UserMapper.blockedArrays\", ids);System.out.println(\"方式二：参数为：arrays\"+sql);sql = SqlHelper.getMapperSql(sqlSession, \"cn.tsoft.account.mapper.UserMapper.blockedList\", list);System.out.println(\"方式二：参数为：list\"+sql); //方式三sql = SqlHelper.getMapperSql(sqlSession, UserMapper.class, \"mobileIsExists\", 1L, \"13800138000\");System.out.println(\"方式三：参数为：@Param：\"+sql);sql = SqlHelper.getMapperSql(sqlSession, UserMapper.class, \"mobileIsExists\");System.out.println(\"方式三：参数为：无参：\"+sql);sql = SqlHelper.getMapperSql(sqlSession, UserMapper.class, \"modifyPassword\", entity);System.out.println(\"方式三：参数为：entity\"+sql);sql = SqlHelper.getMapperSql(sqlSession, UserMapper.class, \"blockedArrays\", ids);System.out.println(\"方式三：参数为：arrays\"+sql);sql = SqlHelper.getMapperSql(sqlSession, UserMapper.class, \"blockedList\", list);System.out.println(\"方式三：参数为：list\"+sql); 日志输出方式一：参数为：@Param：SELECT COUNT(t.`ID`) FROM t_user t WHERE t.`MOBILE` = &apos;13800138000&apos; AND t.`USER_ID` != &apos;1&apos;方式一：参数为：无参：SELECT COUNT(t.`ID`) FROM t_user t WHERE t.`MOBILE` = &apos;null&apos;方式一：参数为：entity：UPDATE t_user t SET t.`PASSWORD` = &apos;sdflkjsldjf&apos; , t.`LAST_UPDATE_TIME` = CURRENT_TIMESTAMP , t.`PASSWORD_MODIFY_TIME` = CURRENT_TIMESTAMP , t.`PASSWORD_EXPIRE` = &apos;Fri Aug 25 19:36:00 CST 2017&apos; , t.`VERSION` = t.`VERSION` + 1 WHERE t.`USER_ID` = 1 AND t.`VERSION` = 2方式一：参数为：arrays：UPDATE t_user t SET t.`LAST_UPDATE_TIME` = CURRENT_TIMESTAMP , t.`VERSION` = t.`VERSION` + 1 WHERE t.`USER_ID` in 1 , 2方式一：参数为：list：UPDATE t_user t SET t.`LAST_UPDATE_TIME` = CURRENT_TIMESTAMP , t.`VERSION` = t.`VERSION` + 1 WHERE t.`USER_ID` in 1 , 2方式二：参数为：@Param：SELECT COUNT(t.`ID`) FROM t_user t WHERE t.`MOBILE` = &apos;13800138000&apos; AND t.`USER_ID` != &apos;1&apos;方式二：参数为：无参：SELECT COUNT(t.`ID`) FROM t_user t WHERE t.`MOBILE` = &apos;null&apos;方式二：参数为：entity：UPDATE t_user t SET t.`PASSWORD` = &apos;sdflkjsldjf&apos; , t.`LAST_UPDATE_TIME` = CURRENT_TIMESTAMP , t.`PASSWORD_MODIFY_TIME` = CURRENT_TIMESTAMP , t.`PASSWORD_EXPIRE` = &apos;Fri Aug 25 19:36:00 CST 2017&apos; , t.`VERSION` = t.`VERSION` + 1 WHERE t.`USER_ID` = 1 AND t.`VERSION` = 2方式二：参数为：arrays：UPDATE t_user t SET t.`LAST_UPDATE_TIME` = CURRENT_TIMESTAMP , t.`VERSION` = t.`VERSION` + 1 WHERE t.`USER_ID` in 1 , 2方式二：参数为：list：UPDATE t_user t SET t.`LAST_UPDATE_TIME` = CURRENT_TIMESTAMP , t.`VERSION` = t.`VERSION` + 1 WHERE t.`USER_ID` in 1 , 2方式三：参数为：@Param：SELECT COUNT(t.`ID`) FROM t_user t WHERE t.`MOBILE` = &apos;13800138000&apos; AND t.`USER_ID` != &apos;1&apos;方式三：参数为：无参：SELECT COUNT(t.`ID`) FROM t_user t WHERE t.`MOBILE` = &apos;null&apos;方式三：参数为：entity：UPDATE t_user t SET t.`PASSWORD` = &apos;sdflkjsldjf&apos; , t.`LAST_UPDATE_TIME` = CURRENT_TIMESTAMP , t.`PASSWORD_MODIFY_TIME` = CURRENT_TIMESTAMP , t.`PASSWORD_EXPIRE` = &apos;Fri Aug 25 19:36:00 CST 2017&apos; , t.`VERSION` = t.`VERSION` + 1 WHERE t.`USER_ID` = 1 AND t.`VERSION` = 2方式三：参数为：arrays：UPDATE t_user t SET t.`LAST_UPDATE_TIME` = CURRENT_TIMESTAMP , t.`VERSION` = t.`VERSION` + 1 WHERE t.`USER_ID` in 1 , 2方式三：参数为：list：UPDATE t_user t SET t.`LAST_UPDATE_TIME` = CURRENT_TIMESTAMP , t.`VERSION` = t.`VERSION` + 1 WHERE t.`USER_ID` in 1 , 2","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://ningyu1.github.io/tags/Mybatis/"},{"name":"Sqlhelper","slug":"Sqlhelper","permalink":"https://ningyu1.github.io/tags/Sqlhelper/"}]},{"title":"JMS实现参数的集中式管理","date":"2017-09-05T09:12:36.000Z","path":"20170905/19-jms-ucm.html","text":"点评虽然现在开源的UCM套件很多，UCM统一配置管理（百度的disconf、阿里的diamond、点评的lion，等很多开源的）。但是很多人是知其然不知其所以然，刚好发现下面这篇文章可以作为原理的教程文章，使用JMS、Redis、Zookeeper简单的实现UCM基本功能，作为学习交流还是很不错的。 文章转自：https://my.oschina.net/OutOfMemory/blog/1510101作者：@ksfzhaohui 前言JMS的发布订阅机制也能实现类似的功能，集群节点通过订阅指定的节点，同时使用JMS对消息的过滤器功能，实现对指定参数的更新，本文将介绍通过JMS实现简单的参数集中式管理。 Maven引入Spring相关的jar引入参考上一篇文章 &lt;dependency&gt; &lt;groupId&gt;javax.jms&lt;/groupId&gt; &lt;artifactId&gt;jms&lt;/artifactId&gt; &lt;version&gt;1.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.10.0&lt;/version&gt;&lt;/dependency&gt; 目标 可以同时配置监听多个节点如/app1,/app2； 希望只需要配置如/app1，就能够监听其子节点如/app1/modual1以及子节点的子节点如/app1/modual1/xxx/…； 服务器启动能获取当前指定父节点下的所有子节点数据； 在添加节点或者在更新节点数据的时候能够动态通知，这样代码中就能够实时获取最新的数据； spring配置中可以从Zookeeper中读取参数进行初始化。 虽然在实现的方式上有点区别，但是最终达成的目标是一致的，同样列出了这5条目标 实现MQWatcher主要用来和JMS建立连接，同时订阅指定节点，建立点对点连接，过滤出需要监听的数据，更新数据，初始化数据，存储数据等InitConfServer主要作为点对点连接的服务器端用来初始化数据 1.同时配置监听多个节点提供一个字符串数组给用户用来添加需要监听的节点： private String[] keyPatterns; 2.能够监听其子节点以及子节点的子节点使用了一种和Zookeeper不一样的方式，JMS的方式是将所有的数据变更都发送到订阅者，然后订阅者通过过滤出需要的数据进行更新 /** MQ的过滤器 **/private StringBuffer keyFilter = new StringBuffer(); private final String TOPIC = \"dynamicConfTopic\"; private void watcherPaths() throws JMSException &#123; Topic topic = session.createTopic(TOPIC); MessageConsumer consumer = session.createConsumer(topic, keyFilter.toString()); consumer.setMessageListener(new MessageListener() &#123; @Override public void onMessage(Message message) &#123; try &#123; String key = message.getStringProperty(IDENTIFIER); TextMessage tm = (TextMessage) message; keyValueMap.put(key, tm.getText()); LOGGER.info(\"key = \" + key + \",value = \" + tm.getText()); &#125; catch (JMSException e) &#123; LOGGER.error(\"onMessage error\", e); &#125; &#125; &#125;);&#125; 对TOPIC进行了订阅，并且指定了过滤器keyFilter，keyFilter正是基于keyPatterns组装而成的 private final String IDENTIFIER = \"confKey\"; /*** 生成接受过滤器*/private void generateKeyFilter() &#123; for (int i = 0; i &lt; keyPatterns.length; i++) &#123; keyFilter.append(IDENTIFIER + \" LIKE '\" + keyPatterns[i] + \"%'\"); if (i &lt; keyPatterns.length - 1) &#123; keyFilter.append(\" OR \"); &#125; &#125; LOGGER.info(\"keyFilter : \" + keyFilter.toString());&#125; 对指定的属性IDENTIFIER，通过LIKE和OR关键字进行过滤 3.服务器启动初始化节点数据通过点对点的方式，在服务器启动时通过请求响应模式来获取初始化数据 private final String QUEUE = \"dynamicConfQueue\"; /** * 初始化key-value值 * * @throws JMSException */private void initKeyValues() throws JMSException &#123; TemporaryQueue responseQueue = null; MessageProducer producer = null; MessageConsumer consumer = null; Queue queue = queueSession.createQueue(QUEUE); TextMessage requestMessage = queueSession.createTextMessage(); requestMessage.setText(generateKeyString()); responseQueue = queueSession.createTemporaryQueue(); producer = queueSession.createProducer(queue); consumer = queueSession.createConsumer(responseQueue); requestMessage.setJMSReplyTo(responseQueue); producer.send(requestMessage); MapMessage receiveMap = (MapMessage) consumer.receive(); @SuppressWarnings(\"unchecked\") Enumeration&lt;String&gt; mapNames = receiveMap.getPropertyNames(); while (mapNames.hasMoreElements()) &#123; String key = mapNames.nextElement(); String value = receiveMap.getStringProperty(key); keyValueMap.put(key, value); LOGGER.info(\"init key = \" + key + \",value = \" + value); &#125;&#125; 通过对指定QUEUE请求，同时建立一个临时的响应QUEUE，然后接受一个MapMessage，用来初始化keyValueMap 4.监听节点数据的变更通过发布订阅模式，接受所有数据，然后进行过滤，目标2中已经有相关实现 5.spring配置中可以从Zookeeper中读取参数进行初始化 public class MQPropPlaceholderConfigurer extends PropertyPlaceholderConfigurer &#123; private MQWatcher mqwatcher; @Override protected Properties mergeProperties() throws IOException &#123; return loadPropFromMQ(super.mergeProperties()); &#125; /** * 从MQ中加载配置的常量 * * @param result * @return */ private Properties loadPropFromMQ(Properties result) &#123; mqwatcher.watcherKeys(); mqwatcher.fillProperties(result); return result; &#125;&#125; 通过以上的处理，可以使用如下简单的配置来达到目标： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd\"&gt; &lt;bean id=\"person\" class=\"zh.maven.DynamicConf.Person\"&gt; &lt;property name=\"name\"&gt; &lt;value&gt;$&#123;/a2/m1&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name=\"address\"&gt; &lt;value&gt;$&#123;/a3/m1/v2&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name=\"company\"&gt; &lt;value&gt;$&#123;/a3/m1/v2/t2&#125;&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"mqwatcher\" class=\"zh.maven.DynamicConf.mq.MQWatcher\"&gt; &lt;property name=\"keyPatterns\" value=\"/a2,/a3\" /&gt; &lt;/bean&gt; &lt;bean id=\"propertyConfigurer\" class=\"zh.maven.DynamicConf.mq.MQPropPlaceholderConfigurer\"&gt; &lt;property name=\"mqwatcher\" ref=\"mqwatcher\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 测试1.启动ActiveMQ activemq.bat 2.InitConfServer启动用来监听集群节点的初始化请求，获取到集群节点发送来的keyPatterns，然后将符合其模式的数据封装成MapMessage发送给集群节点 @Overridepublic void onMessage(Message message) &#123; try &#123; TextMessage receiveMessage = (TextMessage) message; String keys = receiveMessage.getText(); LOGGER.info(\"keys = \" + keys); MapMessage returnMess = session.createMapMessage(); returnMess.setStringProperty(\"/a2/m1\", \"zhaohui\"); returnMess.setStringProperty(\"/a3/m1/v2\", \"nanjing\"); returnMess.setStringProperty(\"/a3/m1/v2/t2\", \"zhaohui\"); QueueSender sender = session.createSender((Queue) message.getJMSReplyTo()); sender.send(returnMess); &#125; catch (Exception e) &#123; LOGGER.error(\"onMessage error\", e); &#125;&#125; 以上代码只是进行了简单的模拟，提供了一个思路 3.启动Main类 public class Main &#123; public static void main(String[] args) throws Exception &#123; ApplicationContext context = new ClassPathXmlApplicationContext(new String[] &#123; \"spring-config.xml\" &#125;); Person person = (Person) context.getBean(\"person\"); System.out.println(person.toString()); &#125;&#125; 4.启动TopicPublisher定时发布数据，同时查看集群节点的Main类日志输出 public class TopicPublisher &#123; private static final String TOPIC = \"dynamicConfTopic\"; private static final String IDENTIFIER = \"confKey\"; public static void main(String[] args) throws JMSException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(\"tcp://localhost:61616\"); Connection connection = factory.createConnection(); connection.start(); Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); Topic topic = session.createTopic(TOPIC); MessageProducer producer = session.createProducer(topic); producer.setDeliveryMode(DeliveryMode.NON_PERSISTENT); int i=1; while (true) &#123; TextMessage message = session.createTextMessage(); message.setStringProperty(IDENTIFIER, \"/a2/\"+i); message.setText(\"message_\" + System.currentTimeMillis()); producer.send(message); System.out.println(\"Sent message: \" + message.getText()); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; i++; &#125; &#125;&#125; 日志输出如下： 2017-08-14 21:52:23 - keyFilter : confKey LIKE &apos;/a2%&apos; OR confKey LIKE &apos;/a3%&apos;2017-08-14 21:52:24 - init key = /a3/m1/v2/t2,value = zhaohui2017-08-14 21:52:24 - init key = /a3/m1/v2,value = nanjing2017-08-14 21:52:24 - init key = /a2/m1,value = zhaohui2017-08-14 21:52:24 - Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@223dd567: defining beans [person,mqwatcher,propertyConfigurer]; root of factory hierarchyname = zhaohui,address = nanjing,company = zhaohui2017-08-14 21:52:33 - key = /a2/1,value = message_15027187538192017-08-14 21:52:35 - key = /a2/2,value = message_15027187558322017-08-14 21:52:37 - key = /a2/3,value = message_15027187578462017-08-14 21:52:39 - key = /a2/4,value = message_15027187598602017-08-14 21:52:41 - key = /a2/5,value = message_1502718761876 总结通过JMS实现了一个简单的参数化平台系统，当然想在生产中使用还有很多需要优化的地方，本文在于提供一个思路；后续有时间准备对DynamicConf提供更加完善的方案。","tags":[{"name":"UCM","slug":"UCM","permalink":"https://ningyu1.github.io/tags/UCM/"},{"name":"JMS","slug":"JMS","permalink":"https://ningyu1.github.io/tags/JMS/"}]},{"title":"Zookeeper实现参数的集中式管理","date":"2017-09-05T09:07:36.000Z","path":"20170905/18-zookeeper-ucm.html","text":"点评虽然现在开源的UCM套件很多，UCM统一配置管理（百度的disconf、阿里的diamond、点评的lion，等很多开源的）。但是很多人是知其然不知其所以然，刚好发现下面这篇文章可以作为原理的教程文章，使用JMS、Redis、Zookeeper简单的实现UCM基本功能，作为学习交流还是很不错的。 文章转自：https://my.oschina.net/OutOfMemory/blog/1503392作者：@ksfzhaohui 前言应用项目中都会有一些参数，一般的做法通常可以选择将其存储在本地配置文件或者内存变量中；对于集群机器规模不大、配置变更不是特别频繁的情况下，这两种方式都能很好的解决；但是一旦集群机器规模变大，且配置信息越来越频繁，依靠这两种方式就越来越困难；我们希望能够快速的做到全局参数的变更，因此需要一种参数的集中式管理，下面利用Zookeeper的一些特性来实现简单的参数管理。 准备jdk:1.7.0_80zookeeper:3.4.3curator:2.6.0spring:3.1.2 Maven引入Spring相关的jar引入参考上一篇文章 &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;3.1.2.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;3.1.2.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;3.1.2.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.3&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.sun.jmx&lt;/groupId&gt; &lt;artifactId&gt;jmxri&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;com.sun.jdmk&lt;/groupId&gt; &lt;artifactId&gt;jmxtools&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;javax.jms&lt;/groupId&gt; &lt;artifactId&gt;jms&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;2.6.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;2.6.0&lt;/version&gt;&lt;/dependency&gt; 目标 可以同时配置监听多个节点如/app1,/app2； 希望只需要配置如/app1，就能够监听其子节点如/app1/modual1以及子节点的子节点如/app1/modual1/xxx/…； 服务器启动能获取当前指定父节点下的所有子节点数据； 在添加节点或者在更新节点数据的时候能够动态通知，这样代码中就能够实时获取最新的数据； spring配置中可以从Zookeeper中读取参数进行初始化。 实现提供ZKWatcher类主要用来和Zookeeper建立连接，监听节点，初始化节点数据，更新节点数据，存储节点数据等 1.同时配置监听多个节点提供一个字符串数组给用户用来添加需要监听的节点： private String[] keyPatterns; 2.能够监听其子节点以及子节点的子节点使用递归的方式用来获取指定监听节点的子节点： private List&lt;String&gt; listChildren(String path) throws Exception &#123; List&lt;String&gt; pathList = new ArrayList&lt;String&gt;(); pathList.add(path); List&lt;String&gt; list = client.getChildren().forPath(path); if (list != null &amp;&amp; list.size() &gt; 0) &#123; for (String cPath : list) &#123; String temp = \"\"; if (\"/\".equals(path)) &#123; temp = path + cPath; &#125; else &#123; temp = path + \"/\" + cPath; &#125; pathList.addAll(listChildren(temp)); &#125; &#125; return pathList;&#125; 3.服务器启动初始化节点数据上面已经递归获取了所有的节点，所有可以遍历获取所有节点数据，并且存储在Map中： private Map&lt;String, String&gt; keyValueMap = new ConcurrentHashMap&lt;String, String&gt;(); if (pathList != null &amp;&amp; pathList.size() &gt; 0) &#123; for (String path : pathList) &#123; keyValueMap.put(path, readPath(path)); watcherPath(path); &#125;&#125; private String readPath(String path) throws Exception &#123; byte[] buffer = client.getData().forPath(path); String value = new String(buffer); logger.info(\"readPath:path = \" + path + \",value = \" + value); return value;&#125; 4.监听节点数据的变更使用PathChildrenCache用来监听子节点的CHILD_ADDED，CHILD_UPDATED，CHILD_REMOVED事件： private void watcherPath(String path) &#123; PathChildrenCache cache = null; try &#123; cache = new PathChildrenCache(client, path, true); cache.start(StartMode.POST_INITIALIZED_EVENT); cache.getListenable().addListener(new PathChildrenCacheListener() &#123; @Override public void childEvent(CuratorFramework client, PathChildrenCacheEvent event) throws Exception &#123; switch (event.getType()) &#123; case CHILD_ADDED: logger.info(\"CHILD_ADDED,\" + event.getData().getPath()); watcherPath(event.getData().getPath()); keyValueMap.put(event.getData().getPath(), new String(event.getData().getData())); break; case CHILD_UPDATED: logger.info(\"CHILD_UPDATED,\" + event.getData().getPath()); keyValueMap.put(event.getData().getPath(), new String(event.getData().getData())); break; case CHILD_REMOVED: logger.info(\"CHILD_REMOVED,\" + event.getData().getPath()); break; default: break; &#125; &#125; &#125;); &#125; catch (Exception e) &#123; if (cache != null) &#123; try &#123; cache.close(); &#125; catch (IOException e1) &#123; &#125; &#125; logger.error(\"watch path error\", e); &#125;&#125; 5.spring配置中可以从Zookeeper中读取参数进行初始化实现自定义的PropertyPlaceholderConfigurer类ZKPropPlaceholderConfigurer： public class ZKPropPlaceholderConfigurer extends PropertyPlaceholderConfigurer &#123; private ZKWatcher zkwatcher; @Override protected Properties mergeProperties() throws IOException &#123; return loadPropFromZK(super.mergeProperties()); &#125; /** * 从zk中加载配置的常量 * * @param result * @return */ private Properties loadPropFromZK(Properties result) &#123; zkwatcher.watcherKeys(); zkwatcher.fillProperties(result); return result; &#125; ......&#125; 通过以上的处理，可以使用如下简单的配置来达到目标： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd\"&gt; &lt;bean id=\"zkwatcher\" class=\"zh.maven.DynamicConf.ZKWatcher\"&gt; &lt;property name=\"keyPatterns\" value=\"/a2,/a3/m1\" /&gt; &lt;/bean&gt; &lt;bean id=\"propertyConfigurer\" class=\"zh.maven.DynamicConf.ZKPropPlaceholderConfigurer\"&gt; &lt;property name=\"zkwatcher\" ref=\"zkwatcher\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"person\" class=\"zh.maven.DynamicConf.Person\"&gt; &lt;property name=\"name\"&gt; &lt;value&gt;$&#123;/a2/m1&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name=\"address\"&gt; &lt;value&gt;$&#123;/a3/m1/v2&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name=\"company\"&gt; &lt;value&gt;$&#123;/a3/m1/v2/t2&#125;&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 测试1.首先启动Zookeeper zkServer.cmd 2.初始化需要使用的节点 public class Create_Node &#123; static String path = \"/a3/m1/v2/t2\"; static CuratorFramework client = CuratorFrameworkFactory.builder() .connectString(\"127.0.0.1:2181\").sessionTimeoutMs(5000) .retryPolicy(new ExponentialBackoffRetry(1000, 3)).build(); public static void main(String[] args) throws Exception &#123; client.start(); client.create().creatingParentsIfNeeded() .withMode(CreateMode.PERSISTENT) .forPath(path, \"init\".getBytes()); &#125;&#125; 创建需要的节点方便ZKWatcher来监听，这里根据以上的配置，分别初始化/a3/m1/v2/t2和/a2/m1/v1/t1 3.启动Main，分别验证配置文件中的初始化以及代码动态获取参数 public class Main &#123; public static void main(String[] args) throws Exception &#123; ApplicationContext context = new ClassPathXmlApplicationContext(new String[] &#123; \"spring-config.xml\" &#125;); Person person = (Person) context.getBean(\"person\"); System.out.println(person.toString()); ZKWatcher zkwatcher = (ZKWatcher) context.getBean(\"zkwatcher\"); while (true) &#123; Person p = new Person(zkwatcher.getKeyValue(\"/a2/m1\"), zkwatcher.getKeyValue(\"/a3/m1/v2\"), zkwatcher.getKeyValue(\"/a3/m1/v2/t2\")); System.out.println(p.toString()); Thread.sleep(1000); &#125; &#125;&#125; 4.观察日志同时更新参数： public class Set_Data &#123; static String path = \"/a3/m1/v2/t2\"; static CuratorFramework client = CuratorFrameworkFactory.builder().connectString(\"127.0.0.1:2181\") .sessionTimeoutMs(5000).retryPolicy(new ExponentialBackoffRetry(1000, 3)).build(); public static void main(String[] args) throws Exception &#123; client.start(); Stat stat = new Stat(); System.out.println(stat.getVersion()); System.out.println(\"Success set node for :\" + path + \",new version:\" + client.setData().forPath(path, \"codingo_v2\".getBytes()).getVersion()); &#125;&#125; 部分日志如下： 2017-08-05 18:04:57 - watcher path : [/a2, /a2/m1, /a2/m1/v1, /a2/m1/v1/t2, /a3/m1, /a3/m1/v2, /a3/m1/v2/t2]2017-08-05 18:04:57 - readPath:path = /a2,value = 2017-08-05 18:04:57 - readPath:path = /a2/m1,value = zhaohui2017-08-05 18:04:57 - readPath:path = /a2/m1/v1,value = 2017-08-05 18:04:57 - readPath:path = /a2/m1/v1/t2,value = init2017-08-05 18:04:57 - readPath:path = /a3/m1,value = 2017-08-05 18:04:57 - readPath:path = /a3/m1/v2,value = nanjing2017-08-05 18:04:57 - readPath:path = /a3/m1/v2/t2,value = codingo_v102017-08-05 18:04:57 - Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@182f4aea: defining beans [zkwatcher,propertyConfigurer,person]; root of factory hierarchyname = zhaohui,address = nanjing,company = codingo_v10name = zhaohui,address = nanjing,company = codingo_v102017-08-05 18:04:57 - CHILD_ADDED,/a2/m12017-08-05 18:04:57 - CHILD_ADDED,/a3/m1/v22017-08-05 18:04:57 - CHILD_ADDED,/a2/m1/v12017-08-05 18:04:57 - CHILD_ADDED,/a2/m1/v1/t22017-08-05 18:04:57 - CHILD_ADDED,/a3/m1/v2/t2name = zhaohui,address = nanjing,company = codingo_v10name = zhaohui,address = nanjing,company = codingo_v10name = zhaohui,address = nanjing,company = codingo_v102017-08-05 18:05:04 - CHILD_UPDATED,/a3/m1/v2/t2name = zhaohui,address = nanjing,company = codingo_v11name = zhaohui,address = nanjing,company = codingo_v11 总结通过Zookeeper实现了一个简单的参数化平台，当然想在生产中使用还有很多需要优化的地方，本文在于提供一个思路；当然除了Zookeeper还可以使用MQ，分布式缓存等来实现参数化平台。","tags":[{"name":"UCM","slug":"UCM","permalink":"https://ningyu1.github.io/tags/UCM/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://ningyu1.github.io/tags/Zookeeper/"}]},{"title":"[转]Redis实现参数的集中式管理","date":"2017-09-05T08:40:36.000Z","path":"20170905/17-redis-ucm.html","text":"点评虽然现在开源的UCM套件很多，UCM统一配置管理（百度的disconf、阿里的diamond、点评的lion，等很多开源的）。但是很多人是知其然不知其所以然，刚好发现下面这篇文章可以作为原理的教程文章，使用JMS、Redis、Zookeeper简单的实现UCM基本功能，作为学习交流还是很不错的。 文章转自：https://my.oschina.net/OutOfMemory/blog/1526063作者：@ksfzhaohui 前言利用的Redis的发布订阅功能实现对参数的集中式管理；分布式缓存Redis提供了类似的发布订阅功能，并且Redis本身提供了缓存和持久化的功能，本文将介绍通过Redis实现简单的参数集中式管理。 Maven引入Spring相关的jar引入参考上一篇文章 &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.4.0&lt;/version&gt;&lt;/dependency&gt; 目标 可以同时配置监听多个节点如/app1,/app2； 希望只需要配置如/app1，就能够监听其子节点如/app1/modual1以及子节点的子节点如/app1/modual1/xxx/…； 服务器启动能获取当前指定父节点下的所有子节点数据； 在添加节点或者在更新节点数据的时候能够动态通知，这样代码中就能够实时获取最新的数据； spring配置中可以从Zookeeper中读取参数进行初始化。 虽然在实现的方式上有点区别，但是最终达成的目标是一致的，同样列出了这5条目标 实现RedisWatcher主要用来和Redis进行连接，然后对监听的节点进行初始化，模糊订阅需要监听的节点，最后接受数据的变更，更新本地数据，存储数据等。 1.同时配置监听多个节点提供一个字符串数组给用户用来添加需要监听的节点： private String[] keyPatterns; 2.能够监听其子节点以及子节点的子节点使用Redis提供的psubscribe命令，订阅一个或多个符合给定模式的频道，提供了模糊订阅的功能 private void watcherPaths() &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; jedis.psubscribe(new JedisPubSub() &#123; @Override public void onMessage(String channel, String message) &#123; try &#123; keyValueMap.put(channel, message); LOGGER.info(\"key = \" + channel + \",value = \" + message); &#125; catch (Exception e) &#123; LOGGER.error(\"onMessage error\", e); &#125; &#125; @Override public void onPMessage(String arg0, String arg1, String arg2) &#123; System.out.println(\"onPMessage=&gt;\" + arg0 + \"=\" + arg1 + \"=\" + arg2); &#125; @Override public void onPSubscribe(String pattern, int subscribedChannels) &#123; LOGGER.info(\"onPSubscribe=&gt;\" + pattern + \"=\" + subscribedChannels); &#125; @Override public void onPUnsubscribe(String arg0, int arg1) &#123; &#125; @Override public void onSubscribe(String arg0, int arg1) &#123; &#125; @Override public void onUnsubscribe(String arg0, int arg1) &#123; &#125; &#125;, getSubKeyPatterns()); &#125; &#125;).start();&#125; 3.服务器启动初始化节点数据通过使用keys命令来获取匹配节点的数据（keys命令可能引发性能问题，根据实际情况使用） private void initKeyValues() &#123; for (String keyPattern : keyPatterns) &#123; Set&lt;String&gt; keys = jedis.keys(keyPattern + \"*\"); for (String key : keys) &#123; String value = jedis.get(key); keyValueMap.put(key, value); LOGGER.info(\"init key = \" + key + \",value = \" + value); &#125; &#125;&#125; 4.监听节点数据的变更目标2中通过psubscribe命令，使用模糊订阅来监听数据的变更，onMessage用来接受变更的数据 5.spring配置中可以从Redis中读取参数进行初始化 public class RedisPropPlaceholderConfigurer extends PropertyPlaceholderConfigurer &#123; private RedisWatcher rediswatcher; @Override protected Properties mergeProperties() throws IOException &#123; return loadPropFromRedis(super.mergeProperties()); &#125; /** * 从Redis中加载配置的常量 * * @param result * @return */ private Properties loadPropFromRedis(Properties result) &#123; rediswatcher.watcherKeys(); rediswatcher.fillProperties(result); return result; &#125;&#125; 通过以上的处理，可以使用如下简单的配置来达到目标： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd\"&gt; &lt;bean id=\"rediswatcher\" class=\"zh.maven.DynamicConf.redis.RedisWatcher\"&gt; &lt;property name=\"keyPatterns\" value=\"/a2,/a3\" /&gt; &lt;/bean&gt; &lt;bean id=\"propertyConfigurer\" class=\"zh.maven.DynamicConf.redis.RedisPropPlaceholderConfigurer\"&gt; &lt;property name=\"rediswatcher\" ref=\"rediswatcher\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"person\" class=\"zh.maven.DynamicConf.Person\"&gt; &lt;property name=\"name\"&gt; &lt;value&gt;$&#123;/a2/m1&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name=\"address\"&gt; &lt;value&gt;$&#123;/a3/m1/v2&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name=\"company\"&gt; &lt;value&gt;$&#123;/a3/m1/v2/t2&#125;&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 测试1.启动Redis服务器 redis-server.exe 2.启动Redis客户端进行初始化数据 redis-cli.exeredis 127.0.0.1:6379&gt; set /a2/m1 zhaohuiOKredis 127.0.0.1:6379&gt; set /a3/m1/v2 nanjingOKredis 127.0.0.1:6379&gt; set /a3/m1/v2/t2 codingoOK 3.启动Main类 public class Main &#123; public static void main(String[] args) throws Exception &#123; ApplicationContext context = new ClassPathXmlApplicationContext(new String[] &#123; \"spring-config.xml\" &#125;); Person person = (Person) context.getBean(\"person\"); System.out.println(person.toString()); &#125;&#125; 4.启动RedisPublish定时发布数据，同时查看集群节点的Main类日志输出 public class RedisPublish &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis(\"127.0.0.1\", 6379); int i = 0; while (true) &#123; jedis.publish(\"/a2/b4/c1\" + i, \"message_\" + System.currentTimeMillis()); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; i++; &#125; &#125;&#125; 日志输出如下： 2017-08-30 10:44:00 - init key = /a2/m1,value = zhaohui2017-08-30 10:44:00 - init key = /a3/m1/v2,value = nanjing2017-08-30 10:44:00 - init key = /a3/m1/v2/t2,value = codingo2017-08-30 10:44:00 - onPSubscribe=&gt;/a2*=12017-08-30 10:44:00 - onPSubscribe=&gt;/a3*=22017-08-30 10:44:00 - Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@4bad4a49: defining beans [rediswatcher,propertyConfigurer,person]; root of factory hierarchyname = zhaohui,address = nanjing,company = codingoonPMessage=&gt;/a2*=/a2/b4/c10=message_1504061045414onPMessage=&gt;/a2*=/a2/b4/c11=message_1504061047458onPMessage=&gt;/a2*=/a2/b4/c12=message_1504061049458onPMessage=&gt;/a2*=/a2/b4/c13=message_1504061051458 总结关于参数的集中式管理一共写了三篇文章，分别利用Zookeeper，MQ以及Redis来实现了一个简单的参数的集中式管理，但更多的只是提供了一个思路离生产还有很大距离，本片文章也是这个系列的最后一篇，综合来看Zookeeper更加适合做参数的集中式管理平台，MQ方式本身没有提供存储的功能只能作为一个中间层存在；而Redis方式虽然提供了持久化功能，但是会因为选择不同的持久化方式会出现丢数据的可能，还有就是本身的集群方式并不是很完善；虽然Zookeeper本身并不是一个存储系统，但是紧紧用来存储少量的参数应该足够了。","tags":[{"name":"Redis","slug":"Redis","permalink":"https://ningyu1.github.io/tags/Redis/"},{"name":"UCM","slug":"UCM","permalink":"https://ningyu1.github.io/tags/UCM/"}]},{"title":"Spring框架-事务管理注意事项","date":"2017-08-26T08:40:36.000Z","path":"20170826/16-spring-transaction.html","text":"常见事务问题 事务不起作用 可能是配置不起效，如扫描问题 事务自动提交了（批量操作中） 可能是在没事务的情况下，利用了数据库的隐式提交 事务配置说明通常情况下我们的Spring Component扫描分为两部分，一部分是Spring Servlet(MVC)，一部分是其他Context Config的内容。主要扫描Annotation定义，包括@Controller、@Autowired、@Resource、@Service、@Component、@Repository等。 Spring Servlet部分的扫描配置可以通过web.xml中DispatchServlet的init-param节点配置确定。 Context Config部分的扫描配置为非以上配置的其他Spring配置文件确定。 为了能够使用事务，需要防止因Spring Servlet的扫描导致@Service事务配置失效。可以调整DispatchServlet中的配置文件，排除对@Service的扫描。 配置如下：&lt;context:component-scan base-package=\"com.jiuyescm.xxx\"&gt; &lt;context:exclude-filter type=\"annotation\" expression=\"org.springframework.stereotype.Service\" /&gt;&lt;/context:component-scan&gt; 如何通过日志判断事务是否已经被Spring所管理？ 在logback或者log4j中对org.springframework.aop、org.springframework.transaction、org.springframework.jdbc、org.mybatis.spring.transaction进行DEBUG级别日志跟踪（开发期） 查看日志中是否有事务管理、开启、提交、回滚等字符，如： DEBUG o.m.spring.transaction.SpringManagedTransaction - JDBC Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@28cfe912] will be managed by Spring 没有被控制的时候，日志如下： DEBUG o.m.spring.transaction.SpringManagedTransaction - JDBC Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@28cfe912] will not be managed by Spring 如何通过程序判断是否存在事务？boolean flag = TransactionSynchronizationManager.isActualTransactionActive(); 返回true，则在事务控制下，否则不在控制下 什么时候做了隐式提交？在没有容器事务的情况下，系统会尝试隐时提交。 spring1 开发建议： 所有Service代码中设置Class级别的@Transactional，并设置为只读，开发时可以很容易发现误数据库操作的动作。如：@Transactional(readOnly=true)。 所有Service代码中Public的方法设置@Transactional，并根据实际情况设置Propagation，可以设置为REQUIRED。 对于有异常产生可能的情况下，根据情况选择合适的rollbackFor，默认情况下可以设置对Exception.class或BizException.class进行控制。 尽可能减少嵌套的使用方法（Service call Service），采用传统的Controller-》Service-》Repository(DAO)的模型。 如果需要深入了解Transaction的流程，请自行翻阅和跟踪Spring和Mybatis相关代码。 以下是嵌套事务的各种情况下的执行结果（前提数据库的AutoCommit为true） 编号 External（Service） Internal（Service） Result Memo 1 No Transactional No Transactional All Committed Auto Commit = True 2 No Transactional Class Level ReadOnly Transactional External Committed Internal TransientDataAccessResourceException Can’t update table 3 No Transactional Transactional(REQUIRED) All Committed 4 No Transactional Transactional(REQUIRES_NEW) All Committed 5 No Transactional Transactional(SUPPORTS) All Committed 6 No Transactional Transactional(MANDATORY) External Committed Internal IllegalTransactionStateException Must under transaction 7 No Transactional Transactional(NOT_SUPPORTED) All Committed 8 No Transactional Transactional(NEVER) All Committed 9 No Transactional Transactional(NESTED) All Committed 10 No Transactional Transactional(REQUIRED) rollackFor=Exception.class IOException External Committed Internal Rollbacked 11 No Transactional Transactional(REQUIRED) rollbackFor=RuntimeException.class IOException All Committed 12 No Transactional Transactional(REQUIRED) rollbackFor=Exception.class RuntimeException External Committed Internal Rollbacked 13 No Transactional Transactional(REQUIRED) rollbackFor=RuntimeException.class RuntimeException External Committed Internal Rollbacked 14 Class Level ReadOnly Transactional No Transactional External TransientDataAccessResourceException Can’t update table 15 Class Level ReadOnly Transactional Class Level ReadOnly Transactional External TransientDataAccessResourceException Can’t update table 16 Transactional(REQUIRED) No Transactional All Committed 17 Transactional(REQUIRES_NEW) No Transactional All Committed 18 Transactional(SUPPORTS) No Transactional All Committed 19 Transactional(MANDATORY) No Transactional External IllegalTransactionStateException Must under transaction 20 Transactional(NOT_SUPPORTED) No Transactional All Committed 21 Transactional(NEVER) No Transactional All Committed 22 Transactional(NESTED) No Transactional All Committed 23 Transactional(REQUIRED) Transactional(REQUIRED) All Committed 24 Transactional(REQUIRED) Transactional(REQUIRES_NEW) All Committed 25 Transactional(REQUIRED) Transactional(SUPPORTS) All Committed 26 Transactional(REQUIRED) Transactional(MANDATORY) All Committed 27 Transactional(REQUIRED) Transactional(NOT_SUPPORTED) All Committed 28 Transactional(REQUIRED) Transactional(NEVER) External Rollbacked Internal IllegalTransactionStateException Must under transaction 29 Transactional(REQUIRED) Transactional(NESTED) All Committed 30 Transactional(REQUIRED) rollackFor=Exception.class Transactional(REQUIRED) rollackFor=Exception.class IOException All Rollbacked 31 Transactional(REQUIRED) rollackFor=Exception.class Transactional(REQUIRED) rollbackFor=RuntimeException.class IOException All Rollbacked 32 Transactional(REQUIRED) rollackFor=RuntimeException.class Transactional(REQUIRED) rollackFor=Exception.class IOException All Rollbacked UnexpectedRollbackException 33 Transactional(REQUIRED) rollackFor=RuntimeException.class Transactional(REQUIRED) rollbackFor=RuntimeException.class IOException All Committed 34 Transactional(REQUIRED) rollackFor=Exception.class Transactional(REQUIRED) rollackFor=Exception.class RuntimeException All Rollbacked 35 Transactional(REQUIRED) rollackFor=Exception.class Transactional(REQUIRED) rollbackFor=RuntimeException.class RuntimeException All Rollbacked 36 Transactional(REQUIRED) rollackFor=RuntimeException.class Transactional(REQUIRED) rollackFor=Exception.class RuntimeException All Rollbacked 37 Transactional(REQUIRED) rollackFor=RuntimeException.class Transactional(REQUIRED) rollbackFor=RuntimeException.class RuntimeException All Rollbacked 38 Transactional(REQUIRED) rollackFor=Exception.class Transactional(REQUIRED) rollackFor=Exception.class IOException Catch IOException All Committed 39 Transactional(REQUIRED) rollackFor=Exception.class Catch IOExceptio Transactional(REQUIRED) rollbackFor=Exception.class IOException All Rollbacked UnexpectedRollbackException 40 Transactional(REQUIRED) rollackFor=Exception.class Catch IOException Transactional(REQUIRED) rollbackFor=RuntimeException.class IOException All Committed 其他情况按照事务是否开启和是否抛出（捕获）对应异常来判断结果。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://ningyu1.github.io/tags/Spring/"},{"name":"Transaction","slug":"Transaction","permalink":"https://ningyu1.github.io/tags/Transaction/"}]},{"title":"NPE（java.lang.NullPointerException）防范","date":"2017-08-26T08:01:36.000Z","path":"20170826/15-java-npe.html","text":"我们程序中NPE还是比较多的，下面介绍良好的编码规范防止NPE的发生 NPE（java.lang.NullPointerException）: 空指针异常 一、【推荐】防止 NPE，是程序员的基本修养，注意 NPE 产生的场景：1） 返回类型为基本数据类型， return 包装数据类型的对象时，自动拆箱有可能产生 NPE。 反例： public int f() { return Integer 对象}， 如果为 null，自动解箱抛 NPE。 2） 数据库的查询结果可能为 null。 3） 集合里的元素即使 isNotEmpty，取出的数据元素也可能为 null。 4） 远程调用返回对象时，一律要求进行空指针判断，防止 NPE。 5） 对于 Session 中获取的数据，建议 NPE 检查，避免空指针。 6） 级联调用 obj.getA().getB().getC()； 一连串调用，易产生 NPE。 正例： 使用 JDK8 的 Optional 类来防止 NPE 问题。 ps.我们现在开发规范jdk版本jdk1.7.0_45，对于jdk8里面的optional可以了解学习，它是一种友好的解决方式。 二、【强制】当某一列的值全是 NULL 时， count(col)的返回结果为 0，但 sum(col)的返回结果为NULL，因此使用 sum()时需注意 NPE 问题。 正例： 可以使用如下方式来避免 sum 的 NPE 问题： SELECT IF(ISNULL(SUM(g)),0,SUM(g)) FROM table; 三、【推荐】高度注意 Map 类集合 K/V 能不能存储 null 值的情况，如下表格： 集合类 Key Value Super 说明 Hashtable 不允许为null 不允许为null Dictionary 线程安全 ConcurrentHashMap 不允许为null 不允许为null AbstractMap 分段锁技术 TreeMap 不允许为null 允许为null AbstractMap 线程不安全 HashMap 允许为null 允许为null AbstractMap 线程不安全 反例： 由于 HashMap 的干扰，很多人认为 ConcurrentHashMap 是可以置入 null 值，而事实上， 存储 null 值时会抛出 NPE 异常。 四、【推荐】方法的返回值可以为 null，不强制返回空集合，或者空对象等，必须添加注释充分说明什么情况下会返回 null 值。调用方需要进行 null 判断防止 NPE 问题。 说明： 明确防止 NPE 是调用者的责任。即使被调用方法返回空集合或者空对象，对调用 者来说，也并非高枕无忧，必须考虑到远程调用失败、 序列化失败、 运行时异常等场景返回 null 的情况。 五、关于基本数据类型与包装数据类型的使用标准如下：1） 【强制】 所有的 POJO 类属性必须使用包装数据类型。 2） 【强制】 RPC 方法的返回值和参数必须使用包装数据类型。 3） 【 推荐】 所有的局部变量使用基本数据类型。 说明： POJO 类属性没有初值是提醒使用者在需要使用时，必须自己显式地进行赋值，任何 NPE 问题，或者入库检查，都由使用者来保证。 正例： 数据库的查询结果可能是 null，因为自动拆箱，用基本数据类型接收有 NPE 风险。 以上内容摘自阿里巴巴Java开发手册v1.2.0.pdf","tags":[{"name":"NPE","slug":"NPE","permalink":"https://ningyu1.github.io/tags/NPE/"},{"name":"NullPointException","slug":"NullPointException","permalink":"https://ningyu1.github.io/tags/NullPointException/"}]},{"title":"JVM调优总结 -Xms -Xmx -Xmn -Xss","date":"2017-08-26T07:56:36.000Z","path":"20170826/15-java-jvm.html","text":"堆大小设置JVM 中最大堆大小有三方面限制：相关操作系统的数据模型（32-bt还是64-bit）限制；系统的可用虚拟内存限制；系统的可用物理内存限制。32位系统下，一般限制在1.5G~2G；64为操作系统对内存无限制。我在Windows Server 2003 系统，3.5G物理内存，JDK5.0下测试，最大可设置为1478m。 典型设置 java -Xmx3550m -Xms3550m -Xmn2g -Xss128k-Xmx3550m：设置JVM最大可用内存为3550M。-Xms3550m：设置JVM促使内存为3550m。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。-Xmn2g：设置年轻代大小为2G。整个JVM内存大小=年轻代大小 + 年老代大小 + 持久代大小。持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。-Xss128k：设置每个线程的堆栈大小。JDK5.0以后每个线程堆栈大小为1M，以前每个线程堆栈大小为256K。更具应用的线程所需内存大小进行调整。在相同物理内存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。 java -Xmx3550m -Xms3550m -Xss128k -XX:NewRatio=4 -XX:SurvivorRatio=4 -XX:MaxPermSize=16m -XX:MaxTenuringThreshold=0-XX:NewRatio=4:设置年轻代（包括Eden和两个Survivor区）与年老代的比值（除去持久代）。设置为4，则年轻代与年老代所占比值为1：4，年轻代占整个堆栈的1/5-XX:SurvivorRatio=4：设置年轻代中Eden区与Survivor区的大小比值。设置为4，则两个Survivor区与一个Eden区的比值为2:4，一个Survivor区占整个年轻代的1/6-XX:MaxPermSize=16m:设置持久代大小为16m。-XX:MaxTenuringThreshold=0：设置垃圾最大年龄。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。 回收器选择JVM给了三种选择：串行收集器、并行收集器、并发收集器，但是串行收集器只适用于小数据量的情况，所以这里的选择主要针对并行收集器和并发收集器。默认情况下，JDK5.0以前都是使用串行收集器，如果想使用其他收集器需要在启动时加入相应参数。JDK5.0以后，JVM会根据当前系统配置进行判断。 java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:ParallelGCThreads=20 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC-XX:+UseConcMarkSweepGC：设置年老代为并发收集。测试中配置这个以后，-XX:NewRatio=4的配置失效了，原因不明。所以，此时年轻代大小最好用-Xmn设置。-XX:+UseParNewGC:设置年轻代为并行收集。可与CMS收集同时使用。JDK5.0以上，JVM会根据系统配置自行设置，所以无需再设置此值。 java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseConcMarkSweepGC -XX:CMSFullGCsBeforeCompaction=5 -XX:+UseCMSCompactAtFullCollection-XX:CMSFullGCsBeforeCompaction：由于并发收集器不对内存空间进行压缩、整理，所以运行一段时间以后会产生“碎片”，使得运行效率降低。此值设置运行多少次GC以后对内存空间进行压缩、整理。-XX:+UseCMSCompactAtFullCollection：打开对年老代的压缩。可能会影响性能，但是可以消除碎片 java -Xmx3800m -Xms3800m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:ParallelGCThreads=20-XX:+UseParallelGC：选择垃圾收集器为并行收集器。此配置仅对年轻代有效。即上述配置下，年轻代使用并发收集，而年老代仍旧使用串行收集。-XX:ParallelGCThreads=20：配置并行收集器的线程数，即：同时多少个线程一起进行垃圾回收。此值最好配置与处理器数目相等。 java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:ParallelGCThreads=20 -XX:+UseParallelOldGC-XX:+UseParallelOldGC：配置年老代垃圾收集方式为并行收集。JDK6.0支持对年老代并行收集。 java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:MaxGCPauseMillis=100-XX:MaxGCPauseMillis=100:设置每次年轻代垃圾回收的最长时间，如果无法满足此时间，JVM会自动调整年轻代大小，以满足此值。 java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:MaxGCPauseMillis=100 -XX:+UseAdaptiveSizePolicy-XX:+UseAdaptiveSizePolicy：设置此选项后，并行收集器会自动选择年轻代区大小和相应的Survivor区比例，以达到目标系统规定的最低相应时间或者收集频率等，此值建议使用并行收集器时，一直打开。 吞吐量优先的并行收集器如上文所述，并行收集器主要以到达一定的吞吐量为目标，适用于科学技术和后台处理等。 响应时间优先的并发收集器如上文所述，并发收集器主要是保证系统的响应时间，减少垃圾收集时的停顿时间。适用于应用服务器、电信领域等。 辅助信息JVM提供了大量命令行参数，打印信息，供调试使用。主要有以下一些： -XX:+PrintGC输出形式： [GC 118250K-&gt;113543K(130112K), 0.0094143 secs][Full GC 121376K-&gt;10414K(130112K), 0.0650971 secs] -XX:+PrintGCDetails输出形式： [GC [DefNew: 8614K-&gt;781K(9088K), 0.0123035 secs] 118250K-&gt;113543K(130112K), 0.0124633 secs][GC [DefNew: 8614K-&gt;8614K(9088K), 0.0000665 secs][Tenured: 112761K-&gt;10414K(121024K), 0.0433488 secs] 121376K-&gt;10414K(130112K), 0.0436268 secs] -XX:+PrintGCTimeStamps -XX:+PrintGC：PrintGCTimeStamps可与上面两个混合使用输出形式： [GC 98328K-&gt;93620K(130112K), 0.0082960 secs] -XX:+PrintGCApplicationConcurrentTime:打印每次垃圾回收前，程序未中断的执行时间。可与上面混合使用输出形式： Application time: 0.5291524 seconds -XX:+PrintGCApplicationStoppedTime：打印垃圾回收期间程序暂停的时间。可与上面混合使用输出形式： Total time for which application threads were stopped: 0.0468229 seconds -XX:PrintHeapAtGC:打印GC前后的详细堆栈信息输出形式： [GC &#123;Heap before gc invocations=7: def new generation total 55296K, used 52568K [0x1ebd0000, 0x227d0000, 0x227d0000) eden space 49152K, 99% used [0x1ebd0000, 0x21bce430, 0x21bd0000) from space 6144K, 55% used [0x221d0000, 0x22527e10, 0x227d0000) to space 6144K, 0% used [0x21bd0000, 0x21bd0000, 0x221d0000) tenured generation total 69632K, used 2696K [0x227d0000, 0x26bd0000, 0x26bd0000) the space 69632K, 3% used [0x227d0000, 0x22a720f8, 0x22a72200, 0x26bd0000) compacting perm gen total 8192K, used 2898K [0x26bd0000, 0x273d0000, 0x2abd0000) the space 8192K, 35% used [0x26bd0000, 0x26ea4ba8, 0x26ea4c00, 0x273d0000) ro space 8192K, 66% used [0x2abd0000, 0x2b12bcc0, 0x2b12be00, 0x2b3d0000) rw space 12288K, 46% used [0x2b3d0000, 0x2b972060, 0x2b972200, 0x2bfd0000) 34.735: [DefNew: 52568K-&gt;3433K(55296K), 0.0072126 secs] 55264K-&gt;6615K(124928K)Heap after gc invocations=8: def new generation total 55296K, used 3433K [0x1ebd0000, 0x227d0000, 0x227d0000) eden space 49152K, 0% used [0x1ebd0000, 0x1ebd0000, 0x21bd0000) from space 6144K, 55% used [0x21bd0000, 0x21f2a5e8, 0x221d0000) to space 6144K, 0% used [0x221d0000, 0x221d0000, 0x227d0000) tenured generation total 69632K, used 3182K [0x227d0000, 0x26bd0000, 0x26bd0000) the space 69632K, 4% used [0x227d0000, 0x22aeb958, 0x22aeba00, 0x26bd0000) compacting perm gen total 8192K, used 2898K [0x26bd0000, 0x273d0000, 0x2abd0000) the space 8192K, 35% used [0x26bd0000, 0x26ea4ba8, 0x26ea4c00, 0x273d0000) ro space 8192K, 66% used [0x2abd0000, 0x2b12bcc0, 0x2b12be00, 0x2b3d0000) rw space 12288K, 46% used [0x2b3d0000, 0x2b972060, 0x2b972200, 0x2bfd0000) &#125; , 0.0757599 secs] -Xloggc:filename:与上面几个配合使用，把相关日志信息记录到文件以便分析。 常见配置汇总 -XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况。 -XX:ParallelGCThreads=n:设置并发收集器年轻代收集方式为并行收集时，使用的CPU数。并行收集线程数。 -XX:ParallelGCThreads=n:设置并行收集器收集时使用的CPU数。并行收集线程数。 -XX:MaxGCPauseMillis=n:设置并行收集最大暂停时间 -XX:GCTimeRatio=n:设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n) -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:filename -XX: +UseSerialGC:设置串行收集器 -XX: +UseParallelGC:设置并行收集器 -XX: +UseParalledlOldGC:设置并行年老代收集器 -XX: +UseConcMarkSweepGC:设置并发收集器 -Xms:初始堆大小 -Xmx:最大堆大小 -XX:NewSize=n:设置年轻代大小 -XX:NewRatio=n:设置年轻代和年老代的比值。如:为3，表示年轻代与年老代比值为1：3，年轻代占整个年轻代年老代和的1/4 -XX:SurvivorRatio=n:年轻代中Eden区与两个Survivor区的比值。注意Survivor区有两个。如：3，表示Eden：Survivor=3：2，一个Survivor区占整个年轻代的1/5 -XX:MaxPermSize=n:设置持久代大小a. 堆设置b. 收集器设置c. 垃圾回收统计信息d. 并行收集器设置f. 并发收集器设置 调优总结年轻代大小选择 响应时间优先的应用：尽可能设大，直到接近系统的最低响应时间限制（根据实际情况选择）。在此种情况下，年轻代收集发生的频率也是最小的。同时，减少到达年老代的对象。 吞吐量优先的应用：尽可能的设置大，可能到达Gbit的程度。因为对响应时间没有要求，垃圾收集可以并行进行，一般适合8CPU以上的应用。 年老代大小选择 并发垃圾收集信息 持久代并发收集次数 传统GC信息 花在年轻代和年老代回收上的时间比例 响应时间优先的应用：年老代使用并发收集器，所以其大小需要小心设置，一般要考虑并发会话率和会话持续时间等一些参数。如果堆设置小了，可以会造成内存碎片、高回收频率以及应用暂停而使用传统的标记清除方式；如果堆大了，则需要较长的收集时间。最优化的方案，一般需要参考以下数据获得：减少年轻代和年老代花费的时间，一般会提高应用的效率 吞吐量优先的应用：一般吞吐量优先的应用都有一个很大的年轻代和一个较小的年老代。原因是，这样可以尽可能回收掉大部分短期对象，减少中期的对象，而年老代尽存放长期存活对象。 较小堆引起的碎片问题因为年老代的并发收集器使用标记、清除算法，所以不会对堆进行压缩。当收集器回收时，他会把相邻的空间进行合并，这样可以分配给较大的对象。但是，当堆空间较小时，运行一段时间以后，就会出现“碎片”，如果并发收集器找不到足够的空间，那么并发收集器将会停止，然后使用传统的标记、清除方式进行回收。如果出现“碎片”，可能需要进行如下配置： -XX:+UseCMSCompactAtFullCollection：使用并发收集器时，开启对年老代的压缩。 -XX:CMSFullGCsBeforeCompaction=0：上面配置开启的情况下，这里设置多少次Full GC后，对年老代进行压缩","tags":[{"name":"调优","slug":"调优","permalink":"https://ningyu1.github.io/tags/调优/"},{"name":"JVM","slug":"JVM","permalink":"https://ningyu1.github.io/tags/JVM/"}]},{"title":"关于Axios的GET与DELETE用法注意事项","date":"2017-08-24T02:51:30.000Z","path":"20170824/12-vue-axios.html","text":"axios的接口定义如下 vue1 config定义如下： vue2 因此，我们在使用get和delete时需要注意，这两个接口接收的第二个参数是config。用时，就需要区别对待，且需要与后台定义对应。 如果想参数在Query Parameter里面，那就用{params: params}，后台那边会用RequestParam接收 如果想参数在Payload里面，那就用{data: params}，后台那边会用RequestBody接收 如果后台不匹配，可能会抛ContentType错误的异常，如： vue3","tags":[{"name":"Vue.js","slug":"Vue-js","permalink":"https://ningyu1.github.io/tags/Vue-js/"},{"name":"Axios","slug":"Axios","permalink":"https://ningyu1.github.io/tags/Axios/"}]},{"title":"Trouble Shooting —— Redis AOF rewrite错误导致Redis被Block住","date":"2017-08-15T02:30:34.000Z","path":"20170815/11-redis-aof-pit.html","text":"问题现状：redis-cli 上去执行任何命令返回：connnection reset by peer 重启的应用无法连接到redis，已经建立连接的应用可以正常使用。 分析过程：第一反应查看redis 日志，如下： 1838:M 16 Aug 01:07:39.319 # Error opening /setting AOF rewrite IPC pipes: Numerical result out of range1838:M 16 Aug 01:07:39.319 * Starting automatic rewriting of AOF on 110% growth1838:M 16 Aug 01:07:39.319 # Error opening /setting AOF rewrite IPC pipes: Numerical result out of range1838:M 16 Aug 01:07:39.419 * Starting automatic rewriting of AOF on 110% growth1838:M 16 Aug 01:07:39.419 # Error opening /setting AOF rewrite IPC pipes: Numerical result out of range1838:M 16 Aug 01:07:39.441 # Error registering fd event for the new client: Numerical result out of range (fd=10311)1838:M 16 Aug 01:07:39.457 # Error registering fd event for the new client: Numerical result out of range (fd=10311)1838:M 16 Aug 01:07:39.457 # Error registering fd event for the new client: Numerical result out of range (fd=10311)1838:M 16 Aug 01:07:39.461 # Error registering fd event for the new client: Numerical result out of range (fd=10311)1838:M 16 Aug 01:07:39.461 # Error registering fd event for the new client: Numerical result out of range (fd=10311)1838:M 16 Aug 01:07:39.462 # Error registering fd event for the new client: Numerical result out of range (fd=10311) 上面有两种错误日志 Error opening /setting AOF rewrite IPC pipes: Numerical result out of range 写aof出错了，超限 Error registering fd event for the new client: Numerical result out of range (fd=10311) 创建连接没有成功，能看到fd已经是10311 过万了 出现这种问题第一个先去看一下redis现在有多少个连接数 &gt;netstat -anp|grep 6379&gt;499 查看redis.conf中配置maxclients没有配置，redis默认为10000这个时候有个疑问？为什么netstat查看的连接数只有499，但是redis日志中已经过万（ fd=10311）？这个问题值得思考？我们通过查询进程的fd看一下具体打开了多少个连接（在linux中任何连接都是open file） &gt;ls -al /proc/1838/fd | grep socket | wc -l&gt;499 &gt;ls -al /proc/1838/fd | wc -l&gt;10322 为什么fd中socket的只有499，所有类型的确是10322呢？通过具体查看发现有9823个全都是pipe类型的连接 &gt;ls -al /proc/1838/fd | grep pipe | wc -l&gt;9823 为什么redis进程会有那么多pipe的连接呢？难道是我们redis client使用的pipeline导致的连接泄漏？ 于是查看了Jedis的源码 /** * Synchronize pipeline by reading all responses. This operation close the pipeline. In order to * get return values from pipelined commands, capture the different Response&amp;lt;?&amp;gt; of the * commands you execute. */public void sync() &#123; if (getPipelinedResponseLength() &gt; 0) &#123; List&lt;Object&gt; unformatted = client.getAll(); for (Object o : unformatted) &#123; generateResponse(o); &#125; &#125;&#125; 能看到注释中有描述调用这个方法会操作连接关闭：This operation close the pipeline 又询问了开发的同学我们目前没有使用到pipelined，因此排除了这个可能 那问题来了是什么原因导致的pipe连接过多？ 网上兜了一圈没发现有价值的信息，没办法只能去扫redis源码， accetpCommonHandler函数源码： static void acceptCommonHandler(int fd, int flags) &#123; redisClient *c; if ((c = createClient(fd)) == NULL) &#123; redisLog(REDIS_WARNING, &quot;Error registering fd event for the new client: %s (fd=%d)&quot;, strerror(errno),fd); close(fd); /* May be already closed, just ignore errors */ return; &#125; /* If maxclient directive is set and this is one client more... close the * connection. Note that we create the client instead to check before * for this condition, since now the socket is already set in non-blocking * mode and we can send an error for free using the Kernel I/O */ if (listLength(server.clients) &gt; server.maxclients) &#123; char *err = &quot;-ERR max number of clients reached\\r\\n&quot;; /* That&apos;s a best effort error message, don&apos;t check write errors */ if (write(c-&gt;fd,err,strlen(err)) == -1) &#123; /* Nothing to do, Just to avoid the warning... */ &#125; server.stat_rejected_conn++; freeClient(c); return; &#125; server.stat_numconnections++; c-&gt;flags |= flags; &#125; ps.这个函数主要调用createClient初始化客户端相关数据结构以及对应的socket，初始化后会判断当前连接的客户端是否超过最大值，如果超过的话，会拒绝这次连接。否则，更新客户端连接数的计数。数据结构redisClient用于表示一个客户端的连接，包括一个客户多次请求的状态，createClient函数主要是初始化这个数据结构。在createClient函数中，首先是创建redisClient，然后是设置socket的属性，然后添加该socket的读事件 createClient函数源码： if (fd != -1) &#123; anetNonBlock(NULL,fd); // &lt;MM&gt; // 关闭Nagle算法，提升响应速度 // &lt;/MM&gt; anetEnableTcpNoDelay(NULL,fd); if (server.tcpkeepalive) anetKeepAlive(NULL,fd,server.tcpkeepalive); if (aeCreateFileEvent(server.el,fd,AE_READABLE, readQueryFromClient, c) == AE_ERR) &#123; close(fd); zfree(c); return NULL; &#125; &#125; ps.将socket设置为非阻塞的并且no delay，关闭Nagle算法，提升响应速度。最后会注册socket的读事件，事件处理函数是readQueryFromClient，这个函数便是客户端请求的起点，之后会详细介绍。 createClient函数的最后部分，就是对redisClient的属性初始化，代码不再列出。 当从acceptTcpHandler返回后，客户端的连接就建立完毕，接下来就是等待客户端的请求。 以上就是这个错误涉及到的redis源码 在redis的github上发现了有类似的问题issue：https://github.com/antirez/redis/issues/2857 在源码aof.c文件中 /* Parent */ server.stat_fork_time = ustime()-start; server.stat_fork_rate = (double) zmalloc_used_memory() * 1000000 / server.stat_fork_time / (1024*1024*1024); /* GB per second. */ latencyAddSampleIfNeeded(&quot;fork&quot;,server.stat_fork_time/1000); if (childpid == -1) &#123; serverLog(LL_WARNING, &quot;Can&apos;t rewrite append only file in background: fork: %s&quot;, strerror(errno)); return C_ERR; &#125; 源码发现在报出Can’t rewrite append only file in background: fork: %s这个错误的时候，没有关闭pipe连接 因此看到了redis官方的修复说明已经修复了这个问题，翻出github上的提交记录，如下 redis1 这个时候看到了希望 于是搜索日志寻找是否有上图的错误：Can’t rewrite append only file in background: fork 1838:M 15 Aug 13:52:01.101 # Can&apos;t rewrite append only file in background: fork: Cannot allocate memory1838:M 15 Aug 13:52:01.202 * Starting automatic rewriting of AOF on 100% growth1838:M 15 Aug 13:52:01.203 # Can&apos;t rewrite append only file in background: fork: Cannot allocate memory1838:M 15 Aug 13:52:01.303 * Starting automatic rewriting of AOF on 100% growth1838:M 15 Aug 13:52:01.304 # Can&apos;t rewrite append only file in background: fork: Cannot allocate memory 有很多我这里截取了前面的，总共出现的次数 &gt;less redis.log.1 | grep \"Can't rewrite append only file in background: fork\" | wc -l&gt;1644 基本可以断定是这个问题引发的连锁反应，这个时候我们需要研究一下Redis AOF机制，最终确认是否是这个问题导致。 研究redis AOF机制 redis aof rewirte机制，自动触发bgrewritedaof的条件： long long growth =(server.appendonly_current_size*100/base) - 100;if (growth &gt;=server.auto_aofrewrite_perc) 我们的配置文件配置的auto-aof-rewrite-percentage 为100，也就是说当写入日志文件文件大小超过上次rewrite之后的文件大小的百分之100的时候就触发rewrite（也就是超过2倍） ps.rewrite之后aof文件会保存keys的最后的状态，清除掉之前冗余的，来缩小这个文件。 通过分析aof rewrite发现rewrite出错就是导致Redis连接数超过最大值的罪魁祸首。分析总结：基本可以定位到，这个错误是个连锁反应最终导致Redis服务出现问题 首先redis在进行aof的rewrite的时候，会检查机器可以用的内存够不够支撑做aof rewrite，这个时候我们机器的可用内存太小，因此报了如下错误 Can&apos;t rewrite append only file in background: fork: Cannot allocate memory 但是rewirte自动触发机制当达到2倍的时候会一直触发，他就会一直尝试aof rewrite 在aof rewrite尝试的过程中，已经创建的连接还是可以正常使用，这导致aof的auto_aofrewrite_perc一直在增长但是无法写入到aof文件中，因此又暴漏出另外一个错误，如下所示 1838:M 16 Aug 01:07:39.319 * Starting automatic rewriting of AOF on 110% growth1838:M 16 Aug 01:07:39.319 # Error opening /setting AOF rewrite IPC pipes: Numerical result out of range 当aof rewirte出错时，从redis代码也能看到，他没有调用close pipes管道连接，这个就造成了服务器上有大量连接被占用（pipe类型） &gt;netstat -anp|grep 6379&gt;499&gt;ls -al /proc/1838/fd | grep socket | wc -l&gt;499&gt;ls -al /proc/1838/fd | grep pipe | wc -l&gt;9823&gt;ls -al /proc/1838/fd | wc -l&gt;10322 当连接到达maxclients 10000时就会拒绝新建连接，并且报如下错误 Error registering fd event for the new client: Numerical result out of range (fd=10311) 本次分析的结论这个问题未解决需要继续跟踪，可能需要升级redis的版本，目前看到3.2.9以上才修复了这个bug，我们用的3.0.6版本的跨度有点大兼容性也需要考虑，还要对redis的配置在进一步研究，通过timeout配置让自动关闭无用的连接着也是一个解决问题的思路，这次只是先定位问题，具体解决还需要进一步研究 这个问题的issue：#2857，#2883 这个问题的提交记录：fix #2883, #2857 pipe fds leak when fork() failed on bg aof rw 问题修改的文件：3.2.9分支 -&gt; aof.c文件","tags":[{"name":"调优","slug":"调优","permalink":"https://ningyu1.github.io/tags/调优/"},{"name":"Redis","slug":"Redis","permalink":"https://ningyu1.github.io/tags/Redis/"},{"name":"AOF","slug":"AOF","permalink":"https://ningyu1.github.io/tags/AOF/"},{"name":"AOF rewriting","slug":"AOF-rewriting","permalink":"https://ningyu1.github.io/tags/AOF-rewriting/"},{"name":"Connnection reset by peer","slug":"Connnection-reset-by-peer","permalink":"https://ningyu1.github.io/tags/Connnection-reset-by-peer/"},{"name":"Numerical result out of range","slug":"Numerical-result-out-of-range","permalink":"https://ningyu1.github.io/tags/Numerical-result-out-of-range/"},{"name":"Cannot allocate memory","slug":"Cannot-allocate-memory","permalink":"https://ningyu1.github.io/tags/Cannot-allocate-memory/"},{"name":"Can't rewrite append only file in background","slug":"Can-t-rewrite-append-only-file-in-background","permalink":"https://ningyu1.github.io/tags/Can-t-rewrite-append-only-file-in-background/"}]},{"title":"Lombok使用说明","date":"2017-07-19T07:22:56.000Z","path":"20170719/04-lombok-quick-start.html","text":"一、项目背景在写Java程序的时候经常会遇到如下情形： 新建了一个Class类，然后在其中设置了几个字段，最后还需要花费很多时间来建立getter和setter方法 lombok项目的产生就是为了省去我们手动创建getter和setter方法的麻烦，它能够在我们编译源码的时候自动帮我们生成getter和setter方法。即它最终能够达到的效果是：在源码中没有getter和setter方法，但是在编译生成的字节码文件中有getter和setter方法 比如源码文件： import java.io.Serializable;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;import lombok.extern.slf4j.Slf4j; @Data@Slf4j@NoArgsConstructor@AllArgsConstructorpublic class TestUserVo implements Serializable&#123; private static final long serialVersionUID = -5648809805573016853L; private Long id; private Long userId; /** * 获取 id * @return the id */ public Long getId() &#123; System.out.println(\"getId\"); return id; &#125; /** * 设置 id * @param id the id to set */ public void setId(Long id) &#123; System.out.println(\"setId\"); this.id = id; &#125;&#125; 以下是编译上述源码文件得到的字节码文件，对其反编译得到的结果import java.io.Serializable;import java.beans.ConstructorProperties;import java.io.PrintStream;import org.slf4j.Logger;import org.slf4j.LoggerFactory; public class TestUserVo implements Serializable &#123; public String toString() &#123; return \"TestUserVo(id=\" + getId() + \", userId=\" + getUserId() + \")\"; &#125; public int hashCode() &#123; int PRIME = 59; int result = 1; Object $id = getId(); result = result * 59 + ($id == null ? 43 : $id.hashCode()); Object $userId = getUserId(); result = result * 59 + ($userId == null ? 43 : $userId.hashCode()); return result; &#125; public void setUserId(Long userId) &#123; this.userId = userId; &#125; public boolean equals(Object o) &#123; if (o == this) &#123; return true; &#125; if (!(o instanceof TestUserVo)) &#123; return false; &#125; TestUserVo other = (TestUserVo) o; if (!other.canEqual(this)) &#123; return false; &#125; Object this$id = getId(); Object other$id = other.getId(); if (this$id == null ? other$id != null : !this$id.equals(other$id)) &#123; return false; &#125; Object this$userId = getUserId(); Object other$userId = other.getUserId(); return this$userId == null ? other$userId == null : this$userId.equals(other$userId); &#125; protected boolean canEqual(Object other) &#123; return other instanceof TestUserVo; &#125; private static final Logger log = LoggerFactory.getLogger(TestUserVo.class); private static final long serialVersionUID = -5648809805573016853L; private Long id; private Long userId; @ConstructorProperties(&#123; \"id\", \"userId\" &#125;) public TestUserVo(Long id, Long userId) &#123; this.id = id; this.userId = userId; &#125; public Long getUserId() &#123; return this.userId; &#125; public Long getId() &#123; System.out.println(\"getId\"); return this.id; &#125; public void setId(Long id) &#123; System.out.println(\"setId\"); this.id = id; &#125; public TestUserVo() &#123; &#125;&#125; 为什么推荐使用它呢，因为我们一般写一个pojo时很容易遗漏（equals、toString、hashCode、canEqual）这几个方法，使用Lombok不但可以在编译的时候自动生成getter、setter方法还会根据字段来生成（equals、toString、hashCode、canEqual）这几个方法. Lombok在生成getter、setter方法时不会覆盖我们源码中已经编写的getter、setter方法，所以可以大胆的使用。 下面介绍几个常用的 lombok 注解： @Data ：注解在类上；提供类所有属性的 getting 和 setting 方法，此外还提供了equals、canEqual、hashCode、toString 方法 @Setter：注解在属性上；为属性提供 setting 方法 @Getter：注解在属性上；为属性提供 getting 方法 @Log4j | @Slf4j | @Log ：注解在类上；为类提供一个 属性名为log 的 log4j | SLF4j | Log(java logging)日志对象 @NoArgsConstructor：注解在类上；为类提供一个无参的构造方法 @AllArgsConstructor：注解在类上；为类提供一个全参的构造方法 其他的查看官网的文档：https://projectlombok.org/features/all 二、使用方法Maven依赖：&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;lombok&lt;/version&gt;&lt;/dependency&gt;``` ps.版本为：1.16.18，并且`scope`为：`provided`，我们只在编译时使用。使用`lombok`项目的方法很简单，分为四个步骤： 1)在需要自动生成类上，加上自动生成注解（`@Data`、`@Setter`、`@Getter`、`@Log4j`、`@Slf4j`、`@Log`、`@NoArgsConstructor`、`@AllArgsConstructor`，等等）2)在编译类路径中加入`lombok.jar`包 ，`maven`中添加依赖3)使用支持`lombok`的编译工具编译源代码（关于支持`lombok`的编译工具，见“四、支持`lombok`的编译工具”） 4)编译得到的字节码文件中自动生成相应配置的代码### 三、原理分析 接下来进行`lombok`能够工作的原理分析，以`Oracle`的`javac`编译工具为例。 自从Java 6起，javac就支持“JSR 269 Pluggable Annotation Processing API”规范，只要程序实现了该API，就能在javac运行的时候得到调用。 举例来说，现在有一个实现了\"JSR 269 API\"的程序A,那么使用javac编译源码的时候具体流程如下： 1)javac对源代码进行分析，生成一棵抽象语法树(AST) 2)运行过程中调用实现了\"JSR 269 API\"的A程序 3)此时A程序就可以完成它自己的逻辑，包括修改第一步骤得到的抽象语法树(AST) 4)javac使用修改后的抽象语法树(AST)生成字节码文件 详细的流程图如下： ![流程图](/img/lombok/1.jpg)`lombok`本质上就是这样的一个实现了\"JSR 269 API\"的程序。在使用javac的过程中，它产生作用的具体流程如下：1)javac对源代码进行分析，生成一棵抽象语法树(AST) 2)运行过程中调用实现了\"JSR 269 API\"的lombok程序 3)此时`lombok`就对第一步骤得到的AST进行处理，找到@Data注解所在类对应的语法树(AST)，然后修改该语法树(AST)，增加`getter`和`setter`方法定义的相应树节点 4)javac使用修改后的抽象语法树(AST)生成字节码文件 ### 四、支持lombok的编译工具 1. 由“三、原理分析”可知，`Oracle` javac直接支持`lombok` 2. 常用的项目管理工具`Maven`所使用的java编译工具来源于配置的第三方工具，如果我们配置这个第三方工具为`Oracle` javac的话，那么`Maven`也就直接支持`lombok`了 3. Intellij Idea中配置，可以下载安装Intellij Idea中的\"Lombok plugin\"。 4. Eclipse中配置lombok支持（或者使用官方的plugin：[https://projectlombok.org/setup/eclipse](https://projectlombok.org/setup/eclipse \"https://projectlombok.org/setup/eclipse\")） 1. 去官网下载：[http://projectlombok.org/ ](http://projectlombok.org/ \"http://projectlombok.org/ \") 2. eclipse / myeclipse 手动安装 `lombok` 3. 将 lombok.jar 复制到 myeclipse.ini / eclipse.ini 所在的文件夹目录下 4. 打开 eclipse.ini / myeclipse.ini，在最后面插入以下两行并保存： 5. ``` -Xbootclasspath/lombok.jar -javaagent:lombok.jar 6. 重启 eclipse / myeclipse 如上配置后，在类以后用上无需书写getter、setter程序中也可以直接引用getter、setter方法其他IDE支持，请去官网：https://projectlombok.org/ 点击Install选择不同的IDE插件安装说明 五、lombok的罪恶使用lombok虽然能够省去手动创建setter和getter方法的麻烦，但是却大大降低了源代码文件的可读性和完整性，降低了阅读源代码的舒适度。","tags":[{"name":"Java","slug":"Java","permalink":"https://ningyu1.github.io/tags/Java/"},{"name":"Lombok","slug":"Lombok","permalink":"https://ningyu1.github.io/tags/Lombok/"}]},{"title":"Fastdfs安装说明与常见问题解决","date":"2017-07-04T00:00:00.000Z","path":"20170704/02-fastdfs-installer.html","text":"Fastdfs安装说明与常见问题解决docker中安装docker pull season/fastdfsdocker tag season/fastdfs 192.168.0.34:5000/season/fastdfsdocker push 192.168.0.34:5000/season/fastdfs 启动会获取tracker ip192.168.0.54:22122 monitor检测/usr/local/bin/fdfs_monitor /etc/fdfs/storage.conf storagestore_path0路径与base_path路径必须不同 物理机安装1.安装gityum install -y git 2.下载fastdfs源码git clone https://github.com/happyfish100/fastdfs.gitgit clone https://github.com/happyfish100/libfastcommon.gitgit clone https://github.com/happyfish100/fastdfs-nginx-module.git 3.下载nginxcp /home/jyftp/nginx-1.10.1.tar.gz ./tar -xvf nginx-1.10.1.tar.gz rm -rf nginx-1.10.1.tar.gz chown -R root.root nginx-1.10.1/mv nginx-1.10.1/ nginx 4.安装libfastcommon (fastdfs依赖的系统库）cd /usr/local/fastdfs/libfastcommon./make.sh./make.sh install 5.安装fastdfscd /usr/local/fastdfs/fastdfs./make.sh./make.sh install 6.安装nginxcd /usr/local/nginx./configure --prefix=/usr/local/nginx --conf-path=/usr/local/nginx/nginx.conf --add-module=/usr/local/fastdfs/fastdfs-nginx-module/srcmake make install 安装nginx错误处理错误信息：./configure: error: the HTTP rewrite module requires the PCRE library. 安装pcre-devel与openssl-devel解决问题，执行下面命令yum -y install pcre-devel openssl openssl-devel 错误信息：/data/soft/fastdfs-nginx-module/src/ngx_http_fastdfs_module.c:894: 错误：‘struct fdfs_http_context’没有名为‘if_modified_since’的成员/data/soft/fastdfs-nginx-module/src/ngx_http_fastdfs_module.c:897: 错误：‘struct fdfs_http_context’没有名为‘if_modified_since’的成员/data/soft/fastdfs-nginx-module/src/ngx_http_fastdfs_module.c:927: 错误：‘struct fdfs_http_context’没有名为‘range’的成员/data/soft/fastdfs-nginx-module/src/ngx_http_fastdfs_module.c:933: 错误：‘struct fdfs_http_context’没有名为‘if_range’的成员/data/soft/fastdfs-nginx-module/src/ngx_http_fastdfs_module.c:933: 错误：‘true’未声明(在此函数内第一次使用)make[1]: *** [objs/addon/src/ngx_http_fastdfs_module.o] 错误 1make[1]: Leaving directory `/data/soft/nginx-1.8.0&apos;make: *** [build] 错误 2 解决办法执行以下2条命令，然后重新makeln -sv /usr/include/fastcommon /usr/local/include/fastcommonln -sv /usr/include/fastdfs /usr/local/include/fastdfs 拷贝相关文件到/etc/fdfs目录下：cp /usr/local/fastdfs/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs/cp /usr/local/fastdfs/fastdfs/conf/mime.types /etc/fdfs/cp /usr/local/fastdfs/fastdfs/conf/http.conf /etc/fdfs/cp /usr/local/fastdfs/fastdfs/conf/anti-steal.jpg /etc/fdfs/ 如果是下面错误，需要安装fastdfs最新版，直接从github上下载源码安装local/fastdfs-nginx-module/src/common.c:1245: 错误：‘FDFSHTTPParams’没有名为‘support_multi_range’的成员make[1]: *** [objs/addon/src/ngx_http_fastdfs_module.o] 错误 1make[1]: Leaving directory `/usr/local/nginx-1.10.1&apos; 解决办法：github上下载最新FastDFS master源码，重新编译安装即可。 7.配置fastdfs7.1 创建数据存放目录（用于存放数据）cd /usr/local/fastdfsmkdir fast_datacd fast_data tracker基础数据和日志mkdir tracker storage基础数据和日志mkdir storage storage 数据存放目录mkdir store_path fast nginx模块基础数据和日志mkdir nginx_module 7.2 创建配置文件目录（用于存放使用的配置文件）mkdir fast_confcd /usr/local/fastdfs/fastdfs/confcp ./* /usr/local/fastdfs/fast_conf/ 7.3 配置tracker编辑basepath＃basepath(用于存放tracker的基本数据，包括日志）base_path=/usr/local/fastdfs/fast_data/tracker 7.4 配置storage修改如下配置：＃用于存储storage基本数据的目录（包括日志）base_path=/usr/local/fastdfs/fast_data/storage＃数据存放的目录store_path0=/usr/local/fastdfs/fast_data/store_path＃group的名字group_name=group1# tracker地址tracker_server=10.30.193.163:22122 这个是tracker的ip地址和端口号tracker_server=192.168.0.48:22122 7.5 修改nginx相关的fastdfs配置文件将nginx module的配置文件拷贝到fastdfs的配置目录cp /usr/local/fastdfs/fastdfs-nginx-module/src/mod_fastdfs.conf /usr/local/fastdfs/fast_conf 修改mod_fastdfs.conf#存放日志等文件base_path=/usr/local/fastdfs/fast_data/nginx_module#tracker的地址（这个是nginx中的plugin使用的）tracker_server=192.168.0.48:22122#本地对应的group名字（当前nginx对应的storage存储的group的名字）group_name=group1#这个配置用于说明nginx对应的storage存储文件的实际位置store_path0=/usr/local/fastdfs/fast_data/store_path#这个是url是否需要带groupnameurl_have_group_name = true 9. 编写启动脚本cd /usr/local/fastdfs 9.1 创建 启动文件目录mkdir bin tracker的启动脚本 9.2 在bin目录下，创建tracker.sh#!/bin/shcase \"$1\" in start) /usr/local/fastdfs/fastdfs/tracker/fdfs_trackerd /usr/local/fastdfs/fast_conf/tracker.conf ;; stop) /usr/local/fastdfs/fastdfs/tracker/fdfs_trackerd /usr/local/fastdfs/fast_conf/tracker.conf stop ;; restart) /usr/local/fastdfs/fastdfs/tracker/fdfs_trackerd /usr/local/fastdfs/fast_conf/tracker.conf restart ;;esac # tailf /usr/local/fastdfs/fast_data/tracker/logs/trackerd.logexit 0 将文件变成可执行chmod +x tracker.sh 9.3 在bin目录下，创建storage.sh#!/bin/shcase \"$1\" in start) /usr/local/fastdfs/fastdfs/storage/fdfs_storaged /usr/local/fastdfs/fast_conf/storage.conf ;; stop) /usr/local/fastdfs/fastdfs/storage/fdfs_storaged /usr/local/fastdfs/fast_conf/storage.conf stop ;; restart) /usr/local/fastdfs/fastdfs/storage/fdfs_storaged /usr/local/fastdfs/fast_conf/storage.conf restart ;;esac # tailf /usr/local/fastdfs/fast_data/storage/logs/storaged.logexit 0 将文件变成可执行chmod +x storage.sh 9.4 配置、启动nginx修改mod_fastdfs.conf配置文件cd /usr/local/fastdfs/fast_conf/vi mod_fastdfs.conf # FastDFS tracker_server can ocur more than once, and tracker_server format is# \"host:port\", host can be hostname or ip address# valid only when load_fdfs_parameters_from_tracker is truetracker_server=192.168.0.48:22122# the port of the local storage server# the default value is 23000storage_server_port=23000# if the url / uri including the group name# set to false when uri like /M00/00/00/xxx# set to true when uri like $&#123;group_name&#125;/M00/00/00/xxx, such as group1/M00/xxx# default value is falseurl_have_group_name = true# store_path#, based 0, if store_path0 not exists, it's value is base_path# the paths must be exist# must same as storage.confstore_path0=/usr/local/fastdfs/fast_data/store_path#store_path1=/home/yuqing/fastdfs1 copy配置文件到 /etc/fdfs下cd /usr/local/fastdfs/fast_conf/cp anti-steal.jpg http.conf mime.types mod_fastdfs.conf /etc/fdfs/ 修改nginx的配置文件cd /usr/local/nginxvi nginx.confserver &#123;listen 8079; location ~/M00 &#123; root /usr/local/fastdfs/fast_data/store_path/data; ngx_fastdfs_module; &#125;&#125; 创建软连接ln -s /usr/local/fastdfs/fast_data/store_path/data /usr/local/fastdfs/fast_data/store_path/data/M00 启动nginx之前先-t检查一下配置文件是否有错误/usr/local/nginx/sbin/nginx -t 输出一下信息表示正确[root@localhost bin]# /usr/local/nginx/sbin/nginx -tngx_http_fastdfs_set pid=125936nginx: the configuration file /usr/local/nginx/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/nginx.conf test is successful 启动nginx/usr/local/nginx/sbin/nginx 启动 Nginx 后会打印出fastdfs模块的pid，看看日志是否报错，正常不会报错的[root@localhost fdfs]# /usr/local/nginx/sbin/nginxngx_http_fastdfs_set pid=126276 遇到的错误错误：ERROR - file: storage_ip_changed_dealer.c, line: 186, connect to tracker server 172.0.0.1:22122 fail, errno: 110, error info: Connection timed out 防火墙中打开tracker服务器端口（ 默认为 22122）vi /etc/sysconfig/iptables 附加：若/etc/sysconfig 目录下没有iptables文件可随便写一条iptables命令配置个防火墙规则：如：iptables -P OUTPUT ACCEPT 然后用命令：service iptables save 进行保存，默认就保存到 /etc/sysconfig/iptables 文件里。这时既有了这个文件。防火墙也可以启动了。接下来要写策略，也可以直接写在/etc/sysconfig/iptables 里了。添加如下端口行：-A INPUT -m state --state NEW -m tcp -p tcp --dport 22122 -j ACCEPT -A INPUT -m state --state NEW -m tcp -p tcp --dport 23000 -j ACCEPT -A INPUT -m state --state NEW -m tcp -p tcp --dport 8079 -j ACCEPT # 22122 tracker 端口# 23000 storage 端口# 8079 nginx listen端口 重启防火墙service iptables restart Fastdfs Client测试执行命令/usr/bin/fdfs_test /usr/local/fastdfs/fast_conf/client.conf upload /usr/local/fastdfs/fast_conf/ 输出This is FastDFS client test program v5.11Copyright (C) 2008, Happy Fish / YuQingFastDFS may be copied only under the terms of the GNU GeneralPublic License V3, which may be found in the FastDFS source kit.Please visit the FastDFS Home Page http://www.csource.org/ for more detail.[2017-05-16 14:03:07] DEBUG - base_path=/usr/local/fastdfs/fast_data, connect_timeout=30, network_timeout=60, tracker_server_count=1, anti_steal_token=0, anti_steal_secret_key length=0, use_connection_pool=0, g_connection_pool_max_idle_time=3600s, use_storage_id=0, storage server id count: 0tracker_query_storage_store_list_without_group: server 1. group_name=, ip_addr=192.168.0.48, port=23000group_name=group1, ip_addr=192.168.0.48, port=23000storage_upload_by_filenamegroup_name=group1, remote_filename=M00/00/00/wKgAMFkalhuARwsaAAAFvLZ-36489.confsource ip address: 192.168.0.48file timestamp=2017-05-16 14:03:07file size=1468file crc32=3061768110example file url: http://192.168.0.48/group1/M00/00/00/wKgAMFkalhuARwsaAAAFvLZ-36489.confstorage_upload_slave_by_filenamegroup_name=group1, remote_filename=M00/00/00/wKgAMFkalhuARwsaAAAFvLZ-36489_big.confsource ip address: 192.168.0.48file timestamp=2017-05-16 14:03:08file size=1468file crc32=3061768110example file url: http://192.168.0.48/group1/M00/00/00/wKgAMFkalhuARwsaAAAFvLZ-36489_big.conf 查看Fastdfs集群监控信息执行命令/usr/bin/fdfs_monitor /usr/local/fastdfs/fast_conf/client.conf 输出[2017-05-16 14:17:38] DEBUG - base_path=/usr/local/fastdfs/fast_data, connect_timeout=30, network_timeout=60, tracker_server_count=1, anti_steal_token=0, anti_steal_secret_key length=0, use_connection_pool=0, g_connection_pool_max_idle_time=3600s, use_storage_id=0, storage server id count: 0server_count=1, server_index=0tracker server is 192.168.0.48:22122group count: 1Group 1:group name = group1disk total space = 46161 MBdisk free space = 33446 MBtrunk free space = 0 MBstorage server count = 1active server count = 1storage server port = 23000storage HTTP port = 8888store path count = 1subdir count per path = 256current write server index = 0current trunk file id = 0 Storage 1: id = 192.168.0.48 ip_addr = 192.168.0.48 ACTIVE http domain = version = 5.11 join time = 2017-05-16 11:40:48 up time = 2017-05-16 13:04:57 total storage = 46161 MB free storage = 33446 MB upload priority = 10 store_path_count = 1 subdir_count_per_path = 256 storage_port = 23000 storage_http_port = 8888 current_write_path = 0 source storage id = if_trunk_server = 0 connection.alloc_count = 256 connection.current_count = 0 connection.max_count = 2 total_upload_count = 3 success_upload_count = 3 total_append_count = 0 success_append_count = 0 total_modify_count = 0 success_modify_count = 0 total_truncate_count = 0 success_truncate_count = 0 total_set_meta_count = 3 success_set_meta_count = 3 total_delete_count = 0 success_delete_count = 0 total_download_count = 0 success_download_count = 0 total_get_meta_count = 0 success_get_meta_count = 0 total_create_link_count = 0 success_create_link_count = 0 total_delete_link_count = 0 success_delete_link_count = 0 total_upload_bytes = 4738 success_upload_bytes = 4738 total_append_bytes = 0 success_append_bytes = 0 total_modify_bytes = 0 success_modify_bytes = 0 stotal_download_bytes = 0 success_download_bytes = 0 total_sync_in_bytes = 0 success_sync_in_bytes = 0 total_sync_out_bytes = 0 success_sync_out_bytes = 0 total_file_open_count = 3 success_file_open_count = 3 total_file_read_count = 0 success_file_read_count = 0 total_file_write_count = 3 success_file_write_count = 3 last_heart_beat_time = 2017-05-16 14:17:31 last_source_update = 2017-05-16 14:14:16 last_sync_update = 1970-01-01 08:00:00 last_synced_timestamp = 1970-01-01 08:00:00","tags":[{"name":"fastdfs","slug":"fastdfs","permalink":"https://ningyu1.github.io/tags/fastdfs/"}]},{"title":"Nginx 502 Bad Gateway问题分析与踩过的坑","date":"2017-06-30T10:36:44.000Z","path":"20170630/03-nginx-502-Bad-Gateway.html","text":"我相信使用Nginx的都会遇到过502 504 这种bad gateway错误，下面我把碰到这个问题分析过程记录并分享出来。先让我们看一下具体的错误信息502 Bad GatewayThe proxy server received an invalid response from an upstream server 从字面上的意思理解，nginx从upstream没有接受到信息，第一感觉就是连接被close？还是超时了？超时的话一般错误信息是 timeout 下面是尝试解决这个问题尝试过的手段 1. 第一感觉是proxy返回超时，因此查找nginx官方文档，找到关于proxy的timeout设置Syntax: proxy_connect_timeout time;Default: proxy_connect_timeout 60s;Context: http, server, locationDefines a timeout for establishing a connection with a proxied server. It should be noted that this timeout cannot usually exceed 75 seconds. ps. 这个时间不能超过75秒Syntax: proxy_read_timeout time;Default: proxy_read_timeout 60s;Context: http, server, locationDefines a timeout for reading a response from the proxied server. The timeout is set only between two successive read operations, not for the transmission of the whole response. If the proxied server does not transmit anything within this time, the connection is closed. ps. 两次read的超时时间，并不是整个的response的超时时间Syntax: proxy_send_timeout time;Default: proxy_send_timeout 60s;Context: http, server, locationSets a timeout for transmitting a request to the proxied server. The timeout is set only between two successive write operations, not for the transmission of the whole request. If the proxied server does not receive anything within this time, the connection is closed. ps. 两次write的超时时间，并不是整个request的超时时间 配置后重启nginx服务进行测试仍然有502错误爆出，继续分析 2. 于是想到了keepalive，分析我们的请求报文头，报文是有keep-alive的头信息 site Architecture 那问题出在哪里？我们应该知道前端请求如果设置为长连接必须要服务端也支持长连接才行，难道是服务器上没有配置长连接导致的？ 翻nginx官网找keepalive的相关配置Syntax: keepalive_timeout timeout [header_timeout];Default: keepalive_timeout 75s;Context: http, server, locationThe first parameter sets a timeout during which a keep-alive client connection will stay open on the server side. The zero value disables keep-alive client connections. The optional second parameter sets a value in the “Keep-Alive: timeout=time” response header field. Two parameters may differ.The “Keep-Alive: timeout=time” header field is recognized by Mozilla and Konqueror. MSIE closes keep-alive connections by itself in about 60 seconds. ps.长连接保持的超时时间设置Syntax: keepalive connections;Default: —Context: upstreamThis directive appeared in version 1.1.4.Activates the cache for connections to upstream servers.The connections parameter sets the maximum number of idle keepalive connections to upstream servers that are preserved in the cache of each worker process. When this number is exceeded, the least recently used connections are closed. ps. 设置upstream长连接的数量 查看tomcat的keepalive的设置 keepAliveTimeout：表示在下次请求过来之前，tomcat保持该连接多久。这就是说假如客户端不断有请求过来，且为超过过期时间，则该连接将一直保持。 maxKeepAliveRequests：表示该连接最大支持的请求数。超过该请求数的连接也将被关闭（此时就会返回一个Connection: close头给客户端）。 以上设置调整后重启服务进行测试，仍然有502错误爆出，继续分析 3. 在nginx的log中发现了请求都是使用的HTTP 1.0，大家应该知道HTTP 1.0是不支持长连接的，于是顺着这条线继续查下去，为什么请求进来都是HTTP1.0呢？查看nginx官网的文档，发现proxy是可以只定HTTP版本的Syntax: proxy_http_version 1.0 | 1.1;Default: proxy_http_version 1.0;Context: http, server, locationThis directive appeared in version 1.1.4.Sets the HTTP protocol version for proxying. By default, version 1.0 is used. Version 1.1 is recommended for use with keepalive connections and NTLM authentication. ps. 1.1.4以后的版本nginx默认使用的是HTTP1.0 于是我们查看一下nginx的版本 nginx -v，我们用的是nginx version: nginx/1.10.1，理论上默认开启的http1.1，不过没关系我们配置一下proxy_http_version 1.1试一下，这个参数要结合上面说道的upstream中的keepalive一起使用才能有效果。 修改好之后重启服务再次进行测试，依然有502的错误爆出，无解！！！，继续分析，为什么版本不生效呢？ 我们前端请求的报文： site Architecture 请求的明明是HTTP 1.1为什么到nginx中成了HTTP 1.0？ 于是想到我们使用了阿里云的SLB，会不会是SLB的问题，先测试一下不通过SLB直接访问，查看日志100.97.90.213 - - [30/Jun/2017:10:44:09 +0800] \"GET /api/v1/saleorder?dataSource=&amp;salesStatus=01&amp;shopNo=&amp;carrierAssignStatus=&amp;creTimeBegin=2017-06-30+00:00:00&amp;creTimeEnd=2017-06-30+23:59:59&amp;salesNo=&amp;status=&amp;carrierStatus=&amp;warehouseStatus=&amp;dataTranslateStatus=&amp;buyerAccount=&amp;changeBuyer=-1&amp;changeSeller=-1&amp;platformOrderTime=&amp;platformOrderEndTime=&amp;confirmPayTime=&amp;confirmPayEndTime=&amp;receiverMobile=&amp;receiverProvince=&amp;receiverCity=&amp;receiverArea=&amp;referenceNo=&amp;receiverName=&amp;page=1&amp;pageSize=50&amp;__preventCache=1498790641974 HTTP/1.1\" 200 105705 \"https://erp-uat.jiuyescm.com/\" \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36\" 日志果然出现了HTTP/1.1，这个让我们找到了希望，但是还有个区别，直接访问走的是ip+port普通的http，slb访问走的是域名而且是ssl，这个会不会跟ssl有关系，于是查询了ssl的http版本支持情况排除了这个问题，那就是继续往SLB上怀疑，翻阿里云负载均衡的说明文档。 让我找到了说明，查看如下信息 site Architecture 找了半天原来是SLB强制转换了协议版本，具体查看阿里云负载均衡的常见问题 问题没有解决，需要咨询阿里云工作人员看对于这类问题是否有好的解决方法，问题持续跟踪 跟阿里云客服沟通后，官方人员建议使用长连接通过slb的tcp协议，我们当初为了ssl方便配置slb选择的是http和https，因此就需要修改部署的结构 删除原有的slb 增加一个新的slb，协议选择tcp，添加两个端口监听，80-xxxx，443-xxxx 域名绑定的ip切换到新创建的slb nginx中添加ssl-module，添加ssl证书配置，添加http跳转到https，调整80-xxxx，443-xxxx 重启nginx进行测试测试通过 site Architecture 采用这种部署方式来解决nginx 502问题","tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://ningyu1.github.io/tags/Nginx/"},{"name":"Bad Gateway","slug":"Bad-Gateway","permalink":"https://ningyu1.github.io/tags/Bad-Gateway/"},{"name":"调优","slug":"调优","permalink":"https://ningyu1.github.io/tags/调优/"}]},{"title":"Cache设计和使用上的套路","date":"2017-06-02T06:06:34.000Z","path":"20170602/05-cache-design.html","text":"一、管道（pipeline）提升效率Redis是一个cs模式的tcp server，使用和http类似的请求响应协议。一个client可以通过一个socket连接发起多个请求命令。每个请求命令发出后client通常会阻塞并等待redis服务处理，redis处理完后请求命令后会将结果通过响应报文返回给client。每执行一个命令需要2个tcp报文才能完成，由于通信会有网络延迟,假如从client和server之间的包传输时间需要0.125秒，那么执行四个命令8个报文至少会需要1秒才能完成，这样即使redis每秒能处理100k命令，而我们的client也只能一秒钟发出四个命令。这显示没有充分利用 redis的处理能力。因此我们需要使用管道（pipeline）的方式从client打包多条命令一起发出，不需要等待单条命令的响应返回，而redis服务端会处理完多条命令后会将多条命令的处理结果打包到一起返回给客户端（它能够让（多条）执行命令简单的，更加快速的发送给服务器，但是没有任何原子性的保证）官方资料 【反例】 cache1 【正例】//管道，批量发送多条命令，但是不支持namespace需要手动添加namespacePipeline pipelined = redisClient.pipelined();pipelined.set(key, value);pipelined.get(key);pipelined.syncAndReturnAll(); //发送命令并接受返回值pipelined.sync();//发送命令不接受返回值 使用管道注意事项： tcp报文过长会被拆分。 如果使用pipeline服务器会被迫使用内存队列来发送应答（服务器会在处理完命令前先缓存所有的命令处理结果） 打包的命令越多，缓存消耗内存也越多，所以并不是打包命令越多越好，需要结合测试找到合适我们业务场景的量（双刃剑） 不保证原子性，因此在Redis中没有数据需要走DB获取数据，Redis也支持事务（multi、watch）但是会影响性能（没有事务和有事务相差还是蛮大的），不是非要强一致的场景请不要使用。 二、连接池使用问题jedis客户端2.4版本以上对连接池资源使用上进行了优化，提供了更优雅的资源回收方法并且支持broken处理，提供close方法替换原来的回收资源方法（returnBrokenResource 、returnResource） 【反例】 cache2 【正例】 cache3 三、使用key值前缀来作命名空间虽然说Redis支持多个数据库（默认32个，可以配置更多），但是除了默认的0号库以外，其它的都需要通过一个额外请求才能使用。所以用前缀作为命名空间可能会更明智一点。另外，在使用前缀作为命名空间区隔不同key的时候，最好在程序中使用全局配置来实现，直接在代码里写前缀的做法要严格避免，这样可维护性实在太差了。 命名分割符使用 “.” 分隔 【正例】 cache4 四、expire对于key过期时间来控制垃圾回收Redis是一个提供持久化功能的内存数据库，如果你不指定上面值的过期时间（TTL），并且也不进行定期的清理工作，那么你的Redis内存占用会越来越大，当有一天它超过了系统可用内存，那么swap上场，离性能陡降的时间就不远了。所以在Redis中保存数据时，一定要预先考虑好数据的生命周期，这有很多方法可以实现。 比如你可以采用Redis自带的过期时间（setEX）为你的数据设定过期时间。但是自动过期有一个问题，很有可能导致你还有大量内存可用时，就让key过期去释放内存，或者是内存已经不足了key还没有过期。 （LRU）如果你想更精准的控制你的数据过期，你可以用一个ZSET来维护你的数据更新程度，你可以用时间戳作为score值，每次更新操作时更新一下score，这样你就得到了一个按更新时间排序序列串，你可以轻松地找到最老的数据，并且从最老的数据开始进行删除，一直删除到你的空间足够为止。 【正例】redisClient.setex(bizkey, 60, value);//set一个key并设置ttl60秒 五、乱用（不要有个锤子看哪都是钉子）当你使用Redis构建你的服务的时候，一定要记住，你只是找了一个合适的工具来实现你需要的功能。而不是说你在用Redis构建一个服务，这是很不同的，你把Redis当作你很多工具中的一个，只在合适使用的时候再使用它，在不合适的时候选择其它的方法。 我们对它的定位更多是Cache服务而非DB 六、缓存设计的误区我们通常是这样设计的，应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。 那试想一下，如果取出来的null，需不需要放入cache呢？答案当然是需要的。 我们试想一下如果取出为null不放入cache会有什么结果？很显然每次取cache没有走db返回null，很容易让攻击者利用这个漏洞搞垮你的服务器，利用洪水攻击让你的程序夯在这个地方导致你的正常流程抢不到资源。 七、缓存更新的问题以下内容摘自酷壳-COOLSHELL的文章《缓存更新的套路》 很多人在写更新缓存数据代码时，先删除缓存，然后再更新数据库，而后续的操作会把数据再装载的缓存中。然而，这个是逻辑是错误的。试想，两个并发操作，一个是更新操作，另一个是查询操作，更新操作删除缓存后，查询操作没有命中缓存，先把老数据读出来后放到缓存中，然后更新操作更新了数据库。于是，在缓存中的数据还是老的数据，导致缓存中的数据是脏的，而且还一直这样脏下去了。 正确更新缓存的Design Pattern有四种：Cache aside, Read through, Write through, Write behind caching Cache Aside Pattern 这是最常用最常用的pattern了。其具体逻辑如下： cache5 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。 命中：应用程序从cache中取数据，取到后返回。 更新：先把数据存到数据库中，成功后，再让缓存失效。 注意，我们的更新是先更新数据库，成功后，让缓存失效。那么，这种方式是否可以没有文章前面提到过的那个问题呢？我们可以脑补一下。 一个是查询操作，一个是更新操作的并发，首先，没有了删除cache数据的操作了，而是先更新了数据库中的数据，此时，缓存依然有效，所以，并发的查询操作拿的是没有更新的数据，但是，更新操作马上让缓存的失效了，后续的查询操作再把数据从数据库中拉出来。而不会像文章开头的那个逻辑产生的问题，后续的查询操作一直都在取老的数据。 这是标准的design pattern，包括Facebook的论文《Scaling Memcache at Facebook》也使用了这个策略。为什么不是写完数据库后更新缓存？你可以看一下Quora上的这个问答《Why does Facebook use delete to remove the key-value pair in Memcached instead of updating the Memcached during write request to the backend?》，主要是怕两个并发的写操作导致脏数据 那么，是不是Cache Aside这个就不会有并发问题了？不是的，比如，一个是读操作，但是没有命中缓存，然后就到数据库中取数据，此时来了一个写操作，写完数据库后，让缓存失效，然后，之前的那个读操作再把老的数据放进去，所以，会造成脏数据。 但，这个case理论上会出现，不过，实际上出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率基本并不大。 所以，这也就是Quora上的那个答案里说的，要么通过2PC或是Paxos协议保证一致性，要么就是拼命的降低并发时脏数据的概率，而Facebook使用了这个降低概率的玩法，因为2PC太慢，而Paxos太复杂。当然，最好还是为缓存设置上过期时间。 Read/Write Through Pattern 我们可以看到，在上面的Cache Aside套路中，我们的应用代码需要维护两个数据存储，一个是缓存（Cache），一个是数据库（Repository）。所以，应用程序比较啰嗦。而Read/Write Through套路是把更新数据库（Repository）的操作由缓存自己代理了，所以，对于应用层来说，就简单很多了。可以理解为，应用认为后端就是一个单一的存储，而存储自己维护自己的Cache。 Read Through Read Through 套路就是在查询操作中更新缓存，也就是说，当缓存失效的时候（过期或LRU换出），Cache Aside是由调用方负责把数据加载入缓存，而Read Through则用缓存服务自己来加载，从而对应用方是透明的。 Write Through Write Through 套路和Read Through相仿，不过是在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作） 下图自来Wikipedia的Cache词条。其中的Memory你可以理解为就是我们例子里的数据库。 cache6 Write Behind Caching Pattern Write Behind 又叫 Write Back。一些了解Linux操作系统内核的同学对write back应该非常熟悉，这不就是Linux文件系统的Page Cache的算法吗？是的，你看基础这玩意全都是相通的。所以，基础很重要，我已经不是一次说过基础很重要这事了。 Write Back套路，一句说就是，在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。这个设计的好处就是让数据的I/O操作飞快无比（因为直接操作内存嘛 ），因为异步，write backg还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。 但是，其带来的问题是，数据不是强一致性的，而且可能会丢失（我们知道Unix/Linux非正常关机会导致数据丢失，就是因为这个事）。在软件设计上，我们基本上不可能做出一个没有缺陷的设计，就像算法设计中的时间换空间，空间换时间一个道理，有时候，强一致性和高性能，高可用和高性性是有冲突的。软件设计从来都是取舍Trade-Off。 另外，Write Back实现逻辑比较复杂，因为他需要track有哪数据是被更新了的，需要刷到持久层上。操作系统的write back会在仅当这个cache需要失效的时候，才会被真正持久起来，比如，内存不够了，或是进程退出了等情况，这又叫lazy write。 在wikipedia上有一张write back的流程图，基本逻辑如下： cache7","tags":[{"name":"Redis","slug":"Redis","permalink":"https://ningyu1.github.io/tags/Redis/"},{"name":"Cache","slug":"Cache","permalink":"https://ningyu1.github.io/tags/Cache/"}]},{"title":"ActiveMQ使用经验分享，配置详解","date":"2017-05-11T04:03:10.000Z","path":"20170511/06-activemq-settings.html","text":"根据我们的使用场景抽取出来了一系列activemq公共配置参数mq.properties mq.propertiesactivemq.connnect.brokerurl=failover:(tcp://192.168.0.66:61616)activemq.connnect.useAsyncSend=true# object对象接受报名单,true不受限制,false需要设置白名单activemq.connnect.trustAllPackages=true # 最大连接数activemq.pool.maxConnections=20# 空闲失效时间,毫秒activemq.pool.idleTimeout=60000 # 初始数量activemq.listener.pool.corePoolSize=5activemq.listener.pool.maxPoolSize=10# 启动守护进程activemq.listener.pool.daemon=true# 单位秒activemq.listener.pool.keepAliveSeconds=120# 由于jms:listener-container不支持propertyPlaceholder替换，因此这些参数值写在spring-mq.xml文件中，参考值# # 接收消息时的超时时间,单位毫秒activemq.consumer.receiveTimeout=60000# 监听目标类型activemq.listener.destinationtype=queue# 监听确认消息方式activemq.listener.acknowledge=auto# 监听数量activemq.listener.concurrency=2-10 spring-mq.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:amq=&quot;http://activemq.apache.org/schema/core&quot; xmlns:jms=&quot;http://www.springframework.org/schema/jms&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/jms http://www.springframework.org/schema/jms/spring-jms-4.0.xsd http://activemq.apache.org/schema/core http://activemq.apache.org/schema/core/activemq-core-5.8.0.xsd&quot;&gt; &lt;!-- 配置activeMQ连接 tcp://192.168.0.66:61616 --&gt; &lt;bean id=&quot;targetConnectionFactory&quot; class=&quot;org.apache.activemq.ActiveMQConnectionFactory&quot;&gt; &lt;property name=&quot;brokerURL&quot; value=&quot;$&#123;activemq.connnect.brokerurl&#125;&quot; /&gt; &lt;!-- useAsyncSend 异步发送 --&gt; &lt;property name=&quot;useAsyncSend&quot; value=&quot;$&#123;activemq.connnect.useAsyncSend&#125;&quot;&gt;&lt;/property&gt; &lt;!-- 关闭对象传输有白名单限制 --&gt; &lt;property name=&quot;trustAllPackages&quot; value=&quot;$&#123;activemq.connnect.trustAllPackages&#125;&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 通过往PooledConnectionFactory注入一个ActiveMQConnectionFactory可以用来将Connection，Session和MessageProducer池化 这样可以大大减少我们的资源消耗， --&gt; &lt;bean id=&quot;pooledConnectionFactory&quot; class=&quot;org.apache.activemq.pool.PooledConnectionFactory&quot;&gt; &lt;property name=&quot;connectionFactory&quot; ref=&quot;targetConnectionFactory&quot; /&gt; &lt;property name=&quot;maxConnections&quot; value=&quot;$&#123;activemq.pool.maxConnections&#125;&quot; /&gt; &lt;property name=&quot;idleTimeout&quot; value=&quot;$&#123;activemq.pool.idleTimeout&#125;&quot; /&gt; &lt;!-- maximumActiveSessionPerConnection : 500 每个连接中使用的最大活动会话数 --&gt; &lt;!-- idleTimeout : 30 * 1000 单位毫秒 --&gt; &lt;!-- blockIfSessionPoolIsFull : true --&gt; &lt;!-- blockIfSessionPoolIsFullTimeout : -1L --&gt; &lt;!-- expiryTimeout : 0L --&gt; &lt;!-- createConnectionOnStartup : true --&gt; &lt;!-- useAnonymousProducers : true --&gt; &lt;!-- reconnectOnException : true --&gt; &lt;!-- maxConnections : 默认1 --&gt; &lt;!-- timeBetweenExpirationCheckMillis : -1 --&gt; &lt;/bean&gt; &lt;!-- 线程池配置 --&gt; &lt;bean id=&quot;queueMessagee x e cutor&quot; class=&quot;org.springframework.scheduling.concurrent.ThreadPoolTaske x e cutor&quot;&gt; &lt;property name=&quot;corePoolSize&quot; value=&quot;$&#123;activemq.listener.pool.corePoolSize&#125;&quot; /&gt; &lt;property name=&quot;maxPoolSize&quot; value=&quot;$&#123;activemq.listener.pool.maxPoolSize&#125;&quot; /&gt; &lt;property name=&quot;daemon&quot; value=&quot;$&#123;activemq.listener.pool.daemon&#125;&quot; /&gt; &lt;property name=&quot;keepAliveSeconds&quot; value=&quot;$&#123;activemq.listener.pool.keepAliveSeconds&#125;&quot; /&gt; &lt;/bean&gt; &lt;!-- 定义JmsTemplate的Queue类型 --&gt; &lt;bean id=&quot;jmsTemplate&quot; class=&quot;org.springframework.jms.core.JmsTemplate&quot;&gt; &lt;constructor-arg ref=&quot;pooledConnectionFactory&quot; /&gt; &lt;!-- deliveryMode : PERSISTENT 默认保存消息 --&gt; &lt;!-- messageIdEnabled : true 默认有消息id --&gt; &lt;!-- messageTimestampEnabled : true 默认有消息发送时间 --&gt; &lt;!-- pubSubNoLocal : false,默认点对点(Queues) --&gt; &lt;!-- receiveTimeout : 0 阻塞接收不超时,接收消息时的超时时间,单位毫秒 --&gt; &lt;!-- deliveryDelay : 0 --&gt; &lt;!-- explicitQosEnabled : false --&gt; &lt;!-- priority : 4 --&gt; &lt;!-- timeToLive : 0 --&gt; &lt;!-- pubSubDomain : false --&gt; &lt;!-- defaultDestination : 默认目标，默认null --&gt; &lt;!-- messageConverter : 消息转换器，默认SimpleMessageConverter --&gt; &lt;!-- sessionTransacted : 事务控制，默认false --&gt; &lt;/bean&gt; &lt;!-- 定义Queue监听器 --&gt; &lt;!-- 由于jms:listener-container不支持propertyPlaceholder替换，因此这些参数值写在spring-mq.xml文件中，参考值：mq.properties文件中 --&gt; &lt;jms:listener-container task-e x e cutor=&quot;queueMessagee x e cutor&quot; receive-timeout=&quot;60000&quot; destination-type=&quot;queue&quot; container-type=&quot;default&quot; connection-factory=&quot;pooledConnectionFactory&quot; acknowledge=&quot;auto&quot; concurrency=&quot;2-10&quot; &gt; &lt;jms:listener destination=&quot;QUEUE.EMAIL&quot; ref=&quot;mailMessageListener&quot; /&gt; &lt;jms:listener destination=&quot;QUEUE.SMS&quot; ref=&quot;smsMessageListener&quot; /&gt; &lt;/jms:listener-container&gt; &lt;bean id=&quot;smsMessageListener&quot; class=&quot;org.springframework.jms.listener.adapter.MessageListenerAdapter&quot;&gt; &lt;!-- 默认调用方法handleMessage --&gt; &lt;property name=&quot;delegate&quot;&gt; &lt;bean class=&quot;com.domain.framework.message.sms.listener.SMSMessageListener&quot; /&gt; &lt;/property&gt; &lt;property name=&quot;defaultListenerMethod&quot; value=&quot;receiveMessage&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;mailMessageListener&quot; class=&quot;org.springframework.jms.listener.adapter.MessageListenerAdapter&quot;&gt; &lt;!-- 默认调用方法handleMessage --&gt; &lt;property name=&quot;delegate&quot;&gt; &lt;bean class=&quot;com.domain.framework.message.mail.listener.EmailMessageListener&quot; /&gt; &lt;/property&gt; &lt;property name=&quot;defaultListenerMethod&quot; value=&quot;receiveMessage&quot;/&gt; &lt;/bean&gt; &lt;/beans&gt; 配置说明 trustAllPackages 等于false时，在做object序列化时会有Class Not Found Exception：This class is not trusted to be serialized as ObjectMessage payload异常抛出，是因为activemq服务器默认是不接受object序列化对象，需要配置白名单（接受的object对象class全名） 等于true时关闭验证 传输对象安全说明: http://activemq.apache.org/objectmessage.htm useAsyncSend 开启异步消息发送，主要是一个性能上的提升从而提升消息吞吐量，但是不能拿到消息发送后的回执消息，消息不会丢失 异步发送的说明：http://activemq.apache.org/async-sends.html executor corePoolSize 该值的配置需要结合listener的个数和concurrency的数量去灵活配置 案例分析 &lt;bean id=&quot;queueMessageExecutor&quot; class=&quot;org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor&quot;&gt; &lt;property name=&quot;corePoolSize&quot; value=&quot;2&quot; /&gt; &lt;property name=&quot;maxPoolSize&quot; value=&quot;10&quot; /&gt; &lt;property name=&quot;daemon&quot; value=&quot;true&quot; /&gt; &lt;property name=&quot;keepAliveSeconds&quot; value=&quot;120&quot; /&gt;&lt;/bean&gt;&lt;jms:listener-container task-executor=&quot;queueMessageExecutor&quot; receive-timeout=&quot;60000&quot; destination-type=&quot;queue&quot; container-type=&quot;default&quot; connection-factory=&quot;pooledConnectionFactory&quot; acknowledge=&quot;auto&quot; concurrency=&quot;2-10&quot; &gt; &lt;jms:listener destination=&quot;QUEUE.EMAIL&quot; ref=&quot;mailMessageListener&quot; /&gt; &lt;jms:listener destination=&quot;QUEUE.SMS&quot; ref=&quot;smsMessageListener&quot; /&gt;&lt;/jms:listener-container&gt; 项目中有2个listener并且项目希望启动初始每个listener启动2个consumer最大10个consumer，如果e x e cutor corePoolSize配置为2，那么启动后只会给一个listener分配2个consumer，因为e x e cutor pool的初始配置数量不够，见下图 修改corePoolSize之后 &lt;property name=&quot;corePoolSize&quot; value=&quot;5&quot; /&gt; executor daemon 是否创建守护线程 设置为true时，在应用程序在紧急关闭时，任然会执行没有完成的runtime线程 jms:listener-container 由于不支持propertyPlaceholder替换，因此这些参数值写在spring-mq.xml文件中，参考值：mq.properties文件中 destination-type 目标类型（QUEUE, TOPIC, DURABLETOPIC） acknowledge 消息确认方式（auto、client、dups-ok、transacted） concurrency listener consumer个数 message-converter 消息转换器，我们这里不配置特殊的转换器，使用Spring提供的org.springframework.jms.support.converter.SimpleMessageConverter.SimpleMessageConverter()简单转换器，支持对象（String、byte[]、Map、Serializable） 结合org.springframework.jms.listener.adapter.MessageListenerAdapter做接受消息自动转换对象 结合org.springframework.jms.core.JmsTemplate使用convertAndSend系列方法对象转换并发送，实现发送消息自动转换。 我们为什么不使用json做消息转换，因为json转换在反序列话时需要明确序列化Class类型，丢失了消息转换器的通用性。 Listener 支持实现JMS接口的类javax.jms.MessageListener，它是一个来自JMS规范的标准化接口，但是你要处理线程。。 支持Spring SessionAwareMessageListener，这是一个Spring特定的接口，提供对JMS会话对象的访问。 这对于请求 - 响应消息传递非常有用。 只需要注意，你必须做自己的异常处理（即，重写handleListenerException方法，这样异常不会丢失）。 支持Spring MessageListenerAdapter，这是一个Spring特定接口，允许特定类型的消息处理。 使用此接口可避免代码中任何特定于JMS的依赖关系。 MessageListenerAdapter 可以代理任意POJO类，无需实现JMS接口，任意指定回调方法，并且消息转换内置实现，JMS会话默认封装使用示例：消息接收 &lt;bean id=&quot;mailMessageListener&quot; class=&quot;org.springframework.jms.listener.adapter.MessageListenerAdapter&quot;&gt; &lt;!-- 默认调用方法handleMessage --&gt; &lt;property name=&quot;delegate&quot;&gt; &lt;bean class=&quot;com.domain.framework.message.mail.listener.EmailMessageListener&quot; /&gt; &lt;/property&gt; &lt;property name=&quot;defaultListenerMethod&quot; value=&quot;receiveMessage&quot;/&gt;&lt;/bean&gt;public class EmailMessageListener &#123; public void receiveMessage(EmailMessageVo message) &#123; ...someing.... &#125;&#125; 消息发送 &lt;bean id=&quot;jmsTemplate&quot; class=&quot;org.springframework.jms.core.JmsTemplate&quot;&gt; &lt;constructor-arg ref=&quot;pooledConnectionFactory&quot; /&gt;&lt;/bean&gt;@Component(&quot;emailService&quot;)public class EmailServiceImpl implements IEmailService &#123; @Autowired private JmsTemplate jmsTemplate; @Override public void sendEmailMessage(EmailMessageVo message) throws BizException &#123; if(message != null) &#123; jmsTemplate.convertAndSend(QueueNames.EMAIL, message); &#125; else &#123; logger.warn(&quot;sendEmailMessage() param[message] is null ,can&apos;t send message!&quot;); &#125; &#125;&#125; ps.上面的示例主要是org.springframework.jms.core.JmsTemplate与org.springframework.jms.listener.adapter.MessageListenerAdapter和业务的POJO做消费者的一个结合使用示例，无需关注序列化，发送与接受对象直接使用业务POJO Q名称的命名规则 名称我们采用大写字母，多个单词之间分隔符使用“.”,例如：QUEUE.XXX、TOPIC.XXX 根据产品线或项目名称增加namespace，例如：APP1.QUEUE.XXX、APP2.QUEUE.XXX Active MQ包使用说明 不要使用activemq-all这个包，这个包打包了依赖（pool源码，spring源码，log4j源码，jms源码），会跟我们的日志框架产生冲突 我们使用activemq-pool、activemq-client、activemq-broker、spring-jms去替换上面的activemq-all包 Spring+Activemq使用配置非常灵活，我们不拘泥于一种形式，如果有更好的经验尽管提出来我们共同努力和进步。","tags":[{"name":"MQ","slug":"MQ","permalink":"https://ningyu1.github.io/tags/MQ/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://ningyu1.github.io/tags/ActiveMQ/"}]},{"title":"Maven settings.xml详解","date":"2017-05-10T02:05:37.000Z","path":"20170510/07-maven-settings.html","text":"settings.xml有什么用从settings.xml的文件名就可以看出，它是用来设置maven参数的配置文件。并且，settings.xml是maven的全局配置文件。而pom.xml文件是所在项目的局部配置。 Settings.xml中包含类似本地仓储位置、修改远程仓储服务器、认证信息等配置。 settings.xml文件位置全局配置: ${M2_HOME}/conf/settings.xml 用户配置: user.home/.m2/settings.xmlnote：用户配置优先于全局配置。user.home/.m2/settings.xmlnote：用户配置优先于全局配置。{user.home} 和和所有其他系统属性只能在3.0+版本上使用。请注意windows和Linux使用变量的区别。 配置优先级需要注意的是：局部配置优先于全局配置。 配置优先级从高到低：pom.xml&gt; user settings &gt; global settings 如果这些文件同时存在，在应用配置时，会合并它们的内容，如果有重复的配置，优先级高的配置会覆盖优先级低的。 ps.修改了配置文件最好吧cmd和eclipse重开一下 settings.xml元素详解顶级元素概览下面列举了settings.xml中的顶级元素&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; &lt;localRepository/&gt; &lt;interactiveMode/&gt; &lt;usePluginRegistry/&gt; &lt;offline/&gt; &lt;pluginGroups/&gt; &lt;servers/&gt; &lt;mirrors/&gt; &lt;proxies/&gt; &lt;profiles/&gt; &lt;activeProfiles/&gt;&lt;/settings&gt; LocalRepository作用：该值表示构建系统本地仓库的路径。 其默认值：~/.m2/repository。&lt;localRepository&gt;${user.home}/.m2/repository&lt;/localRepository&gt; InteractiveMode作用：表示maven是否需要和用户交互以获得输入。 如果maven需要和用户交互以获得输入，则设置成true，反之则应为false。默认为true。&lt;interactiveMode&gt;true&lt;/interactiveMode&gt; UsePluginRegistry作用：maven是否需要使用plugin-registry.xml文件来管理插件版本。 如果需要让maven使用文件~/.m2/plugin-registry.xml来管理插件版本，则设为true。默认为false。&lt;usePluginRegistry&gt;false&lt;/usePluginRegistry&gt; Offline作用：表示maven是否需要在离线模式下运行。 如果构建系统需要在离线模式下运行，则为true，默认为false。 当由于网络设置原因或者安全因素，构建服务器不能连接远程仓库的时候，该配置就十分有用。&lt;offline&gt;false&lt;/offline&gt; PluginGroups作用：当插件的组织id（groupId）没有显式提供时，供搜寻插件组织Id（groupId）的列表。 该元素包含一个pluginGroup元素列表，每个子元素包含了一个组织Id（groupId）。 当我们使用某个插件，并且没有在命令行为其提供组织Id（groupId）的时候，Maven就会使用该列表。默认情况下该列表包含了org.apache.maven.plugins和org.codehaus.mojo。&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; ... &lt;pluginGroups&gt; &lt;!--plugin的组织Id（groupId） --&gt; &lt;pluginGroup&gt;org.codehaus.mojo&lt;/pluginGroup&gt; &lt;/pluginGroups&gt; ...&lt;/settings&gt; Servers作用：一般，仓库的下载和部署是在pom.xml文件中的repositories和distributionManagement元素中定义的。然而，一般类似用户名、密码（有些仓库访问是需要安全认证的）等信息不应该在pom.xml文件中配置，这些信息可以配置在settings.xml中。&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; ... &lt;!--配置服务端的一些设置。一些设置如安全证书不应该和pom.xml一起分发。这种类型的信息应该存在于构建服务器上的settings.xml文件中。 --&gt; &lt;servers&gt; &lt;!--服务器元素包含配置服务器时需要的信息 --&gt; &lt;server&gt; &lt;!--这是server的id（注意不是用户登陆的id），该id与distributionManagement中repository元素的id相匹配。 --&gt; &lt;id&gt;server001&lt;/id&gt; &lt;!--鉴权用户名。鉴权用户名和鉴权密码表示服务器认证所需要的登录名和密码。 --&gt; &lt;username&gt;my_login&lt;/username&gt; &lt;!--鉴权密码 。鉴权用户名和鉴权密码表示服务器认证所需要的登录名和密码。密码加密功能已被添加到2.1.0 +。详情请访问密码加密页面 --&gt; &lt;password&gt;my_password&lt;/password&gt; &lt;!--鉴权时使用的私钥位置。和前两个元素类似，私钥位置和私钥密码指定了一个私钥的路径（默认是$&#123;user.home&#125;/.ssh/id_dsa）以及如果需要的话，一个密语。将来passphrase和password元素可能会被提取到外部，但目前它们必须在settings.xml文件以纯文本的形式声明。 --&gt; &lt;privateKey&gt;$&#123;usr.home&#125;/.ssh/id_dsa&lt;/privateKey&gt; &lt;!--鉴权时使用的私钥密码。 --&gt; &lt;passphrase&gt;some_passphrase&lt;/passphrase&gt; &lt;!--文件被创建时的权限。如果在部署的时候会创建一个仓库文件或者目录，这时候就可以使用权限（permission）。这两个元素合法的值是一个三位数字，其对应了unix文件系统的权限，如664，或者775。 --&gt; &lt;filePermissions&gt;664&lt;/filePermissions&gt; &lt;!--目录被创建时的权限。 --&gt; &lt;directoryPermissions&gt;775&lt;/directoryPermissions&gt; &lt;/server&gt; &lt;/servers&gt; ...&lt;/settings&gt; Mirrors作用：为仓库列表配置的下载镜像列表。&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; ... &lt;mirrors&gt; &lt;!-- 给定仓库的下载镜像。 --&gt; &lt;mirror&gt; &lt;!-- 该镜像的唯一标识符。id用来区分不同的mirror元素。 --&gt; &lt;id&gt;planetmirror.com&lt;/id&gt; &lt;!-- 镜像名称 --&gt; &lt;name&gt;PlanetMirror Australia&lt;/name&gt; &lt;!-- 该镜像的URL。构建系统会优先考虑使用该URL，而非使用默认的服务器URL。 --&gt; &lt;url&gt;http://downloads.planetmirror.com/pub/maven2&lt;/url&gt; &lt;!-- 被镜像的服务器的id。例如，如果我们要设置了一个Maven中央仓库（http://repo.maven.apache.org/maven2/）的镜像，就需要将该元素设置成central。这必须和中央仓库的id central完全一致。 --&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;/mirrors&gt; ...&lt;/settings&gt; Proxies作用：用来配置不同的代理。&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; ... &lt;proxies&gt; &lt;!--代理元素包含配置代理时需要的信息 --&gt; &lt;proxy&gt; &lt;!--代理的唯一定义符，用来区分不同的代理元素。 --&gt; &lt;id&gt;myproxy&lt;/id&gt; &lt;!--该代理是否是激活的那个。true则激活代理。当我们声明了一组代理，而某个时候只需要激活一个代理的时候，该元素就可以派上用处。 --&gt; &lt;active&gt;true&lt;/active&gt; &lt;!--代理的协议。 协议://主机名:端口，分隔成离散的元素以方便配置。 --&gt; &lt;protocol&gt;http&lt;/protocol&gt; &lt;!--代理的主机名。协议://主机名:端口，分隔成离散的元素以方便配置。 --&gt; &lt;host&gt;proxy.somewhere.com&lt;/host&gt; &lt;!--代理的端口。协议://主机名:端口，分隔成离散的元素以方便配置。 --&gt; &lt;port&gt;8080&lt;/port&gt; &lt;!--代理的用户名，用户名和密码表示代理服务器认证的登录名和密码。 --&gt; &lt;username&gt;proxyuser&lt;/username&gt; &lt;!--代理的密码，用户名和密码表示代理服务器认证的登录名和密码。 --&gt; &lt;password&gt;somepassword&lt;/password&gt; &lt;!--不该被代理的主机名列表。该列表的分隔符由代理服务器指定；例子中使用了竖线分隔符，使用逗号分隔也很常见。 --&gt; &lt;nonProxyHosts&gt;*.google.com|ibiblio.org&lt;/nonProxyHosts&gt; &lt;/proxy&gt; &lt;/proxies&gt; ...&lt;/settings&gt; Profiles作用：根据环境参数来调整构建配置的列表。 settings.xml中的profile元素是pom.xml中profile元素的裁剪版本。 它包含了id、activation、repositories、pluginRepositories和 properties元素。这里的profile元素只包含这五个子元素是因为这里只关心构建系统这个整体（这正是settings.xml文件的角色定位），而非单独的项目对象模型设置。如果一个settings.xml中的profile被激活，它的值会覆盖任何其它定义在pom.xml中带有相同id的profile。&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; ... &lt;profiles&gt; &lt;profile&gt; &lt;!-- profile的唯一标识 --&gt; &lt;id&gt;test&lt;/id&gt; &lt;!-- 自动触发profile的条件逻辑 --&gt; &lt;activation /&gt; &lt;!-- 扩展属性列表 --&gt; &lt;properties /&gt; &lt;!-- 远程仓库列表 --&gt; &lt;repositories /&gt; &lt;!-- 插件仓库列表 --&gt; &lt;pluginRepositories /&gt; &lt;/profile&gt; &lt;/profiles&gt; ...&lt;/settings&gt; Activation作用：自动触发profile的条件逻辑。 如pom.xml中的profile一样，profile的作用在于它能够在某些特定的环境中自动使用某些特定的值；这些环境通过activation元素指定。 activation元素并不是激活profile的唯一方式。settings.xml文件中的activeProfile元素可以包含profile的id。profile也可以通过在命令行，使用-P标记和逗号分隔的列表来显式的激活（如，-P test）。&lt;activation&gt; &lt;!--profile默认是否激活的标识 --&gt; &lt;activeByDefault&gt;false&lt;/activeByDefault&gt; &lt;!--当匹配的jdk被检测到，profile被激活。例如，1.4激活JDK1.4，1.4.0_2，而!1.4激活所有版本不是以1.4开头的JDK。 --&gt; &lt;jdk&gt;1.5&lt;/jdk&gt; &lt;!--当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。 --&gt; &lt;os&gt; &lt;!--激活profile的操作系统的名字 --&gt; &lt;name&gt;Windows XP&lt;/name&gt; &lt;!--激活profile的操作系统所属家族(如 &apos;windows&apos;) --&gt; &lt;family&gt;Windows&lt;/family&gt; &lt;!--激活profile的操作系统体系结构 --&gt; &lt;arch&gt;x86&lt;/arch&gt; &lt;!--激活profile的操作系统版本 --&gt; &lt;version&gt;5.1.2600&lt;/version&gt; &lt;/os&gt; &lt;!--如果Maven检测到某一个属性（其值可以在POM中通过$&#123;name&#125;引用），其拥有对应的name = 值，Profile就会被激活。如果值字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段 --&gt; &lt;property&gt; &lt;!--激活profile的属性的名称 --&gt; &lt;name&gt;mavenVersion&lt;/name&gt; &lt;!--激活profile的属性的值 --&gt; &lt;value&gt;2.0.3&lt;/value&gt; &lt;/property&gt; &lt;!--提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活profile。另一方面，exists则会检查文件是否存在，如果存在则激活profile。 --&gt; &lt;file&gt; &lt;!--如果指定的文件存在，则激活profile。 --&gt; &lt;exists&gt;$&#123;basedir&#125;/file2.properties&lt;/exists&gt; &lt;!--如果指定的文件不存在，则激活profile。 --&gt; &lt;missing&gt;$&#123;basedir&#125;/file1.properties&lt;/missing&gt; &lt;/file&gt;&lt;/activation&gt; 注：在maven工程的pom.xml所在目录下执行mvn help:active-profiles命令可以查看中央仓储的profile是否在工程中生效。 properties作用：对应profile的扩展属性列表。 maven属性和ant中的属性一样，可以用来存放一些值。这些值可以在pom.xml中的任何地方使用标记${X}来使用，这里X是指属性的名称。属性有五种不同的形式，并且都能在settings.xml文件中访问。&lt;!-- 1. env.X: 在一个变量前加上&quot;env.&quot;的前缀，会返回一个shell环境变量。例如,&quot;env.PATH&quot;指代了$path环境变量（在Windows上是%PATH%）。 2. project.x：指代了POM中对应的元素值。例如: &lt;project&gt;&lt;version&gt;1.0&lt;/version&gt;&lt;/project&gt;通过$&#123;project.version&#125;获得version的值。 3. settings.x: 指代了settings.xml中对应元素的值。例如：&lt;settings&gt;&lt;offline&gt;false&lt;/offline&gt;&lt;/settings&gt;通过 $&#123;settings.offline&#125;获得offline的值。 4. Java System Properties: 所有可通过java.lang.System.getProperties()访问的属性都能在POM中使用该形式访问，例如 $&#123;java.home&#125;。 5. x: 在&lt;properties/&gt;元素中，或者外部文件中设置，以$&#123;someVar&#125;的形式使用。 --&gt;&lt;properties&gt; &lt;user.install&gt;$&#123;user.home&#125;/our-project&lt;/user.install&gt;&lt;/properties&gt; 注：如果该profile被激活，则可以在pom.xml中使用${user.install}。 Repositories作用：远程仓库列表，它是maven用来填充构建系统本地仓库所使用的一组远程仓库。&lt;repositories&gt; &lt;!--包含需要连接到远程仓库的信息 --&gt; &lt;repository&gt; &lt;!--远程仓库唯一标识 --&gt; &lt;id&gt;codehausSnapshots&lt;/id&gt; &lt;!--远程仓库名称 --&gt; &lt;name&gt;Codehaus Snapshots&lt;/name&gt; &lt;!--如何处理远程仓库里发布版本的下载 --&gt; &lt;releases&gt; &lt;!--true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。 --&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;!--该元素指定更新发生的频率。Maven会比较本地POM和远程POM的时间戳。这里的选项是：always（一直），daily（默认，每日），interval：X（这里X是以分钟为单位的时间间隔），或者never（从不）。 --&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;!--当Maven验证构件校验文件失败时该怎么做-ignore（忽略），fail（失败），或者warn（警告）。 --&gt; &lt;checksumPolicy&gt;warn&lt;/checksumPolicy&gt; &lt;/releases&gt; &lt;!--如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置，POM就可以在每个单独的仓库中，为每种类型的构件采取不同的策略。例如，可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素 --&gt; &lt;snapshots&gt; &lt;enabled /&gt; &lt;updatePolicy /&gt; &lt;checksumPolicy /&gt; &lt;/snapshots&gt; &lt;!--远程仓库URL，按protocol://hostname/path形式 --&gt; &lt;url&gt;http://snapshots.maven.codehaus.org/maven2&lt;/url&gt; &lt;!--用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。Maven 2为其仓库提供了一个默认的布局；然而，Maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。 --&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;/repository&gt;&lt;/repositories&gt; pluginRepositories作用：发现插件的远程仓库列表。 和repository类似，只是repository是管理jar包依赖的仓库，pluginRepositories则是管理插件的仓库。 maven插件是一种特殊类型的构件。由于这个原因，插件仓库独立于其它仓库。pluginRepositories元素的结构和repositories元素的结构类似。每个pluginRepository元素指定一个Maven可以用来寻找新插件的远程地址。&lt;pluginRepositories&gt; &lt;!-- 包含需要连接到远程插件仓库的信息.参见profiles/profile/repositories/repository元素的说明 --&gt; &lt;pluginRepository&gt; &lt;releases&gt; &lt;enabled /&gt; &lt;updatePolicy /&gt; &lt;checksumPolicy /&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled /&gt; &lt;updatePolicy /&gt; &lt;checksumPolicy /&gt; &lt;/snapshots&gt; &lt;id /&gt; &lt;name /&gt; &lt;url /&gt; &lt;layout /&gt; &lt;/pluginRepository&gt;&lt;/pluginRepositories&gt; ActiveProfiles作用：手动激活profiles的列表，按照profile被应用的顺序定义activeProfile。 该元素包含了一组activeProfile元素，每个activeProfile都含有一个profile id。任何在activeProfile中定义的profile id，不论环境设置如何，其对应的 profile都会被激活。如果没有匹配的profile，则什么都不会发生。 例如，env-test是一个activeProfile，则在pom.xml（或者profile.xml）中对应id的profile会被激活。如果运行过程中找不到这样一个profile，Maven则会像往常一样运行。&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; ... &lt;activeProfiles&gt; &lt;!-- 要激活的profile id --&gt; &lt;activeProfile&gt;env-test&lt;/activeProfile&gt; &lt;/activeProfiles&gt; ...&lt;/settings&gt;","tags":[{"name":"Maven","slug":"Maven","permalink":"https://ningyu1.github.io/tags/Maven/"},{"name":"Settings","slug":"Settings","permalink":"https://ningyu1.github.io/tags/Settings/"}]},{"title":"RESTful设计规范","date":"2017-02-21T03:58:19.000Z","path":"20170221/01-RESTful-design-specifications.html","text":"一、 摘要（Abstract）RESTful API 已经非常成熟，也得到了大家的认可。我们按照 Richardson Maturity Model 对 REST 评价的模型，规范基于 level2 来设计 二、版本（Versioning）API的版本号放入URL。例如：https://api.jiuyescm.com/v1/https://api.jiuyescm.com/v1.2/ 三、资源、路径（Endpoint）路径，API的具体地址。在REST中，每个地址都代表一个具体的资源（Resource）约定如下： 路径仅表示资源的路径（位置），尽量不要有actions操作（一些特殊的actions操作除外） 路径以 复数（名词） 进行命名资源，不管返回单个或者多个资源。 使用 小写字母、数字以及下划线（“_”） 。（下划线是为了区分多个单词，如user_name） 资源的路径从父到子依次如： /&#123;resource&#125;/&#123;resource_id&#125;/&#123;sub_resource&#125;/&#123;sub_resource_id&#125;/&#123;sub_resource_property&#125; 使用 ? 来进行资源的过滤、搜索以及分页等 使用版本号，且版本号在资源路径之前 优先使用内容协商来区分表述格式，而不是使用后缀来区分表述格式 应该放在一个专用的域名下，如：http：//api.jiuyescm.com 使用SSL 综上，一个API路径可能会是https://api.domain.com/v1/&#123;resource&#125;/&#123;resource_id&#125;/&#123;sub_resource&#125;/&#123;sub_resource_id&#125;/&#123;sub_resource_property&#125;https://api.domain.com /v1/&#123;resource&#125;?page=1&amp;page_size=10https://api.domain.com /v1/&#123;resource&#125;?name=xx&amp;sortby=name&amp;order=asc 四、操作（HTTP Actions）用HTTP动词（方法）表示对资源的具体操作。常用的HTTP动词有：GET（SELECT）：从服务器取出资源（一项或多项）POST（CREATE）：在服务器新建一个资源PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源） PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性） DELETE（DELETE）：从服务器删除资源还有两个不常用的HTTP动词HEAD：获取资源的元数据OPTIONS：获取信息，关于资源的哪些属性是客户端可以改变的 下面是一些例子 GET /users：列出所有用户 POST /users：新建一个用户 GET /users/&#123;user_id&#125;：获取某个指定用户的信息 PUT /users/&#123;user_id&#125;：更新某个指定用户的信息（提供该用户的全部信息） PATCH /users/&#123;user_id&#125;：更新某个指定用户的信息（提供该用户的部分信息） DELETE /users/&#123;user_id&#125;：删除某个用户 GET /users/&#123;user_id&#125;/resources：列出某个指定用户的所有权限资源 DELETE /users/&#123;user_id&#125;/resources/&#123;resources_id&#125;：删除某个指定用户的指定权限资源 五、数据（Data Format）数据是对资源的具体描述，分为请求数据和返回数据。约定如下： 查询，过滤条件使用query string，例如user?name=xxx Content body 仅仅用来传输数据 通过Content-Type指定请求与返回的数据格式。其中请求数据还要指定Accept。（我们暂时只使用Json） 数据应该拿来就能用，不应该还要进行转换操作 使用字符串（YYYY-MM-dd hh:mm:ss）格式表达时间字段，例如: 2017-02-20 16:00:00 数据采用UTF-8编码 返回的数据应该尽量简单，响应状态应该包含在响应头中 使用 小写字母、数字以及下划线（“_”） 描述字段，不使用大写描述字段（这个由于使用了一些开源的jar所以这个不强求，比如说pageinfo我们无法修改属性名称） 建议资源中的唯一标识命名为id（这个不强求，有的唯一标识名称确实比较复杂） 属性和字符串值必须使用双引号””（这个json转换默认规则） 建议对每个字段设置默认值（数组型可设置为[],字符串型可设置为””，数值可设置为0，对象可设置为{}）,这一条是为了方便前端/客户端进行判断字段存不存在操作（这样json转换会自动转成相应的字符） POST操作应该返回新建的资源；PUT/PATCH操作返回更新后的完整的资源；DELETE返回一个空文档；GET返回资源数组或当个资源 为了方便以后的扩展兼容，如果返回的是数组，强烈建议用一个包含如items属性的对象进行包裹，如： &#123;&quot;items&quot;:[&#123;&#125;,&#123;&#125;]&#125; 示例：POST https://api.domain.com/v1/usersRequest headers: Accept: application/json Content-Type: application/json;charset=UTF-8 body: &#123; &quot;user_name&quot;: &quot;ZhangSan&quot;, &quot;address&quot;: &quot;ujfhysdfsdf&quot;, &quot;nick&quot;: &quot;ZS&quot; &#125;Response status: 201 Created headers: Content-Type: application/json;charset=UTF-8 body: &#123; &quot;requestId&quot;: sdfsdflkjoiusdf, &quot;code&quot;: &quot;&quot;, &quot;message&quot;: &quot;&quot;, &quot;items&quot;: &#123; &quot;id&quot;:&quot;111&quot;, &quot;user_name&quot;: &quot;HingKwan&quot;, &quot;address&quot;: &quot;ujfhysdfsdf&quot;, &quot;nick&quot;: &quot;ZS&quot; &#125; &#125; 六、安全（Security）调用限制为了避免请求泛滥，给API设置速度限制很重要。入速度设置之后，可以在HTTP返回头上对返回的信息进行说明，下面是几个必须的返回头（依照twitter的命名规则）X-Rate-Limit-Limit :当前时间段允许的并发请求数X-Rate-Limit-Remaining:当前时间段保留的请求数X-Rate-Limit-Reset:当前时间段剩余秒数 这个我们一般会在getway中实现 授权校验RESTful API是无状态的也就是说用户请求的鉴权和cookie以及session无关，每一次请求都应该包含鉴权证明。可以使用http请求头Authorization设置授权码; 必须使用User-Agent设置客户端信息, 无User-Agent请求头的请求应该被拒绝访问。具体的授权可以采用OAuth2，或者自己定义并实现相关的授权验证机制（基于token）。这个我们一般会在getway中实现 错误当API返回非2XX的HTTP响应时，应该采用统一的响应信息，格式如：HTTP/1.1 400 Bad RequestContent-Type: application/json;charset=UTF-8&#123; &quot;code&quot;:&quot;INVALID_ARGUMENT&quot;, &quot;message&quot;:&quot;&#123;error message&#125;&quot;, &quot;request_id&quot;:&quot;sdfsdfo8lkjsdf&quot;, &quot;items&quot;:[],&#125; HTTP Header Code：符合HTTP响应的状态码。详细见以下的“状态码”节 code：用来表示某类错误不是具体错误，比如缺少参数等。是对HTTP Header Code的补充，开发团队可以根据自己的需要自己定义 message：错误信息的摘要，应该是对用户处理错误有用的信息 request_id：请求的id，方便开发定位发生错误的请求（可选） code的定义约定： 采用 大写字母命名，字母与字母之间用下划线（”_”） 隔开 code应该用来定义错误类别，而非定义具体的某个错误。 缺少参数使用：MISSING_X 无效参数使用：INVALID_X 逻辑验证错误使用：VALIDATION_X 不存在使用：NO_FOUND_X 七、状态码（Status Codes）服务器向用户返回的状态码和提示信息，常见的有以下一些（方括号中是该状态码对应的HTTP动词）。200 OK - [GET/PUT/PATCH/DELETE]：服务器成功返回用户请求的数据，该操作是幂等的（Idempotent）。 201 Created - [POST/PUT/PATCH]：用户新建或修改数据成功。 202 Accepted - [*]：表示一个请求已经进入后台排队（异步任务） 204 No Content - [DELETE]：用户删除数据成功。 304 Not Modified - HTTP缓存有效。400 Invalid Request - [POST/PUT/PATCH]：用户发出的请求有错误，服务器没有进行新建或修改数据的操作，该操作是幂等的。 401 Unauthorized - [*]：表示用户没有权限（令牌、用户名、密码错误）。 403 Forbidden - [*] 表示用户得到授权（与401错误相对），但是访问是被禁止的。 404 Not Found - [*]：用户发出的请求针对的是不存在的记录，服务器没有进行操作，该操作是幂等的。405 Method Not Allowed - [*]：该http方法不被允许。 406 Not Acceptable - [GET]：用户请求的格式不可得（比如用户请求JSON格式，但是只有XML格式）。 410 Gone -[GET]：用户请求的资源被永久删除，且不会再得到的。 415 Unsupported Media Type - [*]：请求类型错误。422 Unprocesable Entity - [POST/PUT/PATCH] 当创建一个对象时，发生一个验证错误。 429 Too Many Request - [*]：请求过多。500 Internal Server Error - [*]：服务器发生错误，用户将无法判断发出的请求是否成功。 503 Service Unavailable - [*]：服务当前无法处理请求。 八、异常规范（Exceptions） Controller中try catch住service的异常，再转换为restful中需要抛出的异常 try &#123; Long id = userService.save(vo); vo.setId(id);&#125; catch(BizException e) &#123; throw new UnprocesableEntityException(ErrorCode.USER_NAME_EXIST.getCode(), ErrorCode.USER_NAME_EXIST.getMessage());&#125; Controller中抛出的异常必须使用spring-mvc-rest包中的异常类，不允许自定义异常，选择需要返回的httpStatus对应的异常 #403 [*]：表示得到授权（与401错误相对），但是访问是被禁止的。com.jiuyescm.spring.mvc.rest.exception.ForbiddenException#401 [GET]：用户请求的资源被永久删除，且不会再得到的。com.jiuyescm.spring.mvc.rest.exception.GoneException#400 [POST/PUT/PATCH]：用户发出的请求有错误（常用在请求必要的参数错误上），服务器没有进行新建或修改数据的操作，该操作是幂等的。com.jiuyescm.spring.mvc.rest.exception.InvalidRequestException#406 [GET]：用户请求的格式不可得（比如用户请求JSON格式，但是只有XML格式）或（请求参数需要数字，用户传入字符串）com.jiuyescm.spring.mvc.rest.exception.NotAcceptableException#404 [*]：用户发出的请求针对的是不存在的记录，服务器没有进行操作，该操作是幂等的。com.jiuyescm.spring.mvc.rest.exception.NotFoundException#401 [*]：表示没有权限（令牌、用户名、密码错误，或任何资源没有权限）com.jiuyescm.spring.mvc.rest.exception.UnauthorizedException#422 [POST/PUT/PATCH] 当创建一个对象时，发生一个验证错误。com.jiuyescm.spring.mvc.rest.exception.UnprocesableEntityException 抛出的异常中需要传入异常编码和异常信息，异常编码定义遵循上面 《安全中错误编码规范》 &quot;MESSING_ID&quot;, &quot;缺少参数：id&quot;&quot;MESSING_NAME&quot;, &quot;缺少参数：name&quot;&quot;MESSING_ADDRESS&quot;, &quot;缺少参数：address&quot;&quot;USER_NAME_EXIST&quot;, &quot;用户名已存在&quot;&quot;USER_NOT_FOUND&quot;, &quot;用户名不存在&quot; 常用的错误编码、异常、httpStatus对应关系 &quot;MESSING_ID&quot;, &quot;缺少参数：id&quot;、InvalidRequestException、400&quot;MESSING_NAME&quot;, &quot;缺少参数：name&quot;、InvalidRequestException、400&quot;MESSING_ADDRESS&quot;, &quot;缺少参数：address&quot;、InvalidRequestException、400&quot;USER_NAME_EXIST&quot;, &quot;用户名已存在&quot;、UnprocesableEntityException、422&quot;USER_NOT_FOUND&quot;, &quot;用户名不存在&quot;、NotFoundException、404 九、示例（Example）采用user提供的示例代码 POST /usersResourcePOST /v1/users POST ParametersEndpoint requires： Name Type Description name String 用户名称 address String 用户住址 and accepts a few other parameters listed below. Name Type Description remark String 描述信息 Example&#123; &quot;name&quot;:&quot;tuyir&quot;, &quot;address&quot;:&quot;sdflkjsdf&quot;, &quot;remark&quot;:&quot;sdfoiu&quot;&#125; ResponseStatus-Code: 201 Created&#123; &quot;code&quot;: &quot;&quot;, &quot;message&quot;: null, &quot;items&quot;: &#123; &quot;id&quot;: 27, &quot;name&quot;: &quot;tuyir&quot;, &quot;address&quot;: &quot;sdflkjsdf&quot;, &quot;remark&quot;: &quot;sdfoiu&quot; &#125;&#125; Name Type Description code String 错误编码 message String 错误描述 Items Objec t 返回结果 id Long 唯一标识 name String 用户名称 address String 家庭住址 remark String 描述信息 Error responseStatus-Code: 400 Bad Request&#123; &quot;code&quot;: &quot;MESSING_NAME&quot;, &quot;message&quot;: “缺少参数：name”, &quot;items&quot;: &#123;&#125;&#125; Name Type Description code String 错误编码 message String 错误描述 Items Object 返回结果 HTTP Error Codes HTTP Status Code Description 400 MESSING_NAME 缺少参数：name 400 MESSING_ADDRESS 缺少参数：address 422 USER_NAME_EXIST 用户名已存在 500 INTERNAL_SERVER_ERROR 未知的错误 DELETE /users/{user_id}ResourceDELETE /v1/users/{user_id} Path Parameters Name Type Description user_id Long 用户唯一标识 Query ParametersNone Example Requestcurl –H ‘Content-Type: application/json’\\-X DELETE \\‘https://api.jiuyescm.com/v1/users/111’ ResponseStatus-Code: 204 No Content HTTP Error Codes HTTP Status Code Description 400 MESSING_ID 缺少参数：id 404 USER_NOT_FOUND 用户不存在 PUT /usersResourcePUT /v1/users PUT Body ParametersEndpoint requires： Name Type Description user_id Long 用户唯一标识 user_name String 用户名称 address String 用户住址 and accepts a few other parameters listed below.. Name Type Description remark String 描述信息 Example&#123; &quot;user_id&quot;: 12, &quot;name&quot;:&quot;tuyir&quot;, &quot;address&quot;:&quot;sdflkjsdf&quot;, &quot;remark&quot;:&quot;sdfoiu&quot;&#125; ResponseStatus-Code: 200 OK&#123; &quot;code&quot;: &quot;&quot;, &quot;message&quot;: null, &quot;items&quot;: &#123; &quot;id&quot;: 12, &quot;name&quot;: &quot;tuyir&quot;, &quot;address&quot;: &quot;sdflkjsdf&quot;, &quot;remark&quot;: &quot;sdfoiu&quot; &#125;&#125; Name Type Description code String 错误编码 message String 错误描述 Items Object 返回结果 id Long 唯一标识 name String 用户名称 address String 家庭住址 remark String 描述信息 Error responseStatus-Code: 400 Bad Request&#123; &quot;code&quot;: &quot;MESSING_NAME&quot;, &quot;message&quot;: “缺少参数：name”, &quot;items&quot;: &#123;&#125;&#125; Name Type Description code String 错误编码 message String 错误描述 HTTP Error Codes HTTP Status Code Description code String 错误编码 400 MESSING_ID 缺少参数：id 400 MESSING_NAME 缺少参数：name 400 MESSING_ADDRESS 缺少参数：address 422 USER_NAME_EXIST 用户名已存在 500 INTERNAL_SERVER_ERROR 未知的错误 GET /users/{user_id}ResourceGET /v1/users/{user_id} Path Parameters Name Type Description user_id Long 用户唯一标识 Example RequestCurl –H &apos;Content-Type: application/json&apos; \\&apos;https://api.jiuyescm.com/v1/users/12&apos; ResponseStatus-Code: 200 OK&#123; &quot;code&quot;: &quot;&quot;, &quot;message&quot;: null, &quot;items&quot;: &#123; &quot;id&quot;: 12, &quot;name&quot;: &quot;tuyir&quot;, &quot;address&quot;: &quot;sdflkjsdf&quot;, &quot;remark&quot;: &quot;sdfoiu&quot; &#125;&#125; Name Type Description code String 错误编码 message String 错误描述 Items Object 返回结果 id String 唯一标识 name String 用户名称 address String 家庭住址 remark String 描述信息 Error responseStatus-Code: 404 Bad Request&#123; &quot;code&quot;: &quot; USER_NOT_FOUND&quot;, &quot;message&quot;: “用户不存在”, &quot;items&quot;: &#123;&#125;&#125; Name Type Description code String 错误编码 message String 错误描述 HTTP Error Codes HTTP Status Code Description 400 MESSING_ID 缺少参数：id 404 USER_NOT_FOUND 用户不存在 GET /usersResourceGET /v1/users Query Parameters Name Type Description name String 根据用户名称进行查询 page int 第几页，不传入默认1 page_size int 每页返回多少条结果，不传入默认20 Example RequestCurl –H &apos;Content-Type: application/json&apos; \\&apos;https://api.jiuyescm.com/v1/users?name=xxx&amp;page=1&amp;page_size=20&apos; ResponseStatus-Code: 200 Success&#123; &quot;code&quot;: &quot;&quot;, &quot;message&quot;: &quot;&quot;, &quot;items&quot;: &#123; &quot;pageNum&quot;: 1, &quot;pageSize&quot;: 20, &quot;size&quot;: 17, &quot;startRow&quot;: 1, &quot;endRow&quot;: 17, &quot;total&quot;: 17, &quot;pages&quot;: 1, &quot;list&quot;: [ &#123; &quot;id&quot;: 2, &quot;name&quot;: &quot;ningyu1&quot;, &quot;address&quot;: &quot;sdflkjsdf&quot;, &quot;remark&quot;: &quot;sdfoiu&quot; &#125;, &#123; &quot;id&quot;: 3, &quot;name&quot;: &quot;ningyu2&quot;, &quot;address&quot;: &quot;sdflkjsdf&quot;, &quot;remark&quot;: &quot;sdfoiu&quot; &#125;, &#123; &quot;id&quot;: 4, &quot;name&quot;: &quot;ningyu3&quot;, &quot;address&quot;: &quot;sdflkjsdf&quot;, &quot;remark&quot;: &quot;sdfoiu&quot; &#125;, &#123; &quot;id&quot;: 5, &quot;name&quot;: &quot;ningyu4&quot;, &quot;address&quot;: &quot;sdflkjsdf&quot;, &quot;remark&quot;: &quot;sdfoiu&quot; &#125;, &#123; &quot;id&quot;: 6, &quot;name&quot;: &quot;ningyu5&quot;, &quot;address&quot;: &quot;sdflkjsdf&quot;, &quot;remark&quot;: &quot;sdfoiu&quot; &#125;, &#123; &quot;id&quot;: 7, &quot;name&quot;: &quot;8888&quot;, &quot;address&quot;: &quot;8888&quot;, &quot;remark&quot;: &quot;8888&quot; &#125;, &#123; &quot;id&quot;: 8, &quot;name&quot;: &quot;444&quot;, &quot;address&quot;: &quot;444&quot;, &quot;remark&quot;: &quot;444&quot; &#125;, &#123; &quot;id&quot;: 9, &quot;name&quot;: &quot;ningyu7&quot;, &quot;address&quot;: &quot;sdflkjsdf&quot;, &quot;remark&quot;: &quot;sdfoiu&quot; &#125;, &#123; &quot;id&quot;: 12, &quot;name&quot;: &quot;ningyu9&quot;, &quot;address&quot;: &quot;sdflkjsdf&quot;, &quot;remark&quot;: &quot;sdfoiu&quot; &#125;, &#123; &quot;id&quot;: 13, &quot;name&quot;: &quot;ningyu10&quot;, &quot;address&quot;: &quot;sdflkjsdf&quot;, &quot;remark&quot;: &quot;sdfoiu&quot; &#125;, &#123; &quot;id&quot;: 17, &quot;name&quot;: &quot;ningyu&quot;, &quot;address&quot;: &quot;sdflkjsdf&quot;, &quot;remark&quot;: null &#125;, &#123; &quot;id&quot;: 20, &quot;name&quot;: &quot;9999&quot;, &quot;address&quot;: &quot;sdflkjsdf&quot;, &quot;remark&quot;: null &#125;, &#123; &quot;id&quot;: 23, &quot;name&quot;: &quot;888&quot;, &quot;address&quot;: &quot;sdflkjsdf&quot;, &quot;remark&quot;: &quot;sdfoiu&quot; &#125;, &#123; &quot;id&quot;: 24, &quot;name&quot;: &quot;222&quot;, &quot;address&quot;: &quot;sdflkjsdf&quot;, &quot;remark&quot;: &quot;sdfoiu&quot; &#125;, &#123; &quot;id&quot;: 25, &quot;name&quot;: &quot;222444&quot;, &quot;address&quot;: &quot;sdflkjsdf&quot;, &quot;remark&quot;: &quot;sdfoiu&quot; &#125;, &#123; &quot;id&quot;: 26, &quot;name&quot;: &quot;222444sdf&quot;, &quot;address&quot;: &quot;sdflkjsdf&quot;, &quot;remark&quot;: &quot;sdfoiu&quot; &#125;, &#123; &quot;id&quot;: 27, &quot;name&quot;: &quot;tuyir&quot;, &quot;address&quot;: &quot;sdflkjsdf&quot;, &quot;remark&quot;: &quot;sdfoiu&quot; &#125; ], &quot;firstPage&quot;: 1, &quot;prePage&quot;: 0, &quot;nextPage&quot;: 0, &quot;lastPage&quot;: 1, &quot;isFirstPage&quot;: true, &quot;isLastPage&quot;: true, &quot;hasPreviousPage&quot;: false, &quot;hasNextPage&quot;: false, &quot;navigatePages&quot;: 8, &quot;navigatepageNums&quot;: [ 1 ] &#125;&#125; Name Type Description code String 错误编码 message String 错误描述 Items Object 返回结果 id Long 唯一标识 name String 用户名称 address String 家庭住址 remark String 描述信息","tags":[{"name":"RESTful","slug":"RESTful","permalink":"https://ningyu1.github.io/tags/RESTful/"}]},{"title":"Dubbo本地调试最优方式，本地Server端调用本地Client端","date":"2016-12-20T06:32:41.000Z","path":"20161220/09-dubbo-debug.html","text":"分布式应用的调试总是比常规项目开发调试起来要麻烦很多。我们还在为搞不清自己请求的服务是本地服务还是服务器服务而苦恼吗？我们还在为配置文件被修改导致服务器上版本服务不正常而苦恼吗？接下来我介绍一个Dubbo在多环境调试的最优调试方式，在介绍之前先说一下我们现在的调试方式。 不好的方式（现在的方式）：现在本地调试，需要修改DubboServer.xml和DubboClient.xml配置文件 将文件中的dubbo:registry protocol=&quot;zookeeper&quot; address=&quot;$&#123;dubbo.registry&#125;&quot; /&gt;修改为&lt;dubbo:registry address=&quot;N/A&quot; /&gt; 这种方式的弊端： 开发总是不注意将修改为address=”N/A”的文件提交到svn，在其他环境打包run起来，总是没有Export Service。 文件经常被改来改去容易冲突，冲突解决不好容易丢失配置。 无法很好的将本地调试和各环境的相互依赖分离开 最优的方式： 创建一个properties文件，名字可以随便命名，我命名为：dubbo-local.properties，这个文件可以放在任何地方。该文件不提交到svn，我建议不要放在工程目录里以避免自己提交了都不知道，建议放在用户目录下${user.home}(不知道用户目录的自己去 度娘、谷哥、必硬) dubbo-local.properties文件内容如下： &lt;!--注册中心变量 --&gt;dubbo.registry=N/A &lt;!--以下是你们DubboServer.xml中配置的需要Export Service，这里我建议你有几个要Export Service都配置在这里，后面是请求本地的地址地址格式：dubbo://ip:port，这里需要注意的是，需要修改为自己dubbo服务的端口 --&gt;com.domain.imprest.api.IImprestRecordService=dubbo://localhost:20812com.domain.imprest.api.IImprestRequestService=dubbo://localhost:20812com.domain.imprest.api.IImprestTrackService=dubbo://localhost:20812com.domain.imprest.api.IImprestWriteoffService=dubbo://localhost:20812com.domain.imprest.api.IImprestIOCollectService=dubbo://localhost:20812com.domain.imprest.api.ISystemService=dubbo://localhost:20812com.domain.imprest.api.IImprestDeptService=dubbo://localhost:20812 接下来启动你的Dubbo服务，在启动之前需要添加一下启动参数 dubbo1 参数：-Ddubbo.properties.file值：dubbo-local.properties文件的本地地址，绝对地址 接下来启动你的web服务，在启动之前需要添加一下启动参数 dubbo2 参数：-Ddubbo.resolve.file值：dubbo-local.properties文件的本地地址，绝对地址 ps.当你不想连接本地服务调试时，只需将启动参数去掉即可，无需修改配置文件，让配置文件一直保持清爽干净。以后你就可以安心的本地调试你的程序了，再也不会因为服务没有Export出去、配置文件被修改而焦头烂额。 Dubbo Plugin for Apache JMeterDubbo Plugin for Apache JMeter是用来在Jmeter里更加方便的测试Dubbo接口而开发的插件，马上使用 项目地址github: jmeter-plugin-dubbo &nbsp;&nbsp;&nbsp; 码云: jmeter-plugin-dubbo release star fork license V1.2.2 [ star](https://gitee.com/ningyu/jmeter-plugins-dubbo/badge/star.svg?theme=white)](https://gitee.com/ningyu/jmeter-plugins-dubbo/stargazers)|[![fork](https://gitee.com/ningyu/jmeter-plugins-dubbo/badge/fork.svg?theme=white)](https://gitee.com/ningyu/jmeter-plugins-dubbo/members)|[MIT 相关博文 Dubbo接口如何在Jmeter中测试，自研Dubbo Plugin for Apache JMeter Bug Fix Version V1.1.0, Dubbo Plugin for Apache JMeter New Version V1.2.0, Dubbo Plugin for Apache JMeter","tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://ningyu1.github.io/tags/dubbo/"},{"name":"debug","slug":"debug","permalink":"https://ningyu1.github.io/tags/debug/"},{"name":"rpc","slug":"rpc","permalink":"https://ningyu1.github.io/tags/rpc/"}]},{"title":"分支(branche)开发，主干(trunk)发布","date":"2016-12-20T06:32:41.000Z","path":"20161220/08-svn-trunk-branche.html","text":"主干，分支分开开发模式在使用的时候要注意，主干是不做任何代码修改，只负责merge，修改全在分支上，不管是新功能的开发分支，还是修复bug的分支，如果线上有紧急bug修复，要先容trunk上拉一个bugfix分支出来，修改提交然后在merge到主干上去 ，打包测试发包。 图示： svn1 注意事项：本地修改的代码不要藏在本地 不提交，如果发现没有地方可以提交，提交会影响版本发布，那就是主干、分支开发模式使用不当，请及时调整","tags":[{"name":"SVN","slug":"SVN","permalink":"https://ningyu1.github.io/tags/SVN/"},{"name":"trunk","slug":"trunk","permalink":"https://ningyu1.github.io/tags/trunk/"},{"name":"branche","slug":"branche","permalink":"https://ningyu1.github.io/tags/branche/"}]},{"title":"SVN设置文件忽略的多种方法","date":"2016-11-26T02:30:34.000Z","path":"20161126/10-svn-ignore.html","text":"方法一：在svn客户端（小乌龟），想设置忽略提交.class文件，通过 properties -&gt; New -&gt; Other 添加一个忽略的属性，，还是不行：部分屏蔽了，部分class还是在列表中 svn1 方法二：在svn客户端（小乌龟）：Settings -&gt; General -&gt; Global ignore pattern 添加了一个 *.class就行了 svn2 方法三：在 Eclipse 中点击菜单 window -&gt; Preferences -&gt; Team -&gt; Ignored Resources svn3 点击 Add Pattern… 按钮添加你要忽略的文件或目录 方法四：在Eclipse的导航视图中，选中尚未加入版本控制的文件或目录，右键 -&gt; Team -&gt; 添加至SVN:ignore svn4 svn5 方法五：在资源管理器中，右键一个未加入版本控制文件或目录，并从弹出菜单选择TortoiseSVN -&gt; Add to Ignore List，会出现一个子菜单，允许你仅选择该文件或者所有具有相同后缀的文件。 svn6 如果你想从忽略列表中移除一个或多个条目，右击这些条目，选择TortoiseSVN -&gt; 从忽略列表删除。","tags":[{"name":"SVN","slug":"SVN","permalink":"https://ningyu1.github.io/tags/SVN/"},{"name":"ignore","slug":"ignore","permalink":"https://ningyu1.github.io/tags/ignore/"}]},{"title":"SLF4J和Logback日志框架详解","date":"2015-04-10T02:15:03.000Z","path":"20150410/13-slf4j-logback.html","text":"本文讲述SLF4J和Logback日志框架。 logger1 SLF4J是一套简单的日志外观模式的Java API，帮助在项目部署时对接各种日志实现。LogBack在运行时使用JMX帮助修改日志配置，在生产状态下无需重启应用程序。 SLF4JSLF4J是简单的日志外观模式框架，抽象了各种日志框架例如Logback、Log4j、Commons-logging和JDK自带的logging实现接口。它使得用户可以在部署时使用自己想要的日志框架。SLF4J是轻量级的，在性能方面几乎是零消耗的。 SLF4J没有替代任何日志框架，它仅仅是标准日志框架的外观模式。如果在类路径下除了SLF4J再没有任何日志框架，那么默认状态是在控制台输出日志。 LogbackLogback是Log4j的改进版本，而且原生支持SLF4J（因为是同一作者开发的），因此从其它日志框架如Log4j或JDK的logging迁移到Logback是完全可行的。 由于Logback原生支持SLF4J，因此Logback＋SLF4J的组合是日志框架的最佳选择，比SLF4J+其它日志框架的组合要快一些。而且Logback的配置可以是XML或Groovy代码。 注意一个重要的特性，Logback通过JMX修改日志配置（比如日志级别从Debug调整到INFO），可以从JMX控制台直接操作，无需重启应用程序。 此外，Logback的异常堆栈跟踪的信息，有助于调试。 java.lang.NullPointerException: null at com.fimt.poc.LoggingSample.(LoggingSample.java:16) [classes/:na] at com.fimt.poc.LoggingSample.main(LoggingSample.java:23) [fimt-logging-poc-1.0.jar/:1.0 SLF4J API用法 从org.slf4j包导入Logger和LoggerFactory import org.slf4j.Logger; import org.slf4j.LoggerFactory; 声明日志类 private final Logger logger = LoggerFactory.getLogger(LoggingSample.class); 使用debug、warn、info、error方法并跟踪适合的参数。 所有的方法默认都使用字符串作为输入。logger.info(\"This is sample info statement\"); SLF4J结合Logback在pom.xml包含下面的依赖：它会自动包含所有的依赖包logback-core、slf4j-api……&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.0.7&lt;/version&gt; &lt;/dependency&gt; SLF4J能用于现有的日志框架如Log4j、Commons-logging、java.util.logging(JUL)。 SLF4J结合Log4j在pom.xml包含下面的依赖 &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.2&lt;/version&gt; &lt;/dependency&gt; SLF4J结合JUL (java.util.logging)在pom.xml包含下面的依赖 &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-jdk14&lt;/artifactId&gt; &lt;version&gt;1.7.2&lt;/version&gt; &lt;/dependency&gt;","tags":[{"name":"SLF4J","slug":"SLF4J","permalink":"https://ningyu1.github.io/tags/SLF4J/"},{"name":"Logback","slug":"Logback","permalink":"https://ningyu1.github.io/tags/Logback/"}]},{"title":"Google Guava官方教程（中文版）","date":"2015-03-09T09:34:36.000Z","path":"20150309/14-guava.html","text":"Guava 中文是石榴的意思，该项目是 Google 的一个开源项目，包含许多 Google 核心的 Java 常用库。 引言Guava工程包含了若干被Google的 Java项目广泛依赖 的核心库，例如：集合 [collections] 、缓存 [caching] 、原生类型支持 [primitives support] 、并发库 [concurrency libraries] 、通用注解 [common annotations] 、字符串处理 [string processing] 、I/O 等等。 所有这些工具每天都在被Google的工程师应用在产品服务中。 查阅Javadoc并不一定是学习这些库最有效的方式。在此，我们希望通过此文档为Guava中最流行和最强大的功能，提供更具可读性和解释性的说明。 译文格式说明 Guava中的类被首次引用时，都会链接到Guava的API文档。如：Optional。Guava和JDK中的方法被引用时，一般都会链接到Guava或JDK的API文档，一些人所共知的JDK方法除外。如：Optional.of(T), Map.get(key)。译者对文档的额外说明以斜体显示，并且以“译者注：”开始。 目录1. 基本工具 [Basic utilities]让使用Java语言变得更舒适 使用和避免null：null是模棱两可的，会引起令人困惑的错误，有些时候它让人很不舒服。很多Guava工具类用快速失败拒绝null值，而不是盲目地接受 前置条件: 让方法中的条件检查更简单 常见Object方法: 简化Object方法实现，如hashCode()和toString() 排序: Guava强大的”流畅风格比较器” Throwables：简化了异常和错误的传播与检查 2. 集合[Collections]Guava对JDK集合的扩展，这是Guava最成熟和为人所知的部分 不可变集合: 用不变的集合进行防御性编程和性能提升。 新集合类型: multisets, multimaps, tables, bidirectional maps等 强大的集合工具类: 提供java.util.Collections中没有的集合工具 扩展工具类：让实现和扩展集合类变得更容易，比如创建Collection的装饰器，或实现迭代器 3. 缓存[Caches]Guava Cache：本地缓存实现，支持多种缓存过期策略 4. 函数式风格[Functional idioms]Guava的函数式支持可以显著简化代码，但请谨慎使用它 5. 并发[Concurrency]强大而简单的抽象，让编写正确的并发代码更简单 ListenableFuture：完成后触发回调的Future Service框架：抽象可开启和关闭的服务，帮助你维护服务的状态逻辑 6. 字符串处理[Strings]非常有用的字符串工具，包括分割、连接、填充等操作 7. 原生类型[Primitives]扩展 JDK 未提供的原生类型（如int、char）操作， 包括某些类型的无符号形式 8. 区间[Ranges]可比较类型的区间API，包括连续和离散类型 9. I/O简化I/O尤其是I/O流和文件的操作，针对Java5和6版本 10. 散列[Hash]提供比Object.hashCode()更复杂的散列实现，并提供布鲁姆过滤器的实现 11. 事件总线[EventBus]发布-订阅模式的组件通信，但组件不需要显式地注册到其他组件中 12. 数学运算[Math]优化的、充分测试的数学工具类 13. 反射[Reflection]Guava 的 Java 反射机制工具类 参考: Google Guava官方教程（中文版）","tags":[{"name":"Guava","slug":"Guava","permalink":"https://ningyu1.github.io/tags/Guava/"}]}]